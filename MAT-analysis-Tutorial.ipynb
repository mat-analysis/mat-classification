{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAT-analysis: Analisys and Classification methods for Multiple Aspect Trajectory Data Mining \\[MAT-Tools Framework\\]\n",
    "\n",
    "Sample Code in python notebook to use mat-data as a python library.\n",
    "\n",
    "The present package offers a tool, to support the user in the task of data analysis of multiple aspect trajectories. It integrates into a unique framework for multiple aspects trajectories and in general for multidimensional sequence data mining methods.\n",
    "\n",
    "Created on Dec, 2023\n",
    "Copyright (C) 2023, License GPL Version 3 or superior (see LICENSE file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement mat-analysis (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for mat-analysis\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install mat-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading data\n",
    "To use helpers for data pre-processing, import from package `matdata` (dependency: [mat-data](https://github.com/ttportela/mat-data)):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    a) Lets start by loading Brightkite data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset Brightkite of Multiple Aspect Trajectories\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b15853fcd99407789fee52a7c68e9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Brightkite (Multiple Aspect Trajectories):   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>time</th>\n",
       "      <th>day</th>\n",
       "      <th>poi</th>\n",
       "      <th>tid</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.739154</td>\n",
       "      <td>-104.984703</td>\n",
       "      <td>976</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>717121</td>\n",
       "      <td>3174</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.739154</td>\n",
       "      <td>-104.984703</td>\n",
       "      <td>1229</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>717121</td>\n",
       "      <td>3174</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.739154</td>\n",
       "      <td>-104.984703</td>\n",
       "      <td>1233</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>717121</td>\n",
       "      <td>3174</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.739154</td>\n",
       "      <td>-104.984703</td>\n",
       "      <td>132</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>717121</td>\n",
       "      <td>3174</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.739154</td>\n",
       "      <td>-104.984703</td>\n",
       "      <td>218</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>717121</td>\n",
       "      <td>3174</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39483</th>\n",
       "      <td>33.992514</td>\n",
       "      <td>-117.516439</td>\n",
       "      <td>1159</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>716253</td>\n",
       "      <td>600617</td>\n",
       "      <td>54164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39484</th>\n",
       "      <td>34.206394</td>\n",
       "      <td>-118.224241</td>\n",
       "      <td>1270</td>\n",
       "      <td>Monday</td>\n",
       "      <td>716290</td>\n",
       "      <td>600617</td>\n",
       "      <td>54164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39485</th>\n",
       "      <td>33.992514</td>\n",
       "      <td>-117.516439</td>\n",
       "      <td>79</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>716253</td>\n",
       "      <td>600617</td>\n",
       "      <td>54164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39486</th>\n",
       "      <td>34.106399</td>\n",
       "      <td>-117.593108</td>\n",
       "      <td>79</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>716535</td>\n",
       "      <td>600617</td>\n",
       "      <td>54164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39487</th>\n",
       "      <td>33.992514</td>\n",
       "      <td>-117.516439</td>\n",
       "      <td>190</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>716253</td>\n",
       "      <td>600617</td>\n",
       "      <td>54164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130494 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             lat         lon  time        day     poi     tid  label\n",
       "0      39.739154 -104.984703   976  Wednesday  717121    3174     41\n",
       "1      39.739154 -104.984703  1229  Wednesday  717121    3174     41\n",
       "2      39.739154 -104.984703  1233  Wednesday  717121    3174     41\n",
       "3      39.739154 -104.984703   132   Thursday  717121    3174     41\n",
       "4      39.739154 -104.984703   218   Thursday  717121    3174     41\n",
       "...          ...         ...   ...        ...     ...     ...    ...\n",
       "39483  33.992514 -117.516439  1159     Sunday  716253  600617  54164\n",
       "39484  34.206394 -118.224241  1270     Monday  716290  600617  54164\n",
       "39485  33.992514 -117.516439    79  Wednesday  716253  600617  54164\n",
       "39486  34.106399 -117.593108    79  Wednesday  716535  600617  54164\n",
       "39487  33.992514 -117.516439   190  Wednesday  716253  600617  54164\n",
       "\n",
       "[130494 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matdata.datasets import load_ds\n",
    "\n",
    "dataset='mat.Brightkite'\n",
    "\n",
    "df = load_ds(dataset)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    b) Then stratify only 5 labels to reduce the data, and train/test split respecting class balance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cacd854fd8744cda831eb8b3f06d895b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('Train/Test #TIDs:', 98, 45)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matdata.preprocess import klabels_stratify\n",
    "\n",
    "train, test = klabels_stratify(df, kl=5, outformats=[])\n",
    "\n",
    "'Train/Test #TIDs:', len(train['tid'].unique()), len(test['tid'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, experiment with a classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classification Methods\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Trajectory Based Methods\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.1.1. MARC\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matanalysis.methods import MARC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MARC:] Starting: building neural network for MARC \n",
      "==================================== PARAMS ====================================\n",
      "METRICS_FILE = ./MARC-_results.csv\n",
      "dataset = \n",
      "embedder_size = 100\n",
      "merge_type = concatenate \n",
      "\n",
      "WARNING: File './MARC-_results.csv' not found!\n",
      "\n",
      "###########    DATA PREPARATION      ###########\n",
      "[    INFO    ] 2023-12-17 15:40:56 :: Attribute Lat/Lon: 40-bits value\n",
      "[    INFO    ] 2023-12-17 15:40:56 :: Attribute 'time': 1056 unique values\n",
      "[    INFO    ] 2023-12-17 15:40:56 :: Attribute 'day': 7 unique values\n",
      "[    INFO    ] 2023-12-17 15:40:56 :: Attribute 'poi': 160 unique values\n",
      "[    INFO    ] 2023-12-17 15:40:56 :: Attribute 'space': 150 unique values\n",
      "[    INFO    ] 2023-12-17 15:40:56 :: Total of attribute/value pairs: 1413\n",
      "\u001b[[    INFO    ] 2023-12-17 15:40:56 :: Processing trajectory 143/143. \n",
      "[    INFO    ] 2023-12-17 15:40:56 :: Loading data from files ... DONE!\n",
      "[    INFO    ] 2023-12-17 15:40:56 :: Trajectories:  143\n",
      "[    INFO    ] 2023-12-17 15:40:56 :: Labels:        5\n",
      "[    INFO    ] 2023-12-17 15:40:56 :: Train size:    0.6853146853146853\n",
      "[    INFO    ] 2023-12-17 15:40:56 :: Test size:     0.3146853146853147\n",
      "===================================== MARC =====================================\n",
      "CLASS_DROPOUT = 0.5\n",
      "CLASS_HIDDEN_UNITS = 100\n",
      "CLASS_LRATE = 0.001\n",
      "CLASS_BATCH_SIZE = 64\n",
      "CLASS_EPOCHS = 1000\n",
      "EARLY_STOPPING_PATIENCE = 30\n",
      "BASELINE_METRIC = acc\n",
      "BASELINE_VALUE = 0.5 \n",
      "\n",
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/workdir/programs/mat-analysis-pkg/matanalysis/methods/marc/marc_nn.py:450: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x = [np.asarray(f) for f in x]\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
      "  warnings.warn(\n",
      "2023-12-17 15:40:56.620873: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-12-17 15:40:56.620984: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2023-12-17 15:40:56.982100: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Training Epoch 1 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 15:40:57.759946: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 15:40:57.944049: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 15:40:58.107565: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 15:40:58.768979: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 15:40:58.846113: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/4 [======>.......................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 15:40:59.175370: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 15:40:59.238973: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 32ms/step\n",
      "TRAIN\t\tacc: 0.908163\tacc_top5: 1.000000\tf1_macro: 0.758301\tprec_macro: 0.937995\trec_macro: 0.784615\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "TEST\t\tacc: 0.844444\tacc_top5: 1.000000\tf1_macro: 0.712843\tprec_macro: 0.910000\trec_macro: 0.733333\n",
      "===== Training Epoch 2 =====\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "TRAIN\t\tacc: 0.908163\tacc_top5: 1.000000\tf1_macro: 0.768623\tprec_macro: 0.958140\trec_macro: 0.784615\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "TEST\t\tacc: 0.888889\tacc_top5: 1.000000\tf1_macro: 0.753247\tprec_macro: 0.950000\trec_macro: 0.766667\n",
      "===== Training Epoch 3 =====\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "TRAIN\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.776271\tprec_macro: 0.957576\trec_macro: 0.800000\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "TEST\t\tacc: 0.888889\tacc_top5: 1.000000\tf1_macro: 0.746795\tprec_macro: 0.937500\trec_macro: 0.766667\n",
      "===== Training Epoch 4 =====\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "TRAIN\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.776271\tprec_macro: 0.957576\trec_macro: 0.800000\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "TEST\t\tacc: 0.888889\tacc_top5: 1.000000\tf1_macro: 0.746795\tprec_macro: 0.937500\trec_macro: 0.766667\n",
      "===== Training Epoch 5 =====\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "TRAIN\t\tacc: 0.928571\tacc_top5: 1.000000\tf1_macro: 0.776271\tprec_macro: 0.957576\trec_macro: 0.800000\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "TEST\t\tacc: 0.911111\tacc_top5: 1.000000\tf1_macro: 0.771429\tprec_macro: 0.950000\trec_macro: 0.800000\n",
      "===== Training Epoch 6 =====\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "TRAIN\t\tacc: 0.959184\tacc_top5: 1.000000\tf1_macro: 0.905714\tprec_macro: 0.973333\trec_macro: 0.885714\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "TEST\t\tacc: 0.933333\tacc_top5: 1.000000\tf1_macro: 0.857778\tprec_macro: 0.960000\trec_macro: 0.850000\n",
      "===== Training Epoch 7 =====\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 8 =====\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 9 =====\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 10 =====\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 11 =====\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 12 =====\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 13 =====\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 14 =====\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 15 =====\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 16 =====\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 17 =====\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 18 =====\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 19 =====\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 20 =====\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 21 =====\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 22 =====\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 23 =====\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 24 =====\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 25 =====\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 26 =====\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 27 =====\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 28 =====\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 29 =====\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 30 =====\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 31 =====\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 32 =====\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 33 =====\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 34 =====\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 35 =====\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 36 =====\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "===== Training Epoch 37 =====\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "TEST\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "Processing time: 11879.42 milliseconds. Done.\n",
      "------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = MARC(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>acc_top_K5</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.781158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc  acc_top_K5  balanced_accuracy  precision_macro  recall_macro  \\\n",
       "0  1.0         1.0                1.0              1.0           1.0   \n",
       "\n",
       "   f1_macro      loss  \n",
       "0       1.0  2.781158  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()\n",
    "#result.cls_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.1.2. POI-Sequence (extention of POI-Frequency)\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[POIS:] Starting feature extractor ... \n",
      "Dataset: specific, Feature: time, Sequence: 1\n",
      "Starting NPOI...\n",
      "Dataset: specific, Feature: day, Sequence: 1\n",
      "Starting NPOI...\n",
      "Dataset: specific, Feature: poi, Sequence: 1\n",
      "Starting NPOI...\n",
      "[POIS:] Processing time: 80.124 milliseconds. Done.\n",
      "------------------------------------------------------------------------------------------------\n",
      "[POI-S:] Building Neural Network\n",
      "WARNING: File './POIFREQ-metrics.csv' not found!\n",
      "keep_prob = 0.5\n",
      "HIDDEN_UNITS = 100\n",
      "LEARNING_RATE = 0.001\n",
      "EARLY_STOPPING_PATIENCE = 30\n",
      "BASELINE_METRIC = acc\n",
      "BASELINE_VALUE = 0.5\n",
      "BATCH_SIZE = 64\n",
      "EPOCHS = 250 \n",
      "\n",
      "===== Training Epoch 1 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 15:41:08.748724: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n",
      "TRAIN\t\tacc: 0.520408\tacc_top5: 1.000000\tf1_macro: 0.486296\tprec_macro: 0.503504\trec_macro: 0.516749\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "TEST\t\tacc: 0.177778\tacc_top5: 1.000000\tf1_macro: 0.166708\tprec_macro: 0.169697\trec_macro: 0.176667\n",
      "===== Training Epoch 2 =====\n",
      "1/4 [======>.......................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 15:41:08.938751: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 15:41:09.006987: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 0.816327\tacc_top5: 1.000000\tf1_macro: 0.771764\tprec_macro: 0.758622\trec_macro: 0.797206\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "TEST\t\tacc: 0.266667\tacc_top5: 1.000000\tf1_macro: 0.246333\tprec_macro: 0.251538\trec_macro: 0.256667\n",
      "===== Training Epoch 3 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 0.948980\tacc_top5: 1.000000\tf1_macro: 0.919760\tprec_macro: 0.910317\trec_macro: 0.931358\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "TEST\t\tacc: 0.311111\tacc_top5: 1.000000\tf1_macro: 0.276624\tprec_macro: 0.288034\trec_macro: 0.286667\n",
      "===== Training Epoch 4 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "TEST\t\tacc: 0.311111\tacc_top5: 1.000000\tf1_macro: 0.267349\tprec_macro: 0.279798\trec_macro: 0.266667\n",
      "===== Training Epoch 5 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.355556\tacc_top5: 1.000000\tf1_macro: 0.299451\tprec_macro: 0.309091\trec_macro: 0.296667\n",
      "===== Training Epoch 6 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.422222\tacc_top5: 1.000000\tf1_macro: 0.335629\tprec_macro: 0.337662\trec_macro: 0.336667\n",
      "===== Training Epoch 7 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.444444\tacc_top5: 1.000000\tf1_macro: 0.348406\tprec_macro: 0.348860\trec_macro: 0.353333\n",
      "===== Training Epoch 8 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "TEST\t\tacc: 0.444444\tacc_top5: 1.000000\tf1_macro: 0.331905\tprec_macro: 0.326667\trec_macro: 0.345000\n",
      "===== Training Epoch 9 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.422222\tacc_top5: 1.000000\tf1_macro: 0.318406\tprec_macro: 0.315844\trec_macro: 0.328333\n",
      "===== Training Epoch 10 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.422222\tacc_top5: 1.000000\tf1_macro: 0.318406\tprec_macro: 0.315844\trec_macro: 0.328333\n",
      "===== Training Epoch 11 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "TEST\t\tacc: 0.422222\tacc_top5: 1.000000\tf1_macro: 0.318406\tprec_macro: 0.315844\trec_macro: 0.328333\n",
      "===== Training Epoch 12 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "TEST\t\tacc: 0.422222\tacc_top5: 1.000000\tf1_macro: 0.318406\tprec_macro: 0.315844\trec_macro: 0.328333\n",
      "===== Training Epoch 13 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "TEST\t\tacc: 0.422222\tacc_top5: 1.000000\tf1_macro: 0.318406\tprec_macro: 0.315844\trec_macro: 0.328333\n",
      "===== Training Epoch 14 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "TEST\t\tacc: 0.422222\tacc_top5: 1.000000\tf1_macro: 0.318406\tprec_macro: 0.315844\trec_macro: 0.328333\n",
      "===== Training Epoch 15 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.422222\tacc_top5: 1.000000\tf1_macro: 0.318406\tprec_macro: 0.315844\trec_macro: 0.328333\n",
      "===== Training Epoch 16 =====\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.422222\tacc_top5: 1.000000\tf1_macro: 0.318406\tprec_macro: 0.315844\trec_macro: 0.328333\n",
      "===== Training Epoch 17 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.422222\tacc_top5: 1.000000\tf1_macro: 0.318406\tprec_macro: 0.315844\trec_macro: 0.328333\n",
      "===== Training Epoch 18 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.444444\tacc_top5: 1.000000\tf1_macro: 0.335238\tprec_macro: 0.331111\trec_macro: 0.345000\n",
      "===== Training Epoch 19 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.378639\tprec_macro: 0.377597\trec_macro: 0.383333\n",
      "===== Training Epoch 20 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.378639\tprec_macro: 0.377597\trec_macro: 0.383333\n",
      "===== Training Epoch 21 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.378639\tprec_macro: 0.377597\trec_macro: 0.383333\n",
      "===== Training Epoch 22 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.379002\tprec_macro: 0.377387\trec_macro: 0.383333\n",
      "===== Training Epoch 23 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.379002\tprec_macro: 0.377387\trec_macro: 0.383333\n",
      "===== Training Epoch 24 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.379002\tprec_macro: 0.377387\trec_macro: 0.383333\n",
      "===== Training Epoch 25 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.379002\tprec_macro: 0.377387\trec_macro: 0.383333\n",
      "===== Training Epoch 26 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.379002\tprec_macro: 0.377387\trec_macro: 0.383333\n",
      "===== Training Epoch 27 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.379002\tprec_macro: 0.377387\trec_macro: 0.383333\n",
      "===== Training Epoch 28 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.379002\tprec_macro: 0.377387\trec_macro: 0.383333\n",
      "===== Training Epoch 29 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.379002\tprec_macro: 0.377387\trec_macro: 0.383333\n",
      "===== Training Epoch 30 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.511111\tacc_top5: 1.000000\tf1_macro: 0.392464\tprec_macro: 0.391486\trec_macro: 0.396667\n",
      "===== Training Epoch 31 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.511111\tacc_top5: 1.000000\tf1_macro: 0.392464\tprec_macro: 0.391486\trec_macro: 0.396667\n",
      "===== Training Epoch 32 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.511111\tacc_top5: 1.000000\tf1_macro: 0.392464\tprec_macro: 0.391486\trec_macro: 0.396667\n",
      "===== Training Epoch 33 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.358239\tprec_macro: 0.358387\trec_macro: 0.363333\n",
      "===== Training Epoch 34 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.358239\tprec_macro: 0.358387\trec_macro: 0.363333\n",
      "===== Training Epoch 35 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.358239\tprec_macro: 0.358387\trec_macro: 0.363333\n",
      "===== Training Epoch 36 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.358239\tprec_macro: 0.358387\trec_macro: 0.363333\n",
      "===== Training Epoch 37 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.358239\tprec_macro: 0.358387\trec_macro: 0.363333\n",
      "===== Training Epoch 38 =====\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.358239\tprec_macro: 0.358387\trec_macro: 0.363333\n",
      "===== Training Epoch 39 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.358239\tprec_macro: 0.358387\trec_macro: 0.363333\n",
      "===== Training Epoch 40 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.358239\tprec_macro: 0.358387\trec_macro: 0.363333\n",
      "===== Training Epoch 41 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.358239\tprec_macro: 0.358387\trec_macro: 0.363333\n",
      "===== Training Epoch 42 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.358239\tprec_macro: 0.358387\trec_macro: 0.363333\n",
      "===== Training Epoch 43 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.354542\tprec_macro: 0.352597\trec_macro: 0.363333\n",
      "===== Training Epoch 44 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.354542\tprec_macro: 0.352597\trec_macro: 0.363333\n",
      "===== Training Epoch 45 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.354542\tprec_macro: 0.352597\trec_macro: 0.363333\n",
      "===== Training Epoch 46 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.354542\tprec_macro: 0.352597\trec_macro: 0.363333\n",
      "===== Training Epoch 47 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.354542\tprec_macro: 0.352597\trec_macro: 0.363333\n",
      "===== Training Epoch 48 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.354542\tprec_macro: 0.352597\trec_macro: 0.363333\n",
      "===== Training Epoch 49 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.354542\tprec_macro: 0.352597\trec_macro: 0.363333\n",
      "===== Training Epoch 50 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.354542\tprec_macro: 0.352597\trec_macro: 0.363333\n",
      "===== Training Epoch 51 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.354542\tprec_macro: 0.352597\trec_macro: 0.363333\n",
      "===== Training Epoch 52 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.357374\tprec_macro: 0.361905\trec_macro: 0.363333\n",
      "===== Training Epoch 53 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.357374\tprec_macro: 0.361905\trec_macro: 0.363333\n",
      "===== Training Epoch 54 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.357374\tprec_macro: 0.361905\trec_macro: 0.363333\n",
      "===== Training Epoch 55 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.357374\tprec_macro: 0.361905\trec_macro: 0.363333\n",
      "===== Training Epoch 56 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.488889\tacc_top5: 1.000000\tf1_macro: 0.357374\tprec_macro: 0.361905\trec_macro: 0.363333\n",
      "===== Training Epoch 57 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.511111\tacc_top5: 1.000000\tf1_macro: 0.391169\tprec_macro: 0.393810\trec_macro: 0.396667\n",
      "===== Training Epoch 58 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.511111\tacc_top5: 1.000000\tf1_macro: 0.391169\tprec_macro: 0.393810\trec_macro: 0.396667\n",
      "===== Training Epoch 59 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.511111\tacc_top5: 1.000000\tf1_macro: 0.391169\tprec_macro: 0.393810\trec_macro: 0.396667\n",
      "===== Training Epoch 60 =====\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "TRAIN\t\tacc: 1.000000\tacc_top5: 1.000000\tf1_macro: 1.000000\tprec_macro: 1.000000\trec_macro: 1.000000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "TEST\t\tacc: 0.511111\tacc_top5: 1.000000\tf1_macro: 0.391169\tprec_macro: 0.393810\trec_macro: 0.396667\n",
      "[POI-S:] Processing time: {time_ext} milliseconds. Done.\n",
      "------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from matanalysis.methods import POIS\n",
    "\n",
    "sequences = [1] # Sequence sizes to use, example, for 1, 2 or 3 points use: [1, 2, 3] \n",
    "features = ['time', 'day', 'poi'] # Features to build frequency matrix combined with sequence sizes, by default selects the feature with higher variance\n",
    "# method='npoi' # you can pass the extract method\n",
    "\n",
    "result = POIS(train, test, sequences, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>acc_top_K5</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.511111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.39381</td>\n",
       "      <td>0.396667</td>\n",
       "      <td>0.391169</td>\n",
       "      <td>1.40576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc  acc_top_K5 balanced_accuracy  precision_macro  recall_macro  \\\n",
       "0  0.511111         1.0              None          0.39381      0.396667   \n",
       "\n",
       "   f1_macro     loss  \n",
       "0  0.391169  1.40576  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use just the feature extractor, you can check `poifreq` submodule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[POIS:] Starting feature extractor ... \n",
      "Dataset: specific, Feature: poi, Sequence: 1\n",
      "Starting NPOI...\n",
      "[POIS:] Processing time: 23.630000000000003 milliseconds. Done.\n",
      "------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>301</th>\n",
       "      <th>302</th>\n",
       "      <th>303</th>\n",
       "      <th>304</th>\n",
       "      <th>305</th>\n",
       "      <th>306</th>\n",
       "      <th>307</th>\n",
       "      <th>308</th>\n",
       "      <th>309</th>\n",
       "      <th>310</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows Ã— 311 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2     3     4     5     6     7     8     9    ...  301  302  \\\n",
       "0   0.02  0.06  0.12  0.02  0.02  0.02  0.02  0.04  0.02  0.02  ...  0.0  0.0   \n",
       "1   0.00  0.12  0.08  0.00  0.00  0.00  0.00  0.02  0.00  0.04  ...  0.0  0.0   \n",
       "2   0.00  0.12  0.08  0.00  0.00  0.00  0.00  0.02  0.02  0.00  ...  0.0  0.0   \n",
       "3   0.02  0.14  0.06  0.00  0.00  0.00  0.02  0.00  0.00  0.02  ...  0.0  0.0   \n",
       "4   0.00  0.10  0.16  0.00  0.00  0.00  0.02  0.04  0.00  0.00  ...  0.0  0.0   \n",
       "..   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...  ...  ...   \n",
       "65  0.00  0.14  0.08  0.00  0.00  0.00  0.06  0.02  0.00  0.00  ...  0.0  0.0   \n",
       "66  0.00  0.16  0.08  0.00  0.00  0.00  0.04  0.00  0.00  0.02  ...  0.0  0.0   \n",
       "67  0.02  0.18  0.06  0.00  0.00  0.00  0.00  0.00  0.00  0.04  ...  0.0  0.0   \n",
       "68  0.00  0.04  0.08  0.00  0.00  0.00  0.02  0.00  0.00  0.04  ...  0.0  0.0   \n",
       "69  0.02  0.14  0.08  0.00  0.00  0.04  0.00  0.00  0.02  0.02  ...  0.0  0.0   \n",
       "\n",
       "    303   304  305  306  307  308   309   310  \n",
       "0   0.0  0.00  0.0  0.0  0.0  0.0  0.00  0.00  \n",
       "1   0.0  0.00  0.0  0.0  0.0  0.0  0.00  0.00  \n",
       "2   0.0  0.00  0.0  0.0  0.0  0.0  0.00  0.00  \n",
       "3   0.0  0.00  0.0  0.0  0.0  0.0  0.00  0.00  \n",
       "4   0.0  0.00  0.0  0.0  0.0  0.0  0.00  0.00  \n",
       "..  ...   ...  ...  ...  ...  ...   ...   ...  \n",
       "65  0.0  0.00  0.0  0.0  0.0  0.0  0.02  0.00  \n",
       "66  0.0  0.00  0.0  0.0  0.0  0.0  0.00  0.00  \n",
       "67  0.0  0.00  0.0  0.0  0.0  0.0  0.00  0.02  \n",
       "68  0.0  0.02  0.0  0.0  0.0  0.0  0.00  0.00  \n",
       "69  0.0  0.00  0.0  0.0  0.0  0.0  0.00  0.00  \n",
       "\n",
       "[70 rows x 311 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matanalysis.methods.pois.poifreq import pois\n",
    "\n",
    "method='npoi' # default: 'npoi', or, 'poi' and 'wnpoi'\n",
    "\n",
    "x_train, x_test, y_train, y_test, _ = pois(train, test, sequences, features, method)\n",
    "\n",
    "display(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then you can use the `pois_model` to create the classifier. Import from:\n",
    "```\n",
    "from matanalysis.methods.pois.model_poifreq import pois_model`\n",
    "pois_model(x_train, x_test, y_train, y_test)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.1.3. DeepestST\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matanalysis.methods import DeepestST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###########    DATA PREPARATION      ###########\n",
      "\n",
      "Creating a virtual grid without polygons\n",
      "...cell size by degree: 0.0002706929603721246\n",
      "...grid_size_lat_y:358586\n",
      "...grid_size_lon_x:1221516\n",
      "...A virtual grid was created\n",
      "\n",
      "Creating or updating index of the grid feature..\n",
      "\n",
      "...[1419,1419] indexes were created to lat and lon\n",
      "\n",
      "Creating or updating index of the grid feature..\n",
      "\n",
      "...[664,664] indexes were created to lat and lon\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e530e2a738406393ac6de139e65fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute 'time': 704 unique values\n",
      "Attribute 'day': 7 unique values\n",
      "Attribute 'poi': 113 unique values\n",
      "Attribute 'tid': 71 unique values\n",
      "Attribute 'index_grid': 105 unique values\n",
      "Total of attribute/value pairs: 1000\n",
      "\n",
      "\n",
      "###########      DATA ENCODING        ###########\n",
      "\n",
      "Input total: 3\n",
      "... tid_0: 71\n",
      "... tid_1: 27\n",
      "... tid_2: 45\n",
      "col_name: ['time', 'day', 'poi', 'tid', 'label', 'index_grid']...\n",
      "... num_classes: 5\n",
      "... max_lenght: 37\n",
      "Removing column tid of attr\n",
      "Removing column label of attr\n",
      "\n",
      "\n",
      "#####   Encoding string data to integer   ######\n",
      "   Encoding: time\n",
      "   Encoding: day\n",
      "   Encoding: poi\n",
      "   Encoding: index_grid\n",
      "\n",
      "\n",
      "###########      Generating y_train and y_test     ###########\n",
      "OneHot encoding on label y\n",
      "Input total: 3\n",
      "\n",
      "[DEEPEST:] Building DeepestST Model\n",
      "[DEEPEST:] Starting model training, 100 iterations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3621cb238fe44a9950663e15a50cee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[DEEPEST:] Model Training:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8143d6d69bf0406fa17d1014dc323925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 12:18:46.641163: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 12:18:46.881514: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 12:18:46.892442: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 12:18:47.099518: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 12:18:47.113380: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 65.3189 - acc: 0.1408 - top_k_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 12:18:48.315479: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 12:18:48.416445: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 12:18:48.423655: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 1s/step - loss: 65.3189 - acc: 0.1408 - top_k_categorical_accuracy: 1.0000 - val_loss: 62.3059 - val_acc: 0.4444 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 62.1548 - acc: 0.3099 - top_k_categorical_accuracy: 1.0000 - val_loss: 59.2633 - val_acc: 0.4444 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 59.0998 - acc: 0.4648 - top_k_categorical_accuracy: 1.0000 - val_loss: 56.3357 - val_acc: 0.3333 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 56.1731 - acc: 0.4366 - top_k_categorical_accuracy: 1.0000 - val_loss: 53.5216 - val_acc: 0.3333 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 53.3679 - acc: 0.4366 - top_k_categorical_accuracy: 1.0000 - val_loss: 50.8198 - val_acc: 0.3333 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 50.6602 - acc: 0.4507 - top_k_categorical_accuracy: 1.0000 - val_loss: 48.2175 - val_acc: 0.3333 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 48.0488 - acc: 0.4507 - top_k_categorical_accuracy: 1.0000 - val_loss: 45.7166 - val_acc: 0.3333 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 45.5593 - acc: 0.4225 - top_k_categorical_accuracy: 1.0000 - val_loss: 43.3152 - val_acc: 0.3333 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 43.1646 - acc: 0.4507 - top_k_categorical_accuracy: 1.0000 - val_loss: 41.0050 - val_acc: 0.3333 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 40.8331 - acc: 0.4085 - top_k_categorical_accuracy: 1.0000 - val_loss: 38.7882 - val_acc: 0.3333 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 38.6280 - acc: 0.4225 - top_k_categorical_accuracy: 1.0000 - val_loss: 36.6576 - val_acc: 0.3333 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 36.4683 - acc: 0.5352 - top_k_categorical_accuracy: 1.0000 - val_loss: 34.6170 - val_acc: 0.3333 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 34.4436 - acc: 0.4507 - top_k_categorical_accuracy: 1.0000 - val_loss: 32.6657 - val_acc: 0.3333 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 32.4849 - acc: 0.5211 - top_k_categorical_accuracy: 1.0000 - val_loss: 30.7920 - val_acc: 0.4815 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 30.6175 - acc: 0.5211 - top_k_categorical_accuracy: 1.0000 - val_loss: 28.9938 - val_acc: 0.4815 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 28.7933 - acc: 0.5775 - top_k_categorical_accuracy: 1.0000 - val_loss: 27.2664 - val_acc: 0.5185 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 27.0842 - acc: 0.6338 - top_k_categorical_accuracy: 1.0000 - val_loss: 25.6128 - val_acc: 0.5556 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 25.4111 - acc: 0.6901 - top_k_categorical_accuracy: 1.0000 - val_loss: 24.0321 - val_acc: 0.6296 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 23.8343 - acc: 0.7324 - top_k_categorical_accuracy: 1.0000 - val_loss: 22.5145 - val_acc: 0.7037 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 22.3091 - acc: 0.7887 - top_k_categorical_accuracy: 1.0000 - val_loss: 21.0709 - val_acc: 0.7407 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 20.8683 - acc: 0.8169 - top_k_categorical_accuracy: 1.0000 - val_loss: 19.6990 - val_acc: 0.7407 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 19.4791 - acc: 0.8310 - top_k_categorical_accuracy: 1.0000 - val_loss: 18.3903 - val_acc: 0.7778 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 18.1569 - acc: 0.8873 - top_k_categorical_accuracy: 1.0000 - val_loss: 17.1482 - val_acc: 0.8889 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 16.9311 - acc: 0.8873 - top_k_categorical_accuracy: 1.0000 - val_loss: 15.9601 - val_acc: 0.9259 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 15.7343 - acc: 0.9155 - top_k_categorical_accuracy: 1.0000 - val_loss: 14.8463 - val_acc: 0.9259 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 14.6353 - acc: 0.9577 - top_k_categorical_accuracy: 1.0000 - val_loss: 13.7976 - val_acc: 0.9259 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 13.5732 - acc: 0.9437 - top_k_categorical_accuracy: 1.0000 - val_loss: 12.8003 - val_acc: 0.9259 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 12.5863 - acc: 0.9859 - top_k_categorical_accuracy: 1.0000 - val_loss: 11.8588 - val_acc: 0.9259 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 11.6544 - acc: 0.9859 - top_k_categorical_accuracy: 1.0000 - val_loss: 10.9860 - val_acc: 0.9630 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 10.7896 - acc: 0.9718 - top_k_categorical_accuracy: 1.0000 - val_loss: 10.1614 - val_acc: 0.9630 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 9.9789 - acc: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 9.3883 - val_acc: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 9.2336 - acc: 0.9859 - top_k_categorical_accuracy: 1.0000 - val_loss: 8.6716 - val_acc: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 8.5081 - acc: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 8.0053 - val_acc: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 7.8564 - acc: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 7.3822 - val_acc: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 7.2477 - acc: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.8015 - val_acc: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 6.6732 - acc: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.2610 - val_acc: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 6.1351 - acc: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.7571 - val_acc: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 5.6390 - acc: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.2918 - val_acc: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 5.1820 - acc: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.8666 - val_acc: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 4.7660 - acc: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.4677 - val_acc: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 4.3759 - acc: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.0990 - val_acc: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 4.0131 - acc: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.7600 - val_acc: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 3.6727 - acc: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.4453 - val_acc: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 3.3656 - acc: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.1560 - val_acc: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 3.0870 - acc: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.8896 - val_acc: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 2.8158 - acc: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6484 - val_acc: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 47/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mDeepestST\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workdir/programs/mat-analysis-pkg/matanalysis/methods/deepest/DeepestST.py:195\u001b[0m, in \u001b[0;36mDeepestST\u001b[0;34m(df_train, df_test, res_path, prefix, save_results, n_jobs, random_state, rounds, label_poi, y_one_hot_encodding, geohash, geo_precision)\u001b[0m\n\u001b[1;32m    180\u001b[0m             pbar\u001b[38;5;241m.\u001b[39mset_postfix_str(print_params(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnn, un, mt, dp_bf, dp_af, em_s, bs, epoch, pat, mon, opt, lr, ls, y_ohe, features\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    181\u001b[0m                                              nn, un, mt, dp_bf, dp_af, em_s, bs, epoch, pat, mon, opt, lr, ls, y_ohe, features))\n\u001b[1;32m    185\u001b[0m             deepest \u001b[38;5;241m=\u001b[39m DST\u001b[38;5;241m.\u001b[39mDeepeST(max_lenght\u001b[38;5;241m=\u001b[39mmax_lenght,\n\u001b[1;32m    186\u001b[0m                         num_classes\u001b[38;5;241m=\u001b[39mnum_classes,\n\u001b[1;32m    187\u001b[0m                         vocab_size \u001b[38;5;241m=\u001b[39m vocab_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    192\u001b[0m                         dropout_after_rnn\u001b[38;5;241m=\u001b[39mdp_af,\n\u001b[1;32m    193\u001b[0m                         embedding_size \u001b[38;5;241m=\u001b[39m em_s)\n\u001b[0;32m--> 195\u001b[0m             \u001b[43mdeepest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m                        \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m                        \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmin_delta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;43;03m#                        baseline=0.5,\u001b[39;49;00m\n\u001b[1;32m    206\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# By Tarlis\u001b[39;49;00m\n\u001b[1;32m    207\u001b[0m \u001b[43m                        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mnew_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m                        \u001b[49m\u001b[43msave_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmodelname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m                        \u001b[49m\u001b[43msave_best_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m                        \u001b[49m\u001b[43msave_weights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mloss_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mls_p\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m             validation_report, y_pred \u001b[38;5;241m=\u001b[39m deepest\u001b[38;5;241m.\u001b[39mpredict(X_val, y_val)\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m save_results:\n",
      "File \u001b[0;32m~/workdir/programs/mat-analysis-pkg/matanalysis/methods/_lib/pymove/models/classification/DeepestST.py:204\u001b[0m, in \u001b[0;36mDeepeST.fit\u001b[0;34m(self, X_train, y_train, X_val, y_val, batch_size, epochs, monitor, min_delta, patience, verbose, baseline, optimizer, learning_rate, mode, new_metrics, save_model, modelname, save_best_only, save_weights_only, log_dir, loss, loss_parameters)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 my_callbacks\u001b[38;5;241m=\u001b[39m [early_stop]    \n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m#            print('... Starting training')\u001b[39;00m\n\u001b[0;32m--> 204\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmy_callbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result = DeepestST(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresult\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.1.4. Trajectory Random Forrest (TRF)\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matanalysis.methods import TRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###########    DATA PREPARATION      ###########\n",
      "\n",
      "Creating a virtual grid without polygons\n",
      "...cell size by degree: 0.0002706929603721246\n",
      "...grid_size_lat_y:358586\n",
      "...grid_size_lon_x:1221516\n",
      "...A virtual grid was created\n",
      "\n",
      "Creating or updating index of the grid feature..\n",
      "\n",
      "...[1419,1419] indexes were created to lat and lon\n",
      "\n",
      "Creating or updating index of the grid feature..\n",
      "\n",
      "...[664,664] indexes were created to lat and lon\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb80f53d73043dda97f21dcb07239d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute 'time': 704 unique values\n",
      "Attribute 'day': 7 unique values\n",
      "Attribute 'poi': 113 unique values\n",
      "Attribute 'tid': 71 unique values\n",
      "Attribute 'index_grid': 105 unique values\n",
      "Total of attribute/value pairs: 1000\n",
      "\n",
      "\n",
      "###########      DATA ENCODING        ###########\n",
      "Checking sets split count (train, <validation>, test):\n",
      "   TIDs_0: 71\n",
      "   TIDs_1: 27\n",
      "   TIDs_2: 45\n",
      "Encoding string data to integer\n",
      "   Encoding: time\n",
      "   Encoding: day\n",
      "   Encoding: poi\n",
      "   Encoding: index_grid\n",
      "Label encoding on label y\n",
      "\n",
      "[TRF:] Building Random Forrest Model\n",
      "[TRF:] Starting model training, 1080 iterations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d75f33c9488e4dc3907008a8db8f973a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[TRF:] Model Training:   0%|          | 0/1080 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRF:] Filename: ./TRF-/eval_randomforest-200-20-2-1-sqrt-True-['time', 'day', 'poi', 'tid', 'label', 'index_grid'].csv.\n",
      "[TRF:] Creating a model to test set\n",
      "[TRF:] Parameters: \n",
      "\tn_estimators: 200. \n",
      "\tmax_depth: 20. \n",
      "\tmin_samples_split: 2. \n",
      "\tmin_samples_leaf: 1. \n",
      "\tmax_features: sqrt. \n",
      "\tbootstrap: True. \n",
      "\tfeatures: ['time', 'day', 'poi', 'tid', 'label', 'index_grid'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b66a5468a8141818685e3b59dc0cdcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Model Testing:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRF:] Processing time: 575753.061 milliseconds. Done.\n"
     ]
    }
   ],
   "source": [
    "result = TRF(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>acc_top_K5</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.977778</td>\n",
       "      <td>0</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.985103</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc  acc_top_K5  balanced_accuracy  precision_macro  recall_macro  \\\n",
       "0  0.977778           0           0.986667         0.984615      0.986667   \n",
       "\n",
       "   f1_macro  loss  \n",
       "0  0.985103  None  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.1.5. Trajectory XGBoost (TXGB)\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matanalysis.methods import TXGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###########    DATA PREPARATION      ###########\n",
      "\n",
      "Creating a virtual grid without polygons\n",
      "...cell size by degree: 0.0002706929603721246\n",
      "...grid_size_lat_y:358586\n",
      "...grid_size_lon_x:1221516\n",
      "...A virtual grid was created\n",
      "\n",
      "Creating or updating index of the grid feature..\n",
      "\n",
      "...[1419,1419] indexes were created to lat and lon\n",
      "\n",
      "Creating or updating index of the grid feature..\n",
      "\n",
      "...[664,664] indexes were created to lat and lon\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c85600de8b444d69b3bdbcfac86492f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute 'time': 704 unique values\n",
      "Attribute 'day': 7 unique values\n",
      "Attribute 'poi': 113 unique values\n",
      "Attribute 'tid': 71 unique values\n",
      "Attribute 'index_grid': 105 unique values\n",
      "Total of attribute/value pairs: 1000\n",
      "\n",
      "\n",
      "###########      DATA ENCODING        ###########\n",
      "Checking sets split count (train, <validation>, test):\n",
      "   TIDs_0: 71\n",
      "   TIDs_1: 27\n",
      "   TIDs_2: 45\n",
      "Encoding string data to integer\n",
      "   Encoding: time\n",
      "   Encoding: day\n",
      "   Encoding: poi\n",
      "   Encoding: index_grid\n",
      "Label encoding on label y\n",
      "\n",
      "[TXGB:] Building XGBoost Model\n",
      "[TXGB:] Starting model training, 96 iterations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39940cfb8c4f41a9b9ba19cf12bdabef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[TXGB:] Model Training:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:52:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:52:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:52:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:52:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:52:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:52:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:52:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:52:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:52:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:52:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:52:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:52:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:52:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:52:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:52:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:52:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:52:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:52:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:52:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:52:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:00] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:00] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:05] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:05] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:05] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:05] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:06] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:06] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:06] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:06] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:07] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:07] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:08] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:08] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:08] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:08] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:10] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:10] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:10] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:10] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:11] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:11] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:11] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:13] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:13] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:13] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:13] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:15] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:15] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:15] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:15] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:15] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:53:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[TXGB:] Filename: ./TXGB-/eval_xgboost-2000-5-0.01-0.0-0.8-0.7-1.0-100-mlogloss-20-['time', 'day', 'poi', 'tid', 'label', 'index_grid'].csv.\n",
      "[TXGB:] Creating a model to test set\n",
      "[TXGB:] Parameters: ne_2000_md_5_lr_0.01_gm_0.0_ss_0.8_cst_0.7_l1_1.0_l2_100_loss_mlogloss_epch_20_features_['time', 'day', 'poi', 'tid', 'label', 'index_grid']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380124efb6464928924dcc5c56ca54c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Model Testing:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-mlogloss:1.59123\tvalidation_1-mlogloss:1.59516\n",
      "[1]\tvalidation_0-mlogloss:1.57218\tvalidation_1-mlogloss:1.57917\n",
      "[2]\tvalidation_0-mlogloss:1.55485\tvalidation_1-mlogloss:1.56605\n",
      "[3]\tvalidation_0-mlogloss:1.53768\tvalidation_1-mlogloss:1.55254\n",
      "[4]\tvalidation_0-mlogloss:1.51977\tvalidation_1-mlogloss:1.53633\n",
      "[5]\tvalidation_0-mlogloss:1.50312\tvalidation_1-mlogloss:1.52263\n",
      "[6]\tvalidation_0-mlogloss:1.48919\tvalidation_1-mlogloss:1.51134\n",
      "[7]\tvalidation_0-mlogloss:1.47215\tvalidation_1-mlogloss:1.49614\n",
      "[8]\tvalidation_0-mlogloss:1.45529\tvalidation_1-mlogloss:1.48100\n",
      "[9]\tvalidation_0-mlogloss:1.43873\tvalidation_1-mlogloss:1.46716\n",
      "[10]\tvalidation_0-mlogloss:1.42296\tvalidation_1-mlogloss:1.45594\n",
      "[11]\tvalidation_0-mlogloss:1.40731\tvalidation_1-mlogloss:1.44217\n",
      "[12]\tvalidation_0-mlogloss:1.39359\tvalidation_1-mlogloss:1.43111\n",
      "[13]\tvalidation_0-mlogloss:1.38022\tvalidation_1-mlogloss:1.41997\n",
      "[14]\tvalidation_0-mlogloss:1.36596\tvalidation_1-mlogloss:1.41003\n",
      "[15]\tvalidation_0-mlogloss:1.35095\tvalidation_1-mlogloss:1.39803\n",
      "[16]\tvalidation_0-mlogloss:1.33850\tvalidation_1-mlogloss:1.38744\n",
      "[17]\tvalidation_0-mlogloss:1.32565\tvalidation_1-mlogloss:1.37721\n",
      "[18]\tvalidation_0-mlogloss:1.31233\tvalidation_1-mlogloss:1.36657\n",
      "[19]\tvalidation_0-mlogloss:1.29855\tvalidation_1-mlogloss:1.35606\n",
      "[20]\tvalidation_0-mlogloss:1.28505\tvalidation_1-mlogloss:1.34464\n",
      "[21]\tvalidation_0-mlogloss:1.27204\tvalidation_1-mlogloss:1.33396\n",
      "[22]\tvalidation_0-mlogloss:1.25966\tvalidation_1-mlogloss:1.32477\n",
      "[23]\tvalidation_0-mlogloss:1.24746\tvalidation_1-mlogloss:1.31431\n",
      "[24]\tvalidation_0-mlogloss:1.23431\tvalidation_1-mlogloss:1.30314\n",
      "[25]\tvalidation_0-mlogloss:1.22090\tvalidation_1-mlogloss:1.29095\n",
      "[26]\tvalidation_0-mlogloss:1.20867\tvalidation_1-mlogloss:1.28097\n",
      "[27]\tvalidation_0-mlogloss:1.19630\tvalidation_1-mlogloss:1.26943\n",
      "[28]\tvalidation_0-mlogloss:1.18400\tvalidation_1-mlogloss:1.26081\n",
      "[29]\tvalidation_0-mlogloss:1.17204\tvalidation_1-mlogloss:1.25178\n",
      "[30]\tvalidation_0-mlogloss:1.16009\tvalidation_1-mlogloss:1.24066\n",
      "[31]\tvalidation_0-mlogloss:1.14841\tvalidation_1-mlogloss:1.23148\n",
      "[32]\tvalidation_0-mlogloss:1.13691\tvalidation_1-mlogloss:1.22336\n",
      "[33]\tvalidation_0-mlogloss:1.12588\tvalidation_1-mlogloss:1.21512\n",
      "[34]\tvalidation_0-mlogloss:1.11429\tvalidation_1-mlogloss:1.20472\n",
      "[35]\tvalidation_0-mlogloss:1.10325\tvalidation_1-mlogloss:1.19563\n",
      "[36]\tvalidation_0-mlogloss:1.09247\tvalidation_1-mlogloss:1.18679\n",
      "[37]\tvalidation_0-mlogloss:1.08184\tvalidation_1-mlogloss:1.17764\n",
      "[38]\tvalidation_0-mlogloss:1.07132\tvalidation_1-mlogloss:1.16888\n",
      "[39]\tvalidation_0-mlogloss:1.06063\tvalidation_1-mlogloss:1.16039\n",
      "[40]\tvalidation_0-mlogloss:1.05088\tvalidation_1-mlogloss:1.15286\n",
      "[41]\tvalidation_0-mlogloss:1.04114\tvalidation_1-mlogloss:1.14530\n",
      "[42]\tvalidation_0-mlogloss:1.03181\tvalidation_1-mlogloss:1.13773\n",
      "[43]\tvalidation_0-mlogloss:1.02228\tvalidation_1-mlogloss:1.13042\n",
      "[44]\tvalidation_0-mlogloss:1.01239\tvalidation_1-mlogloss:1.12345\n",
      "[45]\tvalidation_0-mlogloss:1.00242\tvalidation_1-mlogloss:1.11539\n",
      "[46]\tvalidation_0-mlogloss:0.99268\tvalidation_1-mlogloss:1.10639\n",
      "[47]\tvalidation_0-mlogloss:0.98303\tvalidation_1-mlogloss:1.09796\n",
      "[48]\tvalidation_0-mlogloss:0.97396\tvalidation_1-mlogloss:1.09078\n",
      "[49]\tvalidation_0-mlogloss:0.96492\tvalidation_1-mlogloss:1.08452\n",
      "[50]\tvalidation_0-mlogloss:0.95591\tvalidation_1-mlogloss:1.07768\n",
      "[51]\tvalidation_0-mlogloss:0.94759\tvalidation_1-mlogloss:1.07166\n",
      "[52]\tvalidation_0-mlogloss:0.93827\tvalidation_1-mlogloss:1.06289\n",
      "[53]\tvalidation_0-mlogloss:0.92955\tvalidation_1-mlogloss:1.05708\n",
      "[54]\tvalidation_0-mlogloss:0.92151\tvalidation_1-mlogloss:1.05083\n",
      "[55]\tvalidation_0-mlogloss:0.91258\tvalidation_1-mlogloss:1.04324\n",
      "[56]\tvalidation_0-mlogloss:0.90397\tvalidation_1-mlogloss:1.03692\n",
      "[57]\tvalidation_0-mlogloss:0.89544\tvalidation_1-mlogloss:1.03010\n",
      "[58]\tvalidation_0-mlogloss:0.88673\tvalidation_1-mlogloss:1.02267\n",
      "[59]\tvalidation_0-mlogloss:0.87879\tvalidation_1-mlogloss:1.01656\n",
      "[60]\tvalidation_0-mlogloss:0.87120\tvalidation_1-mlogloss:1.01120\n",
      "[61]\tvalidation_0-mlogloss:0.86325\tvalidation_1-mlogloss:1.00496\n",
      "[62]\tvalidation_0-mlogloss:0.85544\tvalidation_1-mlogloss:0.99852\n",
      "[63]\tvalidation_0-mlogloss:0.84741\tvalidation_1-mlogloss:0.99314\n",
      "[64]\tvalidation_0-mlogloss:0.83942\tvalidation_1-mlogloss:0.98739\n",
      "[65]\tvalidation_0-mlogloss:0.83184\tvalidation_1-mlogloss:0.98154\n",
      "[66]\tvalidation_0-mlogloss:0.82495\tvalidation_1-mlogloss:0.97677\n",
      "[67]\tvalidation_0-mlogloss:0.81724\tvalidation_1-mlogloss:0.96970\n",
      "[68]\tvalidation_0-mlogloss:0.80970\tvalidation_1-mlogloss:0.96261\n",
      "[69]\tvalidation_0-mlogloss:0.80299\tvalidation_1-mlogloss:0.95875\n",
      "[70]\tvalidation_0-mlogloss:0.79600\tvalidation_1-mlogloss:0.95336\n",
      "[71]\tvalidation_0-mlogloss:0.78885\tvalidation_1-mlogloss:0.94683\n",
      "[72]\tvalidation_0-mlogloss:0.78163\tvalidation_1-mlogloss:0.94108\n",
      "[73]\tvalidation_0-mlogloss:0.77436\tvalidation_1-mlogloss:0.93509\n",
      "[74]\tvalidation_0-mlogloss:0.76736\tvalidation_1-mlogloss:0.92944\n",
      "[75]\tvalidation_0-mlogloss:0.76047\tvalidation_1-mlogloss:0.92406\n",
      "[76]\tvalidation_0-mlogloss:0.75342\tvalidation_1-mlogloss:0.91701\n",
      "[77]\tvalidation_0-mlogloss:0.74643\tvalidation_1-mlogloss:0.91120\n",
      "[78]\tvalidation_0-mlogloss:0.73969\tvalidation_1-mlogloss:0.90490\n",
      "[79]\tvalidation_0-mlogloss:0.73289\tvalidation_1-mlogloss:0.89917\n",
      "[80]\tvalidation_0-mlogloss:0.72649\tvalidation_1-mlogloss:0.89266\n",
      "[81]\tvalidation_0-mlogloss:0.72002\tvalidation_1-mlogloss:0.88800\n",
      "[82]\tvalidation_0-mlogloss:0.71357\tvalidation_1-mlogloss:0.88229\n",
      "[83]\tvalidation_0-mlogloss:0.70729\tvalidation_1-mlogloss:0.87693\n",
      "[84]\tvalidation_0-mlogloss:0.70063\tvalidation_1-mlogloss:0.87016\n",
      "[85]\tvalidation_0-mlogloss:0.69465\tvalidation_1-mlogloss:0.86586\n",
      "[86]\tvalidation_0-mlogloss:0.68840\tvalidation_1-mlogloss:0.86086\n",
      "[87]\tvalidation_0-mlogloss:0.68208\tvalidation_1-mlogloss:0.85468\n",
      "[88]\tvalidation_0-mlogloss:0.67605\tvalidation_1-mlogloss:0.85003\n",
      "[89]\tvalidation_0-mlogloss:0.67010\tvalidation_1-mlogloss:0.84412\n",
      "[90]\tvalidation_0-mlogloss:0.66381\tvalidation_1-mlogloss:0.83867\n",
      "[91]\tvalidation_0-mlogloss:0.65809\tvalidation_1-mlogloss:0.83388\n",
      "[92]\tvalidation_0-mlogloss:0.65195\tvalidation_1-mlogloss:0.82765\n",
      "[93]\tvalidation_0-mlogloss:0.64640\tvalidation_1-mlogloss:0.82286\n",
      "[94]\tvalidation_0-mlogloss:0.64058\tvalidation_1-mlogloss:0.81797\n",
      "[95]\tvalidation_0-mlogloss:0.63494\tvalidation_1-mlogloss:0.81291\n",
      "[96]\tvalidation_0-mlogloss:0.62937\tvalidation_1-mlogloss:0.80897\n",
      "[97]\tvalidation_0-mlogloss:0.62394\tvalidation_1-mlogloss:0.80403\n",
      "[98]\tvalidation_0-mlogloss:0.61868\tvalidation_1-mlogloss:0.79918\n",
      "[99]\tvalidation_0-mlogloss:0.61314\tvalidation_1-mlogloss:0.79449\n",
      "[100]\tvalidation_0-mlogloss:0.60799\tvalidation_1-mlogloss:0.79037\n",
      "[101]\tvalidation_0-mlogloss:0.60276\tvalidation_1-mlogloss:0.78652\n",
      "[102]\tvalidation_0-mlogloss:0.59743\tvalidation_1-mlogloss:0.78143\n",
      "[103]\tvalidation_0-mlogloss:0.59226\tvalidation_1-mlogloss:0.77704\n",
      "[104]\tvalidation_0-mlogloss:0.58711\tvalidation_1-mlogloss:0.77298\n",
      "[105]\tvalidation_0-mlogloss:0.58199\tvalidation_1-mlogloss:0.76812\n",
      "[106]\tvalidation_0-mlogloss:0.57709\tvalidation_1-mlogloss:0.76372\n",
      "[107]\tvalidation_0-mlogloss:0.57200\tvalidation_1-mlogloss:0.76024\n",
      "[108]\tvalidation_0-mlogloss:0.56685\tvalidation_1-mlogloss:0.75514\n",
      "[109]\tvalidation_0-mlogloss:0.56199\tvalidation_1-mlogloss:0.75083\n",
      "[110]\tvalidation_0-mlogloss:0.55692\tvalidation_1-mlogloss:0.74551\n",
      "[111]\tvalidation_0-mlogloss:0.55212\tvalidation_1-mlogloss:0.74178\n",
      "[112]\tvalidation_0-mlogloss:0.54756\tvalidation_1-mlogloss:0.73836\n",
      "[113]\tvalidation_0-mlogloss:0.54284\tvalidation_1-mlogloss:0.73383\n",
      "[114]\tvalidation_0-mlogloss:0.53803\tvalidation_1-mlogloss:0.72913\n",
      "[115]\tvalidation_0-mlogloss:0.53336\tvalidation_1-mlogloss:0.72536\n",
      "[116]\tvalidation_0-mlogloss:0.52895\tvalidation_1-mlogloss:0.72218\n",
      "[117]\tvalidation_0-mlogloss:0.52440\tvalidation_1-mlogloss:0.71872\n",
      "[118]\tvalidation_0-mlogloss:0.52018\tvalidation_1-mlogloss:0.71488\n",
      "[119]\tvalidation_0-mlogloss:0.51589\tvalidation_1-mlogloss:0.71208\n",
      "[120]\tvalidation_0-mlogloss:0.51126\tvalidation_1-mlogloss:0.70812\n",
      "[121]\tvalidation_0-mlogloss:0.50716\tvalidation_1-mlogloss:0.70473\n",
      "[122]\tvalidation_0-mlogloss:0.50278\tvalidation_1-mlogloss:0.70051\n",
      "[123]\tvalidation_0-mlogloss:0.49843\tvalidation_1-mlogloss:0.69762\n",
      "[124]\tvalidation_0-mlogloss:0.49446\tvalidation_1-mlogloss:0.69500\n",
      "[125]\tvalidation_0-mlogloss:0.49041\tvalidation_1-mlogloss:0.69155\n",
      "[126]\tvalidation_0-mlogloss:0.48638\tvalidation_1-mlogloss:0.68822\n",
      "[127]\tvalidation_0-mlogloss:0.48221\tvalidation_1-mlogloss:0.68407\n",
      "[128]\tvalidation_0-mlogloss:0.47882\tvalidation_1-mlogloss:0.68152\n",
      "[129]\tvalidation_0-mlogloss:0.47512\tvalidation_1-mlogloss:0.67818\n",
      "[130]\tvalidation_0-mlogloss:0.47116\tvalidation_1-mlogloss:0.67494\n",
      "[131]\tvalidation_0-mlogloss:0.46720\tvalidation_1-mlogloss:0.67090\n",
      "[132]\tvalidation_0-mlogloss:0.46351\tvalidation_1-mlogloss:0.66737\n",
      "[133]\tvalidation_0-mlogloss:0.46015\tvalidation_1-mlogloss:0.66421\n",
      "[134]\tvalidation_0-mlogloss:0.45639\tvalidation_1-mlogloss:0.66152\n",
      "[135]\tvalidation_0-mlogloss:0.45296\tvalidation_1-mlogloss:0.65866\n",
      "[136]\tvalidation_0-mlogloss:0.44922\tvalidation_1-mlogloss:0.65597\n",
      "[137]\tvalidation_0-mlogloss:0.44556\tvalidation_1-mlogloss:0.65303\n",
      "[138]\tvalidation_0-mlogloss:0.44179\tvalidation_1-mlogloss:0.64945\n",
      "[139]\tvalidation_0-mlogloss:0.43819\tvalidation_1-mlogloss:0.64685\n",
      "[140]\tvalidation_0-mlogloss:0.43480\tvalidation_1-mlogloss:0.64408\n",
      "[141]\tvalidation_0-mlogloss:0.43120\tvalidation_1-mlogloss:0.64109\n",
      "[142]\tvalidation_0-mlogloss:0.42757\tvalidation_1-mlogloss:0.63810\n",
      "[143]\tvalidation_0-mlogloss:0.42391\tvalidation_1-mlogloss:0.63448\n",
      "[144]\tvalidation_0-mlogloss:0.42046\tvalidation_1-mlogloss:0.63210\n",
      "[145]\tvalidation_0-mlogloss:0.41705\tvalidation_1-mlogloss:0.62900\n",
      "[146]\tvalidation_0-mlogloss:0.41361\tvalidation_1-mlogloss:0.62607\n",
      "[147]\tvalidation_0-mlogloss:0.41014\tvalidation_1-mlogloss:0.62295\n",
      "[148]\tvalidation_0-mlogloss:0.40668\tvalidation_1-mlogloss:0.61945\n",
      "[149]\tvalidation_0-mlogloss:0.40341\tvalidation_1-mlogloss:0.61724\n",
      "[150]\tvalidation_0-mlogloss:0.40006\tvalidation_1-mlogloss:0.61434\n",
      "[151]\tvalidation_0-mlogloss:0.39685\tvalidation_1-mlogloss:0.61155\n",
      "[152]\tvalidation_0-mlogloss:0.39360\tvalidation_1-mlogloss:0.60859\n",
      "[153]\tvalidation_0-mlogloss:0.39054\tvalidation_1-mlogloss:0.60626\n",
      "[154]\tvalidation_0-mlogloss:0.38733\tvalidation_1-mlogloss:0.60361\n",
      "[155]\tvalidation_0-mlogloss:0.38414\tvalidation_1-mlogloss:0.60082\n",
      "[156]\tvalidation_0-mlogloss:0.38126\tvalidation_1-mlogloss:0.59852\n",
      "[157]\tvalidation_0-mlogloss:0.37814\tvalidation_1-mlogloss:0.59534\n",
      "[158]\tvalidation_0-mlogloss:0.37521\tvalidation_1-mlogloss:0.59320\n",
      "[159]\tvalidation_0-mlogloss:0.37235\tvalidation_1-mlogloss:0.59073\n",
      "[160]\tvalidation_0-mlogloss:0.36933\tvalidation_1-mlogloss:0.58857\n",
      "[161]\tvalidation_0-mlogloss:0.36640\tvalidation_1-mlogloss:0.58626\n",
      "[162]\tvalidation_0-mlogloss:0.36352\tvalidation_1-mlogloss:0.58344\n",
      "[163]\tvalidation_0-mlogloss:0.36079\tvalidation_1-mlogloss:0.58175\n",
      "[164]\tvalidation_0-mlogloss:0.35787\tvalidation_1-mlogloss:0.57962\n",
      "[165]\tvalidation_0-mlogloss:0.35492\tvalidation_1-mlogloss:0.57634\n",
      "[166]\tvalidation_0-mlogloss:0.35215\tvalidation_1-mlogloss:0.57340\n",
      "[167]\tvalidation_0-mlogloss:0.34930\tvalidation_1-mlogloss:0.57097\n",
      "[168]\tvalidation_0-mlogloss:0.34648\tvalidation_1-mlogloss:0.56819\n",
      "[169]\tvalidation_0-mlogloss:0.34374\tvalidation_1-mlogloss:0.56594\n",
      "[170]\tvalidation_0-mlogloss:0.34098\tvalidation_1-mlogloss:0.56350\n",
      "[171]\tvalidation_0-mlogloss:0.33838\tvalidation_1-mlogloss:0.56178\n",
      "[172]\tvalidation_0-mlogloss:0.33574\tvalidation_1-mlogloss:0.55948\n",
      "[173]\tvalidation_0-mlogloss:0.33332\tvalidation_1-mlogloss:0.55776\n",
      "[174]\tvalidation_0-mlogloss:0.33072\tvalidation_1-mlogloss:0.55575\n",
      "[175]\tvalidation_0-mlogloss:0.32809\tvalidation_1-mlogloss:0.55350\n",
      "[176]\tvalidation_0-mlogloss:0.32570\tvalidation_1-mlogloss:0.55166\n",
      "[177]\tvalidation_0-mlogloss:0.32330\tvalidation_1-mlogloss:0.54985\n",
      "[178]\tvalidation_0-mlogloss:0.32071\tvalidation_1-mlogloss:0.54759\n",
      "[179]\tvalidation_0-mlogloss:0.31831\tvalidation_1-mlogloss:0.54586\n",
      "[180]\tvalidation_0-mlogloss:0.31590\tvalidation_1-mlogloss:0.54455\n",
      "[181]\tvalidation_0-mlogloss:0.31345\tvalidation_1-mlogloss:0.54231\n",
      "[182]\tvalidation_0-mlogloss:0.31096\tvalidation_1-mlogloss:0.54000\n",
      "[183]\tvalidation_0-mlogloss:0.30859\tvalidation_1-mlogloss:0.53850\n",
      "[184]\tvalidation_0-mlogloss:0.30626\tvalidation_1-mlogloss:0.53682\n",
      "[185]\tvalidation_0-mlogloss:0.30389\tvalidation_1-mlogloss:0.53511\n",
      "[186]\tvalidation_0-mlogloss:0.30149\tvalidation_1-mlogloss:0.53299\n",
      "[187]\tvalidation_0-mlogloss:0.29915\tvalidation_1-mlogloss:0.53076\n",
      "[188]\tvalidation_0-mlogloss:0.29687\tvalidation_1-mlogloss:0.52941\n",
      "[189]\tvalidation_0-mlogloss:0.29459\tvalidation_1-mlogloss:0.52752\n",
      "[190]\tvalidation_0-mlogloss:0.29230\tvalidation_1-mlogloss:0.52552\n",
      "[191]\tvalidation_0-mlogloss:0.28999\tvalidation_1-mlogloss:0.52320\n",
      "[192]\tvalidation_0-mlogloss:0.28772\tvalidation_1-mlogloss:0.52161\n",
      "[193]\tvalidation_0-mlogloss:0.28554\tvalidation_1-mlogloss:0.52007\n",
      "[194]\tvalidation_0-mlogloss:0.28345\tvalidation_1-mlogloss:0.51834\n",
      "[195]\tvalidation_0-mlogloss:0.28127\tvalidation_1-mlogloss:0.51603\n",
      "[196]\tvalidation_0-mlogloss:0.27930\tvalidation_1-mlogloss:0.51439\n",
      "[197]\tvalidation_0-mlogloss:0.27713\tvalidation_1-mlogloss:0.51177\n",
      "[198]\tvalidation_0-mlogloss:0.27505\tvalidation_1-mlogloss:0.50978\n",
      "[199]\tvalidation_0-mlogloss:0.27309\tvalidation_1-mlogloss:0.50801\n",
      "[200]\tvalidation_0-mlogloss:0.27107\tvalidation_1-mlogloss:0.50665\n",
      "[201]\tvalidation_0-mlogloss:0.26902\tvalidation_1-mlogloss:0.50492\n",
      "[202]\tvalidation_0-mlogloss:0.26700\tvalidation_1-mlogloss:0.50317\n",
      "[203]\tvalidation_0-mlogloss:0.26508\tvalidation_1-mlogloss:0.50151\n",
      "[204]\tvalidation_0-mlogloss:0.26308\tvalidation_1-mlogloss:0.49980\n",
      "[205]\tvalidation_0-mlogloss:0.26103\tvalidation_1-mlogloss:0.49805\n",
      "[206]\tvalidation_0-mlogloss:0.25906\tvalidation_1-mlogloss:0.49633\n",
      "[207]\tvalidation_0-mlogloss:0.25728\tvalidation_1-mlogloss:0.49513\n",
      "[208]\tvalidation_0-mlogloss:0.25534\tvalidation_1-mlogloss:0.49310\n",
      "[209]\tvalidation_0-mlogloss:0.25341\tvalidation_1-mlogloss:0.49107\n",
      "[210]\tvalidation_0-mlogloss:0.25156\tvalidation_1-mlogloss:0.48920\n",
      "[211]\tvalidation_0-mlogloss:0.24981\tvalidation_1-mlogloss:0.48827\n",
      "[212]\tvalidation_0-mlogloss:0.24793\tvalidation_1-mlogloss:0.48670\n",
      "[213]\tvalidation_0-mlogloss:0.24606\tvalidation_1-mlogloss:0.48446\n",
      "[214]\tvalidation_0-mlogloss:0.24427\tvalidation_1-mlogloss:0.48267\n",
      "[215]\tvalidation_0-mlogloss:0.24250\tvalidation_1-mlogloss:0.48103\n",
      "[216]\tvalidation_0-mlogloss:0.24070\tvalidation_1-mlogloss:0.47935\n",
      "[217]\tvalidation_0-mlogloss:0.23908\tvalidation_1-mlogloss:0.47824\n",
      "[218]\tvalidation_0-mlogloss:0.23730\tvalidation_1-mlogloss:0.47608\n",
      "[219]\tvalidation_0-mlogloss:0.23556\tvalidation_1-mlogloss:0.47461\n",
      "[220]\tvalidation_0-mlogloss:0.23395\tvalidation_1-mlogloss:0.47343\n",
      "[221]\tvalidation_0-mlogloss:0.23229\tvalidation_1-mlogloss:0.47266\n",
      "[222]\tvalidation_0-mlogloss:0.23062\tvalidation_1-mlogloss:0.47082\n",
      "[223]\tvalidation_0-mlogloss:0.22894\tvalidation_1-mlogloss:0.46920\n",
      "[224]\tvalidation_0-mlogloss:0.22727\tvalidation_1-mlogloss:0.46769\n",
      "[225]\tvalidation_0-mlogloss:0.22568\tvalidation_1-mlogloss:0.46668\n",
      "[226]\tvalidation_0-mlogloss:0.22407\tvalidation_1-mlogloss:0.46494\n",
      "[227]\tvalidation_0-mlogloss:0.22249\tvalidation_1-mlogloss:0.46329\n",
      "[228]\tvalidation_0-mlogloss:0.22086\tvalidation_1-mlogloss:0.46165\n",
      "[229]\tvalidation_0-mlogloss:0.21932\tvalidation_1-mlogloss:0.46009\n",
      "[230]\tvalidation_0-mlogloss:0.21771\tvalidation_1-mlogloss:0.45857\n",
      "[231]\tvalidation_0-mlogloss:0.21616\tvalidation_1-mlogloss:0.45739\n",
      "[232]\tvalidation_0-mlogloss:0.21473\tvalidation_1-mlogloss:0.45580\n",
      "[233]\tvalidation_0-mlogloss:0.21319\tvalidation_1-mlogloss:0.45436\n",
      "[234]\tvalidation_0-mlogloss:0.21163\tvalidation_1-mlogloss:0.45306\n",
      "[235]\tvalidation_0-mlogloss:0.21005\tvalidation_1-mlogloss:0.45201\n",
      "[236]\tvalidation_0-mlogloss:0.20859\tvalidation_1-mlogloss:0.45124\n",
      "[237]\tvalidation_0-mlogloss:0.20718\tvalidation_1-mlogloss:0.44988\n",
      "[238]\tvalidation_0-mlogloss:0.20575\tvalidation_1-mlogloss:0.44901\n",
      "[239]\tvalidation_0-mlogloss:0.20434\tvalidation_1-mlogloss:0.44833\n",
      "[240]\tvalidation_0-mlogloss:0.20283\tvalidation_1-mlogloss:0.44707\n",
      "[241]\tvalidation_0-mlogloss:0.20142\tvalidation_1-mlogloss:0.44623\n",
      "[242]\tvalidation_0-mlogloss:0.20000\tvalidation_1-mlogloss:0.44518\n",
      "[243]\tvalidation_0-mlogloss:0.19859\tvalidation_1-mlogloss:0.44397\n",
      "[244]\tvalidation_0-mlogloss:0.19726\tvalidation_1-mlogloss:0.44268\n",
      "[245]\tvalidation_0-mlogloss:0.19593\tvalidation_1-mlogloss:0.44213\n",
      "[246]\tvalidation_0-mlogloss:0.19462\tvalidation_1-mlogloss:0.44123\n",
      "[247]\tvalidation_0-mlogloss:0.19326\tvalidation_1-mlogloss:0.44042\n",
      "[248]\tvalidation_0-mlogloss:0.19194\tvalidation_1-mlogloss:0.43932\n",
      "[249]\tvalidation_0-mlogloss:0.19063\tvalidation_1-mlogloss:0.43862\n",
      "[250]\tvalidation_0-mlogloss:0.18929\tvalidation_1-mlogloss:0.43719\n",
      "[251]\tvalidation_0-mlogloss:0.18805\tvalidation_1-mlogloss:0.43626\n",
      "[252]\tvalidation_0-mlogloss:0.18675\tvalidation_1-mlogloss:0.43568\n",
      "[253]\tvalidation_0-mlogloss:0.18551\tvalidation_1-mlogloss:0.43449\n",
      "[254]\tvalidation_0-mlogloss:0.18424\tvalidation_1-mlogloss:0.43368\n",
      "[255]\tvalidation_0-mlogloss:0.18300\tvalidation_1-mlogloss:0.43274\n",
      "[256]\tvalidation_0-mlogloss:0.18185\tvalidation_1-mlogloss:0.43207\n",
      "[257]\tvalidation_0-mlogloss:0.18063\tvalidation_1-mlogloss:0.43123\n",
      "[258]\tvalidation_0-mlogloss:0.17941\tvalidation_1-mlogloss:0.43067\n",
      "[259]\tvalidation_0-mlogloss:0.17817\tvalidation_1-mlogloss:0.43009\n",
      "[260]\tvalidation_0-mlogloss:0.17701\tvalidation_1-mlogloss:0.42910\n",
      "[261]\tvalidation_0-mlogloss:0.17596\tvalidation_1-mlogloss:0.42842\n",
      "[262]\tvalidation_0-mlogloss:0.17480\tvalidation_1-mlogloss:0.42802\n",
      "[263]\tvalidation_0-mlogloss:0.17366\tvalidation_1-mlogloss:0.42733\n",
      "[264]\tvalidation_0-mlogloss:0.17247\tvalidation_1-mlogloss:0.42632\n",
      "[265]\tvalidation_0-mlogloss:0.17130\tvalidation_1-mlogloss:0.42526\n",
      "[266]\tvalidation_0-mlogloss:0.17011\tvalidation_1-mlogloss:0.42434\n",
      "[267]\tvalidation_0-mlogloss:0.16899\tvalidation_1-mlogloss:0.42342\n",
      "[268]\tvalidation_0-mlogloss:0.16788\tvalidation_1-mlogloss:0.42259\n",
      "[269]\tvalidation_0-mlogloss:0.16691\tvalidation_1-mlogloss:0.42184\n",
      "[270]\tvalidation_0-mlogloss:0.16585\tvalidation_1-mlogloss:0.42141\n",
      "[271]\tvalidation_0-mlogloss:0.16475\tvalidation_1-mlogloss:0.42093\n",
      "[272]\tvalidation_0-mlogloss:0.16367\tvalidation_1-mlogloss:0.42029\n",
      "[273]\tvalidation_0-mlogloss:0.16261\tvalidation_1-mlogloss:0.41989\n",
      "[274]\tvalidation_0-mlogloss:0.16154\tvalidation_1-mlogloss:0.41895\n",
      "[275]\tvalidation_0-mlogloss:0.16054\tvalidation_1-mlogloss:0.41825\n",
      "[276]\tvalidation_0-mlogloss:0.15950\tvalidation_1-mlogloss:0.41745\n",
      "[277]\tvalidation_0-mlogloss:0.15845\tvalidation_1-mlogloss:0.41635\n",
      "[278]\tvalidation_0-mlogloss:0.15748\tvalidation_1-mlogloss:0.41551\n",
      "[279]\tvalidation_0-mlogloss:0.15649\tvalidation_1-mlogloss:0.41505\n",
      "[280]\tvalidation_0-mlogloss:0.15546\tvalidation_1-mlogloss:0.41445\n",
      "[281]\tvalidation_0-mlogloss:0.15449\tvalidation_1-mlogloss:0.41364\n",
      "[282]\tvalidation_0-mlogloss:0.15352\tvalidation_1-mlogloss:0.41268\n",
      "[283]\tvalidation_0-mlogloss:0.15251\tvalidation_1-mlogloss:0.41213\n",
      "[284]\tvalidation_0-mlogloss:0.15159\tvalidation_1-mlogloss:0.41143\n",
      "[285]\tvalidation_0-mlogloss:0.15062\tvalidation_1-mlogloss:0.41063\n",
      "[286]\tvalidation_0-mlogloss:0.14963\tvalidation_1-mlogloss:0.40978\n",
      "[287]\tvalidation_0-mlogloss:0.14864\tvalidation_1-mlogloss:0.40923\n",
      "[288]\tvalidation_0-mlogloss:0.14775\tvalidation_1-mlogloss:0.40884\n",
      "[289]\tvalidation_0-mlogloss:0.14677\tvalidation_1-mlogloss:0.40805\n",
      "[290]\tvalidation_0-mlogloss:0.14584\tvalidation_1-mlogloss:0.40728\n",
      "[291]\tvalidation_0-mlogloss:0.14491\tvalidation_1-mlogloss:0.40648\n",
      "[292]\tvalidation_0-mlogloss:0.14398\tvalidation_1-mlogloss:0.40565\n",
      "[293]\tvalidation_0-mlogloss:0.14313\tvalidation_1-mlogloss:0.40508\n",
      "[294]\tvalidation_0-mlogloss:0.14221\tvalidation_1-mlogloss:0.40444\n",
      "[295]\tvalidation_0-mlogloss:0.14132\tvalidation_1-mlogloss:0.40360\n",
      "[296]\tvalidation_0-mlogloss:0.14047\tvalidation_1-mlogloss:0.40308\n",
      "[297]\tvalidation_0-mlogloss:0.13962\tvalidation_1-mlogloss:0.40266\n",
      "[298]\tvalidation_0-mlogloss:0.13873\tvalidation_1-mlogloss:0.40193\n",
      "[299]\tvalidation_0-mlogloss:0.13794\tvalidation_1-mlogloss:0.40110\n",
      "[300]\tvalidation_0-mlogloss:0.13710\tvalidation_1-mlogloss:0.40078\n",
      "[301]\tvalidation_0-mlogloss:0.13625\tvalidation_1-mlogloss:0.39997\n",
      "[302]\tvalidation_0-mlogloss:0.13543\tvalidation_1-mlogloss:0.39943\n",
      "[303]\tvalidation_0-mlogloss:0.13457\tvalidation_1-mlogloss:0.39859\n",
      "[304]\tvalidation_0-mlogloss:0.13383\tvalidation_1-mlogloss:0.39792\n",
      "[305]\tvalidation_0-mlogloss:0.13301\tvalidation_1-mlogloss:0.39742\n",
      "[306]\tvalidation_0-mlogloss:0.13223\tvalidation_1-mlogloss:0.39699\n",
      "[307]\tvalidation_0-mlogloss:0.13144\tvalidation_1-mlogloss:0.39616\n",
      "[308]\tvalidation_0-mlogloss:0.13063\tvalidation_1-mlogloss:0.39595\n",
      "[309]\tvalidation_0-mlogloss:0.12990\tvalidation_1-mlogloss:0.39557\n",
      "[310]\tvalidation_0-mlogloss:0.12913\tvalidation_1-mlogloss:0.39524\n",
      "[311]\tvalidation_0-mlogloss:0.12841\tvalidation_1-mlogloss:0.39466\n",
      "[312]\tvalidation_0-mlogloss:0.12768\tvalidation_1-mlogloss:0.39432\n",
      "[313]\tvalidation_0-mlogloss:0.12698\tvalidation_1-mlogloss:0.39370\n",
      "[314]\tvalidation_0-mlogloss:0.12621\tvalidation_1-mlogloss:0.39340\n",
      "[315]\tvalidation_0-mlogloss:0.12544\tvalidation_1-mlogloss:0.39259\n",
      "[316]\tvalidation_0-mlogloss:0.12472\tvalidation_1-mlogloss:0.39234\n",
      "[317]\tvalidation_0-mlogloss:0.12406\tvalidation_1-mlogloss:0.39209\n",
      "[318]\tvalidation_0-mlogloss:0.12330\tvalidation_1-mlogloss:0.39130\n",
      "[319]\tvalidation_0-mlogloss:0.12256\tvalidation_1-mlogloss:0.39040\n",
      "[320]\tvalidation_0-mlogloss:0.12184\tvalidation_1-mlogloss:0.38962\n",
      "[321]\tvalidation_0-mlogloss:0.12114\tvalidation_1-mlogloss:0.38908\n",
      "[322]\tvalidation_0-mlogloss:0.12044\tvalidation_1-mlogloss:0.38849\n",
      "[323]\tvalidation_0-mlogloss:0.11975\tvalidation_1-mlogloss:0.38769\n",
      "[324]\tvalidation_0-mlogloss:0.11905\tvalidation_1-mlogloss:0.38705\n",
      "[325]\tvalidation_0-mlogloss:0.11839\tvalidation_1-mlogloss:0.38673\n",
      "[326]\tvalidation_0-mlogloss:0.11774\tvalidation_1-mlogloss:0.38587\n",
      "[327]\tvalidation_0-mlogloss:0.11708\tvalidation_1-mlogloss:0.38538\n",
      "[328]\tvalidation_0-mlogloss:0.11641\tvalidation_1-mlogloss:0.38529\n",
      "[329]\tvalidation_0-mlogloss:0.11571\tvalidation_1-mlogloss:0.38443\n",
      "[330]\tvalidation_0-mlogloss:0.11502\tvalidation_1-mlogloss:0.38398\n",
      "[331]\tvalidation_0-mlogloss:0.11438\tvalidation_1-mlogloss:0.38369\n",
      "[332]\tvalidation_0-mlogloss:0.11372\tvalidation_1-mlogloss:0.38362\n",
      "[333]\tvalidation_0-mlogloss:0.11305\tvalidation_1-mlogloss:0.38323\n",
      "[334]\tvalidation_0-mlogloss:0.11241\tvalidation_1-mlogloss:0.38306\n",
      "[335]\tvalidation_0-mlogloss:0.11180\tvalidation_1-mlogloss:0.38235\n",
      "[336]\tvalidation_0-mlogloss:0.11114\tvalidation_1-mlogloss:0.38144\n",
      "[337]\tvalidation_0-mlogloss:0.11052\tvalidation_1-mlogloss:0.38139\n",
      "[338]\tvalidation_0-mlogloss:0.10989\tvalidation_1-mlogloss:0.38096\n",
      "[339]\tvalidation_0-mlogloss:0.10931\tvalidation_1-mlogloss:0.38046\n",
      "[340]\tvalidation_0-mlogloss:0.10870\tvalidation_1-mlogloss:0.37989\n",
      "[341]\tvalidation_0-mlogloss:0.10817\tvalidation_1-mlogloss:0.37981\n",
      "[342]\tvalidation_0-mlogloss:0.10756\tvalidation_1-mlogloss:0.37916\n",
      "[343]\tvalidation_0-mlogloss:0.10699\tvalidation_1-mlogloss:0.37880\n",
      "[344]\tvalidation_0-mlogloss:0.10639\tvalidation_1-mlogloss:0.37802\n",
      "[345]\tvalidation_0-mlogloss:0.10579\tvalidation_1-mlogloss:0.37745\n",
      "[346]\tvalidation_0-mlogloss:0.10520\tvalidation_1-mlogloss:0.37730\n",
      "[347]\tvalidation_0-mlogloss:0.10461\tvalidation_1-mlogloss:0.37690\n",
      "[348]\tvalidation_0-mlogloss:0.10407\tvalidation_1-mlogloss:0.37677\n",
      "[349]\tvalidation_0-mlogloss:0.10351\tvalidation_1-mlogloss:0.37620\n",
      "[350]\tvalidation_0-mlogloss:0.10294\tvalidation_1-mlogloss:0.37550\n",
      "[351]\tvalidation_0-mlogloss:0.10242\tvalidation_1-mlogloss:0.37522\n",
      "[352]\tvalidation_0-mlogloss:0.10191\tvalidation_1-mlogloss:0.37505\n",
      "[353]\tvalidation_0-mlogloss:0.10137\tvalidation_1-mlogloss:0.37468\n",
      "[354]\tvalidation_0-mlogloss:0.10090\tvalidation_1-mlogloss:0.37430\n",
      "[355]\tvalidation_0-mlogloss:0.10033\tvalidation_1-mlogloss:0.37357\n",
      "[356]\tvalidation_0-mlogloss:0.09982\tvalidation_1-mlogloss:0.37329\n",
      "[357]\tvalidation_0-mlogloss:0.09929\tvalidation_1-mlogloss:0.37277\n",
      "[358]\tvalidation_0-mlogloss:0.09877\tvalidation_1-mlogloss:0.37198\n",
      "[359]\tvalidation_0-mlogloss:0.09826\tvalidation_1-mlogloss:0.37183\n",
      "[360]\tvalidation_0-mlogloss:0.09775\tvalidation_1-mlogloss:0.37154\n",
      "[361]\tvalidation_0-mlogloss:0.09725\tvalidation_1-mlogloss:0.37145\n",
      "[362]\tvalidation_0-mlogloss:0.09681\tvalidation_1-mlogloss:0.37094\n",
      "[363]\tvalidation_0-mlogloss:0.09632\tvalidation_1-mlogloss:0.37090\n",
      "[364]\tvalidation_0-mlogloss:0.09584\tvalidation_1-mlogloss:0.37047\n",
      "[365]\tvalidation_0-mlogloss:0.09533\tvalidation_1-mlogloss:0.37016\n",
      "[366]\tvalidation_0-mlogloss:0.09483\tvalidation_1-mlogloss:0.37011\n",
      "[367]\tvalidation_0-mlogloss:0.09434\tvalidation_1-mlogloss:0.36970\n",
      "[368]\tvalidation_0-mlogloss:0.09382\tvalidation_1-mlogloss:0.36895\n",
      "[369]\tvalidation_0-mlogloss:0.09336\tvalidation_1-mlogloss:0.36841\n",
      "[370]\tvalidation_0-mlogloss:0.09287\tvalidation_1-mlogloss:0.36847\n",
      "[371]\tvalidation_0-mlogloss:0.09246\tvalidation_1-mlogloss:0.36842\n",
      "[372]\tvalidation_0-mlogloss:0.09196\tvalidation_1-mlogloss:0.36815\n",
      "[373]\tvalidation_0-mlogloss:0.09150\tvalidation_1-mlogloss:0.36769\n",
      "[374]\tvalidation_0-mlogloss:0.09106\tvalidation_1-mlogloss:0.36754\n",
      "[375]\tvalidation_0-mlogloss:0.09060\tvalidation_1-mlogloss:0.36700\n",
      "[376]\tvalidation_0-mlogloss:0.09013\tvalidation_1-mlogloss:0.36613\n",
      "[377]\tvalidation_0-mlogloss:0.08972\tvalidation_1-mlogloss:0.36570\n",
      "[378]\tvalidation_0-mlogloss:0.08928\tvalidation_1-mlogloss:0.36550\n",
      "[379]\tvalidation_0-mlogloss:0.08884\tvalidation_1-mlogloss:0.36545\n",
      "[380]\tvalidation_0-mlogloss:0.08838\tvalidation_1-mlogloss:0.36506\n",
      "[381]\tvalidation_0-mlogloss:0.08797\tvalidation_1-mlogloss:0.36463\n",
      "[382]\tvalidation_0-mlogloss:0.08750\tvalidation_1-mlogloss:0.36380\n",
      "[383]\tvalidation_0-mlogloss:0.08707\tvalidation_1-mlogloss:0.36361\n",
      "[384]\tvalidation_0-mlogloss:0.08668\tvalidation_1-mlogloss:0.36360\n",
      "[385]\tvalidation_0-mlogloss:0.08623\tvalidation_1-mlogloss:0.36359\n",
      "[386]\tvalidation_0-mlogloss:0.08586\tvalidation_1-mlogloss:0.36345\n",
      "[387]\tvalidation_0-mlogloss:0.08544\tvalidation_1-mlogloss:0.36351\n",
      "[388]\tvalidation_0-mlogloss:0.08504\tvalidation_1-mlogloss:0.36359\n",
      "[389]\tvalidation_0-mlogloss:0.08464\tvalidation_1-mlogloss:0.36320\n",
      "[390]\tvalidation_0-mlogloss:0.08427\tvalidation_1-mlogloss:0.36292\n",
      "[391]\tvalidation_0-mlogloss:0.08385\tvalidation_1-mlogloss:0.36270\n",
      "[392]\tvalidation_0-mlogloss:0.08346\tvalidation_1-mlogloss:0.36251\n",
      "[393]\tvalidation_0-mlogloss:0.08308\tvalidation_1-mlogloss:0.36222\n",
      "[394]\tvalidation_0-mlogloss:0.08266\tvalidation_1-mlogloss:0.36210\n",
      "[395]\tvalidation_0-mlogloss:0.08225\tvalidation_1-mlogloss:0.36178\n",
      "[396]\tvalidation_0-mlogloss:0.08182\tvalidation_1-mlogloss:0.36175\n",
      "[397]\tvalidation_0-mlogloss:0.08147\tvalidation_1-mlogloss:0.36175\n",
      "[398]\tvalidation_0-mlogloss:0.08110\tvalidation_1-mlogloss:0.36184\n",
      "[399]\tvalidation_0-mlogloss:0.08077\tvalidation_1-mlogloss:0.36157\n",
      "[400]\tvalidation_0-mlogloss:0.08041\tvalidation_1-mlogloss:0.36160\n",
      "[401]\tvalidation_0-mlogloss:0.08005\tvalidation_1-mlogloss:0.36122\n",
      "[402]\tvalidation_0-mlogloss:0.07966\tvalidation_1-mlogloss:0.36090\n",
      "[403]\tvalidation_0-mlogloss:0.07929\tvalidation_1-mlogloss:0.36089\n",
      "[404]\tvalidation_0-mlogloss:0.07899\tvalidation_1-mlogloss:0.36060\n",
      "[405]\tvalidation_0-mlogloss:0.07864\tvalidation_1-mlogloss:0.36012\n",
      "[406]\tvalidation_0-mlogloss:0.07827\tvalidation_1-mlogloss:0.36001\n",
      "[407]\tvalidation_0-mlogloss:0.07791\tvalidation_1-mlogloss:0.35966\n",
      "[408]\tvalidation_0-mlogloss:0.07754\tvalidation_1-mlogloss:0.35964\n",
      "[409]\tvalidation_0-mlogloss:0.07716\tvalidation_1-mlogloss:0.35899\n",
      "[410]\tvalidation_0-mlogloss:0.07685\tvalidation_1-mlogloss:0.35868\n",
      "[411]\tvalidation_0-mlogloss:0.07652\tvalidation_1-mlogloss:0.35873\n",
      "[412]\tvalidation_0-mlogloss:0.07621\tvalidation_1-mlogloss:0.35885\n",
      "[413]\tvalidation_0-mlogloss:0.07585\tvalidation_1-mlogloss:0.35816\n",
      "[414]\tvalidation_0-mlogloss:0.07550\tvalidation_1-mlogloss:0.35820\n",
      "[415]\tvalidation_0-mlogloss:0.07519\tvalidation_1-mlogloss:0.35816\n",
      "[416]\tvalidation_0-mlogloss:0.07486\tvalidation_1-mlogloss:0.35814\n",
      "[417]\tvalidation_0-mlogloss:0.07452\tvalidation_1-mlogloss:0.35755\n",
      "[418]\tvalidation_0-mlogloss:0.07421\tvalidation_1-mlogloss:0.35763\n",
      "[419]\tvalidation_0-mlogloss:0.07386\tvalidation_1-mlogloss:0.35702\n",
      "[420]\tvalidation_0-mlogloss:0.07354\tvalidation_1-mlogloss:0.35674\n",
      "[421]\tvalidation_0-mlogloss:0.07325\tvalidation_1-mlogloss:0.35695\n",
      "[422]\tvalidation_0-mlogloss:0.07298\tvalidation_1-mlogloss:0.35702\n",
      "[423]\tvalidation_0-mlogloss:0.07266\tvalidation_1-mlogloss:0.35657\n",
      "[424]\tvalidation_0-mlogloss:0.07236\tvalidation_1-mlogloss:0.35643\n",
      "[425]\tvalidation_0-mlogloss:0.07205\tvalidation_1-mlogloss:0.35627\n",
      "[426]\tvalidation_0-mlogloss:0.07175\tvalidation_1-mlogloss:0.35579\n",
      "[427]\tvalidation_0-mlogloss:0.07144\tvalidation_1-mlogloss:0.35558\n",
      "[428]\tvalidation_0-mlogloss:0.07111\tvalidation_1-mlogloss:0.35557\n",
      "[429]\tvalidation_0-mlogloss:0.07088\tvalidation_1-mlogloss:0.35524\n",
      "[430]\tvalidation_0-mlogloss:0.07057\tvalidation_1-mlogloss:0.35479\n",
      "[431]\tvalidation_0-mlogloss:0.07029\tvalidation_1-mlogloss:0.35492\n",
      "[432]\tvalidation_0-mlogloss:0.07002\tvalidation_1-mlogloss:0.35474\n",
      "[433]\tvalidation_0-mlogloss:0.06974\tvalidation_1-mlogloss:0.35474\n",
      "[434]\tvalidation_0-mlogloss:0.06947\tvalidation_1-mlogloss:0.35474\n",
      "[435]\tvalidation_0-mlogloss:0.06919\tvalidation_1-mlogloss:0.35455\n",
      "[436]\tvalidation_0-mlogloss:0.06889\tvalidation_1-mlogloss:0.35408\n",
      "[437]\tvalidation_0-mlogloss:0.06867\tvalidation_1-mlogloss:0.35401\n",
      "[438]\tvalidation_0-mlogloss:0.06848\tvalidation_1-mlogloss:0.35405\n",
      "[439]\tvalidation_0-mlogloss:0.06822\tvalidation_1-mlogloss:0.35406\n",
      "[440]\tvalidation_0-mlogloss:0.06799\tvalidation_1-mlogloss:0.35383\n",
      "[441]\tvalidation_0-mlogloss:0.06769\tvalidation_1-mlogloss:0.35350\n",
      "[442]\tvalidation_0-mlogloss:0.06742\tvalidation_1-mlogloss:0.35341\n",
      "[443]\tvalidation_0-mlogloss:0.06717\tvalidation_1-mlogloss:0.35342\n",
      "[444]\tvalidation_0-mlogloss:0.06690\tvalidation_1-mlogloss:0.35341\n",
      "[445]\tvalidation_0-mlogloss:0.06663\tvalidation_1-mlogloss:0.35310\n",
      "[446]\tvalidation_0-mlogloss:0.06634\tvalidation_1-mlogloss:0.35266\n",
      "[447]\tvalidation_0-mlogloss:0.06607\tvalidation_1-mlogloss:0.35245\n",
      "[448]\tvalidation_0-mlogloss:0.06578\tvalidation_1-mlogloss:0.35193\n",
      "[449]\tvalidation_0-mlogloss:0.06551\tvalidation_1-mlogloss:0.35173\n",
      "[450]\tvalidation_0-mlogloss:0.06525\tvalidation_1-mlogloss:0.35151\n",
      "[451]\tvalidation_0-mlogloss:0.06507\tvalidation_1-mlogloss:0.35136\n",
      "[452]\tvalidation_0-mlogloss:0.06482\tvalidation_1-mlogloss:0.35145\n",
      "[453]\tvalidation_0-mlogloss:0.06464\tvalidation_1-mlogloss:0.35153\n",
      "[454]\tvalidation_0-mlogloss:0.06438\tvalidation_1-mlogloss:0.35171\n",
      "[455]\tvalidation_0-mlogloss:0.06419\tvalidation_1-mlogloss:0.35186\n",
      "[456]\tvalidation_0-mlogloss:0.06398\tvalidation_1-mlogloss:0.35174\n",
      "[457]\tvalidation_0-mlogloss:0.06374\tvalidation_1-mlogloss:0.35137\n",
      "[458]\tvalidation_0-mlogloss:0.06352\tvalidation_1-mlogloss:0.35137\n",
      "[459]\tvalidation_0-mlogloss:0.06331\tvalidation_1-mlogloss:0.35118\n",
      "[460]\tvalidation_0-mlogloss:0.06309\tvalidation_1-mlogloss:0.35111\n",
      "[461]\tvalidation_0-mlogloss:0.06286\tvalidation_1-mlogloss:0.35113\n",
      "[462]\tvalidation_0-mlogloss:0.06261\tvalidation_1-mlogloss:0.35108\n",
      "[463]\tvalidation_0-mlogloss:0.06236\tvalidation_1-mlogloss:0.35073\n",
      "[464]\tvalidation_0-mlogloss:0.06215\tvalidation_1-mlogloss:0.35054\n",
      "[465]\tvalidation_0-mlogloss:0.06199\tvalidation_1-mlogloss:0.35024\n",
      "[466]\tvalidation_0-mlogloss:0.06178\tvalidation_1-mlogloss:0.34989\n",
      "[467]\tvalidation_0-mlogloss:0.06159\tvalidation_1-mlogloss:0.34992\n",
      "[468]\tvalidation_0-mlogloss:0.06136\tvalidation_1-mlogloss:0.34991\n",
      "[469]\tvalidation_0-mlogloss:0.06118\tvalidation_1-mlogloss:0.34979\n",
      "[470]\tvalidation_0-mlogloss:0.06095\tvalidation_1-mlogloss:0.34951\n",
      "[471]\tvalidation_0-mlogloss:0.06070\tvalidation_1-mlogloss:0.34960\n",
      "[472]\tvalidation_0-mlogloss:0.06050\tvalidation_1-mlogloss:0.34929\n",
      "[473]\tvalidation_0-mlogloss:0.06030\tvalidation_1-mlogloss:0.34873\n",
      "[474]\tvalidation_0-mlogloss:0.06013\tvalidation_1-mlogloss:0.34848\n",
      "[475]\tvalidation_0-mlogloss:0.05995\tvalidation_1-mlogloss:0.34829\n",
      "[476]\tvalidation_0-mlogloss:0.05972\tvalidation_1-mlogloss:0.34810\n",
      "[477]\tvalidation_0-mlogloss:0.05958\tvalidation_1-mlogloss:0.34797\n",
      "[478]\tvalidation_0-mlogloss:0.05940\tvalidation_1-mlogloss:0.34792\n",
      "[479]\tvalidation_0-mlogloss:0.05920\tvalidation_1-mlogloss:0.34794\n",
      "[480]\tvalidation_0-mlogloss:0.05898\tvalidation_1-mlogloss:0.34754\n",
      "[481]\tvalidation_0-mlogloss:0.05879\tvalidation_1-mlogloss:0.34741\n",
      "[482]\tvalidation_0-mlogloss:0.05869\tvalidation_1-mlogloss:0.34731\n",
      "[483]\tvalidation_0-mlogloss:0.05849\tvalidation_1-mlogloss:0.34688\n",
      "[484]\tvalidation_0-mlogloss:0.05835\tvalidation_1-mlogloss:0.34660\n",
      "[485]\tvalidation_0-mlogloss:0.05819\tvalidation_1-mlogloss:0.34669\n",
      "[486]\tvalidation_0-mlogloss:0.05801\tvalidation_1-mlogloss:0.34658\n",
      "[487]\tvalidation_0-mlogloss:0.05785\tvalidation_1-mlogloss:0.34636\n",
      "[488]\tvalidation_0-mlogloss:0.05770\tvalidation_1-mlogloss:0.34616\n",
      "[489]\tvalidation_0-mlogloss:0.05755\tvalidation_1-mlogloss:0.34612\n",
      "[490]\tvalidation_0-mlogloss:0.05742\tvalidation_1-mlogloss:0.34595\n",
      "[491]\tvalidation_0-mlogloss:0.05730\tvalidation_1-mlogloss:0.34613\n",
      "[492]\tvalidation_0-mlogloss:0.05712\tvalidation_1-mlogloss:0.34605\n",
      "[493]\tvalidation_0-mlogloss:0.05700\tvalidation_1-mlogloss:0.34595\n",
      "[494]\tvalidation_0-mlogloss:0.05687\tvalidation_1-mlogloss:0.34620\n",
      "[495]\tvalidation_0-mlogloss:0.05668\tvalidation_1-mlogloss:0.34578\n",
      "[496]\tvalidation_0-mlogloss:0.05652\tvalidation_1-mlogloss:0.34570\n",
      "[497]\tvalidation_0-mlogloss:0.05633\tvalidation_1-mlogloss:0.34563\n",
      "[498]\tvalidation_0-mlogloss:0.05616\tvalidation_1-mlogloss:0.34567\n",
      "[499]\tvalidation_0-mlogloss:0.05604\tvalidation_1-mlogloss:0.34538\n",
      "[500]\tvalidation_0-mlogloss:0.05591\tvalidation_1-mlogloss:0.34527\n",
      "[501]\tvalidation_0-mlogloss:0.05580\tvalidation_1-mlogloss:0.34510\n",
      "[502]\tvalidation_0-mlogloss:0.05569\tvalidation_1-mlogloss:0.34498\n",
      "[503]\tvalidation_0-mlogloss:0.05553\tvalidation_1-mlogloss:0.34467\n",
      "[504]\tvalidation_0-mlogloss:0.05544\tvalidation_1-mlogloss:0.34441\n",
      "[505]\tvalidation_0-mlogloss:0.05534\tvalidation_1-mlogloss:0.34460\n",
      "[506]\tvalidation_0-mlogloss:0.05528\tvalidation_1-mlogloss:0.34470\n",
      "[507]\tvalidation_0-mlogloss:0.05515\tvalidation_1-mlogloss:0.34456\n",
      "[508]\tvalidation_0-mlogloss:0.05505\tvalidation_1-mlogloss:0.34432\n",
      "[509]\tvalidation_0-mlogloss:0.05491\tvalidation_1-mlogloss:0.34413\n",
      "[510]\tvalidation_0-mlogloss:0.05477\tvalidation_1-mlogloss:0.34411\n",
      "[511]\tvalidation_0-mlogloss:0.05466\tvalidation_1-mlogloss:0.34386\n",
      "[512]\tvalidation_0-mlogloss:0.05448\tvalidation_1-mlogloss:0.34373\n",
      "[513]\tvalidation_0-mlogloss:0.05438\tvalidation_1-mlogloss:0.34369\n",
      "[514]\tvalidation_0-mlogloss:0.05427\tvalidation_1-mlogloss:0.34370\n",
      "[515]\tvalidation_0-mlogloss:0.05412\tvalidation_1-mlogloss:0.34332\n",
      "[516]\tvalidation_0-mlogloss:0.05401\tvalidation_1-mlogloss:0.34309\n",
      "[517]\tvalidation_0-mlogloss:0.05386\tvalidation_1-mlogloss:0.34314\n",
      "[518]\tvalidation_0-mlogloss:0.05373\tvalidation_1-mlogloss:0.34307\n",
      "[519]\tvalidation_0-mlogloss:0.05363\tvalidation_1-mlogloss:0.34303\n",
      "[520]\tvalidation_0-mlogloss:0.05350\tvalidation_1-mlogloss:0.34274\n",
      "[521]\tvalidation_0-mlogloss:0.05348\tvalidation_1-mlogloss:0.34270\n",
      "[522]\tvalidation_0-mlogloss:0.05342\tvalidation_1-mlogloss:0.34263\n",
      "[523]\tvalidation_0-mlogloss:0.05332\tvalidation_1-mlogloss:0.34270\n",
      "[524]\tvalidation_0-mlogloss:0.05323\tvalidation_1-mlogloss:0.34254\n",
      "[525]\tvalidation_0-mlogloss:0.05314\tvalidation_1-mlogloss:0.34236\n",
      "[526]\tvalidation_0-mlogloss:0.05308\tvalidation_1-mlogloss:0.34249\n",
      "[527]\tvalidation_0-mlogloss:0.05299\tvalidation_1-mlogloss:0.34248\n",
      "[528]\tvalidation_0-mlogloss:0.05290\tvalidation_1-mlogloss:0.34228\n",
      "[529]\tvalidation_0-mlogloss:0.05276\tvalidation_1-mlogloss:0.34226\n",
      "[530]\tvalidation_0-mlogloss:0.05258\tvalidation_1-mlogloss:0.34212\n",
      "[531]\tvalidation_0-mlogloss:0.05248\tvalidation_1-mlogloss:0.34192\n",
      "[532]\tvalidation_0-mlogloss:0.05238\tvalidation_1-mlogloss:0.34166\n",
      "[533]\tvalidation_0-mlogloss:0.05227\tvalidation_1-mlogloss:0.34135\n",
      "[534]\tvalidation_0-mlogloss:0.05222\tvalidation_1-mlogloss:0.34137\n",
      "[535]\tvalidation_0-mlogloss:0.05212\tvalidation_1-mlogloss:0.34110\n",
      "[536]\tvalidation_0-mlogloss:0.05200\tvalidation_1-mlogloss:0.34121\n",
      "[537]\tvalidation_0-mlogloss:0.05190\tvalidation_1-mlogloss:0.34100\n",
      "[538]\tvalidation_0-mlogloss:0.05180\tvalidation_1-mlogloss:0.34084\n",
      "[539]\tvalidation_0-mlogloss:0.05174\tvalidation_1-mlogloss:0.34101\n",
      "[540]\tvalidation_0-mlogloss:0.05166\tvalidation_1-mlogloss:0.34119\n",
      "[541]\tvalidation_0-mlogloss:0.05157\tvalidation_1-mlogloss:0.34102\n",
      "[542]\tvalidation_0-mlogloss:0.05148\tvalidation_1-mlogloss:0.34083\n",
      "[543]\tvalidation_0-mlogloss:0.05139\tvalidation_1-mlogloss:0.34056\n",
      "[544]\tvalidation_0-mlogloss:0.05129\tvalidation_1-mlogloss:0.34030\n",
      "[545]\tvalidation_0-mlogloss:0.05120\tvalidation_1-mlogloss:0.34037\n",
      "[546]\tvalidation_0-mlogloss:0.05112\tvalidation_1-mlogloss:0.34041\n",
      "[547]\tvalidation_0-mlogloss:0.05109\tvalidation_1-mlogloss:0.34023\n",
      "[548]\tvalidation_0-mlogloss:0.05096\tvalidation_1-mlogloss:0.33982\n",
      "[549]\tvalidation_0-mlogloss:0.05090\tvalidation_1-mlogloss:0.33978\n",
      "[550]\tvalidation_0-mlogloss:0.05088\tvalidation_1-mlogloss:0.33990\n",
      "[551]\tvalidation_0-mlogloss:0.05079\tvalidation_1-mlogloss:0.33980\n",
      "[552]\tvalidation_0-mlogloss:0.05069\tvalidation_1-mlogloss:0.33956\n",
      "[553]\tvalidation_0-mlogloss:0.05060\tvalidation_1-mlogloss:0.33919\n",
      "[554]\tvalidation_0-mlogloss:0.05055\tvalidation_1-mlogloss:0.33907\n",
      "[555]\tvalidation_0-mlogloss:0.05051\tvalidation_1-mlogloss:0.33898\n",
      "[556]\tvalidation_0-mlogloss:0.05044\tvalidation_1-mlogloss:0.33875\n",
      "[557]\tvalidation_0-mlogloss:0.05037\tvalidation_1-mlogloss:0.33874\n",
      "[558]\tvalidation_0-mlogloss:0.05035\tvalidation_1-mlogloss:0.33865\n",
      "[559]\tvalidation_0-mlogloss:0.05030\tvalidation_1-mlogloss:0.33877\n",
      "[560]\tvalidation_0-mlogloss:0.05020\tvalidation_1-mlogloss:0.33870\n",
      "[561]\tvalidation_0-mlogloss:0.05018\tvalidation_1-mlogloss:0.33862\n",
      "[562]\tvalidation_0-mlogloss:0.05012\tvalidation_1-mlogloss:0.33850\n",
      "[563]\tvalidation_0-mlogloss:0.05007\tvalidation_1-mlogloss:0.33827\n",
      "[564]\tvalidation_0-mlogloss:0.05002\tvalidation_1-mlogloss:0.33830\n",
      "[565]\tvalidation_0-mlogloss:0.04997\tvalidation_1-mlogloss:0.33829\n",
      "[566]\tvalidation_0-mlogloss:0.04992\tvalidation_1-mlogloss:0.33823\n",
      "[567]\tvalidation_0-mlogloss:0.04985\tvalidation_1-mlogloss:0.33798\n",
      "[568]\tvalidation_0-mlogloss:0.04978\tvalidation_1-mlogloss:0.33782\n",
      "[569]\tvalidation_0-mlogloss:0.04970\tvalidation_1-mlogloss:0.33749\n",
      "[570]\tvalidation_0-mlogloss:0.04962\tvalidation_1-mlogloss:0.33745\n",
      "[571]\tvalidation_0-mlogloss:0.04957\tvalidation_1-mlogloss:0.33740\n",
      "[572]\tvalidation_0-mlogloss:0.04948\tvalidation_1-mlogloss:0.33705\n",
      "[573]\tvalidation_0-mlogloss:0.04946\tvalidation_1-mlogloss:0.33695\n",
      "[574]\tvalidation_0-mlogloss:0.04942\tvalidation_1-mlogloss:0.33702\n",
      "[575]\tvalidation_0-mlogloss:0.04938\tvalidation_1-mlogloss:0.33700\n",
      "[576]\tvalidation_0-mlogloss:0.04929\tvalidation_1-mlogloss:0.33676\n",
      "[577]\tvalidation_0-mlogloss:0.04921\tvalidation_1-mlogloss:0.33697\n",
      "[578]\tvalidation_0-mlogloss:0.04917\tvalidation_1-mlogloss:0.33681\n",
      "[579]\tvalidation_0-mlogloss:0.04917\tvalidation_1-mlogloss:0.33684\n",
      "[580]\tvalidation_0-mlogloss:0.04912\tvalidation_1-mlogloss:0.33692\n",
      "[581]\tvalidation_0-mlogloss:0.04903\tvalidation_1-mlogloss:0.33717\n",
      "[582]\tvalidation_0-mlogloss:0.04895\tvalidation_1-mlogloss:0.33697\n",
      "[583]\tvalidation_0-mlogloss:0.04892\tvalidation_1-mlogloss:0.33689\n",
      "[584]\tvalidation_0-mlogloss:0.04885\tvalidation_1-mlogloss:0.33709\n",
      "[585]\tvalidation_0-mlogloss:0.04881\tvalidation_1-mlogloss:0.33703\n",
      "[586]\tvalidation_0-mlogloss:0.04877\tvalidation_1-mlogloss:0.33716\n",
      "[587]\tvalidation_0-mlogloss:0.04872\tvalidation_1-mlogloss:0.33717\n",
      "[588]\tvalidation_0-mlogloss:0.04864\tvalidation_1-mlogloss:0.33714\n",
      "[589]\tvalidation_0-mlogloss:0.04860\tvalidation_1-mlogloss:0.33724\n",
      "[590]\tvalidation_0-mlogloss:0.04857\tvalidation_1-mlogloss:0.33730\n",
      "[591]\tvalidation_0-mlogloss:0.04850\tvalidation_1-mlogloss:0.33728\n",
      "[592]\tvalidation_0-mlogloss:0.04847\tvalidation_1-mlogloss:0.33711\n",
      "[593]\tvalidation_0-mlogloss:0.04845\tvalidation_1-mlogloss:0.33703\n",
      "[594]\tvalidation_0-mlogloss:0.04838\tvalidation_1-mlogloss:0.33700\n",
      "[595]\tvalidation_0-mlogloss:0.04831\tvalidation_1-mlogloss:0.33695\n",
      "[596]\tvalidation_0-mlogloss:0.04827\tvalidation_1-mlogloss:0.33707\n",
      "[16:53:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-mlogloss:1.59266\tvalidation_1-mlogloss:1.59632\n",
      "[1]\tvalidation_0-mlogloss:1.57481\tvalidation_1-mlogloss:1.58325\n",
      "[2]\tvalidation_0-mlogloss:1.55615\tvalidation_1-mlogloss:1.56689\n",
      "[3]\tvalidation_0-mlogloss:1.53878\tvalidation_1-mlogloss:1.55363\n",
      "[4]\tvalidation_0-mlogloss:1.52285\tvalidation_1-mlogloss:1.54223\n",
      "[5]\tvalidation_0-mlogloss:1.50606\tvalidation_1-mlogloss:1.53053\n",
      "[6]\tvalidation_0-mlogloss:1.48895\tvalidation_1-mlogloss:1.51569\n",
      "[7]\tvalidation_0-mlogloss:1.47169\tvalidation_1-mlogloss:1.50042\n",
      "[8]\tvalidation_0-mlogloss:1.45587\tvalidation_1-mlogloss:1.48859\n",
      "[9]\tvalidation_0-mlogloss:1.43956\tvalidation_1-mlogloss:1.47640\n",
      "[10]\tvalidation_0-mlogloss:1.42342\tvalidation_1-mlogloss:1.46286\n",
      "[11]\tvalidation_0-mlogloss:1.40766\tvalidation_1-mlogloss:1.44962\n",
      "[12]\tvalidation_0-mlogloss:1.39204\tvalidation_1-mlogloss:1.43640\n",
      "[13]\tvalidation_0-mlogloss:1.37804\tvalidation_1-mlogloss:1.42589\n",
      "[14]\tvalidation_0-mlogloss:1.36339\tvalidation_1-mlogloss:1.41560\n",
      "[15]\tvalidation_0-mlogloss:1.34928\tvalidation_1-mlogloss:1.40402\n",
      "[16]\tvalidation_0-mlogloss:1.33503\tvalidation_1-mlogloss:1.39384\n",
      "[17]\tvalidation_0-mlogloss:1.32138\tvalidation_1-mlogloss:1.38354\n",
      "[18]\tvalidation_0-mlogloss:1.30683\tvalidation_1-mlogloss:1.37021\n",
      "[19]\tvalidation_0-mlogloss:1.29375\tvalidation_1-mlogloss:1.35957\n",
      "[20]\tvalidation_0-mlogloss:1.28017\tvalidation_1-mlogloss:1.34746\n",
      "[21]\tvalidation_0-mlogloss:1.26657\tvalidation_1-mlogloss:1.33598\n",
      "[22]\tvalidation_0-mlogloss:1.25311\tvalidation_1-mlogloss:1.32425\n",
      "[23]\tvalidation_0-mlogloss:1.24033\tvalidation_1-mlogloss:1.31488\n",
      "[24]\tvalidation_0-mlogloss:1.22787\tvalidation_1-mlogloss:1.30493\n",
      "[25]\tvalidation_0-mlogloss:1.21492\tvalidation_1-mlogloss:1.29437\n",
      "[26]\tvalidation_0-mlogloss:1.20256\tvalidation_1-mlogloss:1.28459\n",
      "[27]\tvalidation_0-mlogloss:1.19116\tvalidation_1-mlogloss:1.27644\n",
      "[28]\tvalidation_0-mlogloss:1.17919\tvalidation_1-mlogloss:1.26675\n",
      "[29]\tvalidation_0-mlogloss:1.16724\tvalidation_1-mlogloss:1.25663\n",
      "[30]\tvalidation_0-mlogloss:1.15674\tvalidation_1-mlogloss:1.24895\n",
      "[31]\tvalidation_0-mlogloss:1.14506\tvalidation_1-mlogloss:1.23817\n",
      "[32]\tvalidation_0-mlogloss:1.13343\tvalidation_1-mlogloss:1.22974\n",
      "[33]\tvalidation_0-mlogloss:1.12227\tvalidation_1-mlogloss:1.22063\n",
      "[34]\tvalidation_0-mlogloss:1.11090\tvalidation_1-mlogloss:1.21110\n",
      "[35]\tvalidation_0-mlogloss:1.10072\tvalidation_1-mlogloss:1.20244\n",
      "[36]\tvalidation_0-mlogloss:1.08999\tvalidation_1-mlogloss:1.19446\n",
      "[37]\tvalidation_0-mlogloss:1.07898\tvalidation_1-mlogloss:1.18550\n",
      "[38]\tvalidation_0-mlogloss:1.06814\tvalidation_1-mlogloss:1.17720\n",
      "[39]\tvalidation_0-mlogloss:1.05762\tvalidation_1-mlogloss:1.16943\n",
      "[40]\tvalidation_0-mlogloss:1.04765\tvalidation_1-mlogloss:1.16091\n",
      "[41]\tvalidation_0-mlogloss:1.03753\tvalidation_1-mlogloss:1.15163\n",
      "[42]\tvalidation_0-mlogloss:1.02844\tvalidation_1-mlogloss:1.14499\n",
      "[43]\tvalidation_0-mlogloss:1.01813\tvalidation_1-mlogloss:1.13660\n",
      "[44]\tvalidation_0-mlogloss:1.00768\tvalidation_1-mlogloss:1.12681\n",
      "[45]\tvalidation_0-mlogloss:0.99822\tvalidation_1-mlogloss:1.12065\n",
      "[46]\tvalidation_0-mlogloss:0.98903\tvalidation_1-mlogloss:1.11330\n",
      "[47]\tvalidation_0-mlogloss:0.97994\tvalidation_1-mlogloss:1.10588\n",
      "[48]\tvalidation_0-mlogloss:0.97033\tvalidation_1-mlogloss:1.09734\n",
      "[49]\tvalidation_0-mlogloss:0.96104\tvalidation_1-mlogloss:1.09014\n",
      "[50]\tvalidation_0-mlogloss:0.95201\tvalidation_1-mlogloss:1.08225\n",
      "[51]\tvalidation_0-mlogloss:0.94316\tvalidation_1-mlogloss:1.07577\n",
      "[52]\tvalidation_0-mlogloss:0.93362\tvalidation_1-mlogloss:1.06765\n",
      "[53]\tvalidation_0-mlogloss:0.92455\tvalidation_1-mlogloss:1.05951\n",
      "[54]\tvalidation_0-mlogloss:0.91593\tvalidation_1-mlogloss:1.05382\n",
      "[55]\tvalidation_0-mlogloss:0.90745\tvalidation_1-mlogloss:1.04778\n",
      "[56]\tvalidation_0-mlogloss:0.89978\tvalidation_1-mlogloss:1.04212\n",
      "[57]\tvalidation_0-mlogloss:0.89111\tvalidation_1-mlogloss:1.03565\n",
      "[58]\tvalidation_0-mlogloss:0.88320\tvalidation_1-mlogloss:1.02959\n",
      "[59]\tvalidation_0-mlogloss:0.87473\tvalidation_1-mlogloss:1.02163\n",
      "[60]\tvalidation_0-mlogloss:0.86656\tvalidation_1-mlogloss:1.01482\n",
      "[61]\tvalidation_0-mlogloss:0.85868\tvalidation_1-mlogloss:1.00827\n",
      "[62]\tvalidation_0-mlogloss:0.85020\tvalidation_1-mlogloss:1.00028\n",
      "[63]\tvalidation_0-mlogloss:0.84224\tvalidation_1-mlogloss:0.99374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64]\tvalidation_0-mlogloss:0.83444\tvalidation_1-mlogloss:0.98856\n",
      "[65]\tvalidation_0-mlogloss:0.82740\tvalidation_1-mlogloss:0.98317\n",
      "[66]\tvalidation_0-mlogloss:0.81988\tvalidation_1-mlogloss:0.97748\n",
      "[67]\tvalidation_0-mlogloss:0.81213\tvalidation_1-mlogloss:0.97177\n",
      "[68]\tvalidation_0-mlogloss:0.80457\tvalidation_1-mlogloss:0.96437\n",
      "[69]\tvalidation_0-mlogloss:0.79694\tvalidation_1-mlogloss:0.95791\n",
      "[70]\tvalidation_0-mlogloss:0.78968\tvalidation_1-mlogloss:0.95310\n",
      "[71]\tvalidation_0-mlogloss:0.78303\tvalidation_1-mlogloss:0.94851\n",
      "[72]\tvalidation_0-mlogloss:0.77612\tvalidation_1-mlogloss:0.94177\n",
      "[73]\tvalidation_0-mlogloss:0.76917\tvalidation_1-mlogloss:0.93505\n",
      "[74]\tvalidation_0-mlogloss:0.76205\tvalidation_1-mlogloss:0.92986\n",
      "[75]\tvalidation_0-mlogloss:0.75555\tvalidation_1-mlogloss:0.92410\n",
      "[76]\tvalidation_0-mlogloss:0.74851\tvalidation_1-mlogloss:0.91787\n",
      "[77]\tvalidation_0-mlogloss:0.74170\tvalidation_1-mlogloss:0.91174\n",
      "[78]\tvalidation_0-mlogloss:0.73562\tvalidation_1-mlogloss:0.90643\n",
      "[79]\tvalidation_0-mlogloss:0.72909\tvalidation_1-mlogloss:0.90210\n",
      "[80]\tvalidation_0-mlogloss:0.72214\tvalidation_1-mlogloss:0.89541\n",
      "[81]\tvalidation_0-mlogloss:0.71546\tvalidation_1-mlogloss:0.88890\n",
      "[82]\tvalidation_0-mlogloss:0.70885\tvalidation_1-mlogloss:0.88331\n",
      "[83]\tvalidation_0-mlogloss:0.70278\tvalidation_1-mlogloss:0.87800\n",
      "[84]\tvalidation_0-mlogloss:0.69669\tvalidation_1-mlogloss:0.87350\n",
      "[85]\tvalidation_0-mlogloss:0.69070\tvalidation_1-mlogloss:0.86845\n",
      "[86]\tvalidation_0-mlogloss:0.68490\tvalidation_1-mlogloss:0.86425\n",
      "[87]\tvalidation_0-mlogloss:0.67849\tvalidation_1-mlogloss:0.85808\n",
      "[88]\tvalidation_0-mlogloss:0.67254\tvalidation_1-mlogloss:0.85317\n",
      "[89]\tvalidation_0-mlogloss:0.66651\tvalidation_1-mlogloss:0.84824\n",
      "[90]\tvalidation_0-mlogloss:0.66059\tvalidation_1-mlogloss:0.84222\n",
      "[91]\tvalidation_0-mlogloss:0.65480\tvalidation_1-mlogloss:0.83755\n",
      "[92]\tvalidation_0-mlogloss:0.64895\tvalidation_1-mlogloss:0.83276\n",
      "[93]\tvalidation_0-mlogloss:0.64313\tvalidation_1-mlogloss:0.82759\n",
      "[94]\tvalidation_0-mlogloss:0.63729\tvalidation_1-mlogloss:0.82260\n",
      "[95]\tvalidation_0-mlogloss:0.63175\tvalidation_1-mlogloss:0.81830\n",
      "[96]\tvalidation_0-mlogloss:0.62620\tvalidation_1-mlogloss:0.81437\n",
      "[97]\tvalidation_0-mlogloss:0.62068\tvalidation_1-mlogloss:0.80932\n",
      "[98]\tvalidation_0-mlogloss:0.61536\tvalidation_1-mlogloss:0.80562\n",
      "[99]\tvalidation_0-mlogloss:0.60992\tvalidation_1-mlogloss:0.80044\n",
      "[100]\tvalidation_0-mlogloss:0.60456\tvalidation_1-mlogloss:0.79620\n",
      "[101]\tvalidation_0-mlogloss:0.59942\tvalidation_1-mlogloss:0.79272\n",
      "[102]\tvalidation_0-mlogloss:0.59407\tvalidation_1-mlogloss:0.78824\n",
      "[103]\tvalidation_0-mlogloss:0.58905\tvalidation_1-mlogloss:0.78464\n",
      "[104]\tvalidation_0-mlogloss:0.58398\tvalidation_1-mlogloss:0.78129\n",
      "[105]\tvalidation_0-mlogloss:0.57920\tvalidation_1-mlogloss:0.77788\n",
      "[106]\tvalidation_0-mlogloss:0.57419\tvalidation_1-mlogloss:0.77410\n",
      "[107]\tvalidation_0-mlogloss:0.56950\tvalidation_1-mlogloss:0.77071\n",
      "[108]\tvalidation_0-mlogloss:0.56444\tvalidation_1-mlogloss:0.76523\n",
      "[109]\tvalidation_0-mlogloss:0.55979\tvalidation_1-mlogloss:0.76159\n",
      "[110]\tvalidation_0-mlogloss:0.55497\tvalidation_1-mlogloss:0.75769\n",
      "[111]\tvalidation_0-mlogloss:0.55001\tvalidation_1-mlogloss:0.75319\n",
      "[112]\tvalidation_0-mlogloss:0.54527\tvalidation_1-mlogloss:0.74878\n",
      "[113]\tvalidation_0-mlogloss:0.54064\tvalidation_1-mlogloss:0.74568\n",
      "[114]\tvalidation_0-mlogloss:0.53591\tvalidation_1-mlogloss:0.74210\n",
      "[115]\tvalidation_0-mlogloss:0.53138\tvalidation_1-mlogloss:0.73880\n",
      "[116]\tvalidation_0-mlogloss:0.52673\tvalidation_1-mlogloss:0.73368\n",
      "[117]\tvalidation_0-mlogloss:0.52228\tvalidation_1-mlogloss:0.73009\n",
      "[118]\tvalidation_0-mlogloss:0.51768\tvalidation_1-mlogloss:0.72541\n",
      "[119]\tvalidation_0-mlogloss:0.51329\tvalidation_1-mlogloss:0.72182\n",
      "[120]\tvalidation_0-mlogloss:0.50888\tvalidation_1-mlogloss:0.71749\n",
      "[121]\tvalidation_0-mlogloss:0.50438\tvalidation_1-mlogloss:0.71357\n",
      "[122]\tvalidation_0-mlogloss:0.50044\tvalidation_1-mlogloss:0.71046\n",
      "[123]\tvalidation_0-mlogloss:0.49620\tvalidation_1-mlogloss:0.70645\n",
      "[124]\tvalidation_0-mlogloss:0.49193\tvalidation_1-mlogloss:0.70297\n",
      "[125]\tvalidation_0-mlogloss:0.48769\tvalidation_1-mlogloss:0.69905\n",
      "[126]\tvalidation_0-mlogloss:0.48362\tvalidation_1-mlogloss:0.69543\n",
      "[127]\tvalidation_0-mlogloss:0.47970\tvalidation_1-mlogloss:0.69190\n",
      "[128]\tvalidation_0-mlogloss:0.47585\tvalidation_1-mlogloss:0.68940\n",
      "[129]\tvalidation_0-mlogloss:0.47185\tvalidation_1-mlogloss:0.68570\n",
      "[130]\tvalidation_0-mlogloss:0.46793\tvalidation_1-mlogloss:0.68225\n",
      "[131]\tvalidation_0-mlogloss:0.46396\tvalidation_1-mlogloss:0.67740\n",
      "[132]\tvalidation_0-mlogloss:0.46009\tvalidation_1-mlogloss:0.67430\n",
      "[133]\tvalidation_0-mlogloss:0.45624\tvalidation_1-mlogloss:0.67154\n",
      "[134]\tvalidation_0-mlogloss:0.45252\tvalidation_1-mlogloss:0.66815\n",
      "[135]\tvalidation_0-mlogloss:0.44884\tvalidation_1-mlogloss:0.66467\n",
      "[136]\tvalidation_0-mlogloss:0.44492\tvalidation_1-mlogloss:0.66124\n",
      "[137]\tvalidation_0-mlogloss:0.44117\tvalidation_1-mlogloss:0.65742\n",
      "[138]\tvalidation_0-mlogloss:0.43757\tvalidation_1-mlogloss:0.65502\n",
      "[139]\tvalidation_0-mlogloss:0.43386\tvalidation_1-mlogloss:0.65121\n",
      "[140]\tvalidation_0-mlogloss:0.43033\tvalidation_1-mlogloss:0.64831\n",
      "[141]\tvalidation_0-mlogloss:0.42666\tvalidation_1-mlogloss:0.64473\n",
      "[142]\tvalidation_0-mlogloss:0.42299\tvalidation_1-mlogloss:0.64156\n",
      "[143]\tvalidation_0-mlogloss:0.41949\tvalidation_1-mlogloss:0.63803\n",
      "[144]\tvalidation_0-mlogloss:0.41613\tvalidation_1-mlogloss:0.63570\n",
      "[145]\tvalidation_0-mlogloss:0.41254\tvalidation_1-mlogloss:0.63258\n",
      "[146]\tvalidation_0-mlogloss:0.40922\tvalidation_1-mlogloss:0.62918\n",
      "[147]\tvalidation_0-mlogloss:0.40573\tvalidation_1-mlogloss:0.62591\n",
      "[148]\tvalidation_0-mlogloss:0.40235\tvalidation_1-mlogloss:0.62274\n",
      "[149]\tvalidation_0-mlogloss:0.39895\tvalidation_1-mlogloss:0.61921\n",
      "[150]\tvalidation_0-mlogloss:0.39605\tvalidation_1-mlogloss:0.61688\n",
      "[151]\tvalidation_0-mlogloss:0.39283\tvalidation_1-mlogloss:0.61359\n",
      "[152]\tvalidation_0-mlogloss:0.38974\tvalidation_1-mlogloss:0.61106\n",
      "[153]\tvalidation_0-mlogloss:0.38675\tvalidation_1-mlogloss:0.60858\n",
      "[154]\tvalidation_0-mlogloss:0.38351\tvalidation_1-mlogloss:0.60532\n",
      "[155]\tvalidation_0-mlogloss:0.38050\tvalidation_1-mlogloss:0.60277\n",
      "[156]\tvalidation_0-mlogloss:0.37733\tvalidation_1-mlogloss:0.59981\n",
      "[157]\tvalidation_0-mlogloss:0.37426\tvalidation_1-mlogloss:0.59708\n",
      "[158]\tvalidation_0-mlogloss:0.37119\tvalidation_1-mlogloss:0.59501\n",
      "[159]\tvalidation_0-mlogloss:0.36818\tvalidation_1-mlogloss:0.59198\n",
      "[160]\tvalidation_0-mlogloss:0.36506\tvalidation_1-mlogloss:0.58880\n",
      "[161]\tvalidation_0-mlogloss:0.36217\tvalidation_1-mlogloss:0.58626\n",
      "[162]\tvalidation_0-mlogloss:0.35941\tvalidation_1-mlogloss:0.58365\n",
      "[163]\tvalidation_0-mlogloss:0.35649\tvalidation_1-mlogloss:0.58046\n",
      "[164]\tvalidation_0-mlogloss:0.35364\tvalidation_1-mlogloss:0.57805\n",
      "[165]\tvalidation_0-mlogloss:0.35093\tvalidation_1-mlogloss:0.57625\n",
      "[166]\tvalidation_0-mlogloss:0.34825\tvalidation_1-mlogloss:0.57368\n",
      "[167]\tvalidation_0-mlogloss:0.34555\tvalidation_1-mlogloss:0.57112\n",
      "[168]\tvalidation_0-mlogloss:0.34277\tvalidation_1-mlogloss:0.56870\n",
      "[169]\tvalidation_0-mlogloss:0.34009\tvalidation_1-mlogloss:0.56681\n",
      "[170]\tvalidation_0-mlogloss:0.33750\tvalidation_1-mlogloss:0.56486\n",
      "[171]\tvalidation_0-mlogloss:0.33479\tvalidation_1-mlogloss:0.56267\n",
      "[172]\tvalidation_0-mlogloss:0.33217\tvalidation_1-mlogloss:0.55952\n",
      "[173]\tvalidation_0-mlogloss:0.32944\tvalidation_1-mlogloss:0.55717\n",
      "[174]\tvalidation_0-mlogloss:0.32681\tvalidation_1-mlogloss:0.55489\n",
      "[175]\tvalidation_0-mlogloss:0.32427\tvalidation_1-mlogloss:0.55289\n",
      "[176]\tvalidation_0-mlogloss:0.32185\tvalidation_1-mlogloss:0.55057\n",
      "[177]\tvalidation_0-mlogloss:0.31937\tvalidation_1-mlogloss:0.54844\n",
      "[178]\tvalidation_0-mlogloss:0.31694\tvalidation_1-mlogloss:0.54674\n",
      "[179]\tvalidation_0-mlogloss:0.31443\tvalidation_1-mlogloss:0.54468\n",
      "[180]\tvalidation_0-mlogloss:0.31210\tvalidation_1-mlogloss:0.54284\n",
      "[181]\tvalidation_0-mlogloss:0.30958\tvalidation_1-mlogloss:0.53990\n",
      "[182]\tvalidation_0-mlogloss:0.30719\tvalidation_1-mlogloss:0.53739\n",
      "[183]\tvalidation_0-mlogloss:0.30482\tvalidation_1-mlogloss:0.53561\n",
      "[184]\tvalidation_0-mlogloss:0.30240\tvalidation_1-mlogloss:0.53309\n",
      "[185]\tvalidation_0-mlogloss:0.30011\tvalidation_1-mlogloss:0.53144\n",
      "[186]\tvalidation_0-mlogloss:0.29788\tvalidation_1-mlogloss:0.52948\n",
      "[187]\tvalidation_0-mlogloss:0.29553\tvalidation_1-mlogloss:0.52742\n",
      "[188]\tvalidation_0-mlogloss:0.29326\tvalidation_1-mlogloss:0.52597\n",
      "[189]\tvalidation_0-mlogloss:0.29108\tvalidation_1-mlogloss:0.52415\n",
      "[190]\tvalidation_0-mlogloss:0.28876\tvalidation_1-mlogloss:0.52145\n",
      "[191]\tvalidation_0-mlogloss:0.28661\tvalidation_1-mlogloss:0.51953\n",
      "[192]\tvalidation_0-mlogloss:0.28450\tvalidation_1-mlogloss:0.51748\n",
      "[193]\tvalidation_0-mlogloss:0.28228\tvalidation_1-mlogloss:0.51538\n",
      "[194]\tvalidation_0-mlogloss:0.28028\tvalidation_1-mlogloss:0.51362\n",
      "[195]\tvalidation_0-mlogloss:0.27810\tvalidation_1-mlogloss:0.51136\n",
      "[196]\tvalidation_0-mlogloss:0.27594\tvalidation_1-mlogloss:0.50981\n",
      "[197]\tvalidation_0-mlogloss:0.27398\tvalidation_1-mlogloss:0.50821\n",
      "[198]\tvalidation_0-mlogloss:0.27190\tvalidation_1-mlogloss:0.50651\n",
      "[199]\tvalidation_0-mlogloss:0.26982\tvalidation_1-mlogloss:0.50427\n",
      "[200]\tvalidation_0-mlogloss:0.26786\tvalidation_1-mlogloss:0.50246\n",
      "[201]\tvalidation_0-mlogloss:0.26604\tvalidation_1-mlogloss:0.50083\n",
      "[202]\tvalidation_0-mlogloss:0.26401\tvalidation_1-mlogloss:0.49887\n",
      "[203]\tvalidation_0-mlogloss:0.26207\tvalidation_1-mlogloss:0.49767\n",
      "[204]\tvalidation_0-mlogloss:0.26011\tvalidation_1-mlogloss:0.49591\n",
      "[205]\tvalidation_0-mlogloss:0.25820\tvalidation_1-mlogloss:0.49424\n",
      "[206]\tvalidation_0-mlogloss:0.25627\tvalidation_1-mlogloss:0.49227\n",
      "[207]\tvalidation_0-mlogloss:0.25439\tvalidation_1-mlogloss:0.49029\n",
      "[208]\tvalidation_0-mlogloss:0.25250\tvalidation_1-mlogloss:0.48878\n",
      "[209]\tvalidation_0-mlogloss:0.25081\tvalidation_1-mlogloss:0.48797\n",
      "[210]\tvalidation_0-mlogloss:0.24903\tvalidation_1-mlogloss:0.48629\n",
      "[211]\tvalidation_0-mlogloss:0.24722\tvalidation_1-mlogloss:0.48502\n",
      "[212]\tvalidation_0-mlogloss:0.24543\tvalidation_1-mlogloss:0.48341\n",
      "[213]\tvalidation_0-mlogloss:0.24368\tvalidation_1-mlogloss:0.48149\n",
      "[214]\tvalidation_0-mlogloss:0.24182\tvalidation_1-mlogloss:0.48011\n",
      "[215]\tvalidation_0-mlogloss:0.24008\tvalidation_1-mlogloss:0.47931\n",
      "[216]\tvalidation_0-mlogloss:0.23838\tvalidation_1-mlogloss:0.47823\n",
      "[217]\tvalidation_0-mlogloss:0.23675\tvalidation_1-mlogloss:0.47679\n",
      "[218]\tvalidation_0-mlogloss:0.23503\tvalidation_1-mlogloss:0.47541\n",
      "[219]\tvalidation_0-mlogloss:0.23330\tvalidation_1-mlogloss:0.47421\n",
      "[220]\tvalidation_0-mlogloss:0.23177\tvalidation_1-mlogloss:0.47275\n",
      "[221]\tvalidation_0-mlogloss:0.23016\tvalidation_1-mlogloss:0.47199\n",
      "[222]\tvalidation_0-mlogloss:0.22846\tvalidation_1-mlogloss:0.47021\n",
      "[223]\tvalidation_0-mlogloss:0.22680\tvalidation_1-mlogloss:0.46876\n",
      "[224]\tvalidation_0-mlogloss:0.22522\tvalidation_1-mlogloss:0.46769\n",
      "[225]\tvalidation_0-mlogloss:0.22361\tvalidation_1-mlogloss:0.46585\n",
      "[226]\tvalidation_0-mlogloss:0.22196\tvalidation_1-mlogloss:0.46386\n",
      "[227]\tvalidation_0-mlogloss:0.22038\tvalidation_1-mlogloss:0.46240\n",
      "[228]\tvalidation_0-mlogloss:0.21873\tvalidation_1-mlogloss:0.46061\n",
      "[229]\tvalidation_0-mlogloss:0.21715\tvalidation_1-mlogloss:0.45945\n",
      "[230]\tvalidation_0-mlogloss:0.21566\tvalidation_1-mlogloss:0.45857\n",
      "[231]\tvalidation_0-mlogloss:0.21417\tvalidation_1-mlogloss:0.45791\n",
      "[232]\tvalidation_0-mlogloss:0.21266\tvalidation_1-mlogloss:0.45715\n",
      "[233]\tvalidation_0-mlogloss:0.21118\tvalidation_1-mlogloss:0.45605\n",
      "[234]\tvalidation_0-mlogloss:0.20980\tvalidation_1-mlogloss:0.45511\n",
      "[235]\tvalidation_0-mlogloss:0.20830\tvalidation_1-mlogloss:0.45378\n",
      "[236]\tvalidation_0-mlogloss:0.20697\tvalidation_1-mlogloss:0.45267\n",
      "[237]\tvalidation_0-mlogloss:0.20554\tvalidation_1-mlogloss:0.45085\n",
      "[238]\tvalidation_0-mlogloss:0.20421\tvalidation_1-mlogloss:0.45006\n",
      "[239]\tvalidation_0-mlogloss:0.20275\tvalidation_1-mlogloss:0.44871\n",
      "[240]\tvalidation_0-mlogloss:0.20137\tvalidation_1-mlogloss:0.44724\n",
      "[241]\tvalidation_0-mlogloss:0.19990\tvalidation_1-mlogloss:0.44564\n",
      "[242]\tvalidation_0-mlogloss:0.19863\tvalidation_1-mlogloss:0.44455\n",
      "[243]\tvalidation_0-mlogloss:0.19721\tvalidation_1-mlogloss:0.44344\n",
      "[244]\tvalidation_0-mlogloss:0.19582\tvalidation_1-mlogloss:0.44160\n",
      "[245]\tvalidation_0-mlogloss:0.19443\tvalidation_1-mlogloss:0.44088\n",
      "[246]\tvalidation_0-mlogloss:0.19306\tvalidation_1-mlogloss:0.43930\n",
      "[247]\tvalidation_0-mlogloss:0.19169\tvalidation_1-mlogloss:0.43767\n",
      "[248]\tvalidation_0-mlogloss:0.19034\tvalidation_1-mlogloss:0.43656\n",
      "[249]\tvalidation_0-mlogloss:0.18900\tvalidation_1-mlogloss:0.43544\n",
      "[250]\tvalidation_0-mlogloss:0.18764\tvalidation_1-mlogloss:0.43447\n",
      "[251]\tvalidation_0-mlogloss:0.18637\tvalidation_1-mlogloss:0.43314\n",
      "[252]\tvalidation_0-mlogloss:0.18511\tvalidation_1-mlogloss:0.43185\n",
      "[253]\tvalidation_0-mlogloss:0.18383\tvalidation_1-mlogloss:0.43120\n",
      "[254]\tvalidation_0-mlogloss:0.18263\tvalidation_1-mlogloss:0.43044\n",
      "[255]\tvalidation_0-mlogloss:0.18133\tvalidation_1-mlogloss:0.42939\n",
      "[256]\tvalidation_0-mlogloss:0.18009\tvalidation_1-mlogloss:0.42835\n",
      "[257]\tvalidation_0-mlogloss:0.17889\tvalidation_1-mlogloss:0.42790\n",
      "[258]\tvalidation_0-mlogloss:0.17772\tvalidation_1-mlogloss:0.42694\n",
      "[259]\tvalidation_0-mlogloss:0.17666\tvalidation_1-mlogloss:0.42608\n",
      "[260]\tvalidation_0-mlogloss:0.17552\tvalidation_1-mlogloss:0.42542\n",
      "[261]\tvalidation_0-mlogloss:0.17438\tvalidation_1-mlogloss:0.42500\n",
      "[262]\tvalidation_0-mlogloss:0.17328\tvalidation_1-mlogloss:0.42458\n",
      "[263]\tvalidation_0-mlogloss:0.17210\tvalidation_1-mlogloss:0.42364\n",
      "[264]\tvalidation_0-mlogloss:0.17097\tvalidation_1-mlogloss:0.42289\n",
      "[265]\tvalidation_0-mlogloss:0.16987\tvalidation_1-mlogloss:0.42187\n",
      "[266]\tvalidation_0-mlogloss:0.16874\tvalidation_1-mlogloss:0.42048\n",
      "[267]\tvalidation_0-mlogloss:0.16767\tvalidation_1-mlogloss:0.41958\n",
      "[268]\tvalidation_0-mlogloss:0.16655\tvalidation_1-mlogloss:0.41814\n",
      "[269]\tvalidation_0-mlogloss:0.16542\tvalidation_1-mlogloss:0.41752\n",
      "[270]\tvalidation_0-mlogloss:0.16449\tvalidation_1-mlogloss:0.41648\n",
      "[271]\tvalidation_0-mlogloss:0.16339\tvalidation_1-mlogloss:0.41534\n",
      "[272]\tvalidation_0-mlogloss:0.16234\tvalidation_1-mlogloss:0.41449\n",
      "[273]\tvalidation_0-mlogloss:0.16125\tvalidation_1-mlogloss:0.41397\n",
      "[274]\tvalidation_0-mlogloss:0.16027\tvalidation_1-mlogloss:0.41334\n",
      "[275]\tvalidation_0-mlogloss:0.15928\tvalidation_1-mlogloss:0.41289\n",
      "[276]\tvalidation_0-mlogloss:0.15823\tvalidation_1-mlogloss:0.41221\n",
      "[277]\tvalidation_0-mlogloss:0.15723\tvalidation_1-mlogloss:0.41144\n",
      "[278]\tvalidation_0-mlogloss:0.15626\tvalidation_1-mlogloss:0.41067\n",
      "[279]\tvalidation_0-mlogloss:0.15531\tvalidation_1-mlogloss:0.40985\n",
      "[280]\tvalidation_0-mlogloss:0.15426\tvalidation_1-mlogloss:0.40901\n",
      "[281]\tvalidation_0-mlogloss:0.15327\tvalidation_1-mlogloss:0.40813\n",
      "[282]\tvalidation_0-mlogloss:0.15229\tvalidation_1-mlogloss:0.40710\n",
      "[283]\tvalidation_0-mlogloss:0.15129\tvalidation_1-mlogloss:0.40570\n",
      "[284]\tvalidation_0-mlogloss:0.15035\tvalidation_1-mlogloss:0.40543\n",
      "[285]\tvalidation_0-mlogloss:0.14950\tvalidation_1-mlogloss:0.40500\n",
      "[286]\tvalidation_0-mlogloss:0.14851\tvalidation_1-mlogloss:0.40383\n",
      "[287]\tvalidation_0-mlogloss:0.14757\tvalidation_1-mlogloss:0.40340\n",
      "[288]\tvalidation_0-mlogloss:0.14673\tvalidation_1-mlogloss:0.40268\n",
      "[289]\tvalidation_0-mlogloss:0.14578\tvalidation_1-mlogloss:0.40168\n",
      "[290]\tvalidation_0-mlogloss:0.14493\tvalidation_1-mlogloss:0.40084\n",
      "[291]\tvalidation_0-mlogloss:0.14411\tvalidation_1-mlogloss:0.40044\n",
      "[292]\tvalidation_0-mlogloss:0.14323\tvalidation_1-mlogloss:0.39975\n",
      "[293]\tvalidation_0-mlogloss:0.14233\tvalidation_1-mlogloss:0.39886\n",
      "[294]\tvalidation_0-mlogloss:0.14141\tvalidation_1-mlogloss:0.39773\n",
      "[295]\tvalidation_0-mlogloss:0.14061\tvalidation_1-mlogloss:0.39720\n",
      "[296]\tvalidation_0-mlogloss:0.13973\tvalidation_1-mlogloss:0.39673\n",
      "[297]\tvalidation_0-mlogloss:0.13890\tvalidation_1-mlogloss:0.39646\n",
      "[298]\tvalidation_0-mlogloss:0.13806\tvalidation_1-mlogloss:0.39584\n",
      "[299]\tvalidation_0-mlogloss:0.13723\tvalidation_1-mlogloss:0.39556\n",
      "[300]\tvalidation_0-mlogloss:0.13636\tvalidation_1-mlogloss:0.39501\n",
      "[301]\tvalidation_0-mlogloss:0.13554\tvalidation_1-mlogloss:0.39488\n",
      "[302]\tvalidation_0-mlogloss:0.13468\tvalidation_1-mlogloss:0.39414\n",
      "[303]\tvalidation_0-mlogloss:0.13388\tvalidation_1-mlogloss:0.39327\n",
      "[304]\tvalidation_0-mlogloss:0.13306\tvalidation_1-mlogloss:0.39245\n",
      "[305]\tvalidation_0-mlogloss:0.13232\tvalidation_1-mlogloss:0.39212\n",
      "[306]\tvalidation_0-mlogloss:0.13153\tvalidation_1-mlogloss:0.39132\n",
      "[307]\tvalidation_0-mlogloss:0.13072\tvalidation_1-mlogloss:0.39076\n",
      "[308]\tvalidation_0-mlogloss:0.12989\tvalidation_1-mlogloss:0.38978\n",
      "[309]\tvalidation_0-mlogloss:0.12918\tvalidation_1-mlogloss:0.38944\n",
      "[310]\tvalidation_0-mlogloss:0.12841\tvalidation_1-mlogloss:0.38874\n",
      "[311]\tvalidation_0-mlogloss:0.12767\tvalidation_1-mlogloss:0.38820\n",
      "[312]\tvalidation_0-mlogloss:0.12701\tvalidation_1-mlogloss:0.38771\n",
      "[313]\tvalidation_0-mlogloss:0.12631\tvalidation_1-mlogloss:0.38759\n",
      "[314]\tvalidation_0-mlogloss:0.12557\tvalidation_1-mlogloss:0.38709\n",
      "[315]\tvalidation_0-mlogloss:0.12488\tvalidation_1-mlogloss:0.38676\n",
      "[316]\tvalidation_0-mlogloss:0.12412\tvalidation_1-mlogloss:0.38594\n",
      "[317]\tvalidation_0-mlogloss:0.12342\tvalidation_1-mlogloss:0.38547\n",
      "[318]\tvalidation_0-mlogloss:0.12264\tvalidation_1-mlogloss:0.38501\n",
      "[319]\tvalidation_0-mlogloss:0.12191\tvalidation_1-mlogloss:0.38441\n",
      "[320]\tvalidation_0-mlogloss:0.12125\tvalidation_1-mlogloss:0.38415\n",
      "[321]\tvalidation_0-mlogloss:0.12050\tvalidation_1-mlogloss:0.38345\n",
      "[322]\tvalidation_0-mlogloss:0.11982\tvalidation_1-mlogloss:0.38296\n",
      "[323]\tvalidation_0-mlogloss:0.11913\tvalidation_1-mlogloss:0.38235\n",
      "[324]\tvalidation_0-mlogloss:0.11839\tvalidation_1-mlogloss:0.38159\n",
      "[325]\tvalidation_0-mlogloss:0.11772\tvalidation_1-mlogloss:0.38123\n",
      "[326]\tvalidation_0-mlogloss:0.11704\tvalidation_1-mlogloss:0.38052\n",
      "[327]\tvalidation_0-mlogloss:0.11640\tvalidation_1-mlogloss:0.38039\n",
      "[328]\tvalidation_0-mlogloss:0.11573\tvalidation_1-mlogloss:0.37982\n",
      "[329]\tvalidation_0-mlogloss:0.11511\tvalidation_1-mlogloss:0.37917\n",
      "[330]\tvalidation_0-mlogloss:0.11446\tvalidation_1-mlogloss:0.37836\n",
      "[331]\tvalidation_0-mlogloss:0.11381\tvalidation_1-mlogloss:0.37790\n",
      "[332]\tvalidation_0-mlogloss:0.11325\tvalidation_1-mlogloss:0.37752\n",
      "[333]\tvalidation_0-mlogloss:0.11267\tvalidation_1-mlogloss:0.37705\n",
      "[334]\tvalidation_0-mlogloss:0.11206\tvalidation_1-mlogloss:0.37671\n",
      "[335]\tvalidation_0-mlogloss:0.11140\tvalidation_1-mlogloss:0.37629\n",
      "[336]\tvalidation_0-mlogloss:0.11076\tvalidation_1-mlogloss:0.37558\n",
      "[337]\tvalidation_0-mlogloss:0.11012\tvalidation_1-mlogloss:0.37506\n",
      "[338]\tvalidation_0-mlogloss:0.10954\tvalidation_1-mlogloss:0.37454\n",
      "[339]\tvalidation_0-mlogloss:0.10893\tvalidation_1-mlogloss:0.37398\n",
      "[340]\tvalidation_0-mlogloss:0.10833\tvalidation_1-mlogloss:0.37383\n",
      "[341]\tvalidation_0-mlogloss:0.10775\tvalidation_1-mlogloss:0.37357\n",
      "[342]\tvalidation_0-mlogloss:0.10713\tvalidation_1-mlogloss:0.37318\n",
      "[343]\tvalidation_0-mlogloss:0.10656\tvalidation_1-mlogloss:0.37276\n",
      "[344]\tvalidation_0-mlogloss:0.10601\tvalidation_1-mlogloss:0.37257\n",
      "[345]\tvalidation_0-mlogloss:0.10544\tvalidation_1-mlogloss:0.37242\n",
      "[346]\tvalidation_0-mlogloss:0.10483\tvalidation_1-mlogloss:0.37206\n",
      "[347]\tvalidation_0-mlogloss:0.10424\tvalidation_1-mlogloss:0.37186\n",
      "[348]\tvalidation_0-mlogloss:0.10372\tvalidation_1-mlogloss:0.37182\n",
      "[349]\tvalidation_0-mlogloss:0.10320\tvalidation_1-mlogloss:0.37169\n",
      "[350]\tvalidation_0-mlogloss:0.10260\tvalidation_1-mlogloss:0.37113\n",
      "[351]\tvalidation_0-mlogloss:0.10203\tvalidation_1-mlogloss:0.37048\n",
      "[352]\tvalidation_0-mlogloss:0.10148\tvalidation_1-mlogloss:0.36982\n",
      "[353]\tvalidation_0-mlogloss:0.10091\tvalidation_1-mlogloss:0.36911\n",
      "[354]\tvalidation_0-mlogloss:0.10037\tvalidation_1-mlogloss:0.36889\n",
      "[355]\tvalidation_0-mlogloss:0.09981\tvalidation_1-mlogloss:0.36821\n",
      "[356]\tvalidation_0-mlogloss:0.09932\tvalidation_1-mlogloss:0.36786\n",
      "[357]\tvalidation_0-mlogloss:0.09881\tvalidation_1-mlogloss:0.36739\n",
      "[358]\tvalidation_0-mlogloss:0.09826\tvalidation_1-mlogloss:0.36682\n",
      "[359]\tvalidation_0-mlogloss:0.09777\tvalidation_1-mlogloss:0.36621\n",
      "[360]\tvalidation_0-mlogloss:0.09727\tvalidation_1-mlogloss:0.36609\n",
      "[361]\tvalidation_0-mlogloss:0.09674\tvalidation_1-mlogloss:0.36593\n",
      "[362]\tvalidation_0-mlogloss:0.09622\tvalidation_1-mlogloss:0.36544\n",
      "[363]\tvalidation_0-mlogloss:0.09569\tvalidation_1-mlogloss:0.36490\n",
      "[364]\tvalidation_0-mlogloss:0.09519\tvalidation_1-mlogloss:0.36501\n",
      "[365]\tvalidation_0-mlogloss:0.09468\tvalidation_1-mlogloss:0.36475\n",
      "[366]\tvalidation_0-mlogloss:0.09419\tvalidation_1-mlogloss:0.36463\n",
      "[367]\tvalidation_0-mlogloss:0.09370\tvalidation_1-mlogloss:0.36433\n",
      "[368]\tvalidation_0-mlogloss:0.09319\tvalidation_1-mlogloss:0.36361\n",
      "[369]\tvalidation_0-mlogloss:0.09270\tvalidation_1-mlogloss:0.36328\n",
      "[370]\tvalidation_0-mlogloss:0.09220\tvalidation_1-mlogloss:0.36282\n",
      "[371]\tvalidation_0-mlogloss:0.09172\tvalidation_1-mlogloss:0.36265\n",
      "[372]\tvalidation_0-mlogloss:0.09127\tvalidation_1-mlogloss:0.36254\n",
      "[373]\tvalidation_0-mlogloss:0.09082\tvalidation_1-mlogloss:0.36217\n",
      "[374]\tvalidation_0-mlogloss:0.09041\tvalidation_1-mlogloss:0.36165\n",
      "[375]\tvalidation_0-mlogloss:0.08994\tvalidation_1-mlogloss:0.36173\n",
      "[376]\tvalidation_0-mlogloss:0.08949\tvalidation_1-mlogloss:0.36114\n",
      "[377]\tvalidation_0-mlogloss:0.08910\tvalidation_1-mlogloss:0.36086\n",
      "[378]\tvalidation_0-mlogloss:0.08866\tvalidation_1-mlogloss:0.36024\n",
      "[379]\tvalidation_0-mlogloss:0.08820\tvalidation_1-mlogloss:0.35986\n",
      "[380]\tvalidation_0-mlogloss:0.08777\tvalidation_1-mlogloss:0.35960\n",
      "[381]\tvalidation_0-mlogloss:0.08734\tvalidation_1-mlogloss:0.35912\n",
      "[382]\tvalidation_0-mlogloss:0.08694\tvalidation_1-mlogloss:0.35889\n",
      "[383]\tvalidation_0-mlogloss:0.08651\tvalidation_1-mlogloss:0.35839\n",
      "[384]\tvalidation_0-mlogloss:0.08609\tvalidation_1-mlogloss:0.35762\n",
      "[385]\tvalidation_0-mlogloss:0.08566\tvalidation_1-mlogloss:0.35724\n",
      "[386]\tvalidation_0-mlogloss:0.08524\tvalidation_1-mlogloss:0.35674\n",
      "[387]\tvalidation_0-mlogloss:0.08479\tvalidation_1-mlogloss:0.35605\n",
      "[388]\tvalidation_0-mlogloss:0.08438\tvalidation_1-mlogloss:0.35543\n",
      "[389]\tvalidation_0-mlogloss:0.08397\tvalidation_1-mlogloss:0.35540\n",
      "[390]\tvalidation_0-mlogloss:0.08361\tvalidation_1-mlogloss:0.35518\n",
      "[391]\tvalidation_0-mlogloss:0.08327\tvalidation_1-mlogloss:0.35500\n",
      "[392]\tvalidation_0-mlogloss:0.08290\tvalidation_1-mlogloss:0.35475\n",
      "[393]\tvalidation_0-mlogloss:0.08252\tvalidation_1-mlogloss:0.35469\n",
      "[394]\tvalidation_0-mlogloss:0.08215\tvalidation_1-mlogloss:0.35460\n",
      "[395]\tvalidation_0-mlogloss:0.08180\tvalidation_1-mlogloss:0.35464\n",
      "[396]\tvalidation_0-mlogloss:0.08145\tvalidation_1-mlogloss:0.35439\n",
      "[397]\tvalidation_0-mlogloss:0.08104\tvalidation_1-mlogloss:0.35385\n",
      "[398]\tvalidation_0-mlogloss:0.08070\tvalidation_1-mlogloss:0.35325\n",
      "[399]\tvalidation_0-mlogloss:0.08031\tvalidation_1-mlogloss:0.35303\n",
      "[400]\tvalidation_0-mlogloss:0.07995\tvalidation_1-mlogloss:0.35301\n",
      "[401]\tvalidation_0-mlogloss:0.07957\tvalidation_1-mlogloss:0.35305\n",
      "[402]\tvalidation_0-mlogloss:0.07921\tvalidation_1-mlogloss:0.35298\n",
      "[403]\tvalidation_0-mlogloss:0.07886\tvalidation_1-mlogloss:0.35253\n",
      "[404]\tvalidation_0-mlogloss:0.07847\tvalidation_1-mlogloss:0.35251\n",
      "[405]\tvalidation_0-mlogloss:0.07810\tvalidation_1-mlogloss:0.35234\n",
      "[406]\tvalidation_0-mlogloss:0.07771\tvalidation_1-mlogloss:0.35198\n",
      "[407]\tvalidation_0-mlogloss:0.07735\tvalidation_1-mlogloss:0.35153\n",
      "[408]\tvalidation_0-mlogloss:0.07695\tvalidation_1-mlogloss:0.35130\n",
      "[409]\tvalidation_0-mlogloss:0.07663\tvalidation_1-mlogloss:0.35086\n",
      "[410]\tvalidation_0-mlogloss:0.07631\tvalidation_1-mlogloss:0.35072\n",
      "[411]\tvalidation_0-mlogloss:0.07599\tvalidation_1-mlogloss:0.35065\n",
      "[412]\tvalidation_0-mlogloss:0.07570\tvalidation_1-mlogloss:0.35058\n",
      "[413]\tvalidation_0-mlogloss:0.07536\tvalidation_1-mlogloss:0.35063\n",
      "[414]\tvalidation_0-mlogloss:0.07501\tvalidation_1-mlogloss:0.35002\n",
      "[415]\tvalidation_0-mlogloss:0.07470\tvalidation_1-mlogloss:0.34975\n",
      "[416]\tvalidation_0-mlogloss:0.07435\tvalidation_1-mlogloss:0.34991\n",
      "[417]\tvalidation_0-mlogloss:0.07400\tvalidation_1-mlogloss:0.34955\n",
      "[418]\tvalidation_0-mlogloss:0.07369\tvalidation_1-mlogloss:0.34925\n",
      "[419]\tvalidation_0-mlogloss:0.07344\tvalidation_1-mlogloss:0.34902\n",
      "[420]\tvalidation_0-mlogloss:0.07318\tvalidation_1-mlogloss:0.34910\n",
      "[421]\tvalidation_0-mlogloss:0.07286\tvalidation_1-mlogloss:0.34861\n",
      "[422]\tvalidation_0-mlogloss:0.07255\tvalidation_1-mlogloss:0.34833\n",
      "[423]\tvalidation_0-mlogloss:0.07223\tvalidation_1-mlogloss:0.34840\n",
      "[424]\tvalidation_0-mlogloss:0.07191\tvalidation_1-mlogloss:0.34851\n",
      "[425]\tvalidation_0-mlogloss:0.07159\tvalidation_1-mlogloss:0.34813\n",
      "[426]\tvalidation_0-mlogloss:0.07129\tvalidation_1-mlogloss:0.34824\n",
      "[427]\tvalidation_0-mlogloss:0.07102\tvalidation_1-mlogloss:0.34832\n",
      "[428]\tvalidation_0-mlogloss:0.07074\tvalidation_1-mlogloss:0.34838\n",
      "[429]\tvalidation_0-mlogloss:0.07048\tvalidation_1-mlogloss:0.34808\n",
      "[430]\tvalidation_0-mlogloss:0.07014\tvalidation_1-mlogloss:0.34771\n",
      "[431]\tvalidation_0-mlogloss:0.06985\tvalidation_1-mlogloss:0.34758\n",
      "[432]\tvalidation_0-mlogloss:0.06958\tvalidation_1-mlogloss:0.34738\n",
      "[433]\tvalidation_0-mlogloss:0.06930\tvalidation_1-mlogloss:0.34754\n",
      "[434]\tvalidation_0-mlogloss:0.06898\tvalidation_1-mlogloss:0.34677\n",
      "[435]\tvalidation_0-mlogloss:0.06869\tvalidation_1-mlogloss:0.34640\n",
      "[436]\tvalidation_0-mlogloss:0.06841\tvalidation_1-mlogloss:0.34632\n",
      "[437]\tvalidation_0-mlogloss:0.06815\tvalidation_1-mlogloss:0.34625\n",
      "[438]\tvalidation_0-mlogloss:0.06791\tvalidation_1-mlogloss:0.34627\n",
      "[439]\tvalidation_0-mlogloss:0.06763\tvalidation_1-mlogloss:0.34586\n",
      "[440]\tvalidation_0-mlogloss:0.06738\tvalidation_1-mlogloss:0.34581\n",
      "[441]\tvalidation_0-mlogloss:0.06714\tvalidation_1-mlogloss:0.34578\n",
      "[442]\tvalidation_0-mlogloss:0.06689\tvalidation_1-mlogloss:0.34571\n",
      "[443]\tvalidation_0-mlogloss:0.06672\tvalidation_1-mlogloss:0.34554\n",
      "[444]\tvalidation_0-mlogloss:0.06648\tvalidation_1-mlogloss:0.34518\n",
      "[445]\tvalidation_0-mlogloss:0.06620\tvalidation_1-mlogloss:0.34513\n",
      "[446]\tvalidation_0-mlogloss:0.06603\tvalidation_1-mlogloss:0.34487\n",
      "[447]\tvalidation_0-mlogloss:0.06583\tvalidation_1-mlogloss:0.34481\n",
      "[448]\tvalidation_0-mlogloss:0.06559\tvalidation_1-mlogloss:0.34447\n",
      "[449]\tvalidation_0-mlogloss:0.06531\tvalidation_1-mlogloss:0.34446\n",
      "[450]\tvalidation_0-mlogloss:0.06506\tvalidation_1-mlogloss:0.34449\n",
      "[451]\tvalidation_0-mlogloss:0.06481\tvalidation_1-mlogloss:0.34432\n",
      "[452]\tvalidation_0-mlogloss:0.06459\tvalidation_1-mlogloss:0.34437\n",
      "[453]\tvalidation_0-mlogloss:0.06435\tvalidation_1-mlogloss:0.34447\n",
      "[454]\tvalidation_0-mlogloss:0.06412\tvalidation_1-mlogloss:0.34450\n",
      "[455]\tvalidation_0-mlogloss:0.06389\tvalidation_1-mlogloss:0.34432\n",
      "[456]\tvalidation_0-mlogloss:0.06362\tvalidation_1-mlogloss:0.34409\n",
      "[457]\tvalidation_0-mlogloss:0.06338\tvalidation_1-mlogloss:0.34395\n",
      "[458]\tvalidation_0-mlogloss:0.06317\tvalidation_1-mlogloss:0.34366\n",
      "[459]\tvalidation_0-mlogloss:0.06293\tvalidation_1-mlogloss:0.34334\n",
      "[460]\tvalidation_0-mlogloss:0.06280\tvalidation_1-mlogloss:0.34330\n",
      "[461]\tvalidation_0-mlogloss:0.06255\tvalidation_1-mlogloss:0.34285\n",
      "[462]\tvalidation_0-mlogloss:0.06233\tvalidation_1-mlogloss:0.34266\n",
      "[463]\tvalidation_0-mlogloss:0.06210\tvalidation_1-mlogloss:0.34270\n",
      "[464]\tvalidation_0-mlogloss:0.06185\tvalidation_1-mlogloss:0.34237\n",
      "[465]\tvalidation_0-mlogloss:0.06169\tvalidation_1-mlogloss:0.34231\n",
      "[466]\tvalidation_0-mlogloss:0.06152\tvalidation_1-mlogloss:0.34231\n",
      "[467]\tvalidation_0-mlogloss:0.06133\tvalidation_1-mlogloss:0.34201\n",
      "[468]\tvalidation_0-mlogloss:0.06114\tvalidation_1-mlogloss:0.34203\n",
      "[469]\tvalidation_0-mlogloss:0.06094\tvalidation_1-mlogloss:0.34167\n",
      "[470]\tvalidation_0-mlogloss:0.06074\tvalidation_1-mlogloss:0.34189\n",
      "[471]\tvalidation_0-mlogloss:0.06059\tvalidation_1-mlogloss:0.34160\n",
      "[472]\tvalidation_0-mlogloss:0.06044\tvalidation_1-mlogloss:0.34157\n",
      "[473]\tvalidation_0-mlogloss:0.06026\tvalidation_1-mlogloss:0.34150\n",
      "[474]\tvalidation_0-mlogloss:0.06006\tvalidation_1-mlogloss:0.34135\n",
      "[475]\tvalidation_0-mlogloss:0.05986\tvalidation_1-mlogloss:0.34122\n",
      "[476]\tvalidation_0-mlogloss:0.05963\tvalidation_1-mlogloss:0.34104\n",
      "[477]\tvalidation_0-mlogloss:0.05945\tvalidation_1-mlogloss:0.34125\n",
      "[478]\tvalidation_0-mlogloss:0.05929\tvalidation_1-mlogloss:0.34090\n",
      "[479]\tvalidation_0-mlogloss:0.05915\tvalidation_1-mlogloss:0.34100\n",
      "[480]\tvalidation_0-mlogloss:0.05897\tvalidation_1-mlogloss:0.34043\n",
      "[481]\tvalidation_0-mlogloss:0.05884\tvalidation_1-mlogloss:0.34002\n",
      "[482]\tvalidation_0-mlogloss:0.05862\tvalidation_1-mlogloss:0.33981\n",
      "[483]\tvalidation_0-mlogloss:0.05843\tvalidation_1-mlogloss:0.33957\n",
      "[484]\tvalidation_0-mlogloss:0.05822\tvalidation_1-mlogloss:0.33967\n",
      "[485]\tvalidation_0-mlogloss:0.05810\tvalidation_1-mlogloss:0.33931\n",
      "[486]\tvalidation_0-mlogloss:0.05790\tvalidation_1-mlogloss:0.33871\n",
      "[487]\tvalidation_0-mlogloss:0.05783\tvalidation_1-mlogloss:0.33867\n",
      "[488]\tvalidation_0-mlogloss:0.05764\tvalidation_1-mlogloss:0.33848\n",
      "[489]\tvalidation_0-mlogloss:0.05745\tvalidation_1-mlogloss:0.33801\n",
      "[490]\tvalidation_0-mlogloss:0.05734\tvalidation_1-mlogloss:0.33809\n",
      "[491]\tvalidation_0-mlogloss:0.05719\tvalidation_1-mlogloss:0.33787\n",
      "[492]\tvalidation_0-mlogloss:0.05700\tvalidation_1-mlogloss:0.33779\n",
      "[493]\tvalidation_0-mlogloss:0.05681\tvalidation_1-mlogloss:0.33762\n",
      "[494]\tvalidation_0-mlogloss:0.05669\tvalidation_1-mlogloss:0.33735\n",
      "[495]\tvalidation_0-mlogloss:0.05652\tvalidation_1-mlogloss:0.33750\n",
      "[496]\tvalidation_0-mlogloss:0.05643\tvalidation_1-mlogloss:0.33737\n",
      "[497]\tvalidation_0-mlogloss:0.05627\tvalidation_1-mlogloss:0.33746\n",
      "[498]\tvalidation_0-mlogloss:0.05616\tvalidation_1-mlogloss:0.33749\n",
      "[499]\tvalidation_0-mlogloss:0.05604\tvalidation_1-mlogloss:0.33762\n",
      "[500]\tvalidation_0-mlogloss:0.05587\tvalidation_1-mlogloss:0.33752\n",
      "[501]\tvalidation_0-mlogloss:0.05575\tvalidation_1-mlogloss:0.33741\n",
      "[502]\tvalidation_0-mlogloss:0.05565\tvalidation_1-mlogloss:0.33705\n",
      "[503]\tvalidation_0-mlogloss:0.05556\tvalidation_1-mlogloss:0.33714\n",
      "[504]\tvalidation_0-mlogloss:0.05543\tvalidation_1-mlogloss:0.33667\n",
      "[505]\tvalidation_0-mlogloss:0.05533\tvalidation_1-mlogloss:0.33653\n",
      "[506]\tvalidation_0-mlogloss:0.05522\tvalidation_1-mlogloss:0.33618\n",
      "[507]\tvalidation_0-mlogloss:0.05509\tvalidation_1-mlogloss:0.33583\n",
      "[508]\tvalidation_0-mlogloss:0.05500\tvalidation_1-mlogloss:0.33578\n",
      "[509]\tvalidation_0-mlogloss:0.05485\tvalidation_1-mlogloss:0.33574\n",
      "[510]\tvalidation_0-mlogloss:0.05470\tvalidation_1-mlogloss:0.33551\n",
      "[511]\tvalidation_0-mlogloss:0.05460\tvalidation_1-mlogloss:0.33524\n",
      "[512]\tvalidation_0-mlogloss:0.05447\tvalidation_1-mlogloss:0.33527\n",
      "[513]\tvalidation_0-mlogloss:0.05435\tvalidation_1-mlogloss:0.33514\n",
      "[514]\tvalidation_0-mlogloss:0.05425\tvalidation_1-mlogloss:0.33515\n",
      "[515]\tvalidation_0-mlogloss:0.05414\tvalidation_1-mlogloss:0.33507\n",
      "[516]\tvalidation_0-mlogloss:0.05399\tvalidation_1-mlogloss:0.33494\n",
      "[517]\tvalidation_0-mlogloss:0.05384\tvalidation_1-mlogloss:0.33458\n",
      "[518]\tvalidation_0-mlogloss:0.05374\tvalidation_1-mlogloss:0.33443\n",
      "[519]\tvalidation_0-mlogloss:0.05359\tvalidation_1-mlogloss:0.33436\n",
      "[520]\tvalidation_0-mlogloss:0.05349\tvalidation_1-mlogloss:0.33436\n",
      "[521]\tvalidation_0-mlogloss:0.05343\tvalidation_1-mlogloss:0.33415\n",
      "[522]\tvalidation_0-mlogloss:0.05333\tvalidation_1-mlogloss:0.33401\n",
      "[523]\tvalidation_0-mlogloss:0.05324\tvalidation_1-mlogloss:0.33394\n",
      "[524]\tvalidation_0-mlogloss:0.05314\tvalidation_1-mlogloss:0.33378\n",
      "[525]\tvalidation_0-mlogloss:0.05305\tvalidation_1-mlogloss:0.33357\n",
      "[526]\tvalidation_0-mlogloss:0.05291\tvalidation_1-mlogloss:0.33334\n",
      "[527]\tvalidation_0-mlogloss:0.05284\tvalidation_1-mlogloss:0.33316\n",
      "[528]\tvalidation_0-mlogloss:0.05273\tvalidation_1-mlogloss:0.33304\n",
      "[529]\tvalidation_0-mlogloss:0.05262\tvalidation_1-mlogloss:0.33269\n",
      "[530]\tvalidation_0-mlogloss:0.05252\tvalidation_1-mlogloss:0.33260\n",
      "[531]\tvalidation_0-mlogloss:0.05242\tvalidation_1-mlogloss:0.33226\n",
      "[532]\tvalidation_0-mlogloss:0.05233\tvalidation_1-mlogloss:0.33214\n",
      "[533]\tvalidation_0-mlogloss:0.05223\tvalidation_1-mlogloss:0.33230\n",
      "[534]\tvalidation_0-mlogloss:0.05210\tvalidation_1-mlogloss:0.33232\n",
      "[535]\tvalidation_0-mlogloss:0.05201\tvalidation_1-mlogloss:0.33231\n",
      "[536]\tvalidation_0-mlogloss:0.05195\tvalidation_1-mlogloss:0.33226\n",
      "[537]\tvalidation_0-mlogloss:0.05189\tvalidation_1-mlogloss:0.33223\n",
      "[538]\tvalidation_0-mlogloss:0.05179\tvalidation_1-mlogloss:0.33206\n",
      "[539]\tvalidation_0-mlogloss:0.05175\tvalidation_1-mlogloss:0.33206\n",
      "[540]\tvalidation_0-mlogloss:0.05165\tvalidation_1-mlogloss:0.33191\n",
      "[541]\tvalidation_0-mlogloss:0.05157\tvalidation_1-mlogloss:0.33182\n",
      "[542]\tvalidation_0-mlogloss:0.05148\tvalidation_1-mlogloss:0.33176\n",
      "[543]\tvalidation_0-mlogloss:0.05143\tvalidation_1-mlogloss:0.33160\n",
      "[544]\tvalidation_0-mlogloss:0.05137\tvalidation_1-mlogloss:0.33138\n",
      "[545]\tvalidation_0-mlogloss:0.05127\tvalidation_1-mlogloss:0.33139\n",
      "[546]\tvalidation_0-mlogloss:0.05122\tvalidation_1-mlogloss:0.33134\n",
      "[547]\tvalidation_0-mlogloss:0.05113\tvalidation_1-mlogloss:0.33120\n",
      "[548]\tvalidation_0-mlogloss:0.05105\tvalidation_1-mlogloss:0.33115\n",
      "[549]\tvalidation_0-mlogloss:0.05097\tvalidation_1-mlogloss:0.33100\n",
      "[550]\tvalidation_0-mlogloss:0.05092\tvalidation_1-mlogloss:0.33111\n",
      "[551]\tvalidation_0-mlogloss:0.05088\tvalidation_1-mlogloss:0.33105\n",
      "[552]\tvalidation_0-mlogloss:0.05079\tvalidation_1-mlogloss:0.33100\n",
      "[553]\tvalidation_0-mlogloss:0.05076\tvalidation_1-mlogloss:0.33088\n",
      "[554]\tvalidation_0-mlogloss:0.05067\tvalidation_1-mlogloss:0.33069\n",
      "[555]\tvalidation_0-mlogloss:0.05053\tvalidation_1-mlogloss:0.33037\n",
      "[556]\tvalidation_0-mlogloss:0.05043\tvalidation_1-mlogloss:0.33012\n",
      "[557]\tvalidation_0-mlogloss:0.05038\tvalidation_1-mlogloss:0.33004\n",
      "[558]\tvalidation_0-mlogloss:0.05031\tvalidation_1-mlogloss:0.32996\n",
      "[559]\tvalidation_0-mlogloss:0.05023\tvalidation_1-mlogloss:0.32977\n",
      "[560]\tvalidation_0-mlogloss:0.05015\tvalidation_1-mlogloss:0.32973\n",
      "[561]\tvalidation_0-mlogloss:0.05010\tvalidation_1-mlogloss:0.32985\n",
      "[562]\tvalidation_0-mlogloss:0.05006\tvalidation_1-mlogloss:0.32992\n",
      "[563]\tvalidation_0-mlogloss:0.04997\tvalidation_1-mlogloss:0.32976\n",
      "[564]\tvalidation_0-mlogloss:0.04989\tvalidation_1-mlogloss:0.32945\n",
      "[565]\tvalidation_0-mlogloss:0.04987\tvalidation_1-mlogloss:0.32953\n",
      "[566]\tvalidation_0-mlogloss:0.04979\tvalidation_1-mlogloss:0.32925\n",
      "[567]\tvalidation_0-mlogloss:0.04974\tvalidation_1-mlogloss:0.32919\n",
      "[568]\tvalidation_0-mlogloss:0.04969\tvalidation_1-mlogloss:0.32912\n",
      "[569]\tvalidation_0-mlogloss:0.04965\tvalidation_1-mlogloss:0.32927\n",
      "[570]\tvalidation_0-mlogloss:0.04959\tvalidation_1-mlogloss:0.32902\n",
      "[571]\tvalidation_0-mlogloss:0.04954\tvalidation_1-mlogloss:0.32895\n",
      "[572]\tvalidation_0-mlogloss:0.04949\tvalidation_1-mlogloss:0.32878\n",
      "[573]\tvalidation_0-mlogloss:0.04944\tvalidation_1-mlogloss:0.32858\n",
      "[574]\tvalidation_0-mlogloss:0.04939\tvalidation_1-mlogloss:0.32853\n",
      "[575]\tvalidation_0-mlogloss:0.04934\tvalidation_1-mlogloss:0.32873\n",
      "[576]\tvalidation_0-mlogloss:0.04925\tvalidation_1-mlogloss:0.32849\n",
      "[577]\tvalidation_0-mlogloss:0.04913\tvalidation_1-mlogloss:0.32842\n",
      "[578]\tvalidation_0-mlogloss:0.04909\tvalidation_1-mlogloss:0.32828\n",
      "[579]\tvalidation_0-mlogloss:0.04908\tvalidation_1-mlogloss:0.32843\n",
      "[580]\tvalidation_0-mlogloss:0.04904\tvalidation_1-mlogloss:0.32840\n",
      "[581]\tvalidation_0-mlogloss:0.04899\tvalidation_1-mlogloss:0.32832\n",
      "[582]\tvalidation_0-mlogloss:0.04898\tvalidation_1-mlogloss:0.32838\n",
      "[583]\tvalidation_0-mlogloss:0.04890\tvalidation_1-mlogloss:0.32827\n",
      "[584]\tvalidation_0-mlogloss:0.04882\tvalidation_1-mlogloss:0.32825\n",
      "[585]\tvalidation_0-mlogloss:0.04878\tvalidation_1-mlogloss:0.32817\n",
      "[586]\tvalidation_0-mlogloss:0.04876\tvalidation_1-mlogloss:0.32824\n",
      "[587]\tvalidation_0-mlogloss:0.04871\tvalidation_1-mlogloss:0.32839\n",
      "[588]\tvalidation_0-mlogloss:0.04863\tvalidation_1-mlogloss:0.32806\n",
      "[589]\tvalidation_0-mlogloss:0.04855\tvalidation_1-mlogloss:0.32783\n",
      "[590]\tvalidation_0-mlogloss:0.04847\tvalidation_1-mlogloss:0.32781\n",
      "[591]\tvalidation_0-mlogloss:0.04845\tvalidation_1-mlogloss:0.32788\n",
      "[592]\tvalidation_0-mlogloss:0.04840\tvalidation_1-mlogloss:0.32770\n",
      "[593]\tvalidation_0-mlogloss:0.04833\tvalidation_1-mlogloss:0.32771\n",
      "[594]\tvalidation_0-mlogloss:0.04824\tvalidation_1-mlogloss:0.32774\n",
      "[595]\tvalidation_0-mlogloss:0.04820\tvalidation_1-mlogloss:0.32764\n",
      "[596]\tvalidation_0-mlogloss:0.04816\tvalidation_1-mlogloss:0.32755\n",
      "[597]\tvalidation_0-mlogloss:0.04814\tvalidation_1-mlogloss:0.32749\n",
      "[598]\tvalidation_0-mlogloss:0.04809\tvalidation_1-mlogloss:0.32743\n",
      "[599]\tvalidation_0-mlogloss:0.04802\tvalidation_1-mlogloss:0.32726\n",
      "[600]\tvalidation_0-mlogloss:0.04791\tvalidation_1-mlogloss:0.32699\n",
      "[601]\tvalidation_0-mlogloss:0.04789\tvalidation_1-mlogloss:0.32699\n",
      "[602]\tvalidation_0-mlogloss:0.04785\tvalidation_1-mlogloss:0.32698\n",
      "[603]\tvalidation_0-mlogloss:0.04780\tvalidation_1-mlogloss:0.32692\n",
      "[604]\tvalidation_0-mlogloss:0.04772\tvalidation_1-mlogloss:0.32674\n",
      "[605]\tvalidation_0-mlogloss:0.04768\tvalidation_1-mlogloss:0.32685\n",
      "[606]\tvalidation_0-mlogloss:0.04764\tvalidation_1-mlogloss:0.32682\n",
      "[607]\tvalidation_0-mlogloss:0.04757\tvalidation_1-mlogloss:0.32676\n",
      "[608]\tvalidation_0-mlogloss:0.04755\tvalidation_1-mlogloss:0.32669\n",
      "[609]\tvalidation_0-mlogloss:0.04753\tvalidation_1-mlogloss:0.32672\n",
      "[610]\tvalidation_0-mlogloss:0.04749\tvalidation_1-mlogloss:0.32668\n",
      "[611]\tvalidation_0-mlogloss:0.04741\tvalidation_1-mlogloss:0.32658\n",
      "[612]\tvalidation_0-mlogloss:0.04733\tvalidation_1-mlogloss:0.32639\n",
      "[613]\tvalidation_0-mlogloss:0.04727\tvalidation_1-mlogloss:0.32634\n",
      "[614]\tvalidation_0-mlogloss:0.04722\tvalidation_1-mlogloss:0.32650\n",
      "[615]\tvalidation_0-mlogloss:0.04719\tvalidation_1-mlogloss:0.32647\n",
      "[616]\tvalidation_0-mlogloss:0.04712\tvalidation_1-mlogloss:0.32672\n",
      "[617]\tvalidation_0-mlogloss:0.04704\tvalidation_1-mlogloss:0.32667\n",
      "[618]\tvalidation_0-mlogloss:0.04700\tvalidation_1-mlogloss:0.32684\n",
      "[619]\tvalidation_0-mlogloss:0.04696\tvalidation_1-mlogloss:0.32682\n",
      "[620]\tvalidation_0-mlogloss:0.04692\tvalidation_1-mlogloss:0.32694\n",
      "[621]\tvalidation_0-mlogloss:0.04691\tvalidation_1-mlogloss:0.32704\n",
      "[622]\tvalidation_0-mlogloss:0.04690\tvalidation_1-mlogloss:0.32712\n",
      "[623]\tvalidation_0-mlogloss:0.04688\tvalidation_1-mlogloss:0.32723\n",
      "[624]\tvalidation_0-mlogloss:0.04683\tvalidation_1-mlogloss:0.32720\n",
      "[625]\tvalidation_0-mlogloss:0.04680\tvalidation_1-mlogloss:0.32718\n",
      "[626]\tvalidation_0-mlogloss:0.04676\tvalidation_1-mlogloss:0.32726\n",
      "[627]\tvalidation_0-mlogloss:0.04674\tvalidation_1-mlogloss:0.32742\n",
      "[628]\tvalidation_0-mlogloss:0.04671\tvalidation_1-mlogloss:0.32730\n",
      "[629]\tvalidation_0-mlogloss:0.04667\tvalidation_1-mlogloss:0.32743\n",
      "[630]\tvalidation_0-mlogloss:0.04665\tvalidation_1-mlogloss:0.32738\n",
      "[631]\tvalidation_0-mlogloss:0.04661\tvalidation_1-mlogloss:0.32746\n",
      "[632]\tvalidation_0-mlogloss:0.04655\tvalidation_1-mlogloss:0.32745\n",
      "[16:53:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-mlogloss:1.59176\tvalidation_1-mlogloss:1.59635\n",
      "[1]\tvalidation_0-mlogloss:1.57377\tvalidation_1-mlogloss:1.58187\n",
      "[2]\tvalidation_0-mlogloss:1.55750\tvalidation_1-mlogloss:1.56914\n",
      "[3]\tvalidation_0-mlogloss:1.54086\tvalidation_1-mlogloss:1.55593\n",
      "[4]\tvalidation_0-mlogloss:1.52471\tvalidation_1-mlogloss:1.54392\n",
      "[5]\tvalidation_0-mlogloss:1.50728\tvalidation_1-mlogloss:1.53120\n",
      "[6]\tvalidation_0-mlogloss:1.49208\tvalidation_1-mlogloss:1.52144\n",
      "[7]\tvalidation_0-mlogloss:1.47712\tvalidation_1-mlogloss:1.51018\n",
      "[8]\tvalidation_0-mlogloss:1.46232\tvalidation_1-mlogloss:1.49852\n",
      "[9]\tvalidation_0-mlogloss:1.44689\tvalidation_1-mlogloss:1.48626\n",
      "[10]\tvalidation_0-mlogloss:1.43230\tvalidation_1-mlogloss:1.47461\n",
      "[11]\tvalidation_0-mlogloss:1.41829\tvalidation_1-mlogloss:1.46419\n",
      "[12]\tvalidation_0-mlogloss:1.40334\tvalidation_1-mlogloss:1.45236\n",
      "[13]\tvalidation_0-mlogloss:1.38874\tvalidation_1-mlogloss:1.44098\n",
      "[14]\tvalidation_0-mlogloss:1.37385\tvalidation_1-mlogloss:1.42996\n",
      "[15]\tvalidation_0-mlogloss:1.35991\tvalidation_1-mlogloss:1.41921\n",
      "[16]\tvalidation_0-mlogloss:1.34660\tvalidation_1-mlogloss:1.40808\n",
      "[17]\tvalidation_0-mlogloss:1.33229\tvalidation_1-mlogloss:1.39669\n",
      "[18]\tvalidation_0-mlogloss:1.31867\tvalidation_1-mlogloss:1.38534\n",
      "[19]\tvalidation_0-mlogloss:1.30625\tvalidation_1-mlogloss:1.37534\n",
      "[20]\tvalidation_0-mlogloss:1.29313\tvalidation_1-mlogloss:1.36455\n",
      "[21]\tvalidation_0-mlogloss:1.28049\tvalidation_1-mlogloss:1.35592\n",
      "[22]\tvalidation_0-mlogloss:1.26665\tvalidation_1-mlogloss:1.34426\n",
      "[23]\tvalidation_0-mlogloss:1.25335\tvalidation_1-mlogloss:1.33192\n",
      "[24]\tvalidation_0-mlogloss:1.24088\tvalidation_1-mlogloss:1.32221\n",
      "[25]\tvalidation_0-mlogloss:1.22837\tvalidation_1-mlogloss:1.31192\n",
      "[26]\tvalidation_0-mlogloss:1.21591\tvalidation_1-mlogloss:1.30307\n",
      "[27]\tvalidation_0-mlogloss:1.20394\tvalidation_1-mlogloss:1.29525\n",
      "[28]\tvalidation_0-mlogloss:1.19166\tvalidation_1-mlogloss:1.28485\n",
      "[29]\tvalidation_0-mlogloss:1.17923\tvalidation_1-mlogloss:1.27384\n",
      "[30]\tvalidation_0-mlogloss:1.16708\tvalidation_1-mlogloss:1.26268\n",
      "[31]\tvalidation_0-mlogloss:1.15595\tvalidation_1-mlogloss:1.25333\n",
      "[32]\tvalidation_0-mlogloss:1.14536\tvalidation_1-mlogloss:1.24464\n",
      "[33]\tvalidation_0-mlogloss:1.13360\tvalidation_1-mlogloss:1.23520\n",
      "[34]\tvalidation_0-mlogloss:1.12239\tvalidation_1-mlogloss:1.22718\n",
      "[35]\tvalidation_0-mlogloss:1.11128\tvalidation_1-mlogloss:1.21951\n",
      "[36]\tvalidation_0-mlogloss:1.10143\tvalidation_1-mlogloss:1.21243\n",
      "[37]\tvalidation_0-mlogloss:1.09069\tvalidation_1-mlogloss:1.20395\n",
      "[38]\tvalidation_0-mlogloss:1.08024\tvalidation_1-mlogloss:1.19483\n",
      "[39]\tvalidation_0-mlogloss:1.06974\tvalidation_1-mlogloss:1.18749\n",
      "[40]\tvalidation_0-mlogloss:1.05944\tvalidation_1-mlogloss:1.17952\n",
      "[41]\tvalidation_0-mlogloss:1.04967\tvalidation_1-mlogloss:1.17167\n",
      "[42]\tvalidation_0-mlogloss:1.03923\tvalidation_1-mlogloss:1.16340\n",
      "[43]\tvalidation_0-mlogloss:1.02913\tvalidation_1-mlogloss:1.15484\n",
      "[44]\tvalidation_0-mlogloss:1.01964\tvalidation_1-mlogloss:1.14811\n",
      "[45]\tvalidation_0-mlogloss:1.00913\tvalidation_1-mlogloss:1.13836\n",
      "[46]\tvalidation_0-mlogloss:0.99918\tvalidation_1-mlogloss:1.13020\n",
      "[47]\tvalidation_0-mlogloss:0.98940\tvalidation_1-mlogloss:1.12109\n",
      "[48]\tvalidation_0-mlogloss:0.97969\tvalidation_1-mlogloss:1.11208\n",
      "[49]\tvalidation_0-mlogloss:0.97020\tvalidation_1-mlogloss:1.10406\n",
      "[50]\tvalidation_0-mlogloss:0.96071\tvalidation_1-mlogloss:1.09524\n",
      "[51]\tvalidation_0-mlogloss:0.95194\tvalidation_1-mlogloss:1.08845\n",
      "[52]\tvalidation_0-mlogloss:0.94266\tvalidation_1-mlogloss:1.07979\n",
      "[53]\tvalidation_0-mlogloss:0.93338\tvalidation_1-mlogloss:1.07224\n",
      "[54]\tvalidation_0-mlogloss:0.92416\tvalidation_1-mlogloss:1.06520\n",
      "[55]\tvalidation_0-mlogloss:0.91532\tvalidation_1-mlogloss:1.05790\n",
      "[56]\tvalidation_0-mlogloss:0.90645\tvalidation_1-mlogloss:1.05128\n",
      "[57]\tvalidation_0-mlogloss:0.89827\tvalidation_1-mlogloss:1.04563\n",
      "[58]\tvalidation_0-mlogloss:0.89002\tvalidation_1-mlogloss:1.03915\n",
      "[59]\tvalidation_0-mlogloss:0.88178\tvalidation_1-mlogloss:1.03272\n",
      "[60]\tvalidation_0-mlogloss:0.87345\tvalidation_1-mlogloss:1.02585\n",
      "[61]\tvalidation_0-mlogloss:0.86481\tvalidation_1-mlogloss:1.01750\n",
      "[62]\tvalidation_0-mlogloss:0.85725\tvalidation_1-mlogloss:1.01205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63]\tvalidation_0-mlogloss:0.84899\tvalidation_1-mlogloss:1.00523\n",
      "[64]\tvalidation_0-mlogloss:0.84059\tvalidation_1-mlogloss:0.99734\n",
      "[65]\tvalidation_0-mlogloss:0.83293\tvalidation_1-mlogloss:0.99217\n",
      "[66]\tvalidation_0-mlogloss:0.82484\tvalidation_1-mlogloss:0.98443\n",
      "[67]\tvalidation_0-mlogloss:0.81800\tvalidation_1-mlogloss:0.97939\n",
      "[68]\tvalidation_0-mlogloss:0.81054\tvalidation_1-mlogloss:0.97355\n",
      "[69]\tvalidation_0-mlogloss:0.80297\tvalidation_1-mlogloss:0.96649\n",
      "[70]\tvalidation_0-mlogloss:0.79572\tvalidation_1-mlogloss:0.96232\n",
      "[71]\tvalidation_0-mlogloss:0.78867\tvalidation_1-mlogloss:0.95570\n",
      "[72]\tvalidation_0-mlogloss:0.78181\tvalidation_1-mlogloss:0.94977\n",
      "[73]\tvalidation_0-mlogloss:0.77519\tvalidation_1-mlogloss:0.94437\n",
      "[74]\tvalidation_0-mlogloss:0.76901\tvalidation_1-mlogloss:0.93946\n",
      "[75]\tvalidation_0-mlogloss:0.76228\tvalidation_1-mlogloss:0.93378\n",
      "[76]\tvalidation_0-mlogloss:0.75526\tvalidation_1-mlogloss:0.92731\n",
      "[77]\tvalidation_0-mlogloss:0.74821\tvalidation_1-mlogloss:0.92113\n",
      "[78]\tvalidation_0-mlogloss:0.74136\tvalidation_1-mlogloss:0.91421\n",
      "[79]\tvalidation_0-mlogloss:0.73455\tvalidation_1-mlogloss:0.90801\n",
      "[80]\tvalidation_0-mlogloss:0.72823\tvalidation_1-mlogloss:0.90229\n",
      "[81]\tvalidation_0-mlogloss:0.72194\tvalidation_1-mlogloss:0.89722\n",
      "[82]\tvalidation_0-mlogloss:0.71530\tvalidation_1-mlogloss:0.89123\n",
      "[83]\tvalidation_0-mlogloss:0.70872\tvalidation_1-mlogloss:0.88507\n",
      "[84]\tvalidation_0-mlogloss:0.70200\tvalidation_1-mlogloss:0.87881\n",
      "[85]\tvalidation_0-mlogloss:0.69557\tvalidation_1-mlogloss:0.87326\n",
      "[86]\tvalidation_0-mlogloss:0.68931\tvalidation_1-mlogloss:0.86885\n",
      "[87]\tvalidation_0-mlogloss:0.68398\tvalidation_1-mlogloss:0.86478\n",
      "[88]\tvalidation_0-mlogloss:0.67781\tvalidation_1-mlogloss:0.86034\n",
      "[89]\tvalidation_0-mlogloss:0.67192\tvalidation_1-mlogloss:0.85567\n",
      "[90]\tvalidation_0-mlogloss:0.66591\tvalidation_1-mlogloss:0.85083\n",
      "[91]\tvalidation_0-mlogloss:0.66023\tvalidation_1-mlogloss:0.84591\n",
      "[92]\tvalidation_0-mlogloss:0.65437\tvalidation_1-mlogloss:0.84147\n",
      "[93]\tvalidation_0-mlogloss:0.64862\tvalidation_1-mlogloss:0.83667\n",
      "[94]\tvalidation_0-mlogloss:0.64312\tvalidation_1-mlogloss:0.83161\n",
      "[95]\tvalidation_0-mlogloss:0.63740\tvalidation_1-mlogloss:0.82693\n",
      "[96]\tvalidation_0-mlogloss:0.63184\tvalidation_1-mlogloss:0.82177\n",
      "[97]\tvalidation_0-mlogloss:0.62636\tvalidation_1-mlogloss:0.81718\n",
      "[98]\tvalidation_0-mlogloss:0.62058\tvalidation_1-mlogloss:0.81190\n",
      "[99]\tvalidation_0-mlogloss:0.61527\tvalidation_1-mlogloss:0.80764\n",
      "[100]\tvalidation_0-mlogloss:0.60989\tvalidation_1-mlogloss:0.80244\n",
      "[101]\tvalidation_0-mlogloss:0.60457\tvalidation_1-mlogloss:0.79743\n",
      "[102]\tvalidation_0-mlogloss:0.59916\tvalidation_1-mlogloss:0.79303\n",
      "[103]\tvalidation_0-mlogloss:0.59387\tvalidation_1-mlogloss:0.78907\n",
      "[104]\tvalidation_0-mlogloss:0.58871\tvalidation_1-mlogloss:0.78417\n",
      "[105]\tvalidation_0-mlogloss:0.58379\tvalidation_1-mlogloss:0.78003\n",
      "[106]\tvalidation_0-mlogloss:0.57859\tvalidation_1-mlogloss:0.77451\n",
      "[107]\tvalidation_0-mlogloss:0.57389\tvalidation_1-mlogloss:0.77007\n",
      "[108]\tvalidation_0-mlogloss:0.56871\tvalidation_1-mlogloss:0.76547\n",
      "[109]\tvalidation_0-mlogloss:0.56377\tvalidation_1-mlogloss:0.76137\n",
      "[110]\tvalidation_0-mlogloss:0.55873\tvalidation_1-mlogloss:0.75672\n",
      "[111]\tvalidation_0-mlogloss:0.55378\tvalidation_1-mlogloss:0.75169\n",
      "[112]\tvalidation_0-mlogloss:0.54912\tvalidation_1-mlogloss:0.74846\n",
      "[113]\tvalidation_0-mlogloss:0.54440\tvalidation_1-mlogloss:0.74415\n",
      "[114]\tvalidation_0-mlogloss:0.53956\tvalidation_1-mlogloss:0.73992\n",
      "[115]\tvalidation_0-mlogloss:0.53493\tvalidation_1-mlogloss:0.73669\n",
      "[116]\tvalidation_0-mlogloss:0.53027\tvalidation_1-mlogloss:0.73274\n",
      "[117]\tvalidation_0-mlogloss:0.52609\tvalidation_1-mlogloss:0.72973\n",
      "[118]\tvalidation_0-mlogloss:0.52167\tvalidation_1-mlogloss:0.72636\n",
      "[119]\tvalidation_0-mlogloss:0.51745\tvalidation_1-mlogloss:0.72309\n",
      "[120]\tvalidation_0-mlogloss:0.51287\tvalidation_1-mlogloss:0.71910\n",
      "[121]\tvalidation_0-mlogloss:0.50875\tvalidation_1-mlogloss:0.71619\n",
      "[122]\tvalidation_0-mlogloss:0.50436\tvalidation_1-mlogloss:0.71239\n",
      "[123]\tvalidation_0-mlogloss:0.50004\tvalidation_1-mlogloss:0.70852\n",
      "[124]\tvalidation_0-mlogloss:0.49575\tvalidation_1-mlogloss:0.70533\n",
      "[125]\tvalidation_0-mlogloss:0.49160\tvalidation_1-mlogloss:0.70185\n",
      "[126]\tvalidation_0-mlogloss:0.48733\tvalidation_1-mlogloss:0.69806\n",
      "[127]\tvalidation_0-mlogloss:0.48322\tvalidation_1-mlogloss:0.69505\n",
      "[128]\tvalidation_0-mlogloss:0.47916\tvalidation_1-mlogloss:0.69128\n",
      "[129]\tvalidation_0-mlogloss:0.47517\tvalidation_1-mlogloss:0.68819\n",
      "[130]\tvalidation_0-mlogloss:0.47103\tvalidation_1-mlogloss:0.68455\n",
      "[131]\tvalidation_0-mlogloss:0.46705\tvalidation_1-mlogloss:0.68018\n",
      "[132]\tvalidation_0-mlogloss:0.46316\tvalidation_1-mlogloss:0.67736\n",
      "[133]\tvalidation_0-mlogloss:0.45922\tvalidation_1-mlogloss:0.67457\n",
      "[134]\tvalidation_0-mlogloss:0.45560\tvalidation_1-mlogloss:0.67184\n",
      "[135]\tvalidation_0-mlogloss:0.45199\tvalidation_1-mlogloss:0.66952\n",
      "[136]\tvalidation_0-mlogloss:0.44809\tvalidation_1-mlogloss:0.66608\n",
      "[137]\tvalidation_0-mlogloss:0.44444\tvalidation_1-mlogloss:0.66321\n",
      "[138]\tvalidation_0-mlogloss:0.44074\tvalidation_1-mlogloss:0.66064\n",
      "[139]\tvalidation_0-mlogloss:0.43706\tvalidation_1-mlogloss:0.65759\n",
      "[140]\tvalidation_0-mlogloss:0.43340\tvalidation_1-mlogloss:0.65399\n",
      "[141]\tvalidation_0-mlogloss:0.42968\tvalidation_1-mlogloss:0.65018\n",
      "[142]\tvalidation_0-mlogloss:0.42612\tvalidation_1-mlogloss:0.64644\n",
      "[143]\tvalidation_0-mlogloss:0.42253\tvalidation_1-mlogloss:0.64286\n",
      "[144]\tvalidation_0-mlogloss:0.41915\tvalidation_1-mlogloss:0.63969\n",
      "[145]\tvalidation_0-mlogloss:0.41571\tvalidation_1-mlogloss:0.63701\n",
      "[146]\tvalidation_0-mlogloss:0.41226\tvalidation_1-mlogloss:0.63406\n",
      "[147]\tvalidation_0-mlogloss:0.40895\tvalidation_1-mlogloss:0.63171\n",
      "[148]\tvalidation_0-mlogloss:0.40565\tvalidation_1-mlogloss:0.62834\n",
      "[149]\tvalidation_0-mlogloss:0.40234\tvalidation_1-mlogloss:0.62527\n",
      "[150]\tvalidation_0-mlogloss:0.39919\tvalidation_1-mlogloss:0.62284\n",
      "[151]\tvalidation_0-mlogloss:0.39603\tvalidation_1-mlogloss:0.62062\n",
      "[152]\tvalidation_0-mlogloss:0.39278\tvalidation_1-mlogloss:0.61736\n",
      "[153]\tvalidation_0-mlogloss:0.38970\tvalidation_1-mlogloss:0.61444\n",
      "[154]\tvalidation_0-mlogloss:0.38654\tvalidation_1-mlogloss:0.61158\n",
      "[155]\tvalidation_0-mlogloss:0.38344\tvalidation_1-mlogloss:0.60909\n",
      "[156]\tvalidation_0-mlogloss:0.38037\tvalidation_1-mlogloss:0.60534\n",
      "[157]\tvalidation_0-mlogloss:0.37744\tvalidation_1-mlogloss:0.60268\n",
      "[158]\tvalidation_0-mlogloss:0.37453\tvalidation_1-mlogloss:0.60078\n",
      "[159]\tvalidation_0-mlogloss:0.37149\tvalidation_1-mlogloss:0.59801\n",
      "[160]\tvalidation_0-mlogloss:0.36856\tvalidation_1-mlogloss:0.59639\n",
      "[161]\tvalidation_0-mlogloss:0.36579\tvalidation_1-mlogloss:0.59495\n",
      "[162]\tvalidation_0-mlogloss:0.36302\tvalidation_1-mlogloss:0.59266\n",
      "[163]\tvalidation_0-mlogloss:0.36019\tvalidation_1-mlogloss:0.59029\n",
      "[164]\tvalidation_0-mlogloss:0.35722\tvalidation_1-mlogloss:0.58780\n",
      "[165]\tvalidation_0-mlogloss:0.35454\tvalidation_1-mlogloss:0.58500\n",
      "[166]\tvalidation_0-mlogloss:0.35169\tvalidation_1-mlogloss:0.58250\n",
      "[167]\tvalidation_0-mlogloss:0.34890\tvalidation_1-mlogloss:0.57968\n",
      "[168]\tvalidation_0-mlogloss:0.34635\tvalidation_1-mlogloss:0.57808\n",
      "[169]\tvalidation_0-mlogloss:0.34363\tvalidation_1-mlogloss:0.57629\n",
      "[170]\tvalidation_0-mlogloss:0.34099\tvalidation_1-mlogloss:0.57452\n",
      "[171]\tvalidation_0-mlogloss:0.33834\tvalidation_1-mlogloss:0.57198\n",
      "[172]\tvalidation_0-mlogloss:0.33567\tvalidation_1-mlogloss:0.57025\n",
      "[173]\tvalidation_0-mlogloss:0.33302\tvalidation_1-mlogloss:0.56769\n",
      "[174]\tvalidation_0-mlogloss:0.33050\tvalidation_1-mlogloss:0.56515\n",
      "[175]\tvalidation_0-mlogloss:0.32803\tvalidation_1-mlogloss:0.56294\n",
      "[176]\tvalidation_0-mlogloss:0.32566\tvalidation_1-mlogloss:0.56120\n",
      "[177]\tvalidation_0-mlogloss:0.32310\tvalidation_1-mlogloss:0.55869\n",
      "[178]\tvalidation_0-mlogloss:0.32053\tvalidation_1-mlogloss:0.55613\n",
      "[179]\tvalidation_0-mlogloss:0.31800\tvalidation_1-mlogloss:0.55410\n",
      "[180]\tvalidation_0-mlogloss:0.31567\tvalidation_1-mlogloss:0.55222\n",
      "[181]\tvalidation_0-mlogloss:0.31324\tvalidation_1-mlogloss:0.55066\n",
      "[182]\tvalidation_0-mlogloss:0.31083\tvalidation_1-mlogloss:0.54814\n",
      "[183]\tvalidation_0-mlogloss:0.30840\tvalidation_1-mlogloss:0.54543\n",
      "[184]\tvalidation_0-mlogloss:0.30604\tvalidation_1-mlogloss:0.54377\n",
      "[185]\tvalidation_0-mlogloss:0.30371\tvalidation_1-mlogloss:0.54151\n",
      "[186]\tvalidation_0-mlogloss:0.30132\tvalidation_1-mlogloss:0.53935\n",
      "[187]\tvalidation_0-mlogloss:0.29904\tvalidation_1-mlogloss:0.53711\n",
      "[188]\tvalidation_0-mlogloss:0.29676\tvalidation_1-mlogloss:0.53470\n",
      "[189]\tvalidation_0-mlogloss:0.29462\tvalidation_1-mlogloss:0.53316\n",
      "[190]\tvalidation_0-mlogloss:0.29244\tvalidation_1-mlogloss:0.53106\n",
      "[191]\tvalidation_0-mlogloss:0.29021\tvalidation_1-mlogloss:0.52871\n",
      "[192]\tvalidation_0-mlogloss:0.28812\tvalidation_1-mlogloss:0.52725\n",
      "[193]\tvalidation_0-mlogloss:0.28602\tvalidation_1-mlogloss:0.52567\n",
      "[194]\tvalidation_0-mlogloss:0.28383\tvalidation_1-mlogloss:0.52281\n",
      "[195]\tvalidation_0-mlogloss:0.28169\tvalidation_1-mlogloss:0.52123\n",
      "[196]\tvalidation_0-mlogloss:0.27950\tvalidation_1-mlogloss:0.51972\n",
      "[197]\tvalidation_0-mlogloss:0.27731\tvalidation_1-mlogloss:0.51795\n",
      "[198]\tvalidation_0-mlogloss:0.27518\tvalidation_1-mlogloss:0.51599\n",
      "[199]\tvalidation_0-mlogloss:0.27305\tvalidation_1-mlogloss:0.51416\n",
      "[200]\tvalidation_0-mlogloss:0.27105\tvalidation_1-mlogloss:0.51220\n",
      "[201]\tvalidation_0-mlogloss:0.26898\tvalidation_1-mlogloss:0.51014\n",
      "[202]\tvalidation_0-mlogloss:0.26700\tvalidation_1-mlogloss:0.50862\n",
      "[203]\tvalidation_0-mlogloss:0.26495\tvalidation_1-mlogloss:0.50713\n",
      "[204]\tvalidation_0-mlogloss:0.26306\tvalidation_1-mlogloss:0.50543\n",
      "[205]\tvalidation_0-mlogloss:0.26106\tvalidation_1-mlogloss:0.50376\n",
      "[206]\tvalidation_0-mlogloss:0.25905\tvalidation_1-mlogloss:0.50169\n",
      "[207]\tvalidation_0-mlogloss:0.25727\tvalidation_1-mlogloss:0.50034\n",
      "[208]\tvalidation_0-mlogloss:0.25534\tvalidation_1-mlogloss:0.49801\n",
      "[209]\tvalidation_0-mlogloss:0.25356\tvalidation_1-mlogloss:0.49641\n",
      "[210]\tvalidation_0-mlogloss:0.25163\tvalidation_1-mlogloss:0.49449\n",
      "[211]\tvalidation_0-mlogloss:0.24988\tvalidation_1-mlogloss:0.49350\n",
      "[212]\tvalidation_0-mlogloss:0.24814\tvalidation_1-mlogloss:0.49192\n",
      "[213]\tvalidation_0-mlogloss:0.24641\tvalidation_1-mlogloss:0.49037\n",
      "[214]\tvalidation_0-mlogloss:0.24465\tvalidation_1-mlogloss:0.48864\n",
      "[215]\tvalidation_0-mlogloss:0.24296\tvalidation_1-mlogloss:0.48781\n",
      "[216]\tvalidation_0-mlogloss:0.24125\tvalidation_1-mlogloss:0.48662\n",
      "[217]\tvalidation_0-mlogloss:0.23956\tvalidation_1-mlogloss:0.48493\n",
      "[218]\tvalidation_0-mlogloss:0.23772\tvalidation_1-mlogloss:0.48296\n",
      "[219]\tvalidation_0-mlogloss:0.23595\tvalidation_1-mlogloss:0.48113\n",
      "[220]\tvalidation_0-mlogloss:0.23429\tvalidation_1-mlogloss:0.47987\n",
      "[221]\tvalidation_0-mlogloss:0.23263\tvalidation_1-mlogloss:0.47862\n",
      "[222]\tvalidation_0-mlogloss:0.23091\tvalidation_1-mlogloss:0.47723\n",
      "[223]\tvalidation_0-mlogloss:0.22919\tvalidation_1-mlogloss:0.47516\n",
      "[224]\tvalidation_0-mlogloss:0.22753\tvalidation_1-mlogloss:0.47353\n",
      "[225]\tvalidation_0-mlogloss:0.22592\tvalidation_1-mlogloss:0.47191\n",
      "[226]\tvalidation_0-mlogloss:0.22431\tvalidation_1-mlogloss:0.47016\n",
      "[227]\tvalidation_0-mlogloss:0.22273\tvalidation_1-mlogloss:0.46900\n",
      "[228]\tvalidation_0-mlogloss:0.22113\tvalidation_1-mlogloss:0.46795\n",
      "[229]\tvalidation_0-mlogloss:0.21955\tvalidation_1-mlogloss:0.46625\n",
      "[230]\tvalidation_0-mlogloss:0.21818\tvalidation_1-mlogloss:0.46523\n",
      "[231]\tvalidation_0-mlogloss:0.21670\tvalidation_1-mlogloss:0.46402\n",
      "[232]\tvalidation_0-mlogloss:0.21511\tvalidation_1-mlogloss:0.46260\n",
      "[233]\tvalidation_0-mlogloss:0.21357\tvalidation_1-mlogloss:0.46150\n",
      "[234]\tvalidation_0-mlogloss:0.21215\tvalidation_1-mlogloss:0.46018\n",
      "[235]\tvalidation_0-mlogloss:0.21073\tvalidation_1-mlogloss:0.45872\n",
      "[236]\tvalidation_0-mlogloss:0.20920\tvalidation_1-mlogloss:0.45715\n",
      "[237]\tvalidation_0-mlogloss:0.20768\tvalidation_1-mlogloss:0.45561\n",
      "[238]\tvalidation_0-mlogloss:0.20627\tvalidation_1-mlogloss:0.45465\n",
      "[239]\tvalidation_0-mlogloss:0.20480\tvalidation_1-mlogloss:0.45363\n",
      "[240]\tvalidation_0-mlogloss:0.20339\tvalidation_1-mlogloss:0.45232\n",
      "[241]\tvalidation_0-mlogloss:0.20195\tvalidation_1-mlogloss:0.45119\n",
      "[242]\tvalidation_0-mlogloss:0.20054\tvalidation_1-mlogloss:0.45003\n",
      "[243]\tvalidation_0-mlogloss:0.19907\tvalidation_1-mlogloss:0.44851\n",
      "[244]\tvalidation_0-mlogloss:0.19760\tvalidation_1-mlogloss:0.44698\n",
      "[245]\tvalidation_0-mlogloss:0.19621\tvalidation_1-mlogloss:0.44590\n",
      "[246]\tvalidation_0-mlogloss:0.19487\tvalidation_1-mlogloss:0.44475\n",
      "[247]\tvalidation_0-mlogloss:0.19355\tvalidation_1-mlogloss:0.44396\n",
      "[248]\tvalidation_0-mlogloss:0.19221\tvalidation_1-mlogloss:0.44280\n",
      "[249]\tvalidation_0-mlogloss:0.19089\tvalidation_1-mlogloss:0.44129\n",
      "[250]\tvalidation_0-mlogloss:0.18959\tvalidation_1-mlogloss:0.44015\n",
      "[251]\tvalidation_0-mlogloss:0.18824\tvalidation_1-mlogloss:0.43873\n",
      "[252]\tvalidation_0-mlogloss:0.18691\tvalidation_1-mlogloss:0.43770\n",
      "[253]\tvalidation_0-mlogloss:0.18564\tvalidation_1-mlogloss:0.43634\n",
      "[254]\tvalidation_0-mlogloss:0.18436\tvalidation_1-mlogloss:0.43524\n",
      "[255]\tvalidation_0-mlogloss:0.18308\tvalidation_1-mlogloss:0.43442\n",
      "[256]\tvalidation_0-mlogloss:0.18182\tvalidation_1-mlogloss:0.43294\n",
      "[257]\tvalidation_0-mlogloss:0.18056\tvalidation_1-mlogloss:0.43194\n",
      "[258]\tvalidation_0-mlogloss:0.17933\tvalidation_1-mlogloss:0.43131\n",
      "[259]\tvalidation_0-mlogloss:0.17812\tvalidation_1-mlogloss:0.43039\n",
      "[260]\tvalidation_0-mlogloss:0.17694\tvalidation_1-mlogloss:0.42945\n",
      "[261]\tvalidation_0-mlogloss:0.17574\tvalidation_1-mlogloss:0.42832\n",
      "[262]\tvalidation_0-mlogloss:0.17456\tvalidation_1-mlogloss:0.42737\n",
      "[263]\tvalidation_0-mlogloss:0.17342\tvalidation_1-mlogloss:0.42636\n",
      "[264]\tvalidation_0-mlogloss:0.17227\tvalidation_1-mlogloss:0.42493\n",
      "[265]\tvalidation_0-mlogloss:0.17110\tvalidation_1-mlogloss:0.42432\n",
      "[266]\tvalidation_0-mlogloss:0.16995\tvalidation_1-mlogloss:0.42306\n",
      "[267]\tvalidation_0-mlogloss:0.16877\tvalidation_1-mlogloss:0.42183\n",
      "[268]\tvalidation_0-mlogloss:0.16765\tvalidation_1-mlogloss:0.42112\n",
      "[269]\tvalidation_0-mlogloss:0.16652\tvalidation_1-mlogloss:0.42004\n",
      "[270]\tvalidation_0-mlogloss:0.16542\tvalidation_1-mlogloss:0.41959\n",
      "[271]\tvalidation_0-mlogloss:0.16438\tvalidation_1-mlogloss:0.41880\n",
      "[272]\tvalidation_0-mlogloss:0.16326\tvalidation_1-mlogloss:0.41786\n",
      "[273]\tvalidation_0-mlogloss:0.16218\tvalidation_1-mlogloss:0.41712\n",
      "[274]\tvalidation_0-mlogloss:0.16110\tvalidation_1-mlogloss:0.41637\n",
      "[275]\tvalidation_0-mlogloss:0.16010\tvalidation_1-mlogloss:0.41544\n",
      "[276]\tvalidation_0-mlogloss:0.15908\tvalidation_1-mlogloss:0.41467\n",
      "[277]\tvalidation_0-mlogloss:0.15804\tvalidation_1-mlogloss:0.41366\n",
      "[278]\tvalidation_0-mlogloss:0.15704\tvalidation_1-mlogloss:0.41298\n",
      "[279]\tvalidation_0-mlogloss:0.15609\tvalidation_1-mlogloss:0.41251\n",
      "[280]\tvalidation_0-mlogloss:0.15514\tvalidation_1-mlogloss:0.41188\n",
      "[281]\tvalidation_0-mlogloss:0.15423\tvalidation_1-mlogloss:0.41122\n",
      "[282]\tvalidation_0-mlogloss:0.15318\tvalidation_1-mlogloss:0.41002\n",
      "[283]\tvalidation_0-mlogloss:0.15226\tvalidation_1-mlogloss:0.40976\n",
      "[284]\tvalidation_0-mlogloss:0.15138\tvalidation_1-mlogloss:0.40931\n",
      "[285]\tvalidation_0-mlogloss:0.15045\tvalidation_1-mlogloss:0.40836\n",
      "[286]\tvalidation_0-mlogloss:0.14960\tvalidation_1-mlogloss:0.40785\n",
      "[287]\tvalidation_0-mlogloss:0.14871\tvalidation_1-mlogloss:0.40758\n",
      "[288]\tvalidation_0-mlogloss:0.14773\tvalidation_1-mlogloss:0.40665\n",
      "[289]\tvalidation_0-mlogloss:0.14676\tvalidation_1-mlogloss:0.40558\n",
      "[290]\tvalidation_0-mlogloss:0.14592\tvalidation_1-mlogloss:0.40479\n",
      "[291]\tvalidation_0-mlogloss:0.14495\tvalidation_1-mlogloss:0.40398\n",
      "[292]\tvalidation_0-mlogloss:0.14405\tvalidation_1-mlogloss:0.40376\n",
      "[293]\tvalidation_0-mlogloss:0.14315\tvalidation_1-mlogloss:0.40323\n",
      "[294]\tvalidation_0-mlogloss:0.14221\tvalidation_1-mlogloss:0.40215\n",
      "[295]\tvalidation_0-mlogloss:0.14133\tvalidation_1-mlogloss:0.40179\n",
      "[296]\tvalidation_0-mlogloss:0.14048\tvalidation_1-mlogloss:0.40107\n",
      "[297]\tvalidation_0-mlogloss:0.13960\tvalidation_1-mlogloss:0.40036\n",
      "[298]\tvalidation_0-mlogloss:0.13877\tvalidation_1-mlogloss:0.39961\n",
      "[299]\tvalidation_0-mlogloss:0.13788\tvalidation_1-mlogloss:0.39903\n",
      "[300]\tvalidation_0-mlogloss:0.13704\tvalidation_1-mlogloss:0.39876\n",
      "[301]\tvalidation_0-mlogloss:0.13619\tvalidation_1-mlogloss:0.39821\n",
      "[302]\tvalidation_0-mlogloss:0.13534\tvalidation_1-mlogloss:0.39761\n",
      "[303]\tvalidation_0-mlogloss:0.13450\tvalidation_1-mlogloss:0.39664\n",
      "[304]\tvalidation_0-mlogloss:0.13374\tvalidation_1-mlogloss:0.39587\n",
      "[305]\tvalidation_0-mlogloss:0.13293\tvalidation_1-mlogloss:0.39534\n",
      "[306]\tvalidation_0-mlogloss:0.13220\tvalidation_1-mlogloss:0.39518\n",
      "[307]\tvalidation_0-mlogloss:0.13138\tvalidation_1-mlogloss:0.39428\n",
      "[308]\tvalidation_0-mlogloss:0.13051\tvalidation_1-mlogloss:0.39360\n",
      "[309]\tvalidation_0-mlogloss:0.12974\tvalidation_1-mlogloss:0.39307\n",
      "[310]\tvalidation_0-mlogloss:0.12898\tvalidation_1-mlogloss:0.39257\n",
      "[311]\tvalidation_0-mlogloss:0.12822\tvalidation_1-mlogloss:0.39203\n",
      "[312]\tvalidation_0-mlogloss:0.12741\tvalidation_1-mlogloss:0.39145\n",
      "[313]\tvalidation_0-mlogloss:0.12664\tvalidation_1-mlogloss:0.39087\n",
      "[314]\tvalidation_0-mlogloss:0.12588\tvalidation_1-mlogloss:0.39044\n",
      "[315]\tvalidation_0-mlogloss:0.12509\tvalidation_1-mlogloss:0.38965\n",
      "[316]\tvalidation_0-mlogloss:0.12438\tvalidation_1-mlogloss:0.38954\n",
      "[317]\tvalidation_0-mlogloss:0.12363\tvalidation_1-mlogloss:0.38887\n",
      "[318]\tvalidation_0-mlogloss:0.12291\tvalidation_1-mlogloss:0.38850\n",
      "[319]\tvalidation_0-mlogloss:0.12219\tvalidation_1-mlogloss:0.38796\n",
      "[320]\tvalidation_0-mlogloss:0.12152\tvalidation_1-mlogloss:0.38747\n",
      "[321]\tvalidation_0-mlogloss:0.12084\tvalidation_1-mlogloss:0.38646\n",
      "[322]\tvalidation_0-mlogloss:0.12012\tvalidation_1-mlogloss:0.38611\n",
      "[323]\tvalidation_0-mlogloss:0.11947\tvalidation_1-mlogloss:0.38600\n",
      "[324]\tvalidation_0-mlogloss:0.11883\tvalidation_1-mlogloss:0.38555\n",
      "[325]\tvalidation_0-mlogloss:0.11820\tvalidation_1-mlogloss:0.38493\n",
      "[326]\tvalidation_0-mlogloss:0.11755\tvalidation_1-mlogloss:0.38467\n",
      "[327]\tvalidation_0-mlogloss:0.11698\tvalidation_1-mlogloss:0.38438\n",
      "[328]\tvalidation_0-mlogloss:0.11635\tvalidation_1-mlogloss:0.38424\n",
      "[329]\tvalidation_0-mlogloss:0.11570\tvalidation_1-mlogloss:0.38366\n",
      "[330]\tvalidation_0-mlogloss:0.11503\tvalidation_1-mlogloss:0.38298\n",
      "[331]\tvalidation_0-mlogloss:0.11440\tvalidation_1-mlogloss:0.38259\n",
      "[332]\tvalidation_0-mlogloss:0.11369\tvalidation_1-mlogloss:0.38175\n",
      "[333]\tvalidation_0-mlogloss:0.11304\tvalidation_1-mlogloss:0.38133\n",
      "[334]\tvalidation_0-mlogloss:0.11247\tvalidation_1-mlogloss:0.38091\n",
      "[335]\tvalidation_0-mlogloss:0.11188\tvalidation_1-mlogloss:0.38048\n",
      "[336]\tvalidation_0-mlogloss:0.11123\tvalidation_1-mlogloss:0.37987\n",
      "[337]\tvalidation_0-mlogloss:0.11060\tvalidation_1-mlogloss:0.37938\n",
      "[338]\tvalidation_0-mlogloss:0.10996\tvalidation_1-mlogloss:0.37873\n",
      "[339]\tvalidation_0-mlogloss:0.10934\tvalidation_1-mlogloss:0.37827\n",
      "[340]\tvalidation_0-mlogloss:0.10878\tvalidation_1-mlogloss:0.37789\n",
      "[341]\tvalidation_0-mlogloss:0.10820\tvalidation_1-mlogloss:0.37735\n",
      "[342]\tvalidation_0-mlogloss:0.10757\tvalidation_1-mlogloss:0.37664\n",
      "[343]\tvalidation_0-mlogloss:0.10706\tvalidation_1-mlogloss:0.37623\n",
      "[344]\tvalidation_0-mlogloss:0.10648\tvalidation_1-mlogloss:0.37567\n",
      "[345]\tvalidation_0-mlogloss:0.10589\tvalidation_1-mlogloss:0.37501\n",
      "[346]\tvalidation_0-mlogloss:0.10532\tvalidation_1-mlogloss:0.37499\n",
      "[347]\tvalidation_0-mlogloss:0.10477\tvalidation_1-mlogloss:0.37451\n",
      "[348]\tvalidation_0-mlogloss:0.10430\tvalidation_1-mlogloss:0.37419\n",
      "[349]\tvalidation_0-mlogloss:0.10384\tvalidation_1-mlogloss:0.37422\n",
      "[350]\tvalidation_0-mlogloss:0.10324\tvalidation_1-mlogloss:0.37361\n",
      "[351]\tvalidation_0-mlogloss:0.10265\tvalidation_1-mlogloss:0.37317\n",
      "[352]\tvalidation_0-mlogloss:0.10211\tvalidation_1-mlogloss:0.37299\n",
      "[353]\tvalidation_0-mlogloss:0.10152\tvalidation_1-mlogloss:0.37224\n",
      "[354]\tvalidation_0-mlogloss:0.10097\tvalidation_1-mlogloss:0.37193\n",
      "[355]\tvalidation_0-mlogloss:0.10044\tvalidation_1-mlogloss:0.37146\n",
      "[356]\tvalidation_0-mlogloss:0.09998\tvalidation_1-mlogloss:0.37088\n",
      "[357]\tvalidation_0-mlogloss:0.09945\tvalidation_1-mlogloss:0.37089\n",
      "[358]\tvalidation_0-mlogloss:0.09890\tvalidation_1-mlogloss:0.37022\n",
      "[359]\tvalidation_0-mlogloss:0.09840\tvalidation_1-mlogloss:0.37012\n",
      "[360]\tvalidation_0-mlogloss:0.09794\tvalidation_1-mlogloss:0.37001\n",
      "[361]\tvalidation_0-mlogloss:0.09741\tvalidation_1-mlogloss:0.36985\n",
      "[362]\tvalidation_0-mlogloss:0.09691\tvalidation_1-mlogloss:0.36950\n",
      "[363]\tvalidation_0-mlogloss:0.09639\tvalidation_1-mlogloss:0.36919\n",
      "[364]\tvalidation_0-mlogloss:0.09587\tvalidation_1-mlogloss:0.36854\n",
      "[365]\tvalidation_0-mlogloss:0.09535\tvalidation_1-mlogloss:0.36828\n",
      "[366]\tvalidation_0-mlogloss:0.09484\tvalidation_1-mlogloss:0.36806\n",
      "[367]\tvalidation_0-mlogloss:0.09435\tvalidation_1-mlogloss:0.36791\n",
      "[368]\tvalidation_0-mlogloss:0.09385\tvalidation_1-mlogloss:0.36734\n",
      "[369]\tvalidation_0-mlogloss:0.09335\tvalidation_1-mlogloss:0.36728\n",
      "[370]\tvalidation_0-mlogloss:0.09286\tvalidation_1-mlogloss:0.36710\n",
      "[371]\tvalidation_0-mlogloss:0.09241\tvalidation_1-mlogloss:0.36704\n",
      "[372]\tvalidation_0-mlogloss:0.09192\tvalidation_1-mlogloss:0.36657\n",
      "[373]\tvalidation_0-mlogloss:0.09142\tvalidation_1-mlogloss:0.36592\n",
      "[374]\tvalidation_0-mlogloss:0.09099\tvalidation_1-mlogloss:0.36572\n",
      "[375]\tvalidation_0-mlogloss:0.09053\tvalidation_1-mlogloss:0.36558\n",
      "[376]\tvalidation_0-mlogloss:0.09007\tvalidation_1-mlogloss:0.36493\n",
      "[377]\tvalidation_0-mlogloss:0.08961\tvalidation_1-mlogloss:0.36462\n",
      "[378]\tvalidation_0-mlogloss:0.08914\tvalidation_1-mlogloss:0.36392\n",
      "[379]\tvalidation_0-mlogloss:0.08871\tvalidation_1-mlogloss:0.36402\n",
      "[380]\tvalidation_0-mlogloss:0.08827\tvalidation_1-mlogloss:0.36363\n",
      "[381]\tvalidation_0-mlogloss:0.08784\tvalidation_1-mlogloss:0.36324\n",
      "[382]\tvalidation_0-mlogloss:0.08744\tvalidation_1-mlogloss:0.36270\n",
      "[383]\tvalidation_0-mlogloss:0.08701\tvalidation_1-mlogloss:0.36254\n",
      "[384]\tvalidation_0-mlogloss:0.08659\tvalidation_1-mlogloss:0.36209\n",
      "[385]\tvalidation_0-mlogloss:0.08618\tvalidation_1-mlogloss:0.36221\n",
      "[386]\tvalidation_0-mlogloss:0.08580\tvalidation_1-mlogloss:0.36221\n",
      "[387]\tvalidation_0-mlogloss:0.08539\tvalidation_1-mlogloss:0.36223\n",
      "[388]\tvalidation_0-mlogloss:0.08501\tvalidation_1-mlogloss:0.36213\n",
      "[389]\tvalidation_0-mlogloss:0.08459\tvalidation_1-mlogloss:0.36191\n",
      "[390]\tvalidation_0-mlogloss:0.08420\tvalidation_1-mlogloss:0.36170\n",
      "[391]\tvalidation_0-mlogloss:0.08378\tvalidation_1-mlogloss:0.36132\n",
      "[392]\tvalidation_0-mlogloss:0.08337\tvalidation_1-mlogloss:0.36099\n",
      "[393]\tvalidation_0-mlogloss:0.08295\tvalidation_1-mlogloss:0.36027\n",
      "[394]\tvalidation_0-mlogloss:0.08253\tvalidation_1-mlogloss:0.35973\n",
      "[395]\tvalidation_0-mlogloss:0.08213\tvalidation_1-mlogloss:0.35914\n",
      "[396]\tvalidation_0-mlogloss:0.08174\tvalidation_1-mlogloss:0.35900\n",
      "[397]\tvalidation_0-mlogloss:0.08139\tvalidation_1-mlogloss:0.35897\n",
      "[398]\tvalidation_0-mlogloss:0.08099\tvalidation_1-mlogloss:0.35867\n",
      "[399]\tvalidation_0-mlogloss:0.08062\tvalidation_1-mlogloss:0.35876\n",
      "[400]\tvalidation_0-mlogloss:0.08027\tvalidation_1-mlogloss:0.35833\n",
      "[401]\tvalidation_0-mlogloss:0.07989\tvalidation_1-mlogloss:0.35781\n",
      "[402]\tvalidation_0-mlogloss:0.07949\tvalidation_1-mlogloss:0.35762\n",
      "[403]\tvalidation_0-mlogloss:0.07914\tvalidation_1-mlogloss:0.35735\n",
      "[404]\tvalidation_0-mlogloss:0.07879\tvalidation_1-mlogloss:0.35698\n",
      "[405]\tvalidation_0-mlogloss:0.07841\tvalidation_1-mlogloss:0.35649\n",
      "[406]\tvalidation_0-mlogloss:0.07807\tvalidation_1-mlogloss:0.35671\n",
      "[407]\tvalidation_0-mlogloss:0.07771\tvalidation_1-mlogloss:0.35685\n",
      "[408]\tvalidation_0-mlogloss:0.07734\tvalidation_1-mlogloss:0.35655\n",
      "[409]\tvalidation_0-mlogloss:0.07701\tvalidation_1-mlogloss:0.35610\n",
      "[410]\tvalidation_0-mlogloss:0.07667\tvalidation_1-mlogloss:0.35590\n",
      "[411]\tvalidation_0-mlogloss:0.07635\tvalidation_1-mlogloss:0.35558\n",
      "[412]\tvalidation_0-mlogloss:0.07600\tvalidation_1-mlogloss:0.35520\n",
      "[413]\tvalidation_0-mlogloss:0.07567\tvalidation_1-mlogloss:0.35503\n",
      "[414]\tvalidation_0-mlogloss:0.07534\tvalidation_1-mlogloss:0.35483\n",
      "[415]\tvalidation_0-mlogloss:0.07502\tvalidation_1-mlogloss:0.35488\n",
      "[416]\tvalidation_0-mlogloss:0.07471\tvalidation_1-mlogloss:0.35493\n",
      "[417]\tvalidation_0-mlogloss:0.07442\tvalidation_1-mlogloss:0.35491\n",
      "[418]\tvalidation_0-mlogloss:0.07407\tvalidation_1-mlogloss:0.35496\n",
      "[419]\tvalidation_0-mlogloss:0.07376\tvalidation_1-mlogloss:0.35466\n",
      "[420]\tvalidation_0-mlogloss:0.07341\tvalidation_1-mlogloss:0.35430\n",
      "[421]\tvalidation_0-mlogloss:0.07309\tvalidation_1-mlogloss:0.35396\n",
      "[422]\tvalidation_0-mlogloss:0.07274\tvalidation_1-mlogloss:0.35418\n",
      "[423]\tvalidation_0-mlogloss:0.07242\tvalidation_1-mlogloss:0.35393\n",
      "[424]\tvalidation_0-mlogloss:0.07209\tvalidation_1-mlogloss:0.35372\n",
      "[425]\tvalidation_0-mlogloss:0.07181\tvalidation_1-mlogloss:0.35365\n",
      "[426]\tvalidation_0-mlogloss:0.07148\tvalidation_1-mlogloss:0.35365\n",
      "[427]\tvalidation_0-mlogloss:0.07117\tvalidation_1-mlogloss:0.35349\n",
      "[428]\tvalidation_0-mlogloss:0.07087\tvalidation_1-mlogloss:0.35321\n",
      "[429]\tvalidation_0-mlogloss:0.07058\tvalidation_1-mlogloss:0.35302\n",
      "[430]\tvalidation_0-mlogloss:0.07029\tvalidation_1-mlogloss:0.35279\n",
      "[431]\tvalidation_0-mlogloss:0.07002\tvalidation_1-mlogloss:0.35248\n",
      "[432]\tvalidation_0-mlogloss:0.06978\tvalidation_1-mlogloss:0.35203\n",
      "[433]\tvalidation_0-mlogloss:0.06948\tvalidation_1-mlogloss:0.35217\n",
      "[434]\tvalidation_0-mlogloss:0.06916\tvalidation_1-mlogloss:0.35151\n",
      "[435]\tvalidation_0-mlogloss:0.06886\tvalidation_1-mlogloss:0.35171\n",
      "[436]\tvalidation_0-mlogloss:0.06856\tvalidation_1-mlogloss:0.35138\n",
      "[437]\tvalidation_0-mlogloss:0.06828\tvalidation_1-mlogloss:0.35116\n",
      "[438]\tvalidation_0-mlogloss:0.06800\tvalidation_1-mlogloss:0.35095\n",
      "[439]\tvalidation_0-mlogloss:0.06772\tvalidation_1-mlogloss:0.35072\n",
      "[440]\tvalidation_0-mlogloss:0.06749\tvalidation_1-mlogloss:0.35023\n",
      "[441]\tvalidation_0-mlogloss:0.06729\tvalidation_1-mlogloss:0.35029\n",
      "[442]\tvalidation_0-mlogloss:0.06706\tvalidation_1-mlogloss:0.35000\n",
      "[443]\tvalidation_0-mlogloss:0.06678\tvalidation_1-mlogloss:0.34974\n",
      "[444]\tvalidation_0-mlogloss:0.06651\tvalidation_1-mlogloss:0.34937\n",
      "[445]\tvalidation_0-mlogloss:0.06623\tvalidation_1-mlogloss:0.34940\n",
      "[446]\tvalidation_0-mlogloss:0.06595\tvalidation_1-mlogloss:0.34905\n",
      "[447]\tvalidation_0-mlogloss:0.06568\tvalidation_1-mlogloss:0.34876\n",
      "[448]\tvalidation_0-mlogloss:0.06539\tvalidation_1-mlogloss:0.34829\n",
      "[449]\tvalidation_0-mlogloss:0.06513\tvalidation_1-mlogloss:0.34835\n",
      "[450]\tvalidation_0-mlogloss:0.06486\tvalidation_1-mlogloss:0.34838\n",
      "[451]\tvalidation_0-mlogloss:0.06458\tvalidation_1-mlogloss:0.34832\n",
      "[452]\tvalidation_0-mlogloss:0.06433\tvalidation_1-mlogloss:0.34830\n",
      "[453]\tvalidation_0-mlogloss:0.06411\tvalidation_1-mlogloss:0.34792\n",
      "[454]\tvalidation_0-mlogloss:0.06391\tvalidation_1-mlogloss:0.34816\n",
      "[455]\tvalidation_0-mlogloss:0.06374\tvalidation_1-mlogloss:0.34796\n",
      "[456]\tvalidation_0-mlogloss:0.06352\tvalidation_1-mlogloss:0.34809\n",
      "[457]\tvalidation_0-mlogloss:0.06329\tvalidation_1-mlogloss:0.34802\n",
      "[458]\tvalidation_0-mlogloss:0.06308\tvalidation_1-mlogloss:0.34790\n",
      "[459]\tvalidation_0-mlogloss:0.06287\tvalidation_1-mlogloss:0.34781\n",
      "[460]\tvalidation_0-mlogloss:0.06264\tvalidation_1-mlogloss:0.34757\n",
      "[461]\tvalidation_0-mlogloss:0.06238\tvalidation_1-mlogloss:0.34718\n",
      "[462]\tvalidation_0-mlogloss:0.06217\tvalidation_1-mlogloss:0.34731\n",
      "[463]\tvalidation_0-mlogloss:0.06196\tvalidation_1-mlogloss:0.34703\n",
      "[464]\tvalidation_0-mlogloss:0.06175\tvalidation_1-mlogloss:0.34701\n",
      "[465]\tvalidation_0-mlogloss:0.06158\tvalidation_1-mlogloss:0.34711\n",
      "[466]\tvalidation_0-mlogloss:0.06139\tvalidation_1-mlogloss:0.34732\n",
      "[467]\tvalidation_0-mlogloss:0.06121\tvalidation_1-mlogloss:0.34691\n",
      "[468]\tvalidation_0-mlogloss:0.06098\tvalidation_1-mlogloss:0.34673\n",
      "[469]\tvalidation_0-mlogloss:0.06080\tvalidation_1-mlogloss:0.34648\n",
      "[470]\tvalidation_0-mlogloss:0.06064\tvalidation_1-mlogloss:0.34627\n",
      "[471]\tvalidation_0-mlogloss:0.06047\tvalidation_1-mlogloss:0.34594\n",
      "[472]\tvalidation_0-mlogloss:0.06026\tvalidation_1-mlogloss:0.34596\n",
      "[473]\tvalidation_0-mlogloss:0.06009\tvalidation_1-mlogloss:0.34563\n",
      "[474]\tvalidation_0-mlogloss:0.05993\tvalidation_1-mlogloss:0.34556\n",
      "[475]\tvalidation_0-mlogloss:0.05973\tvalidation_1-mlogloss:0.34546\n",
      "[476]\tvalidation_0-mlogloss:0.05955\tvalidation_1-mlogloss:0.34539\n",
      "[477]\tvalidation_0-mlogloss:0.05932\tvalidation_1-mlogloss:0.34545\n",
      "[478]\tvalidation_0-mlogloss:0.05913\tvalidation_1-mlogloss:0.34565\n",
      "[479]\tvalidation_0-mlogloss:0.05890\tvalidation_1-mlogloss:0.34548\n",
      "[480]\tvalidation_0-mlogloss:0.05877\tvalidation_1-mlogloss:0.34560\n",
      "[481]\tvalidation_0-mlogloss:0.05856\tvalidation_1-mlogloss:0.34566\n",
      "[482]\tvalidation_0-mlogloss:0.05833\tvalidation_1-mlogloss:0.34541\n",
      "[483]\tvalidation_0-mlogloss:0.05811\tvalidation_1-mlogloss:0.34514\n",
      "[484]\tvalidation_0-mlogloss:0.05794\tvalidation_1-mlogloss:0.34467\n",
      "[485]\tvalidation_0-mlogloss:0.05776\tvalidation_1-mlogloss:0.34436\n",
      "[486]\tvalidation_0-mlogloss:0.05764\tvalidation_1-mlogloss:0.34445\n",
      "[487]\tvalidation_0-mlogloss:0.05754\tvalidation_1-mlogloss:0.34412\n",
      "[488]\tvalidation_0-mlogloss:0.05735\tvalidation_1-mlogloss:0.34409\n",
      "[489]\tvalidation_0-mlogloss:0.05719\tvalidation_1-mlogloss:0.34387\n",
      "[490]\tvalidation_0-mlogloss:0.05702\tvalidation_1-mlogloss:0.34355\n",
      "[491]\tvalidation_0-mlogloss:0.05691\tvalidation_1-mlogloss:0.34368\n",
      "[492]\tvalidation_0-mlogloss:0.05680\tvalidation_1-mlogloss:0.34363\n",
      "[493]\tvalidation_0-mlogloss:0.05660\tvalidation_1-mlogloss:0.34358\n",
      "[494]\tvalidation_0-mlogloss:0.05645\tvalidation_1-mlogloss:0.34355\n",
      "[495]\tvalidation_0-mlogloss:0.05627\tvalidation_1-mlogloss:0.34349\n",
      "[496]\tvalidation_0-mlogloss:0.05615\tvalidation_1-mlogloss:0.34360\n",
      "[497]\tvalidation_0-mlogloss:0.05593\tvalidation_1-mlogloss:0.34332\n",
      "[498]\tvalidation_0-mlogloss:0.05575\tvalidation_1-mlogloss:0.34332\n",
      "[499]\tvalidation_0-mlogloss:0.05560\tvalidation_1-mlogloss:0.34320\n",
      "[500]\tvalidation_0-mlogloss:0.05545\tvalidation_1-mlogloss:0.34290\n",
      "[501]\tvalidation_0-mlogloss:0.05533\tvalidation_1-mlogloss:0.34298\n",
      "[502]\tvalidation_0-mlogloss:0.05517\tvalidation_1-mlogloss:0.34294\n",
      "[503]\tvalidation_0-mlogloss:0.05499\tvalidation_1-mlogloss:0.34248\n",
      "[504]\tvalidation_0-mlogloss:0.05483\tvalidation_1-mlogloss:0.34229\n",
      "[505]\tvalidation_0-mlogloss:0.05468\tvalidation_1-mlogloss:0.34211\n",
      "[506]\tvalidation_0-mlogloss:0.05458\tvalidation_1-mlogloss:0.34210\n",
      "[507]\tvalidation_0-mlogloss:0.05445\tvalidation_1-mlogloss:0.34203\n",
      "[508]\tvalidation_0-mlogloss:0.05439\tvalidation_1-mlogloss:0.34206\n",
      "[509]\tvalidation_0-mlogloss:0.05425\tvalidation_1-mlogloss:0.34173\n",
      "[510]\tvalidation_0-mlogloss:0.05411\tvalidation_1-mlogloss:0.34167\n",
      "[511]\tvalidation_0-mlogloss:0.05401\tvalidation_1-mlogloss:0.34148\n",
      "[512]\tvalidation_0-mlogloss:0.05392\tvalidation_1-mlogloss:0.34153\n",
      "[513]\tvalidation_0-mlogloss:0.05385\tvalidation_1-mlogloss:0.34175\n",
      "[514]\tvalidation_0-mlogloss:0.05374\tvalidation_1-mlogloss:0.34151\n",
      "[515]\tvalidation_0-mlogloss:0.05360\tvalidation_1-mlogloss:0.34115\n",
      "[516]\tvalidation_0-mlogloss:0.05354\tvalidation_1-mlogloss:0.34099\n",
      "[517]\tvalidation_0-mlogloss:0.05345\tvalidation_1-mlogloss:0.34098\n",
      "[518]\tvalidation_0-mlogloss:0.05335\tvalidation_1-mlogloss:0.34084\n",
      "[519]\tvalidation_0-mlogloss:0.05326\tvalidation_1-mlogloss:0.34045\n",
      "[520]\tvalidation_0-mlogloss:0.05314\tvalidation_1-mlogloss:0.34048\n",
      "[521]\tvalidation_0-mlogloss:0.05309\tvalidation_1-mlogloss:0.34045\n",
      "[522]\tvalidation_0-mlogloss:0.05297\tvalidation_1-mlogloss:0.34035\n",
      "[523]\tvalidation_0-mlogloss:0.05287\tvalidation_1-mlogloss:0.34023\n",
      "[524]\tvalidation_0-mlogloss:0.05274\tvalidation_1-mlogloss:0.34016\n",
      "[525]\tvalidation_0-mlogloss:0.05265\tvalidation_1-mlogloss:0.34001\n",
      "[526]\tvalidation_0-mlogloss:0.05255\tvalidation_1-mlogloss:0.33994\n",
      "[527]\tvalidation_0-mlogloss:0.05247\tvalidation_1-mlogloss:0.33984\n",
      "[528]\tvalidation_0-mlogloss:0.05237\tvalidation_1-mlogloss:0.33999\n",
      "[529]\tvalidation_0-mlogloss:0.05226\tvalidation_1-mlogloss:0.33988\n",
      "[530]\tvalidation_0-mlogloss:0.05222\tvalidation_1-mlogloss:0.33981\n",
      "[531]\tvalidation_0-mlogloss:0.05214\tvalidation_1-mlogloss:0.33994\n",
      "[532]\tvalidation_0-mlogloss:0.05200\tvalidation_1-mlogloss:0.33984\n",
      "[533]\tvalidation_0-mlogloss:0.05187\tvalidation_1-mlogloss:0.33986\n",
      "[534]\tvalidation_0-mlogloss:0.05178\tvalidation_1-mlogloss:0.33972\n",
      "[535]\tvalidation_0-mlogloss:0.05168\tvalidation_1-mlogloss:0.33952\n",
      "[536]\tvalidation_0-mlogloss:0.05157\tvalidation_1-mlogloss:0.33950\n",
      "[537]\tvalidation_0-mlogloss:0.05150\tvalidation_1-mlogloss:0.33945\n",
      "[538]\tvalidation_0-mlogloss:0.05140\tvalidation_1-mlogloss:0.33930\n",
      "[539]\tvalidation_0-mlogloss:0.05132\tvalidation_1-mlogloss:0.33894\n",
      "[540]\tvalidation_0-mlogloss:0.05123\tvalidation_1-mlogloss:0.33889\n",
      "[541]\tvalidation_0-mlogloss:0.05118\tvalidation_1-mlogloss:0.33874\n",
      "[542]\tvalidation_0-mlogloss:0.05109\tvalidation_1-mlogloss:0.33873\n",
      "[543]\tvalidation_0-mlogloss:0.05100\tvalidation_1-mlogloss:0.33872\n",
      "[544]\tvalidation_0-mlogloss:0.05095\tvalidation_1-mlogloss:0.33848\n",
      "[545]\tvalidation_0-mlogloss:0.05092\tvalidation_1-mlogloss:0.33838\n",
      "[546]\tvalidation_0-mlogloss:0.05089\tvalidation_1-mlogloss:0.33849\n",
      "[547]\tvalidation_0-mlogloss:0.05081\tvalidation_1-mlogloss:0.33818\n",
      "[548]\tvalidation_0-mlogloss:0.05076\tvalidation_1-mlogloss:0.33827\n",
      "[549]\tvalidation_0-mlogloss:0.05074\tvalidation_1-mlogloss:0.33815\n",
      "[550]\tvalidation_0-mlogloss:0.05065\tvalidation_1-mlogloss:0.33812\n",
      "[551]\tvalidation_0-mlogloss:0.05058\tvalidation_1-mlogloss:0.33812\n",
      "[552]\tvalidation_0-mlogloss:0.05048\tvalidation_1-mlogloss:0.33772\n",
      "[553]\tvalidation_0-mlogloss:0.05047\tvalidation_1-mlogloss:0.33776\n",
      "[554]\tvalidation_0-mlogloss:0.05039\tvalidation_1-mlogloss:0.33773\n",
      "[555]\tvalidation_0-mlogloss:0.05030\tvalidation_1-mlogloss:0.33781\n",
      "[556]\tvalidation_0-mlogloss:0.05022\tvalidation_1-mlogloss:0.33772\n",
      "[557]\tvalidation_0-mlogloss:0.05014\tvalidation_1-mlogloss:0.33742\n",
      "[558]\tvalidation_0-mlogloss:0.05009\tvalidation_1-mlogloss:0.33740\n",
      "[559]\tvalidation_0-mlogloss:0.05000\tvalidation_1-mlogloss:0.33735\n",
      "[560]\tvalidation_0-mlogloss:0.04995\tvalidation_1-mlogloss:0.33752\n",
      "[561]\tvalidation_0-mlogloss:0.04986\tvalidation_1-mlogloss:0.33735\n",
      "[562]\tvalidation_0-mlogloss:0.04981\tvalidation_1-mlogloss:0.33733\n",
      "[563]\tvalidation_0-mlogloss:0.04976\tvalidation_1-mlogloss:0.33728\n",
      "[564]\tvalidation_0-mlogloss:0.04972\tvalidation_1-mlogloss:0.33738\n",
      "[565]\tvalidation_0-mlogloss:0.04970\tvalidation_1-mlogloss:0.33755\n",
      "[566]\tvalidation_0-mlogloss:0.04961\tvalidation_1-mlogloss:0.33732\n",
      "[567]\tvalidation_0-mlogloss:0.04954\tvalidation_1-mlogloss:0.33738\n",
      "[568]\tvalidation_0-mlogloss:0.04944\tvalidation_1-mlogloss:0.33723\n",
      "[569]\tvalidation_0-mlogloss:0.04940\tvalidation_1-mlogloss:0.33712\n",
      "[570]\tvalidation_0-mlogloss:0.04931\tvalidation_1-mlogloss:0.33710\n",
      "[571]\tvalidation_0-mlogloss:0.04927\tvalidation_1-mlogloss:0.33711\n",
      "[572]\tvalidation_0-mlogloss:0.04922\tvalidation_1-mlogloss:0.33728\n",
      "[573]\tvalidation_0-mlogloss:0.04913\tvalidation_1-mlogloss:0.33731\n",
      "[574]\tvalidation_0-mlogloss:0.04909\tvalidation_1-mlogloss:0.33729\n",
      "[575]\tvalidation_0-mlogloss:0.04904\tvalidation_1-mlogloss:0.33725\n",
      "[576]\tvalidation_0-mlogloss:0.04899\tvalidation_1-mlogloss:0.33723\n",
      "[577]\tvalidation_0-mlogloss:0.04892\tvalidation_1-mlogloss:0.33689\n",
      "[578]\tvalidation_0-mlogloss:0.04888\tvalidation_1-mlogloss:0.33683\n",
      "[579]\tvalidation_0-mlogloss:0.04881\tvalidation_1-mlogloss:0.33682\n",
      "[580]\tvalidation_0-mlogloss:0.04878\tvalidation_1-mlogloss:0.33678\n",
      "[581]\tvalidation_0-mlogloss:0.04874\tvalidation_1-mlogloss:0.33689\n",
      "[582]\tvalidation_0-mlogloss:0.04866\tvalidation_1-mlogloss:0.33689\n",
      "[583]\tvalidation_0-mlogloss:0.04861\tvalidation_1-mlogloss:0.33694\n",
      "[584]\tvalidation_0-mlogloss:0.04858\tvalidation_1-mlogloss:0.33690\n",
      "[585]\tvalidation_0-mlogloss:0.04853\tvalidation_1-mlogloss:0.33691\n",
      "[586]\tvalidation_0-mlogloss:0.04848\tvalidation_1-mlogloss:0.33704\n",
      "[587]\tvalidation_0-mlogloss:0.04841\tvalidation_1-mlogloss:0.33683\n",
      "[588]\tvalidation_0-mlogloss:0.04835\tvalidation_1-mlogloss:0.33686\n",
      "[589]\tvalidation_0-mlogloss:0.04827\tvalidation_1-mlogloss:0.33654\n",
      "[590]\tvalidation_0-mlogloss:0.04819\tvalidation_1-mlogloss:0.33655\n",
      "[591]\tvalidation_0-mlogloss:0.04815\tvalidation_1-mlogloss:0.33649\n",
      "[592]\tvalidation_0-mlogloss:0.04809\tvalidation_1-mlogloss:0.33645\n",
      "[593]\tvalidation_0-mlogloss:0.04806\tvalidation_1-mlogloss:0.33636\n",
      "[594]\tvalidation_0-mlogloss:0.04801\tvalidation_1-mlogloss:0.33629\n",
      "[595]\tvalidation_0-mlogloss:0.04797\tvalidation_1-mlogloss:0.33626\n",
      "[596]\tvalidation_0-mlogloss:0.04792\tvalidation_1-mlogloss:0.33639\n",
      "[597]\tvalidation_0-mlogloss:0.04788\tvalidation_1-mlogloss:0.33634\n",
      "[598]\tvalidation_0-mlogloss:0.04783\tvalidation_1-mlogloss:0.33632\n",
      "[599]\tvalidation_0-mlogloss:0.04782\tvalidation_1-mlogloss:0.33624\n",
      "[600]\tvalidation_0-mlogloss:0.04779\tvalidation_1-mlogloss:0.33629\n",
      "[601]\tvalidation_0-mlogloss:0.04777\tvalidation_1-mlogloss:0.33635\n",
      "[602]\tvalidation_0-mlogloss:0.04772\tvalidation_1-mlogloss:0.33634\n",
      "[603]\tvalidation_0-mlogloss:0.04768\tvalidation_1-mlogloss:0.33631\n",
      "[604]\tvalidation_0-mlogloss:0.04764\tvalidation_1-mlogloss:0.33630\n",
      "[605]\tvalidation_0-mlogloss:0.04760\tvalidation_1-mlogloss:0.33635\n",
      "[606]\tvalidation_0-mlogloss:0.04752\tvalidation_1-mlogloss:0.33613\n",
      "[607]\tvalidation_0-mlogloss:0.04747\tvalidation_1-mlogloss:0.33611\n",
      "[608]\tvalidation_0-mlogloss:0.04745\tvalidation_1-mlogloss:0.33605\n",
      "[609]\tvalidation_0-mlogloss:0.04742\tvalidation_1-mlogloss:0.33608\n",
      "[610]\tvalidation_0-mlogloss:0.04741\tvalidation_1-mlogloss:0.33611\n",
      "[611]\tvalidation_0-mlogloss:0.04737\tvalidation_1-mlogloss:0.33611\n",
      "[612]\tvalidation_0-mlogloss:0.04734\tvalidation_1-mlogloss:0.33629\n",
      "[613]\tvalidation_0-mlogloss:0.04732\tvalidation_1-mlogloss:0.33621\n",
      "[614]\tvalidation_0-mlogloss:0.04725\tvalidation_1-mlogloss:0.33605\n",
      "[615]\tvalidation_0-mlogloss:0.04722\tvalidation_1-mlogloss:0.33597\n",
      "[616]\tvalidation_0-mlogloss:0.04717\tvalidation_1-mlogloss:0.33614\n",
      "[617]\tvalidation_0-mlogloss:0.04710\tvalidation_1-mlogloss:0.33597\n",
      "[618]\tvalidation_0-mlogloss:0.04708\tvalidation_1-mlogloss:0.33601\n",
      "[619]\tvalidation_0-mlogloss:0.04705\tvalidation_1-mlogloss:0.33610\n",
      "[620]\tvalidation_0-mlogloss:0.04701\tvalidation_1-mlogloss:0.33609\n",
      "[621]\tvalidation_0-mlogloss:0.04694\tvalidation_1-mlogloss:0.33586\n",
      "[622]\tvalidation_0-mlogloss:0.04690\tvalidation_1-mlogloss:0.33607\n",
      "[623]\tvalidation_0-mlogloss:0.04682\tvalidation_1-mlogloss:0.33606\n",
      "[624]\tvalidation_0-mlogloss:0.04676\tvalidation_1-mlogloss:0.33595\n",
      "[625]\tvalidation_0-mlogloss:0.04674\tvalidation_1-mlogloss:0.33601\n",
      "[626]\tvalidation_0-mlogloss:0.04671\tvalidation_1-mlogloss:0.33612\n",
      "[627]\tvalidation_0-mlogloss:0.04667\tvalidation_1-mlogloss:0.33602\n",
      "[628]\tvalidation_0-mlogloss:0.04664\tvalidation_1-mlogloss:0.33614\n",
      "[629]\tvalidation_0-mlogloss:0.04658\tvalidation_1-mlogloss:0.33596\n",
      "[630]\tvalidation_0-mlogloss:0.04652\tvalidation_1-mlogloss:0.33591\n",
      "[631]\tvalidation_0-mlogloss:0.04651\tvalidation_1-mlogloss:0.33606\n",
      "[632]\tvalidation_0-mlogloss:0.04648\tvalidation_1-mlogloss:0.33617\n",
      "[633]\tvalidation_0-mlogloss:0.04643\tvalidation_1-mlogloss:0.33616\n",
      "[634]\tvalidation_0-mlogloss:0.04641\tvalidation_1-mlogloss:0.33608\n",
      "[635]\tvalidation_0-mlogloss:0.04639\tvalidation_1-mlogloss:0.33618\n",
      "[636]\tvalidation_0-mlogloss:0.04638\tvalidation_1-mlogloss:0.33623\n",
      "[637]\tvalidation_0-mlogloss:0.04632\tvalidation_1-mlogloss:0.33625\n",
      "[638]\tvalidation_0-mlogloss:0.04628\tvalidation_1-mlogloss:0.33622\n",
      "[639]\tvalidation_0-mlogloss:0.04625\tvalidation_1-mlogloss:0.33632\n",
      "[640]\tvalidation_0-mlogloss:0.04623\tvalidation_1-mlogloss:0.33638\n",
      "[16:53:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-mlogloss:1.59110\tvalidation_1-mlogloss:1.59435\n",
      "[1]\tvalidation_0-mlogloss:1.57345\tvalidation_1-mlogloss:1.58093\n",
      "[2]\tvalidation_0-mlogloss:1.55630\tvalidation_1-mlogloss:1.56615\n",
      "[3]\tvalidation_0-mlogloss:1.53808\tvalidation_1-mlogloss:1.55043\n",
      "[4]\tvalidation_0-mlogloss:1.51999\tvalidation_1-mlogloss:1.53424\n",
      "[5]\tvalidation_0-mlogloss:1.50403\tvalidation_1-mlogloss:1.52111\n",
      "[6]\tvalidation_0-mlogloss:1.48648\tvalidation_1-mlogloss:1.50544\n",
      "[7]\tvalidation_0-mlogloss:1.46996\tvalidation_1-mlogloss:1.49239\n",
      "[8]\tvalidation_0-mlogloss:1.45471\tvalidation_1-mlogloss:1.48049\n",
      "[9]\tvalidation_0-mlogloss:1.43918\tvalidation_1-mlogloss:1.46850\n",
      "[10]\tvalidation_0-mlogloss:1.42258\tvalidation_1-mlogloss:1.45479\n",
      "[11]\tvalidation_0-mlogloss:1.40691\tvalidation_1-mlogloss:1.44394\n",
      "[12]\tvalidation_0-mlogloss:1.39330\tvalidation_1-mlogloss:1.43357\n",
      "[13]\tvalidation_0-mlogloss:1.37909\tvalidation_1-mlogloss:1.42295\n",
      "[14]\tvalidation_0-mlogloss:1.36425\tvalidation_1-mlogloss:1.40936\n",
      "[15]\tvalidation_0-mlogloss:1.34960\tvalidation_1-mlogloss:1.39777\n",
      "[16]\tvalidation_0-mlogloss:1.33509\tvalidation_1-mlogloss:1.38692\n",
      "[17]\tvalidation_0-mlogloss:1.32085\tvalidation_1-mlogloss:1.37614\n",
      "[18]\tvalidation_0-mlogloss:1.30785\tvalidation_1-mlogloss:1.36615\n",
      "[19]\tvalidation_0-mlogloss:1.29324\tvalidation_1-mlogloss:1.35327\n",
      "[20]\tvalidation_0-mlogloss:1.28090\tvalidation_1-mlogloss:1.34274\n",
      "[21]\tvalidation_0-mlogloss:1.26767\tvalidation_1-mlogloss:1.33236\n",
      "[22]\tvalidation_0-mlogloss:1.25579\tvalidation_1-mlogloss:1.32159\n",
      "[23]\tvalidation_0-mlogloss:1.24229\tvalidation_1-mlogloss:1.31020\n",
      "[24]\tvalidation_0-mlogloss:1.23014\tvalidation_1-mlogloss:1.30146\n",
      "[25]\tvalidation_0-mlogloss:1.21755\tvalidation_1-mlogloss:1.29126\n",
      "[26]\tvalidation_0-mlogloss:1.20523\tvalidation_1-mlogloss:1.28242\n",
      "[27]\tvalidation_0-mlogloss:1.19331\tvalidation_1-mlogloss:1.27251\n",
      "[28]\tvalidation_0-mlogloss:1.18123\tvalidation_1-mlogloss:1.26179\n",
      "[29]\tvalidation_0-mlogloss:1.16960\tvalidation_1-mlogloss:1.25223\n",
      "[30]\tvalidation_0-mlogloss:1.15739\tvalidation_1-mlogloss:1.24251\n",
      "[31]\tvalidation_0-mlogloss:1.14567\tvalidation_1-mlogloss:1.23338\n",
      "[32]\tvalidation_0-mlogloss:1.13490\tvalidation_1-mlogloss:1.22525\n",
      "[33]\tvalidation_0-mlogloss:1.12456\tvalidation_1-mlogloss:1.21746\n",
      "[34]\tvalidation_0-mlogloss:1.11439\tvalidation_1-mlogloss:1.21004\n",
      "[35]\tvalidation_0-mlogloss:1.10345\tvalidation_1-mlogloss:1.20220\n",
      "[36]\tvalidation_0-mlogloss:1.09272\tvalidation_1-mlogloss:1.19461\n",
      "[37]\tvalidation_0-mlogloss:1.08175\tvalidation_1-mlogloss:1.18465\n",
      "[38]\tvalidation_0-mlogloss:1.07133\tvalidation_1-mlogloss:1.17624\n",
      "[39]\tvalidation_0-mlogloss:1.06128\tvalidation_1-mlogloss:1.16786\n",
      "[40]\tvalidation_0-mlogloss:1.05043\tvalidation_1-mlogloss:1.15791\n",
      "[41]\tvalidation_0-mlogloss:1.03978\tvalidation_1-mlogloss:1.14891\n",
      "[42]\tvalidation_0-mlogloss:1.02935\tvalidation_1-mlogloss:1.14015\n",
      "[43]\tvalidation_0-mlogloss:1.01911\tvalidation_1-mlogloss:1.13138\n",
      "[44]\tvalidation_0-mlogloss:1.00907\tvalidation_1-mlogloss:1.12338\n",
      "[45]\tvalidation_0-mlogloss:0.99888\tvalidation_1-mlogloss:1.11512\n",
      "[46]\tvalidation_0-mlogloss:0.98932\tvalidation_1-mlogloss:1.10577\n",
      "[47]\tvalidation_0-mlogloss:0.98039\tvalidation_1-mlogloss:1.09790\n",
      "[48]\tvalidation_0-mlogloss:0.97084\tvalidation_1-mlogloss:1.09019\n",
      "[49]\tvalidation_0-mlogloss:0.96221\tvalidation_1-mlogloss:1.08387\n",
      "[50]\tvalidation_0-mlogloss:0.95278\tvalidation_1-mlogloss:1.07579\n",
      "[51]\tvalidation_0-mlogloss:0.94370\tvalidation_1-mlogloss:1.06832\n",
      "[52]\tvalidation_0-mlogloss:0.93533\tvalidation_1-mlogloss:1.06259\n",
      "[53]\tvalidation_0-mlogloss:0.92645\tvalidation_1-mlogloss:1.05500\n",
      "[54]\tvalidation_0-mlogloss:0.91796\tvalidation_1-mlogloss:1.04909\n",
      "[55]\tvalidation_0-mlogloss:0.90900\tvalidation_1-mlogloss:1.04114\n",
      "[56]\tvalidation_0-mlogloss:0.90113\tvalidation_1-mlogloss:1.03479\n",
      "[57]\tvalidation_0-mlogloss:0.89313\tvalidation_1-mlogloss:1.02835\n",
      "[58]\tvalidation_0-mlogloss:0.88526\tvalidation_1-mlogloss:1.02140\n",
      "[59]\tvalidation_0-mlogloss:0.87695\tvalidation_1-mlogloss:1.01354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60]\tvalidation_0-mlogloss:0.86966\tvalidation_1-mlogloss:1.00773\n",
      "[61]\tvalidation_0-mlogloss:0.86149\tvalidation_1-mlogloss:1.00086\n",
      "[62]\tvalidation_0-mlogloss:0.85414\tvalidation_1-mlogloss:0.99494\n",
      "[63]\tvalidation_0-mlogloss:0.84626\tvalidation_1-mlogloss:0.98951\n",
      "[64]\tvalidation_0-mlogloss:0.83851\tvalidation_1-mlogloss:0.98310\n",
      "[65]\tvalidation_0-mlogloss:0.83081\tvalidation_1-mlogloss:0.97792\n",
      "[66]\tvalidation_0-mlogloss:0.82346\tvalidation_1-mlogloss:0.97198\n",
      "[67]\tvalidation_0-mlogloss:0.81565\tvalidation_1-mlogloss:0.96508\n",
      "[68]\tvalidation_0-mlogloss:0.80773\tvalidation_1-mlogloss:0.95758\n",
      "[69]\tvalidation_0-mlogloss:0.79983\tvalidation_1-mlogloss:0.95086\n",
      "[70]\tvalidation_0-mlogloss:0.79264\tvalidation_1-mlogloss:0.94526\n",
      "[71]\tvalidation_0-mlogloss:0.78545\tvalidation_1-mlogloss:0.94054\n",
      "[72]\tvalidation_0-mlogloss:0.77853\tvalidation_1-mlogloss:0.93485\n",
      "[73]\tvalidation_0-mlogloss:0.77151\tvalidation_1-mlogloss:0.92911\n",
      "[74]\tvalidation_0-mlogloss:0.76449\tvalidation_1-mlogloss:0.92392\n",
      "[75]\tvalidation_0-mlogloss:0.75753\tvalidation_1-mlogloss:0.91811\n",
      "[76]\tvalidation_0-mlogloss:0.75053\tvalidation_1-mlogloss:0.91271\n",
      "[77]\tvalidation_0-mlogloss:0.74411\tvalidation_1-mlogloss:0.90863\n",
      "[78]\tvalidation_0-mlogloss:0.73773\tvalidation_1-mlogloss:0.90402\n",
      "[79]\tvalidation_0-mlogloss:0.73085\tvalidation_1-mlogloss:0.89860\n",
      "[80]\tvalidation_0-mlogloss:0.72448\tvalidation_1-mlogloss:0.89391\n",
      "[81]\tvalidation_0-mlogloss:0.71770\tvalidation_1-mlogloss:0.88715\n",
      "[82]\tvalidation_0-mlogloss:0.71142\tvalidation_1-mlogloss:0.88204\n",
      "[83]\tvalidation_0-mlogloss:0.70538\tvalidation_1-mlogloss:0.87697\n",
      "[84]\tvalidation_0-mlogloss:0.69915\tvalidation_1-mlogloss:0.87287\n",
      "[85]\tvalidation_0-mlogloss:0.69308\tvalidation_1-mlogloss:0.86765\n",
      "[86]\tvalidation_0-mlogloss:0.68677\tvalidation_1-mlogloss:0.86206\n",
      "[87]\tvalidation_0-mlogloss:0.68156\tvalidation_1-mlogloss:0.85813\n",
      "[88]\tvalidation_0-mlogloss:0.67553\tvalidation_1-mlogloss:0.85314\n",
      "[89]\tvalidation_0-mlogloss:0.66946\tvalidation_1-mlogloss:0.84732\n",
      "[90]\tvalidation_0-mlogloss:0.66376\tvalidation_1-mlogloss:0.84298\n",
      "[91]\tvalidation_0-mlogloss:0.65789\tvalidation_1-mlogloss:0.83837\n",
      "[92]\tvalidation_0-mlogloss:0.65204\tvalidation_1-mlogloss:0.83349\n",
      "[93]\tvalidation_0-mlogloss:0.64597\tvalidation_1-mlogloss:0.82711\n",
      "[94]\tvalidation_0-mlogloss:0.64001\tvalidation_1-mlogloss:0.82136\n",
      "[95]\tvalidation_0-mlogloss:0.63456\tvalidation_1-mlogloss:0.81732\n",
      "[96]\tvalidation_0-mlogloss:0.62907\tvalidation_1-mlogloss:0.81338\n",
      "[97]\tvalidation_0-mlogloss:0.62355\tvalidation_1-mlogloss:0.80781\n",
      "[98]\tvalidation_0-mlogloss:0.61849\tvalidation_1-mlogloss:0.80337\n",
      "[99]\tvalidation_0-mlogloss:0.61296\tvalidation_1-mlogloss:0.79866\n",
      "[100]\tvalidation_0-mlogloss:0.60751\tvalidation_1-mlogloss:0.79365\n",
      "[101]\tvalidation_0-mlogloss:0.60269\tvalidation_1-mlogloss:0.78983\n",
      "[102]\tvalidation_0-mlogloss:0.59743\tvalidation_1-mlogloss:0.78560\n",
      "[103]\tvalidation_0-mlogloss:0.59224\tvalidation_1-mlogloss:0.78152\n",
      "[104]\tvalidation_0-mlogloss:0.58695\tvalidation_1-mlogloss:0.77658\n",
      "[105]\tvalidation_0-mlogloss:0.58191\tvalidation_1-mlogloss:0.77194\n",
      "[106]\tvalidation_0-mlogloss:0.57706\tvalidation_1-mlogloss:0.76849\n",
      "[107]\tvalidation_0-mlogloss:0.57183\tvalidation_1-mlogloss:0.76342\n",
      "[108]\tvalidation_0-mlogloss:0.56673\tvalidation_1-mlogloss:0.75926\n",
      "[109]\tvalidation_0-mlogloss:0.56160\tvalidation_1-mlogloss:0.75427\n",
      "[110]\tvalidation_0-mlogloss:0.55700\tvalidation_1-mlogloss:0.75084\n",
      "[111]\tvalidation_0-mlogloss:0.55254\tvalidation_1-mlogloss:0.74722\n",
      "[112]\tvalidation_0-mlogloss:0.54799\tvalidation_1-mlogloss:0.74377\n",
      "[113]\tvalidation_0-mlogloss:0.54355\tvalidation_1-mlogloss:0.73968\n",
      "[114]\tvalidation_0-mlogloss:0.53882\tvalidation_1-mlogloss:0.73586\n",
      "[115]\tvalidation_0-mlogloss:0.53419\tvalidation_1-mlogloss:0.73230\n",
      "[116]\tvalidation_0-mlogloss:0.52952\tvalidation_1-mlogloss:0.72883\n",
      "[117]\tvalidation_0-mlogloss:0.52493\tvalidation_1-mlogloss:0.72426\n",
      "[118]\tvalidation_0-mlogloss:0.52045\tvalidation_1-mlogloss:0.72002\n",
      "[119]\tvalidation_0-mlogloss:0.51618\tvalidation_1-mlogloss:0.71723\n",
      "[120]\tvalidation_0-mlogloss:0.51161\tvalidation_1-mlogloss:0.71279\n",
      "[121]\tvalidation_0-mlogloss:0.50709\tvalidation_1-mlogloss:0.70842\n",
      "[122]\tvalidation_0-mlogloss:0.50283\tvalidation_1-mlogloss:0.70544\n",
      "[123]\tvalidation_0-mlogloss:0.49850\tvalidation_1-mlogloss:0.70172\n",
      "[124]\tvalidation_0-mlogloss:0.49429\tvalidation_1-mlogloss:0.69823\n",
      "[125]\tvalidation_0-mlogloss:0.49011\tvalidation_1-mlogloss:0.69434\n",
      "[126]\tvalidation_0-mlogloss:0.48623\tvalidation_1-mlogloss:0.69067\n",
      "[127]\tvalidation_0-mlogloss:0.48201\tvalidation_1-mlogloss:0.68623\n",
      "[128]\tvalidation_0-mlogloss:0.47798\tvalidation_1-mlogloss:0.68280\n",
      "[129]\tvalidation_0-mlogloss:0.47408\tvalidation_1-mlogloss:0.67974\n",
      "[130]\tvalidation_0-mlogloss:0.47005\tvalidation_1-mlogloss:0.67654\n",
      "[131]\tvalidation_0-mlogloss:0.46591\tvalidation_1-mlogloss:0.67293\n",
      "[132]\tvalidation_0-mlogloss:0.46201\tvalidation_1-mlogloss:0.66951\n",
      "[133]\tvalidation_0-mlogloss:0.45853\tvalidation_1-mlogloss:0.66702\n",
      "[134]\tvalidation_0-mlogloss:0.45485\tvalidation_1-mlogloss:0.66401\n",
      "[135]\tvalidation_0-mlogloss:0.45127\tvalidation_1-mlogloss:0.66149\n",
      "[136]\tvalidation_0-mlogloss:0.44748\tvalidation_1-mlogloss:0.65741\n",
      "[137]\tvalidation_0-mlogloss:0.44368\tvalidation_1-mlogloss:0.65363\n",
      "[138]\tvalidation_0-mlogloss:0.43999\tvalidation_1-mlogloss:0.65059\n",
      "[139]\tvalidation_0-mlogloss:0.43621\tvalidation_1-mlogloss:0.64753\n",
      "[140]\tvalidation_0-mlogloss:0.43256\tvalidation_1-mlogloss:0.64440\n",
      "[141]\tvalidation_0-mlogloss:0.42903\tvalidation_1-mlogloss:0.64122\n",
      "[142]\tvalidation_0-mlogloss:0.42553\tvalidation_1-mlogloss:0.63864\n",
      "[143]\tvalidation_0-mlogloss:0.42217\tvalidation_1-mlogloss:0.63656\n",
      "[144]\tvalidation_0-mlogloss:0.41854\tvalidation_1-mlogloss:0.63339\n",
      "[145]\tvalidation_0-mlogloss:0.41535\tvalidation_1-mlogloss:0.63060\n",
      "[146]\tvalidation_0-mlogloss:0.41196\tvalidation_1-mlogloss:0.62728\n",
      "[147]\tvalidation_0-mlogloss:0.40869\tvalidation_1-mlogloss:0.62474\n",
      "[148]\tvalidation_0-mlogloss:0.40548\tvalidation_1-mlogloss:0.62251\n",
      "[149]\tvalidation_0-mlogloss:0.40223\tvalidation_1-mlogloss:0.61994\n",
      "[150]\tvalidation_0-mlogloss:0.39934\tvalidation_1-mlogloss:0.61803\n",
      "[151]\tvalidation_0-mlogloss:0.39617\tvalidation_1-mlogloss:0.61522\n",
      "[152]\tvalidation_0-mlogloss:0.39283\tvalidation_1-mlogloss:0.61218\n",
      "[153]\tvalidation_0-mlogloss:0.38950\tvalidation_1-mlogloss:0.60894\n",
      "[154]\tvalidation_0-mlogloss:0.38642\tvalidation_1-mlogloss:0.60595\n",
      "[155]\tvalidation_0-mlogloss:0.38343\tvalidation_1-mlogloss:0.60348\n",
      "[156]\tvalidation_0-mlogloss:0.38057\tvalidation_1-mlogloss:0.60087\n",
      "[157]\tvalidation_0-mlogloss:0.37748\tvalidation_1-mlogloss:0.59847\n",
      "[158]\tvalidation_0-mlogloss:0.37436\tvalidation_1-mlogloss:0.59639\n",
      "[159]\tvalidation_0-mlogloss:0.37131\tvalidation_1-mlogloss:0.59445\n",
      "[160]\tvalidation_0-mlogloss:0.36849\tvalidation_1-mlogloss:0.59240\n",
      "[161]\tvalidation_0-mlogloss:0.36575\tvalidation_1-mlogloss:0.58998\n",
      "[162]\tvalidation_0-mlogloss:0.36297\tvalidation_1-mlogloss:0.58791\n",
      "[163]\tvalidation_0-mlogloss:0.35995\tvalidation_1-mlogloss:0.58497\n",
      "[164]\tvalidation_0-mlogloss:0.35707\tvalidation_1-mlogloss:0.58227\n",
      "[165]\tvalidation_0-mlogloss:0.35432\tvalidation_1-mlogloss:0.58023\n",
      "[166]\tvalidation_0-mlogloss:0.35172\tvalidation_1-mlogloss:0.57826\n",
      "[167]\tvalidation_0-mlogloss:0.34928\tvalidation_1-mlogloss:0.57662\n",
      "[168]\tvalidation_0-mlogloss:0.34658\tvalidation_1-mlogloss:0.57421\n",
      "[169]\tvalidation_0-mlogloss:0.34384\tvalidation_1-mlogloss:0.57244\n",
      "[170]\tvalidation_0-mlogloss:0.34119\tvalidation_1-mlogloss:0.56990\n",
      "[171]\tvalidation_0-mlogloss:0.33843\tvalidation_1-mlogloss:0.56779\n",
      "[172]\tvalidation_0-mlogloss:0.33580\tvalidation_1-mlogloss:0.56543\n",
      "[173]\tvalidation_0-mlogloss:0.33328\tvalidation_1-mlogloss:0.56330\n",
      "[174]\tvalidation_0-mlogloss:0.33073\tvalidation_1-mlogloss:0.56129\n",
      "[175]\tvalidation_0-mlogloss:0.32809\tvalidation_1-mlogloss:0.55866\n",
      "[176]\tvalidation_0-mlogloss:0.32569\tvalidation_1-mlogloss:0.55723\n",
      "[177]\tvalidation_0-mlogloss:0.32313\tvalidation_1-mlogloss:0.55476\n",
      "[178]\tvalidation_0-mlogloss:0.32081\tvalidation_1-mlogloss:0.55239\n",
      "[179]\tvalidation_0-mlogloss:0.31832\tvalidation_1-mlogloss:0.55001\n",
      "[180]\tvalidation_0-mlogloss:0.31579\tvalidation_1-mlogloss:0.54756\n",
      "[181]\tvalidation_0-mlogloss:0.31330\tvalidation_1-mlogloss:0.54482\n",
      "[182]\tvalidation_0-mlogloss:0.31105\tvalidation_1-mlogloss:0.54290\n",
      "[183]\tvalidation_0-mlogloss:0.30883\tvalidation_1-mlogloss:0.54155\n",
      "[184]\tvalidation_0-mlogloss:0.30646\tvalidation_1-mlogloss:0.53979\n",
      "[185]\tvalidation_0-mlogloss:0.30411\tvalidation_1-mlogloss:0.53823\n",
      "[186]\tvalidation_0-mlogloss:0.30190\tvalidation_1-mlogloss:0.53682\n",
      "[187]\tvalidation_0-mlogloss:0.29962\tvalidation_1-mlogloss:0.53475\n",
      "[188]\tvalidation_0-mlogloss:0.29727\tvalidation_1-mlogloss:0.53242\n",
      "[189]\tvalidation_0-mlogloss:0.29505\tvalidation_1-mlogloss:0.53070\n",
      "[190]\tvalidation_0-mlogloss:0.29277\tvalidation_1-mlogloss:0.52884\n",
      "[191]\tvalidation_0-mlogloss:0.29045\tvalidation_1-mlogloss:0.52686\n",
      "[192]\tvalidation_0-mlogloss:0.28824\tvalidation_1-mlogloss:0.52507\n",
      "[193]\tvalidation_0-mlogloss:0.28602\tvalidation_1-mlogloss:0.52360\n",
      "[194]\tvalidation_0-mlogloss:0.28389\tvalidation_1-mlogloss:0.52175\n",
      "[195]\tvalidation_0-mlogloss:0.28176\tvalidation_1-mlogloss:0.52029\n",
      "[196]\tvalidation_0-mlogloss:0.27967\tvalidation_1-mlogloss:0.51844\n",
      "[197]\tvalidation_0-mlogloss:0.27749\tvalidation_1-mlogloss:0.51666\n",
      "[198]\tvalidation_0-mlogloss:0.27539\tvalidation_1-mlogloss:0.51472\n",
      "[199]\tvalidation_0-mlogloss:0.27332\tvalidation_1-mlogloss:0.51278\n",
      "[200]\tvalidation_0-mlogloss:0.27120\tvalidation_1-mlogloss:0.51058\n",
      "[201]\tvalidation_0-mlogloss:0.26922\tvalidation_1-mlogloss:0.50861\n",
      "[202]\tvalidation_0-mlogloss:0.26724\tvalidation_1-mlogloss:0.50748\n",
      "[203]\tvalidation_0-mlogloss:0.26528\tvalidation_1-mlogloss:0.50577\n",
      "[204]\tvalidation_0-mlogloss:0.26330\tvalidation_1-mlogloss:0.50389\n",
      "[205]\tvalidation_0-mlogloss:0.26136\tvalidation_1-mlogloss:0.50204\n",
      "[206]\tvalidation_0-mlogloss:0.25940\tvalidation_1-mlogloss:0.50055\n",
      "[207]\tvalidation_0-mlogloss:0.25764\tvalidation_1-mlogloss:0.49887\n",
      "[208]\tvalidation_0-mlogloss:0.25569\tvalidation_1-mlogloss:0.49702\n",
      "[209]\tvalidation_0-mlogloss:0.25374\tvalidation_1-mlogloss:0.49563\n",
      "[210]\tvalidation_0-mlogloss:0.25185\tvalidation_1-mlogloss:0.49412\n",
      "[211]\tvalidation_0-mlogloss:0.24996\tvalidation_1-mlogloss:0.49206\n",
      "[212]\tvalidation_0-mlogloss:0.24809\tvalidation_1-mlogloss:0.49069\n",
      "[213]\tvalidation_0-mlogloss:0.24634\tvalidation_1-mlogloss:0.48920\n",
      "[214]\tvalidation_0-mlogloss:0.24456\tvalidation_1-mlogloss:0.48814\n",
      "[215]\tvalidation_0-mlogloss:0.24291\tvalidation_1-mlogloss:0.48628\n",
      "[216]\tvalidation_0-mlogloss:0.24112\tvalidation_1-mlogloss:0.48464\n",
      "[217]\tvalidation_0-mlogloss:0.23937\tvalidation_1-mlogloss:0.48257\n",
      "[218]\tvalidation_0-mlogloss:0.23765\tvalidation_1-mlogloss:0.48126\n",
      "[219]\tvalidation_0-mlogloss:0.23590\tvalidation_1-mlogloss:0.47942\n",
      "[220]\tvalidation_0-mlogloss:0.23418\tvalidation_1-mlogloss:0.47813\n",
      "[221]\tvalidation_0-mlogloss:0.23255\tvalidation_1-mlogloss:0.47709\n",
      "[222]\tvalidation_0-mlogloss:0.23088\tvalidation_1-mlogloss:0.47583\n",
      "[223]\tvalidation_0-mlogloss:0.22935\tvalidation_1-mlogloss:0.47503\n",
      "[224]\tvalidation_0-mlogloss:0.22771\tvalidation_1-mlogloss:0.47370\n",
      "[225]\tvalidation_0-mlogloss:0.22602\tvalidation_1-mlogloss:0.47199\n",
      "[226]\tvalidation_0-mlogloss:0.22433\tvalidation_1-mlogloss:0.47041\n",
      "[227]\tvalidation_0-mlogloss:0.22280\tvalidation_1-mlogloss:0.46956\n",
      "[228]\tvalidation_0-mlogloss:0.22127\tvalidation_1-mlogloss:0.46879\n",
      "[229]\tvalidation_0-mlogloss:0.21970\tvalidation_1-mlogloss:0.46761\n",
      "[230]\tvalidation_0-mlogloss:0.21819\tvalidation_1-mlogloss:0.46650\n",
      "[231]\tvalidation_0-mlogloss:0.21656\tvalidation_1-mlogloss:0.46465\n",
      "[232]\tvalidation_0-mlogloss:0.21496\tvalidation_1-mlogloss:0.46315\n",
      "[233]\tvalidation_0-mlogloss:0.21343\tvalidation_1-mlogloss:0.46200\n",
      "[234]\tvalidation_0-mlogloss:0.21195\tvalidation_1-mlogloss:0.46008\n",
      "[235]\tvalidation_0-mlogloss:0.21047\tvalidation_1-mlogloss:0.45928\n",
      "[236]\tvalidation_0-mlogloss:0.20907\tvalidation_1-mlogloss:0.45830\n",
      "[237]\tvalidation_0-mlogloss:0.20752\tvalidation_1-mlogloss:0.45695\n",
      "[238]\tvalidation_0-mlogloss:0.20601\tvalidation_1-mlogloss:0.45574\n",
      "[239]\tvalidation_0-mlogloss:0.20456\tvalidation_1-mlogloss:0.45453\n",
      "[240]\tvalidation_0-mlogloss:0.20315\tvalidation_1-mlogloss:0.45313\n",
      "[241]\tvalidation_0-mlogloss:0.20167\tvalidation_1-mlogloss:0.45183\n",
      "[242]\tvalidation_0-mlogloss:0.20025\tvalidation_1-mlogloss:0.45047\n",
      "[243]\tvalidation_0-mlogloss:0.19892\tvalidation_1-mlogloss:0.44988\n",
      "[244]\tvalidation_0-mlogloss:0.19755\tvalidation_1-mlogloss:0.44888\n",
      "[245]\tvalidation_0-mlogloss:0.19625\tvalidation_1-mlogloss:0.44783\n",
      "[246]\tvalidation_0-mlogloss:0.19490\tvalidation_1-mlogloss:0.44670\n",
      "[247]\tvalidation_0-mlogloss:0.19363\tvalidation_1-mlogloss:0.44508\n",
      "[248]\tvalidation_0-mlogloss:0.19227\tvalidation_1-mlogloss:0.44408\n",
      "[249]\tvalidation_0-mlogloss:0.19094\tvalidation_1-mlogloss:0.44264\n",
      "[250]\tvalidation_0-mlogloss:0.18960\tvalidation_1-mlogloss:0.44157\n",
      "[251]\tvalidation_0-mlogloss:0.18834\tvalidation_1-mlogloss:0.44077\n",
      "[252]\tvalidation_0-mlogloss:0.18721\tvalidation_1-mlogloss:0.43986\n",
      "[253]\tvalidation_0-mlogloss:0.18589\tvalidation_1-mlogloss:0.43837\n",
      "[254]\tvalidation_0-mlogloss:0.18468\tvalidation_1-mlogloss:0.43773\n",
      "[255]\tvalidation_0-mlogloss:0.18345\tvalidation_1-mlogloss:0.43681\n",
      "[256]\tvalidation_0-mlogloss:0.18218\tvalidation_1-mlogloss:0.43569\n",
      "[257]\tvalidation_0-mlogloss:0.18095\tvalidation_1-mlogloss:0.43475\n",
      "[258]\tvalidation_0-mlogloss:0.17974\tvalidation_1-mlogloss:0.43385\n",
      "[259]\tvalidation_0-mlogloss:0.17855\tvalidation_1-mlogloss:0.43280\n",
      "[260]\tvalidation_0-mlogloss:0.17742\tvalidation_1-mlogloss:0.43181\n",
      "[261]\tvalidation_0-mlogloss:0.17618\tvalidation_1-mlogloss:0.43075\n",
      "[262]\tvalidation_0-mlogloss:0.17509\tvalidation_1-mlogloss:0.42984\n",
      "[263]\tvalidation_0-mlogloss:0.17393\tvalidation_1-mlogloss:0.42899\n",
      "[264]\tvalidation_0-mlogloss:0.17284\tvalidation_1-mlogloss:0.42826\n",
      "[265]\tvalidation_0-mlogloss:0.17168\tvalidation_1-mlogloss:0.42762\n",
      "[266]\tvalidation_0-mlogloss:0.17059\tvalidation_1-mlogloss:0.42718\n",
      "[267]\tvalidation_0-mlogloss:0.16944\tvalidation_1-mlogloss:0.42643\n",
      "[268]\tvalidation_0-mlogloss:0.16833\tvalidation_1-mlogloss:0.42562\n",
      "[269]\tvalidation_0-mlogloss:0.16718\tvalidation_1-mlogloss:0.42461\n",
      "[270]\tvalidation_0-mlogloss:0.16610\tvalidation_1-mlogloss:0.42388\n",
      "[271]\tvalidation_0-mlogloss:0.16496\tvalidation_1-mlogloss:0.42278\n",
      "[272]\tvalidation_0-mlogloss:0.16386\tvalidation_1-mlogloss:0.42158\n",
      "[273]\tvalidation_0-mlogloss:0.16280\tvalidation_1-mlogloss:0.42069\n",
      "[274]\tvalidation_0-mlogloss:0.16172\tvalidation_1-mlogloss:0.41968\n",
      "[275]\tvalidation_0-mlogloss:0.16072\tvalidation_1-mlogloss:0.41901\n",
      "[276]\tvalidation_0-mlogloss:0.15967\tvalidation_1-mlogloss:0.41776\n",
      "[277]\tvalidation_0-mlogloss:0.15867\tvalidation_1-mlogloss:0.41748\n",
      "[278]\tvalidation_0-mlogloss:0.15761\tvalidation_1-mlogloss:0.41662\n",
      "[279]\tvalidation_0-mlogloss:0.15665\tvalidation_1-mlogloss:0.41601\n",
      "[280]\tvalidation_0-mlogloss:0.15566\tvalidation_1-mlogloss:0.41566\n",
      "[281]\tvalidation_0-mlogloss:0.15472\tvalidation_1-mlogloss:0.41494\n",
      "[282]\tvalidation_0-mlogloss:0.15370\tvalidation_1-mlogloss:0.41450\n",
      "[283]\tvalidation_0-mlogloss:0.15276\tvalidation_1-mlogloss:0.41382\n",
      "[284]\tvalidation_0-mlogloss:0.15178\tvalidation_1-mlogloss:0.41276\n",
      "[285]\tvalidation_0-mlogloss:0.15078\tvalidation_1-mlogloss:0.41161\n",
      "[286]\tvalidation_0-mlogloss:0.14985\tvalidation_1-mlogloss:0.41123\n",
      "[287]\tvalidation_0-mlogloss:0.14886\tvalidation_1-mlogloss:0.41017\n",
      "[288]\tvalidation_0-mlogloss:0.14789\tvalidation_1-mlogloss:0.40949\n",
      "[289]\tvalidation_0-mlogloss:0.14691\tvalidation_1-mlogloss:0.40890\n",
      "[290]\tvalidation_0-mlogloss:0.14601\tvalidation_1-mlogloss:0.40848\n",
      "[291]\tvalidation_0-mlogloss:0.14509\tvalidation_1-mlogloss:0.40785\n",
      "[292]\tvalidation_0-mlogloss:0.14424\tvalidation_1-mlogloss:0.40741\n",
      "[293]\tvalidation_0-mlogloss:0.14333\tvalidation_1-mlogloss:0.40680\n",
      "[294]\tvalidation_0-mlogloss:0.14242\tvalidation_1-mlogloss:0.40627\n",
      "[295]\tvalidation_0-mlogloss:0.14153\tvalidation_1-mlogloss:0.40530\n",
      "[296]\tvalidation_0-mlogloss:0.14075\tvalidation_1-mlogloss:0.40467\n",
      "[297]\tvalidation_0-mlogloss:0.13991\tvalidation_1-mlogloss:0.40448\n",
      "[298]\tvalidation_0-mlogloss:0.13902\tvalidation_1-mlogloss:0.40349\n",
      "[299]\tvalidation_0-mlogloss:0.13815\tvalidation_1-mlogloss:0.40250\n",
      "[300]\tvalidation_0-mlogloss:0.13727\tvalidation_1-mlogloss:0.40182\n",
      "[301]\tvalidation_0-mlogloss:0.13642\tvalidation_1-mlogloss:0.40127\n",
      "[302]\tvalidation_0-mlogloss:0.13561\tvalidation_1-mlogloss:0.40053\n",
      "[303]\tvalidation_0-mlogloss:0.13482\tvalidation_1-mlogloss:0.40036\n",
      "[304]\tvalidation_0-mlogloss:0.13405\tvalidation_1-mlogloss:0.40022\n",
      "[305]\tvalidation_0-mlogloss:0.13326\tvalidation_1-mlogloss:0.39988\n",
      "[306]\tvalidation_0-mlogloss:0.13251\tvalidation_1-mlogloss:0.39932\n",
      "[307]\tvalidation_0-mlogloss:0.13167\tvalidation_1-mlogloss:0.39872\n",
      "[308]\tvalidation_0-mlogloss:0.13087\tvalidation_1-mlogloss:0.39806\n",
      "[309]\tvalidation_0-mlogloss:0.13004\tvalidation_1-mlogloss:0.39744\n",
      "[310]\tvalidation_0-mlogloss:0.12927\tvalidation_1-mlogloss:0.39680\n",
      "[311]\tvalidation_0-mlogloss:0.12848\tvalidation_1-mlogloss:0.39655\n",
      "[312]\tvalidation_0-mlogloss:0.12772\tvalidation_1-mlogloss:0.39602\n",
      "[313]\tvalidation_0-mlogloss:0.12694\tvalidation_1-mlogloss:0.39558\n",
      "[314]\tvalidation_0-mlogloss:0.12620\tvalidation_1-mlogloss:0.39542\n",
      "[315]\tvalidation_0-mlogloss:0.12548\tvalidation_1-mlogloss:0.39519\n",
      "[316]\tvalidation_0-mlogloss:0.12485\tvalidation_1-mlogloss:0.39486\n",
      "[317]\tvalidation_0-mlogloss:0.12419\tvalidation_1-mlogloss:0.39459\n",
      "[318]\tvalidation_0-mlogloss:0.12349\tvalidation_1-mlogloss:0.39419\n",
      "[319]\tvalidation_0-mlogloss:0.12276\tvalidation_1-mlogloss:0.39319\n",
      "[320]\tvalidation_0-mlogloss:0.12204\tvalidation_1-mlogloss:0.39304\n",
      "[321]\tvalidation_0-mlogloss:0.12128\tvalidation_1-mlogloss:0.39229\n",
      "[322]\tvalidation_0-mlogloss:0.12063\tvalidation_1-mlogloss:0.39205\n",
      "[323]\tvalidation_0-mlogloss:0.11989\tvalidation_1-mlogloss:0.39125\n",
      "[324]\tvalidation_0-mlogloss:0.11919\tvalidation_1-mlogloss:0.39085\n",
      "[325]\tvalidation_0-mlogloss:0.11849\tvalidation_1-mlogloss:0.39005\n",
      "[326]\tvalidation_0-mlogloss:0.11780\tvalidation_1-mlogloss:0.38991\n",
      "[327]\tvalidation_0-mlogloss:0.11713\tvalidation_1-mlogloss:0.38921\n",
      "[328]\tvalidation_0-mlogloss:0.11643\tvalidation_1-mlogloss:0.38889\n",
      "[329]\tvalidation_0-mlogloss:0.11575\tvalidation_1-mlogloss:0.38819\n",
      "[330]\tvalidation_0-mlogloss:0.11508\tvalidation_1-mlogloss:0.38757\n",
      "[331]\tvalidation_0-mlogloss:0.11444\tvalidation_1-mlogloss:0.38717\n",
      "[332]\tvalidation_0-mlogloss:0.11375\tvalidation_1-mlogloss:0.38626\n",
      "[333]\tvalidation_0-mlogloss:0.11308\tvalidation_1-mlogloss:0.38575\n",
      "[334]\tvalidation_0-mlogloss:0.11242\tvalidation_1-mlogloss:0.38539\n",
      "[335]\tvalidation_0-mlogloss:0.11178\tvalidation_1-mlogloss:0.38489\n",
      "[336]\tvalidation_0-mlogloss:0.11122\tvalidation_1-mlogloss:0.38449\n",
      "[337]\tvalidation_0-mlogloss:0.11057\tvalidation_1-mlogloss:0.38417\n",
      "[338]\tvalidation_0-mlogloss:0.10999\tvalidation_1-mlogloss:0.38336\n",
      "[339]\tvalidation_0-mlogloss:0.10940\tvalidation_1-mlogloss:0.38304\n",
      "[340]\tvalidation_0-mlogloss:0.10880\tvalidation_1-mlogloss:0.38291\n",
      "[341]\tvalidation_0-mlogloss:0.10823\tvalidation_1-mlogloss:0.38243\n",
      "[342]\tvalidation_0-mlogloss:0.10764\tvalidation_1-mlogloss:0.38208\n",
      "[343]\tvalidation_0-mlogloss:0.10707\tvalidation_1-mlogloss:0.38188\n",
      "[344]\tvalidation_0-mlogloss:0.10650\tvalidation_1-mlogloss:0.38185\n",
      "[345]\tvalidation_0-mlogloss:0.10594\tvalidation_1-mlogloss:0.38159\n",
      "[346]\tvalidation_0-mlogloss:0.10540\tvalidation_1-mlogloss:0.38125\n",
      "[347]\tvalidation_0-mlogloss:0.10482\tvalidation_1-mlogloss:0.38065\n",
      "[348]\tvalidation_0-mlogloss:0.10427\tvalidation_1-mlogloss:0.38002\n",
      "[349]\tvalidation_0-mlogloss:0.10374\tvalidation_1-mlogloss:0.37977\n",
      "[350]\tvalidation_0-mlogloss:0.10320\tvalidation_1-mlogloss:0.37953\n",
      "[351]\tvalidation_0-mlogloss:0.10264\tvalidation_1-mlogloss:0.37917\n",
      "[352]\tvalidation_0-mlogloss:0.10207\tvalidation_1-mlogloss:0.37864\n",
      "[353]\tvalidation_0-mlogloss:0.10151\tvalidation_1-mlogloss:0.37839\n",
      "[354]\tvalidation_0-mlogloss:0.10100\tvalidation_1-mlogloss:0.37818\n",
      "[355]\tvalidation_0-mlogloss:0.10048\tvalidation_1-mlogloss:0.37805\n",
      "[356]\tvalidation_0-mlogloss:0.10002\tvalidation_1-mlogloss:0.37743\n",
      "[357]\tvalidation_0-mlogloss:0.09947\tvalidation_1-mlogloss:0.37720\n",
      "[358]\tvalidation_0-mlogloss:0.09898\tvalidation_1-mlogloss:0.37723\n",
      "[359]\tvalidation_0-mlogloss:0.09842\tvalidation_1-mlogloss:0.37687\n",
      "[360]\tvalidation_0-mlogloss:0.09796\tvalidation_1-mlogloss:0.37631\n",
      "[361]\tvalidation_0-mlogloss:0.09749\tvalidation_1-mlogloss:0.37634\n",
      "[362]\tvalidation_0-mlogloss:0.09695\tvalidation_1-mlogloss:0.37591\n",
      "[363]\tvalidation_0-mlogloss:0.09651\tvalidation_1-mlogloss:0.37580\n",
      "[364]\tvalidation_0-mlogloss:0.09601\tvalidation_1-mlogloss:0.37530\n",
      "[365]\tvalidation_0-mlogloss:0.09551\tvalidation_1-mlogloss:0.37459\n",
      "[366]\tvalidation_0-mlogloss:0.09501\tvalidation_1-mlogloss:0.37420\n",
      "[367]\tvalidation_0-mlogloss:0.09455\tvalidation_1-mlogloss:0.37347\n",
      "[368]\tvalidation_0-mlogloss:0.09408\tvalidation_1-mlogloss:0.37325\n",
      "[369]\tvalidation_0-mlogloss:0.09359\tvalidation_1-mlogloss:0.37292\n",
      "[370]\tvalidation_0-mlogloss:0.09313\tvalidation_1-mlogloss:0.37258\n",
      "[371]\tvalidation_0-mlogloss:0.09267\tvalidation_1-mlogloss:0.37194\n",
      "[372]\tvalidation_0-mlogloss:0.09218\tvalidation_1-mlogloss:0.37152\n",
      "[373]\tvalidation_0-mlogloss:0.09174\tvalidation_1-mlogloss:0.37150\n",
      "[374]\tvalidation_0-mlogloss:0.09131\tvalidation_1-mlogloss:0.37095\n",
      "[375]\tvalidation_0-mlogloss:0.09086\tvalidation_1-mlogloss:0.37032\n",
      "[376]\tvalidation_0-mlogloss:0.09044\tvalidation_1-mlogloss:0.36966\n",
      "[377]\tvalidation_0-mlogloss:0.08999\tvalidation_1-mlogloss:0.36951\n",
      "[378]\tvalidation_0-mlogloss:0.08957\tvalidation_1-mlogloss:0.36943\n",
      "[379]\tvalidation_0-mlogloss:0.08913\tvalidation_1-mlogloss:0.36887\n",
      "[380]\tvalidation_0-mlogloss:0.08870\tvalidation_1-mlogloss:0.36856\n",
      "[381]\tvalidation_0-mlogloss:0.08828\tvalidation_1-mlogloss:0.36813\n",
      "[382]\tvalidation_0-mlogloss:0.08783\tvalidation_1-mlogloss:0.36758\n",
      "[383]\tvalidation_0-mlogloss:0.08742\tvalidation_1-mlogloss:0.36759\n",
      "[384]\tvalidation_0-mlogloss:0.08700\tvalidation_1-mlogloss:0.36720\n",
      "[385]\tvalidation_0-mlogloss:0.08652\tvalidation_1-mlogloss:0.36691\n",
      "[386]\tvalidation_0-mlogloss:0.08609\tvalidation_1-mlogloss:0.36659\n",
      "[387]\tvalidation_0-mlogloss:0.08570\tvalidation_1-mlogloss:0.36649\n",
      "[388]\tvalidation_0-mlogloss:0.08528\tvalidation_1-mlogloss:0.36629\n",
      "[389]\tvalidation_0-mlogloss:0.08488\tvalidation_1-mlogloss:0.36571\n",
      "[390]\tvalidation_0-mlogloss:0.08447\tvalidation_1-mlogloss:0.36547\n",
      "[391]\tvalidation_0-mlogloss:0.08413\tvalidation_1-mlogloss:0.36524\n",
      "[392]\tvalidation_0-mlogloss:0.08372\tvalidation_1-mlogloss:0.36472\n",
      "[393]\tvalidation_0-mlogloss:0.08333\tvalidation_1-mlogloss:0.36460\n",
      "[394]\tvalidation_0-mlogloss:0.08291\tvalidation_1-mlogloss:0.36392\n",
      "[395]\tvalidation_0-mlogloss:0.08253\tvalidation_1-mlogloss:0.36370\n",
      "[396]\tvalidation_0-mlogloss:0.08212\tvalidation_1-mlogloss:0.36351\n",
      "[397]\tvalidation_0-mlogloss:0.08178\tvalidation_1-mlogloss:0.36322\n",
      "[398]\tvalidation_0-mlogloss:0.08138\tvalidation_1-mlogloss:0.36289\n",
      "[399]\tvalidation_0-mlogloss:0.08098\tvalidation_1-mlogloss:0.36296\n",
      "[400]\tvalidation_0-mlogloss:0.08064\tvalidation_1-mlogloss:0.36289\n",
      "[401]\tvalidation_0-mlogloss:0.08029\tvalidation_1-mlogloss:0.36275\n",
      "[402]\tvalidation_0-mlogloss:0.07993\tvalidation_1-mlogloss:0.36224\n",
      "[403]\tvalidation_0-mlogloss:0.07964\tvalidation_1-mlogloss:0.36192\n",
      "[404]\tvalidation_0-mlogloss:0.07929\tvalidation_1-mlogloss:0.36149\n",
      "[405]\tvalidation_0-mlogloss:0.07892\tvalidation_1-mlogloss:0.36158\n",
      "[406]\tvalidation_0-mlogloss:0.07854\tvalidation_1-mlogloss:0.36151\n",
      "[407]\tvalidation_0-mlogloss:0.07817\tvalidation_1-mlogloss:0.36157\n",
      "[408]\tvalidation_0-mlogloss:0.07784\tvalidation_1-mlogloss:0.36138\n",
      "[409]\tvalidation_0-mlogloss:0.07750\tvalidation_1-mlogloss:0.36098\n",
      "[410]\tvalidation_0-mlogloss:0.07714\tvalidation_1-mlogloss:0.36097\n",
      "[411]\tvalidation_0-mlogloss:0.07679\tvalidation_1-mlogloss:0.36091\n",
      "[412]\tvalidation_0-mlogloss:0.07642\tvalidation_1-mlogloss:0.36029\n",
      "[413]\tvalidation_0-mlogloss:0.07614\tvalidation_1-mlogloss:0.36048\n",
      "[414]\tvalidation_0-mlogloss:0.07580\tvalidation_1-mlogloss:0.36053\n",
      "[415]\tvalidation_0-mlogloss:0.07549\tvalidation_1-mlogloss:0.36035\n",
      "[416]\tvalidation_0-mlogloss:0.07515\tvalidation_1-mlogloss:0.36047\n",
      "[417]\tvalidation_0-mlogloss:0.07484\tvalidation_1-mlogloss:0.36035\n",
      "[418]\tvalidation_0-mlogloss:0.07458\tvalidation_1-mlogloss:0.36014\n",
      "[419]\tvalidation_0-mlogloss:0.07420\tvalidation_1-mlogloss:0.35962\n",
      "[420]\tvalidation_0-mlogloss:0.07386\tvalidation_1-mlogloss:0.35951\n",
      "[421]\tvalidation_0-mlogloss:0.07355\tvalidation_1-mlogloss:0.35915\n",
      "[422]\tvalidation_0-mlogloss:0.07325\tvalidation_1-mlogloss:0.35919\n",
      "[423]\tvalidation_0-mlogloss:0.07291\tvalidation_1-mlogloss:0.35930\n",
      "[424]\tvalidation_0-mlogloss:0.07260\tvalidation_1-mlogloss:0.35925\n",
      "[425]\tvalidation_0-mlogloss:0.07233\tvalidation_1-mlogloss:0.35931\n",
      "[426]\tvalidation_0-mlogloss:0.07201\tvalidation_1-mlogloss:0.35918\n",
      "[427]\tvalidation_0-mlogloss:0.07174\tvalidation_1-mlogloss:0.35922\n",
      "[428]\tvalidation_0-mlogloss:0.07146\tvalidation_1-mlogloss:0.35921\n",
      "[429]\tvalidation_0-mlogloss:0.07117\tvalidation_1-mlogloss:0.35892\n",
      "[430]\tvalidation_0-mlogloss:0.07086\tvalidation_1-mlogloss:0.35857\n",
      "[431]\tvalidation_0-mlogloss:0.07055\tvalidation_1-mlogloss:0.35867\n",
      "[432]\tvalidation_0-mlogloss:0.07026\tvalidation_1-mlogloss:0.35839\n",
      "[433]\tvalidation_0-mlogloss:0.06995\tvalidation_1-mlogloss:0.35820\n",
      "[434]\tvalidation_0-mlogloss:0.06966\tvalidation_1-mlogloss:0.35829\n",
      "[435]\tvalidation_0-mlogloss:0.06936\tvalidation_1-mlogloss:0.35799\n",
      "[436]\tvalidation_0-mlogloss:0.06910\tvalidation_1-mlogloss:0.35809\n",
      "[437]\tvalidation_0-mlogloss:0.06882\tvalidation_1-mlogloss:0.35764\n",
      "[438]\tvalidation_0-mlogloss:0.06853\tvalidation_1-mlogloss:0.35762\n",
      "[439]\tvalidation_0-mlogloss:0.06822\tvalidation_1-mlogloss:0.35781\n",
      "[440]\tvalidation_0-mlogloss:0.06794\tvalidation_1-mlogloss:0.35760\n",
      "[441]\tvalidation_0-mlogloss:0.06767\tvalidation_1-mlogloss:0.35761\n",
      "[442]\tvalidation_0-mlogloss:0.06741\tvalidation_1-mlogloss:0.35756\n",
      "[443]\tvalidation_0-mlogloss:0.06718\tvalidation_1-mlogloss:0.35725\n",
      "[444]\tvalidation_0-mlogloss:0.06689\tvalidation_1-mlogloss:0.35706\n",
      "[445]\tvalidation_0-mlogloss:0.06660\tvalidation_1-mlogloss:0.35709\n",
      "[446]\tvalidation_0-mlogloss:0.06641\tvalidation_1-mlogloss:0.35682\n",
      "[447]\tvalidation_0-mlogloss:0.06618\tvalidation_1-mlogloss:0.35682\n",
      "[448]\tvalidation_0-mlogloss:0.06593\tvalidation_1-mlogloss:0.35679\n",
      "[449]\tvalidation_0-mlogloss:0.06566\tvalidation_1-mlogloss:0.35627\n",
      "[450]\tvalidation_0-mlogloss:0.06540\tvalidation_1-mlogloss:0.35625\n",
      "[451]\tvalidation_0-mlogloss:0.06513\tvalidation_1-mlogloss:0.35601\n",
      "[452]\tvalidation_0-mlogloss:0.06486\tvalidation_1-mlogloss:0.35588\n",
      "[453]\tvalidation_0-mlogloss:0.06457\tvalidation_1-mlogloss:0.35592\n",
      "[454]\tvalidation_0-mlogloss:0.06430\tvalidation_1-mlogloss:0.35598\n",
      "[455]\tvalidation_0-mlogloss:0.06409\tvalidation_1-mlogloss:0.35588\n",
      "[456]\tvalidation_0-mlogloss:0.06380\tvalidation_1-mlogloss:0.35571\n",
      "[457]\tvalidation_0-mlogloss:0.06355\tvalidation_1-mlogloss:0.35536\n",
      "[458]\tvalidation_0-mlogloss:0.06328\tvalidation_1-mlogloss:0.35501\n",
      "[459]\tvalidation_0-mlogloss:0.06303\tvalidation_1-mlogloss:0.35457\n",
      "[460]\tvalidation_0-mlogloss:0.06285\tvalidation_1-mlogloss:0.35462\n",
      "[461]\tvalidation_0-mlogloss:0.06271\tvalidation_1-mlogloss:0.35439\n",
      "[462]\tvalidation_0-mlogloss:0.06247\tvalidation_1-mlogloss:0.35431\n",
      "[463]\tvalidation_0-mlogloss:0.06222\tvalidation_1-mlogloss:0.35446\n",
      "[464]\tvalidation_0-mlogloss:0.06197\tvalidation_1-mlogloss:0.35458\n",
      "[465]\tvalidation_0-mlogloss:0.06170\tvalidation_1-mlogloss:0.35441\n",
      "[466]\tvalidation_0-mlogloss:0.06147\tvalidation_1-mlogloss:0.35437\n",
      "[467]\tvalidation_0-mlogloss:0.06131\tvalidation_1-mlogloss:0.35439\n",
      "[468]\tvalidation_0-mlogloss:0.06109\tvalidation_1-mlogloss:0.35441\n",
      "[469]\tvalidation_0-mlogloss:0.06090\tvalidation_1-mlogloss:0.35420\n",
      "[470]\tvalidation_0-mlogloss:0.06065\tvalidation_1-mlogloss:0.35395\n",
      "[471]\tvalidation_0-mlogloss:0.06045\tvalidation_1-mlogloss:0.35373\n",
      "[472]\tvalidation_0-mlogloss:0.06028\tvalidation_1-mlogloss:0.35353\n",
      "[473]\tvalidation_0-mlogloss:0.06006\tvalidation_1-mlogloss:0.35321\n",
      "[474]\tvalidation_0-mlogloss:0.05988\tvalidation_1-mlogloss:0.35290\n",
      "[475]\tvalidation_0-mlogloss:0.05971\tvalidation_1-mlogloss:0.35258\n",
      "[476]\tvalidation_0-mlogloss:0.05953\tvalidation_1-mlogloss:0.35239\n",
      "[477]\tvalidation_0-mlogloss:0.05936\tvalidation_1-mlogloss:0.35258\n",
      "[478]\tvalidation_0-mlogloss:0.05915\tvalidation_1-mlogloss:0.35262\n",
      "[479]\tvalidation_0-mlogloss:0.05901\tvalidation_1-mlogloss:0.35247\n",
      "[480]\tvalidation_0-mlogloss:0.05885\tvalidation_1-mlogloss:0.35239\n",
      "[481]\tvalidation_0-mlogloss:0.05865\tvalidation_1-mlogloss:0.35206\n",
      "[482]\tvalidation_0-mlogloss:0.05848\tvalidation_1-mlogloss:0.35186\n",
      "[483]\tvalidation_0-mlogloss:0.05829\tvalidation_1-mlogloss:0.35173\n",
      "[484]\tvalidation_0-mlogloss:0.05808\tvalidation_1-mlogloss:0.35149\n",
      "[485]\tvalidation_0-mlogloss:0.05796\tvalidation_1-mlogloss:0.35115\n",
      "[486]\tvalidation_0-mlogloss:0.05777\tvalidation_1-mlogloss:0.35104\n",
      "[487]\tvalidation_0-mlogloss:0.05762\tvalidation_1-mlogloss:0.35114\n",
      "[488]\tvalidation_0-mlogloss:0.05750\tvalidation_1-mlogloss:0.35091\n",
      "[489]\tvalidation_0-mlogloss:0.05728\tvalidation_1-mlogloss:0.35072\n",
      "[490]\tvalidation_0-mlogloss:0.05712\tvalidation_1-mlogloss:0.35021\n",
      "[491]\tvalidation_0-mlogloss:0.05694\tvalidation_1-mlogloss:0.35000\n",
      "[492]\tvalidation_0-mlogloss:0.05681\tvalidation_1-mlogloss:0.34974\n",
      "[493]\tvalidation_0-mlogloss:0.05673\tvalidation_1-mlogloss:0.34965\n",
      "[494]\tvalidation_0-mlogloss:0.05661\tvalidation_1-mlogloss:0.34960\n",
      "[495]\tvalidation_0-mlogloss:0.05648\tvalidation_1-mlogloss:0.34962\n",
      "[496]\tvalidation_0-mlogloss:0.05638\tvalidation_1-mlogloss:0.34929\n",
      "[497]\tvalidation_0-mlogloss:0.05622\tvalidation_1-mlogloss:0.34933\n",
      "[498]\tvalidation_0-mlogloss:0.05608\tvalidation_1-mlogloss:0.34943\n",
      "[499]\tvalidation_0-mlogloss:0.05593\tvalidation_1-mlogloss:0.34930\n",
      "[500]\tvalidation_0-mlogloss:0.05582\tvalidation_1-mlogloss:0.34925\n",
      "[501]\tvalidation_0-mlogloss:0.05568\tvalidation_1-mlogloss:0.34921\n",
      "[502]\tvalidation_0-mlogloss:0.05555\tvalidation_1-mlogloss:0.34883\n",
      "[503]\tvalidation_0-mlogloss:0.05544\tvalidation_1-mlogloss:0.34880\n",
      "[504]\tvalidation_0-mlogloss:0.05533\tvalidation_1-mlogloss:0.34860\n",
      "[505]\tvalidation_0-mlogloss:0.05522\tvalidation_1-mlogloss:0.34855\n",
      "[506]\tvalidation_0-mlogloss:0.05510\tvalidation_1-mlogloss:0.34825\n",
      "[507]\tvalidation_0-mlogloss:0.05495\tvalidation_1-mlogloss:0.34827\n",
      "[508]\tvalidation_0-mlogloss:0.05484\tvalidation_1-mlogloss:0.34824\n",
      "[509]\tvalidation_0-mlogloss:0.05474\tvalidation_1-mlogloss:0.34801\n",
      "[510]\tvalidation_0-mlogloss:0.05461\tvalidation_1-mlogloss:0.34794\n",
      "[511]\tvalidation_0-mlogloss:0.05457\tvalidation_1-mlogloss:0.34784\n",
      "[512]\tvalidation_0-mlogloss:0.05445\tvalidation_1-mlogloss:0.34784\n",
      "[513]\tvalidation_0-mlogloss:0.05430\tvalidation_1-mlogloss:0.34778\n",
      "[514]\tvalidation_0-mlogloss:0.05415\tvalidation_1-mlogloss:0.34747\n",
      "[515]\tvalidation_0-mlogloss:0.05405\tvalidation_1-mlogloss:0.34722\n",
      "[516]\tvalidation_0-mlogloss:0.05399\tvalidation_1-mlogloss:0.34719\n",
      "[517]\tvalidation_0-mlogloss:0.05388\tvalidation_1-mlogloss:0.34695\n",
      "[518]\tvalidation_0-mlogloss:0.05379\tvalidation_1-mlogloss:0.34692\n",
      "[519]\tvalidation_0-mlogloss:0.05368\tvalidation_1-mlogloss:0.34663\n",
      "[520]\tvalidation_0-mlogloss:0.05357\tvalidation_1-mlogloss:0.34656\n",
      "[521]\tvalidation_0-mlogloss:0.05352\tvalidation_1-mlogloss:0.34655\n",
      "[522]\tvalidation_0-mlogloss:0.05342\tvalidation_1-mlogloss:0.34666\n",
      "[523]\tvalidation_0-mlogloss:0.05330\tvalidation_1-mlogloss:0.34635\n",
      "[524]\tvalidation_0-mlogloss:0.05320\tvalidation_1-mlogloss:0.34606\n",
      "[525]\tvalidation_0-mlogloss:0.05309\tvalidation_1-mlogloss:0.34624\n",
      "[526]\tvalidation_0-mlogloss:0.05299\tvalidation_1-mlogloss:0.34614\n",
      "[527]\tvalidation_0-mlogloss:0.05289\tvalidation_1-mlogloss:0.34610\n",
      "[528]\tvalidation_0-mlogloss:0.05279\tvalidation_1-mlogloss:0.34616\n",
      "[529]\tvalidation_0-mlogloss:0.05269\tvalidation_1-mlogloss:0.34587\n",
      "[530]\tvalidation_0-mlogloss:0.05264\tvalidation_1-mlogloss:0.34600\n",
      "[531]\tvalidation_0-mlogloss:0.05255\tvalidation_1-mlogloss:0.34600\n",
      "[532]\tvalidation_0-mlogloss:0.05249\tvalidation_1-mlogloss:0.34595\n",
      "[533]\tvalidation_0-mlogloss:0.05235\tvalidation_1-mlogloss:0.34566\n",
      "[534]\tvalidation_0-mlogloss:0.05225\tvalidation_1-mlogloss:0.34541\n",
      "[535]\tvalidation_0-mlogloss:0.05211\tvalidation_1-mlogloss:0.34509\n",
      "[536]\tvalidation_0-mlogloss:0.05198\tvalidation_1-mlogloss:0.34513\n",
      "[537]\tvalidation_0-mlogloss:0.05193\tvalidation_1-mlogloss:0.34490\n",
      "[538]\tvalidation_0-mlogloss:0.05184\tvalidation_1-mlogloss:0.34471\n",
      "[539]\tvalidation_0-mlogloss:0.05175\tvalidation_1-mlogloss:0.34464\n",
      "[540]\tvalidation_0-mlogloss:0.05164\tvalidation_1-mlogloss:0.34466\n",
      "[541]\tvalidation_0-mlogloss:0.05156\tvalidation_1-mlogloss:0.34427\n",
      "[542]\tvalidation_0-mlogloss:0.05146\tvalidation_1-mlogloss:0.34408\n",
      "[543]\tvalidation_0-mlogloss:0.05141\tvalidation_1-mlogloss:0.34398\n",
      "[544]\tvalidation_0-mlogloss:0.05135\tvalidation_1-mlogloss:0.34396\n",
      "[545]\tvalidation_0-mlogloss:0.05122\tvalidation_1-mlogloss:0.34372\n",
      "[546]\tvalidation_0-mlogloss:0.05111\tvalidation_1-mlogloss:0.34333\n",
      "[547]\tvalidation_0-mlogloss:0.05106\tvalidation_1-mlogloss:0.34338\n",
      "[548]\tvalidation_0-mlogloss:0.05099\tvalidation_1-mlogloss:0.34312\n",
      "[549]\tvalidation_0-mlogloss:0.05095\tvalidation_1-mlogloss:0.34304\n",
      "[550]\tvalidation_0-mlogloss:0.05086\tvalidation_1-mlogloss:0.34312\n",
      "[551]\tvalidation_0-mlogloss:0.05081\tvalidation_1-mlogloss:0.34307\n",
      "[552]\tvalidation_0-mlogloss:0.05072\tvalidation_1-mlogloss:0.34289\n",
      "[553]\tvalidation_0-mlogloss:0.05060\tvalidation_1-mlogloss:0.34278\n",
      "[554]\tvalidation_0-mlogloss:0.05054\tvalidation_1-mlogloss:0.34291\n",
      "[555]\tvalidation_0-mlogloss:0.05047\tvalidation_1-mlogloss:0.34256\n",
      "[556]\tvalidation_0-mlogloss:0.05042\tvalidation_1-mlogloss:0.34244\n",
      "[557]\tvalidation_0-mlogloss:0.05033\tvalidation_1-mlogloss:0.34204\n",
      "[558]\tvalidation_0-mlogloss:0.05024\tvalidation_1-mlogloss:0.34184\n",
      "[559]\tvalidation_0-mlogloss:0.05016\tvalidation_1-mlogloss:0.34187\n",
      "[560]\tvalidation_0-mlogloss:0.05008\tvalidation_1-mlogloss:0.34174\n",
      "[561]\tvalidation_0-mlogloss:0.04998\tvalidation_1-mlogloss:0.34168\n",
      "[562]\tvalidation_0-mlogloss:0.04988\tvalidation_1-mlogloss:0.34143\n",
      "[563]\tvalidation_0-mlogloss:0.04982\tvalidation_1-mlogloss:0.34134\n",
      "[564]\tvalidation_0-mlogloss:0.04973\tvalidation_1-mlogloss:0.34138\n",
      "[565]\tvalidation_0-mlogloss:0.04965\tvalidation_1-mlogloss:0.34120\n",
      "[566]\tvalidation_0-mlogloss:0.04959\tvalidation_1-mlogloss:0.34099\n",
      "[567]\tvalidation_0-mlogloss:0.04955\tvalidation_1-mlogloss:0.34111\n",
      "[568]\tvalidation_0-mlogloss:0.04947\tvalidation_1-mlogloss:0.34091\n",
      "[569]\tvalidation_0-mlogloss:0.04938\tvalidation_1-mlogloss:0.34100\n",
      "[570]\tvalidation_0-mlogloss:0.04936\tvalidation_1-mlogloss:0.34111\n",
      "[571]\tvalidation_0-mlogloss:0.04931\tvalidation_1-mlogloss:0.34108\n",
      "[572]\tvalidation_0-mlogloss:0.04925\tvalidation_1-mlogloss:0.34104\n",
      "[573]\tvalidation_0-mlogloss:0.04922\tvalidation_1-mlogloss:0.34107\n",
      "[574]\tvalidation_0-mlogloss:0.04917\tvalidation_1-mlogloss:0.34107\n",
      "[575]\tvalidation_0-mlogloss:0.04915\tvalidation_1-mlogloss:0.34114\n",
      "[576]\tvalidation_0-mlogloss:0.04910\tvalidation_1-mlogloss:0.34105\n",
      "[577]\tvalidation_0-mlogloss:0.04906\tvalidation_1-mlogloss:0.34115\n",
      "[578]\tvalidation_0-mlogloss:0.04904\tvalidation_1-mlogloss:0.34109\n",
      "[579]\tvalidation_0-mlogloss:0.04900\tvalidation_1-mlogloss:0.34120\n",
      "[580]\tvalidation_0-mlogloss:0.04894\tvalidation_1-mlogloss:0.34119\n",
      "[581]\tvalidation_0-mlogloss:0.04885\tvalidation_1-mlogloss:0.34084\n",
      "[582]\tvalidation_0-mlogloss:0.04883\tvalidation_1-mlogloss:0.34071\n",
      "[583]\tvalidation_0-mlogloss:0.04878\tvalidation_1-mlogloss:0.34062\n",
      "[584]\tvalidation_0-mlogloss:0.04873\tvalidation_1-mlogloss:0.34057\n",
      "[585]\tvalidation_0-mlogloss:0.04865\tvalidation_1-mlogloss:0.34052\n",
      "[586]\tvalidation_0-mlogloss:0.04858\tvalidation_1-mlogloss:0.34033\n",
      "[587]\tvalidation_0-mlogloss:0.04856\tvalidation_1-mlogloss:0.34037\n",
      "[588]\tvalidation_0-mlogloss:0.04851\tvalidation_1-mlogloss:0.34011\n",
      "[589]\tvalidation_0-mlogloss:0.04849\tvalidation_1-mlogloss:0.34017\n",
      "[590]\tvalidation_0-mlogloss:0.04844\tvalidation_1-mlogloss:0.34000\n",
      "[591]\tvalidation_0-mlogloss:0.04837\tvalidation_1-mlogloss:0.33972\n",
      "[592]\tvalidation_0-mlogloss:0.04830\tvalidation_1-mlogloss:0.33951\n",
      "[593]\tvalidation_0-mlogloss:0.04821\tvalidation_1-mlogloss:0.33931\n",
      "[594]\tvalidation_0-mlogloss:0.04816\tvalidation_1-mlogloss:0.33918\n",
      "[595]\tvalidation_0-mlogloss:0.04813\tvalidation_1-mlogloss:0.33908\n",
      "[596]\tvalidation_0-mlogloss:0.04809\tvalidation_1-mlogloss:0.33896\n",
      "[597]\tvalidation_0-mlogloss:0.04804\tvalidation_1-mlogloss:0.33903\n",
      "[598]\tvalidation_0-mlogloss:0.04800\tvalidation_1-mlogloss:0.33918\n",
      "[599]\tvalidation_0-mlogloss:0.04795\tvalidation_1-mlogloss:0.33936\n",
      "[600]\tvalidation_0-mlogloss:0.04787\tvalidation_1-mlogloss:0.33930\n",
      "[601]\tvalidation_0-mlogloss:0.04785\tvalidation_1-mlogloss:0.33922\n",
      "[602]\tvalidation_0-mlogloss:0.04778\tvalidation_1-mlogloss:0.33904\n",
      "[603]\tvalidation_0-mlogloss:0.04777\tvalidation_1-mlogloss:0.33923\n",
      "[604]\tvalidation_0-mlogloss:0.04769\tvalidation_1-mlogloss:0.33929\n",
      "[605]\tvalidation_0-mlogloss:0.04767\tvalidation_1-mlogloss:0.33923\n",
      "[606]\tvalidation_0-mlogloss:0.04764\tvalidation_1-mlogloss:0.33917\n",
      "[607]\tvalidation_0-mlogloss:0.04762\tvalidation_1-mlogloss:0.33931\n",
      "[608]\tvalidation_0-mlogloss:0.04760\tvalidation_1-mlogloss:0.33916\n",
      "[609]\tvalidation_0-mlogloss:0.04756\tvalidation_1-mlogloss:0.33936\n",
      "[610]\tvalidation_0-mlogloss:0.04754\tvalidation_1-mlogloss:0.33948\n",
      "[611]\tvalidation_0-mlogloss:0.04751\tvalidation_1-mlogloss:0.33951\n",
      "[612]\tvalidation_0-mlogloss:0.04747\tvalidation_1-mlogloss:0.33966\n",
      "[613]\tvalidation_0-mlogloss:0.04743\tvalidation_1-mlogloss:0.33946\n",
      "[614]\tvalidation_0-mlogloss:0.04739\tvalidation_1-mlogloss:0.33956\n",
      "[615]\tvalidation_0-mlogloss:0.04734\tvalidation_1-mlogloss:0.33952\n",
      "[16:53:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-mlogloss:1.59155\tvalidation_1-mlogloss:1.59477\n",
      "[1]\tvalidation_0-mlogloss:1.57397\tvalidation_1-mlogloss:1.57938\n",
      "[2]\tvalidation_0-mlogloss:1.55777\tvalidation_1-mlogloss:1.56743\n",
      "[3]\tvalidation_0-mlogloss:1.53920\tvalidation_1-mlogloss:1.55160\n",
      "[4]\tvalidation_0-mlogloss:1.52212\tvalidation_1-mlogloss:1.53764\n",
      "[5]\tvalidation_0-mlogloss:1.50585\tvalidation_1-mlogloss:1.52298\n",
      "[6]\tvalidation_0-mlogloss:1.48961\tvalidation_1-mlogloss:1.50994\n",
      "[7]\tvalidation_0-mlogloss:1.47260\tvalidation_1-mlogloss:1.49722\n",
      "[8]\tvalidation_0-mlogloss:1.45708\tvalidation_1-mlogloss:1.48473\n",
      "[9]\tvalidation_0-mlogloss:1.44089\tvalidation_1-mlogloss:1.47154\n",
      "[10]\tvalidation_0-mlogloss:1.42652\tvalidation_1-mlogloss:1.46121\n",
      "[11]\tvalidation_0-mlogloss:1.41153\tvalidation_1-mlogloss:1.45079\n",
      "[12]\tvalidation_0-mlogloss:1.39765\tvalidation_1-mlogloss:1.44056\n",
      "[13]\tvalidation_0-mlogloss:1.38312\tvalidation_1-mlogloss:1.43019\n",
      "[14]\tvalidation_0-mlogloss:1.36880\tvalidation_1-mlogloss:1.41948\n",
      "[15]\tvalidation_0-mlogloss:1.35416\tvalidation_1-mlogloss:1.40896\n",
      "[16]\tvalidation_0-mlogloss:1.34062\tvalidation_1-mlogloss:1.39920\n",
      "[17]\tvalidation_0-mlogloss:1.32633\tvalidation_1-mlogloss:1.38775\n",
      "[18]\tvalidation_0-mlogloss:1.31235\tvalidation_1-mlogloss:1.37754\n",
      "[19]\tvalidation_0-mlogloss:1.29950\tvalidation_1-mlogloss:1.36715\n",
      "[20]\tvalidation_0-mlogloss:1.28652\tvalidation_1-mlogloss:1.35774\n",
      "[21]\tvalidation_0-mlogloss:1.27364\tvalidation_1-mlogloss:1.34835\n",
      "[22]\tvalidation_0-mlogloss:1.26048\tvalidation_1-mlogloss:1.33775\n",
      "[23]\tvalidation_0-mlogloss:1.24693\tvalidation_1-mlogloss:1.32532\n",
      "[24]\tvalidation_0-mlogloss:1.23433\tvalidation_1-mlogloss:1.31601\n",
      "[25]\tvalidation_0-mlogloss:1.22246\tvalidation_1-mlogloss:1.30783\n",
      "[26]\tvalidation_0-mlogloss:1.21056\tvalidation_1-mlogloss:1.29808\n",
      "[27]\tvalidation_0-mlogloss:1.19774\tvalidation_1-mlogloss:1.28741\n",
      "[28]\tvalidation_0-mlogloss:1.18631\tvalidation_1-mlogloss:1.27946\n",
      "[29]\tvalidation_0-mlogloss:1.17625\tvalidation_1-mlogloss:1.27259\n",
      "[30]\tvalidation_0-mlogloss:1.16427\tvalidation_1-mlogloss:1.26275\n",
      "[31]\tvalidation_0-mlogloss:1.15274\tvalidation_1-mlogloss:1.25257\n",
      "[32]\tvalidation_0-mlogloss:1.14058\tvalidation_1-mlogloss:1.24133\n",
      "[33]\tvalidation_0-mlogloss:1.12915\tvalidation_1-mlogloss:1.23206\n",
      "[34]\tvalidation_0-mlogloss:1.11911\tvalidation_1-mlogloss:1.22416\n",
      "[35]\tvalidation_0-mlogloss:1.10758\tvalidation_1-mlogloss:1.21447\n",
      "[36]\tvalidation_0-mlogloss:1.09641\tvalidation_1-mlogloss:1.20516\n",
      "[37]\tvalidation_0-mlogloss:1.08488\tvalidation_1-mlogloss:1.19427\n",
      "[38]\tvalidation_0-mlogloss:1.07464\tvalidation_1-mlogloss:1.18667\n",
      "[39]\tvalidation_0-mlogloss:1.06414\tvalidation_1-mlogloss:1.17804\n",
      "[40]\tvalidation_0-mlogloss:1.05449\tvalidation_1-mlogloss:1.16973\n",
      "[41]\tvalidation_0-mlogloss:1.04390\tvalidation_1-mlogloss:1.16041\n",
      "[42]\tvalidation_0-mlogloss:1.03364\tvalidation_1-mlogloss:1.15143\n",
      "[43]\tvalidation_0-mlogloss:1.02327\tvalidation_1-mlogloss:1.14230\n",
      "[44]\tvalidation_0-mlogloss:1.01304\tvalidation_1-mlogloss:1.13530\n",
      "[45]\tvalidation_0-mlogloss:1.00395\tvalidation_1-mlogloss:1.12768\n",
      "[46]\tvalidation_0-mlogloss:0.99444\tvalidation_1-mlogloss:1.12099\n",
      "[47]\tvalidation_0-mlogloss:0.98493\tvalidation_1-mlogloss:1.11419\n",
      "[48]\tvalidation_0-mlogloss:0.97548\tvalidation_1-mlogloss:1.10681\n",
      "[49]\tvalidation_0-mlogloss:0.96631\tvalidation_1-mlogloss:1.09879\n",
      "[50]\tvalidation_0-mlogloss:0.95736\tvalidation_1-mlogloss:1.09204\n",
      "[51]\tvalidation_0-mlogloss:0.94886\tvalidation_1-mlogloss:1.08472\n",
      "[52]\tvalidation_0-mlogloss:0.93948\tvalidation_1-mlogloss:1.07621\n",
      "[53]\tvalidation_0-mlogloss:0.93136\tvalidation_1-mlogloss:1.06920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54]\tvalidation_0-mlogloss:0.92231\tvalidation_1-mlogloss:1.06151\n",
      "[55]\tvalidation_0-mlogloss:0.91356\tvalidation_1-mlogloss:1.05446\n",
      "[56]\tvalidation_0-mlogloss:0.90517\tvalidation_1-mlogloss:1.04808\n",
      "[57]\tvalidation_0-mlogloss:0.89658\tvalidation_1-mlogloss:1.04066\n",
      "[58]\tvalidation_0-mlogloss:0.88823\tvalidation_1-mlogloss:1.03494\n",
      "[59]\tvalidation_0-mlogloss:0.87969\tvalidation_1-mlogloss:1.02709\n",
      "[60]\tvalidation_0-mlogloss:0.87121\tvalidation_1-mlogloss:1.02005\n",
      "[61]\tvalidation_0-mlogloss:0.86305\tvalidation_1-mlogloss:1.01327\n",
      "[62]\tvalidation_0-mlogloss:0.85463\tvalidation_1-mlogloss:1.00664\n",
      "[63]\tvalidation_0-mlogloss:0.84688\tvalidation_1-mlogloss:1.00112\n",
      "[64]\tvalidation_0-mlogloss:0.83929\tvalidation_1-mlogloss:0.99571\n",
      "[65]\tvalidation_0-mlogloss:0.83130\tvalidation_1-mlogloss:0.98843\n",
      "[66]\tvalidation_0-mlogloss:0.82341\tvalidation_1-mlogloss:0.98119\n",
      "[67]\tvalidation_0-mlogloss:0.81581\tvalidation_1-mlogloss:0.97590\n",
      "[68]\tvalidation_0-mlogloss:0.80826\tvalidation_1-mlogloss:0.96992\n",
      "[69]\tvalidation_0-mlogloss:0.80094\tvalidation_1-mlogloss:0.96184\n",
      "[70]\tvalidation_0-mlogloss:0.79332\tvalidation_1-mlogloss:0.95497\n",
      "[71]\tvalidation_0-mlogloss:0.78597\tvalidation_1-mlogloss:0.94876\n",
      "[72]\tvalidation_0-mlogloss:0.77861\tvalidation_1-mlogloss:0.94290\n",
      "[73]\tvalidation_0-mlogloss:0.77244\tvalidation_1-mlogloss:0.93829\n",
      "[74]\tvalidation_0-mlogloss:0.76517\tvalidation_1-mlogloss:0.93155\n",
      "[75]\tvalidation_0-mlogloss:0.75830\tvalidation_1-mlogloss:0.92515\n",
      "[76]\tvalidation_0-mlogloss:0.75105\tvalidation_1-mlogloss:0.91821\n",
      "[77]\tvalidation_0-mlogloss:0.74469\tvalidation_1-mlogloss:0.91295\n",
      "[78]\tvalidation_0-mlogloss:0.73809\tvalidation_1-mlogloss:0.90800\n",
      "[79]\tvalidation_0-mlogloss:0.73146\tvalidation_1-mlogloss:0.90259\n",
      "[80]\tvalidation_0-mlogloss:0.72510\tvalidation_1-mlogloss:0.89700\n",
      "[81]\tvalidation_0-mlogloss:0.71878\tvalidation_1-mlogloss:0.89220\n",
      "[82]\tvalidation_0-mlogloss:0.71194\tvalidation_1-mlogloss:0.88561\n",
      "[83]\tvalidation_0-mlogloss:0.70557\tvalidation_1-mlogloss:0.88052\n",
      "[84]\tvalidation_0-mlogloss:0.69910\tvalidation_1-mlogloss:0.87445\n",
      "[85]\tvalidation_0-mlogloss:0.69252\tvalidation_1-mlogloss:0.86865\n",
      "[86]\tvalidation_0-mlogloss:0.68652\tvalidation_1-mlogloss:0.86351\n",
      "[87]\tvalidation_0-mlogloss:0.68037\tvalidation_1-mlogloss:0.85813\n",
      "[88]\tvalidation_0-mlogloss:0.67470\tvalidation_1-mlogloss:0.85392\n",
      "[89]\tvalidation_0-mlogloss:0.66852\tvalidation_1-mlogloss:0.84851\n",
      "[90]\tvalidation_0-mlogloss:0.66278\tvalidation_1-mlogloss:0.84411\n",
      "[91]\tvalidation_0-mlogloss:0.65686\tvalidation_1-mlogloss:0.83914\n",
      "[92]\tvalidation_0-mlogloss:0.65133\tvalidation_1-mlogloss:0.83424\n",
      "[93]\tvalidation_0-mlogloss:0.64542\tvalidation_1-mlogloss:0.82835\n",
      "[94]\tvalidation_0-mlogloss:0.63989\tvalidation_1-mlogloss:0.82408\n",
      "[95]\tvalidation_0-mlogloss:0.63411\tvalidation_1-mlogloss:0.81840\n",
      "[96]\tvalidation_0-mlogloss:0.62893\tvalidation_1-mlogloss:0.81364\n",
      "[97]\tvalidation_0-mlogloss:0.62308\tvalidation_1-mlogloss:0.80801\n",
      "[98]\tvalidation_0-mlogloss:0.61793\tvalidation_1-mlogloss:0.80456\n",
      "[99]\tvalidation_0-mlogloss:0.61227\tvalidation_1-mlogloss:0.79940\n",
      "[100]\tvalidation_0-mlogloss:0.60683\tvalidation_1-mlogloss:0.79503\n",
      "[101]\tvalidation_0-mlogloss:0.60143\tvalidation_1-mlogloss:0.79058\n",
      "[102]\tvalidation_0-mlogloss:0.59632\tvalidation_1-mlogloss:0.78662\n",
      "[103]\tvalidation_0-mlogloss:0.59109\tvalidation_1-mlogloss:0.78292\n",
      "[104]\tvalidation_0-mlogloss:0.58595\tvalidation_1-mlogloss:0.77870\n",
      "[105]\tvalidation_0-mlogloss:0.58095\tvalidation_1-mlogloss:0.77560\n",
      "[106]\tvalidation_0-mlogloss:0.57576\tvalidation_1-mlogloss:0.77047\n",
      "[107]\tvalidation_0-mlogloss:0.57076\tvalidation_1-mlogloss:0.76648\n",
      "[108]\tvalidation_0-mlogloss:0.56602\tvalidation_1-mlogloss:0.76236\n",
      "[109]\tvalidation_0-mlogloss:0.56088\tvalidation_1-mlogloss:0.75746\n",
      "[110]\tvalidation_0-mlogloss:0.55597\tvalidation_1-mlogloss:0.75391\n",
      "[111]\tvalidation_0-mlogloss:0.55104\tvalidation_1-mlogloss:0.75031\n",
      "[112]\tvalidation_0-mlogloss:0.54648\tvalidation_1-mlogloss:0.74637\n",
      "[113]\tvalidation_0-mlogloss:0.54175\tvalidation_1-mlogloss:0.74287\n",
      "[114]\tvalidation_0-mlogloss:0.53744\tvalidation_1-mlogloss:0.73885\n",
      "[115]\tvalidation_0-mlogloss:0.53264\tvalidation_1-mlogloss:0.73424\n",
      "[116]\tvalidation_0-mlogloss:0.52820\tvalidation_1-mlogloss:0.73097\n",
      "[117]\tvalidation_0-mlogloss:0.52387\tvalidation_1-mlogloss:0.72755\n",
      "[118]\tvalidation_0-mlogloss:0.51953\tvalidation_1-mlogloss:0.72366\n",
      "[119]\tvalidation_0-mlogloss:0.51509\tvalidation_1-mlogloss:0.71920\n",
      "[120]\tvalidation_0-mlogloss:0.51101\tvalidation_1-mlogloss:0.71590\n",
      "[121]\tvalidation_0-mlogloss:0.50671\tvalidation_1-mlogloss:0.71158\n",
      "[122]\tvalidation_0-mlogloss:0.50216\tvalidation_1-mlogloss:0.70709\n",
      "[123]\tvalidation_0-mlogloss:0.49801\tvalidation_1-mlogloss:0.70354\n",
      "[124]\tvalidation_0-mlogloss:0.49378\tvalidation_1-mlogloss:0.69974\n",
      "[125]\tvalidation_0-mlogloss:0.48954\tvalidation_1-mlogloss:0.69652\n",
      "[126]\tvalidation_0-mlogloss:0.48538\tvalidation_1-mlogloss:0.69346\n",
      "[127]\tvalidation_0-mlogloss:0.48132\tvalidation_1-mlogloss:0.69090\n",
      "[128]\tvalidation_0-mlogloss:0.47732\tvalidation_1-mlogloss:0.68704\n",
      "[129]\tvalidation_0-mlogloss:0.47321\tvalidation_1-mlogloss:0.68307\n",
      "[130]\tvalidation_0-mlogloss:0.46938\tvalidation_1-mlogloss:0.67989\n",
      "[131]\tvalidation_0-mlogloss:0.46582\tvalidation_1-mlogloss:0.67683\n",
      "[132]\tvalidation_0-mlogloss:0.46181\tvalidation_1-mlogloss:0.67334\n",
      "[133]\tvalidation_0-mlogloss:0.45785\tvalidation_1-mlogloss:0.66966\n",
      "[134]\tvalidation_0-mlogloss:0.45390\tvalidation_1-mlogloss:0.66610\n",
      "[135]\tvalidation_0-mlogloss:0.45010\tvalidation_1-mlogloss:0.66295\n",
      "[136]\tvalidation_0-mlogloss:0.44633\tvalidation_1-mlogloss:0.65954\n",
      "[137]\tvalidation_0-mlogloss:0.44295\tvalidation_1-mlogloss:0.65706\n",
      "[138]\tvalidation_0-mlogloss:0.43972\tvalidation_1-mlogloss:0.65489\n",
      "[139]\tvalidation_0-mlogloss:0.43612\tvalidation_1-mlogloss:0.65132\n",
      "[140]\tvalidation_0-mlogloss:0.43255\tvalidation_1-mlogloss:0.64836\n",
      "[141]\tvalidation_0-mlogloss:0.42880\tvalidation_1-mlogloss:0.64465\n",
      "[142]\tvalidation_0-mlogloss:0.42564\tvalidation_1-mlogloss:0.64238\n",
      "[143]\tvalidation_0-mlogloss:0.42211\tvalidation_1-mlogloss:0.63994\n",
      "[144]\tvalidation_0-mlogloss:0.41864\tvalidation_1-mlogloss:0.63766\n",
      "[145]\tvalidation_0-mlogloss:0.41514\tvalidation_1-mlogloss:0.63461\n",
      "[146]\tvalidation_0-mlogloss:0.41190\tvalidation_1-mlogloss:0.63278\n",
      "[147]\tvalidation_0-mlogloss:0.40852\tvalidation_1-mlogloss:0.63040\n",
      "[148]\tvalidation_0-mlogloss:0.40503\tvalidation_1-mlogloss:0.62734\n",
      "[149]\tvalidation_0-mlogloss:0.40185\tvalidation_1-mlogloss:0.62512\n",
      "[150]\tvalidation_0-mlogloss:0.39853\tvalidation_1-mlogloss:0.62240\n",
      "[151]\tvalidation_0-mlogloss:0.39538\tvalidation_1-mlogloss:0.61959\n",
      "[152]\tvalidation_0-mlogloss:0.39218\tvalidation_1-mlogloss:0.61684\n",
      "[153]\tvalidation_0-mlogloss:0.38881\tvalidation_1-mlogloss:0.61348\n",
      "[154]\tvalidation_0-mlogloss:0.38555\tvalidation_1-mlogloss:0.61062\n",
      "[155]\tvalidation_0-mlogloss:0.38248\tvalidation_1-mlogloss:0.60806\n",
      "[156]\tvalidation_0-mlogloss:0.37934\tvalidation_1-mlogloss:0.60490\n",
      "[157]\tvalidation_0-mlogloss:0.37641\tvalidation_1-mlogloss:0.60232\n",
      "[158]\tvalidation_0-mlogloss:0.37329\tvalidation_1-mlogloss:0.59943\n",
      "[159]\tvalidation_0-mlogloss:0.37026\tvalidation_1-mlogloss:0.59703\n",
      "[160]\tvalidation_0-mlogloss:0.36727\tvalidation_1-mlogloss:0.59424\n",
      "[161]\tvalidation_0-mlogloss:0.36424\tvalidation_1-mlogloss:0.59095\n",
      "[162]\tvalidation_0-mlogloss:0.36148\tvalidation_1-mlogloss:0.58902\n",
      "[163]\tvalidation_0-mlogloss:0.35855\tvalidation_1-mlogloss:0.58577\n",
      "[164]\tvalidation_0-mlogloss:0.35566\tvalidation_1-mlogloss:0.58316\n",
      "[165]\tvalidation_0-mlogloss:0.35296\tvalidation_1-mlogloss:0.58092\n",
      "[166]\tvalidation_0-mlogloss:0.35026\tvalidation_1-mlogloss:0.57830\n",
      "[167]\tvalidation_0-mlogloss:0.34755\tvalidation_1-mlogloss:0.57617\n",
      "[168]\tvalidation_0-mlogloss:0.34478\tvalidation_1-mlogloss:0.57352\n",
      "[169]\tvalidation_0-mlogloss:0.34201\tvalidation_1-mlogloss:0.57159\n",
      "[170]\tvalidation_0-mlogloss:0.33937\tvalidation_1-mlogloss:0.56959\n",
      "[171]\tvalidation_0-mlogloss:0.33673\tvalidation_1-mlogloss:0.56732\n",
      "[172]\tvalidation_0-mlogloss:0.33395\tvalidation_1-mlogloss:0.56434\n",
      "[173]\tvalidation_0-mlogloss:0.33141\tvalidation_1-mlogloss:0.56272\n",
      "[174]\tvalidation_0-mlogloss:0.32880\tvalidation_1-mlogloss:0.56002\n",
      "[175]\tvalidation_0-mlogloss:0.32610\tvalidation_1-mlogloss:0.55742\n",
      "[176]\tvalidation_0-mlogloss:0.32344\tvalidation_1-mlogloss:0.55516\n",
      "[177]\tvalidation_0-mlogloss:0.32088\tvalidation_1-mlogloss:0.55257\n",
      "[178]\tvalidation_0-mlogloss:0.31859\tvalidation_1-mlogloss:0.55011\n",
      "[179]\tvalidation_0-mlogloss:0.31623\tvalidation_1-mlogloss:0.54807\n",
      "[180]\tvalidation_0-mlogloss:0.31378\tvalidation_1-mlogloss:0.54666\n",
      "[181]\tvalidation_0-mlogloss:0.31133\tvalidation_1-mlogloss:0.54438\n",
      "[182]\tvalidation_0-mlogloss:0.30888\tvalidation_1-mlogloss:0.54232\n",
      "[183]\tvalidation_0-mlogloss:0.30651\tvalidation_1-mlogloss:0.54046\n",
      "[184]\tvalidation_0-mlogloss:0.30403\tvalidation_1-mlogloss:0.53810\n",
      "[185]\tvalidation_0-mlogloss:0.30176\tvalidation_1-mlogloss:0.53672\n",
      "[186]\tvalidation_0-mlogloss:0.29950\tvalidation_1-mlogloss:0.53503\n",
      "[187]\tvalidation_0-mlogloss:0.29724\tvalidation_1-mlogloss:0.53296\n",
      "[188]\tvalidation_0-mlogloss:0.29513\tvalidation_1-mlogloss:0.53170\n",
      "[189]\tvalidation_0-mlogloss:0.29289\tvalidation_1-mlogloss:0.52946\n",
      "[190]\tvalidation_0-mlogloss:0.29064\tvalidation_1-mlogloss:0.52739\n",
      "[191]\tvalidation_0-mlogloss:0.28836\tvalidation_1-mlogloss:0.52512\n",
      "[192]\tvalidation_0-mlogloss:0.28623\tvalidation_1-mlogloss:0.52399\n",
      "[193]\tvalidation_0-mlogloss:0.28407\tvalidation_1-mlogloss:0.52249\n",
      "[194]\tvalidation_0-mlogloss:0.28203\tvalidation_1-mlogloss:0.52060\n",
      "[195]\tvalidation_0-mlogloss:0.27984\tvalidation_1-mlogloss:0.51853\n",
      "[196]\tvalidation_0-mlogloss:0.27769\tvalidation_1-mlogloss:0.51650\n",
      "[197]\tvalidation_0-mlogloss:0.27565\tvalidation_1-mlogloss:0.51475\n",
      "[198]\tvalidation_0-mlogloss:0.27371\tvalidation_1-mlogloss:0.51358\n",
      "[199]\tvalidation_0-mlogloss:0.27159\tvalidation_1-mlogloss:0.51111\n",
      "[200]\tvalidation_0-mlogloss:0.26950\tvalidation_1-mlogloss:0.50943\n",
      "[201]\tvalidation_0-mlogloss:0.26751\tvalidation_1-mlogloss:0.50738\n",
      "[202]\tvalidation_0-mlogloss:0.26556\tvalidation_1-mlogloss:0.50608\n",
      "[203]\tvalidation_0-mlogloss:0.26354\tvalidation_1-mlogloss:0.50464\n",
      "[204]\tvalidation_0-mlogloss:0.26154\tvalidation_1-mlogloss:0.50263\n",
      "[205]\tvalidation_0-mlogloss:0.25953\tvalidation_1-mlogloss:0.50115\n",
      "[206]\tvalidation_0-mlogloss:0.25765\tvalidation_1-mlogloss:0.49925\n",
      "[207]\tvalidation_0-mlogloss:0.25585\tvalidation_1-mlogloss:0.49760\n",
      "[208]\tvalidation_0-mlogloss:0.25394\tvalidation_1-mlogloss:0.49642\n",
      "[209]\tvalidation_0-mlogloss:0.25199\tvalidation_1-mlogloss:0.49443\n",
      "[210]\tvalidation_0-mlogloss:0.25022\tvalidation_1-mlogloss:0.49313\n",
      "[211]\tvalidation_0-mlogloss:0.24842\tvalidation_1-mlogloss:0.49177\n",
      "[212]\tvalidation_0-mlogloss:0.24653\tvalidation_1-mlogloss:0.48970\n",
      "[213]\tvalidation_0-mlogloss:0.24484\tvalidation_1-mlogloss:0.48867\n",
      "[214]\tvalidation_0-mlogloss:0.24302\tvalidation_1-mlogloss:0.48646\n",
      "[215]\tvalidation_0-mlogloss:0.24124\tvalidation_1-mlogloss:0.48499\n",
      "[216]\tvalidation_0-mlogloss:0.23947\tvalidation_1-mlogloss:0.48373\n",
      "[217]\tvalidation_0-mlogloss:0.23783\tvalidation_1-mlogloss:0.48245\n",
      "[218]\tvalidation_0-mlogloss:0.23614\tvalidation_1-mlogloss:0.48084\n",
      "[219]\tvalidation_0-mlogloss:0.23443\tvalidation_1-mlogloss:0.47927\n",
      "[220]\tvalidation_0-mlogloss:0.23294\tvalidation_1-mlogloss:0.47826\n",
      "[221]\tvalidation_0-mlogloss:0.23123\tvalidation_1-mlogloss:0.47696\n",
      "[222]\tvalidation_0-mlogloss:0.22957\tvalidation_1-mlogloss:0.47563\n",
      "[223]\tvalidation_0-mlogloss:0.22798\tvalidation_1-mlogloss:0.47477\n",
      "[224]\tvalidation_0-mlogloss:0.22628\tvalidation_1-mlogloss:0.47277\n",
      "[225]\tvalidation_0-mlogloss:0.22470\tvalidation_1-mlogloss:0.47153\n",
      "[226]\tvalidation_0-mlogloss:0.22307\tvalidation_1-mlogloss:0.46990\n",
      "[227]\tvalidation_0-mlogloss:0.22147\tvalidation_1-mlogloss:0.46859\n",
      "[228]\tvalidation_0-mlogloss:0.21984\tvalidation_1-mlogloss:0.46725\n",
      "[229]\tvalidation_0-mlogloss:0.21831\tvalidation_1-mlogloss:0.46603\n",
      "[230]\tvalidation_0-mlogloss:0.21677\tvalidation_1-mlogloss:0.46456\n",
      "[231]\tvalidation_0-mlogloss:0.21525\tvalidation_1-mlogloss:0.46319\n",
      "[232]\tvalidation_0-mlogloss:0.21375\tvalidation_1-mlogloss:0.46176\n",
      "[233]\tvalidation_0-mlogloss:0.21221\tvalidation_1-mlogloss:0.46065\n",
      "[234]\tvalidation_0-mlogloss:0.21077\tvalidation_1-mlogloss:0.45976\n",
      "[235]\tvalidation_0-mlogloss:0.20931\tvalidation_1-mlogloss:0.45862\n",
      "[236]\tvalidation_0-mlogloss:0.20788\tvalidation_1-mlogloss:0.45772\n",
      "[237]\tvalidation_0-mlogloss:0.20643\tvalidation_1-mlogloss:0.45643\n",
      "[238]\tvalidation_0-mlogloss:0.20501\tvalidation_1-mlogloss:0.45521\n",
      "[239]\tvalidation_0-mlogloss:0.20355\tvalidation_1-mlogloss:0.45334\n",
      "[240]\tvalidation_0-mlogloss:0.20215\tvalidation_1-mlogloss:0.45239\n",
      "[241]\tvalidation_0-mlogloss:0.20078\tvalidation_1-mlogloss:0.45139\n",
      "[242]\tvalidation_0-mlogloss:0.19942\tvalidation_1-mlogloss:0.45023\n",
      "[243]\tvalidation_0-mlogloss:0.19805\tvalidation_1-mlogloss:0.44919\n",
      "[244]\tvalidation_0-mlogloss:0.19666\tvalidation_1-mlogloss:0.44760\n",
      "[245]\tvalidation_0-mlogloss:0.19524\tvalidation_1-mlogloss:0.44646\n",
      "[246]\tvalidation_0-mlogloss:0.19391\tvalidation_1-mlogloss:0.44568\n",
      "[247]\tvalidation_0-mlogloss:0.19273\tvalidation_1-mlogloss:0.44497\n",
      "[248]\tvalidation_0-mlogloss:0.19143\tvalidation_1-mlogloss:0.44380\n",
      "[249]\tvalidation_0-mlogloss:0.19006\tvalidation_1-mlogloss:0.44260\n",
      "[250]\tvalidation_0-mlogloss:0.18880\tvalidation_1-mlogloss:0.44199\n",
      "[251]\tvalidation_0-mlogloss:0.18747\tvalidation_1-mlogloss:0.44105\n",
      "[252]\tvalidation_0-mlogloss:0.18620\tvalidation_1-mlogloss:0.43979\n",
      "[253]\tvalidation_0-mlogloss:0.18487\tvalidation_1-mlogloss:0.43874\n",
      "[254]\tvalidation_0-mlogloss:0.18365\tvalidation_1-mlogloss:0.43808\n",
      "[255]\tvalidation_0-mlogloss:0.18239\tvalidation_1-mlogloss:0.43711\n",
      "[256]\tvalidation_0-mlogloss:0.18122\tvalidation_1-mlogloss:0.43633\n",
      "[257]\tvalidation_0-mlogloss:0.18001\tvalidation_1-mlogloss:0.43535\n",
      "[258]\tvalidation_0-mlogloss:0.17880\tvalidation_1-mlogloss:0.43464\n",
      "[259]\tvalidation_0-mlogloss:0.17759\tvalidation_1-mlogloss:0.43356\n",
      "[260]\tvalidation_0-mlogloss:0.17647\tvalidation_1-mlogloss:0.43216\n",
      "[261]\tvalidation_0-mlogloss:0.17523\tvalidation_1-mlogloss:0.43122\n",
      "[262]\tvalidation_0-mlogloss:0.17402\tvalidation_1-mlogloss:0.43013\n",
      "[263]\tvalidation_0-mlogloss:0.17284\tvalidation_1-mlogloss:0.42891\n",
      "[264]\tvalidation_0-mlogloss:0.17173\tvalidation_1-mlogloss:0.42834\n",
      "[265]\tvalidation_0-mlogloss:0.17061\tvalidation_1-mlogloss:0.42714\n",
      "[266]\tvalidation_0-mlogloss:0.16948\tvalidation_1-mlogloss:0.42589\n",
      "[267]\tvalidation_0-mlogloss:0.16838\tvalidation_1-mlogloss:0.42500\n",
      "[268]\tvalidation_0-mlogloss:0.16729\tvalidation_1-mlogloss:0.42444\n",
      "[269]\tvalidation_0-mlogloss:0.16621\tvalidation_1-mlogloss:0.42382\n",
      "[270]\tvalidation_0-mlogloss:0.16510\tvalidation_1-mlogloss:0.42318\n",
      "[271]\tvalidation_0-mlogloss:0.16426\tvalidation_1-mlogloss:0.42265\n",
      "[272]\tvalidation_0-mlogloss:0.16336\tvalidation_1-mlogloss:0.42236\n",
      "[273]\tvalidation_0-mlogloss:0.16225\tvalidation_1-mlogloss:0.42135\n",
      "[274]\tvalidation_0-mlogloss:0.16115\tvalidation_1-mlogloss:0.42023\n",
      "[275]\tvalidation_0-mlogloss:0.16010\tvalidation_1-mlogloss:0.41957\n",
      "[276]\tvalidation_0-mlogloss:0.15911\tvalidation_1-mlogloss:0.41868\n",
      "[277]\tvalidation_0-mlogloss:0.15809\tvalidation_1-mlogloss:0.41773\n",
      "[278]\tvalidation_0-mlogloss:0.15711\tvalidation_1-mlogloss:0.41722\n",
      "[279]\tvalidation_0-mlogloss:0.15619\tvalidation_1-mlogloss:0.41672\n",
      "[280]\tvalidation_0-mlogloss:0.15519\tvalidation_1-mlogloss:0.41590\n",
      "[281]\tvalidation_0-mlogloss:0.15412\tvalidation_1-mlogloss:0.41502\n",
      "[282]\tvalidation_0-mlogloss:0.15315\tvalidation_1-mlogloss:0.41422\n",
      "[283]\tvalidation_0-mlogloss:0.15218\tvalidation_1-mlogloss:0.41330\n",
      "[284]\tvalidation_0-mlogloss:0.15119\tvalidation_1-mlogloss:0.41234\n",
      "[285]\tvalidation_0-mlogloss:0.15031\tvalidation_1-mlogloss:0.41192\n",
      "[286]\tvalidation_0-mlogloss:0.14940\tvalidation_1-mlogloss:0.41153\n",
      "[287]\tvalidation_0-mlogloss:0.14847\tvalidation_1-mlogloss:0.41093\n",
      "[288]\tvalidation_0-mlogloss:0.14752\tvalidation_1-mlogloss:0.41006\n",
      "[289]\tvalidation_0-mlogloss:0.14660\tvalidation_1-mlogloss:0.40924\n",
      "[290]\tvalidation_0-mlogloss:0.14571\tvalidation_1-mlogloss:0.40865\n",
      "[291]\tvalidation_0-mlogloss:0.14485\tvalidation_1-mlogloss:0.40786\n",
      "[292]\tvalidation_0-mlogloss:0.14393\tvalidation_1-mlogloss:0.40720\n",
      "[293]\tvalidation_0-mlogloss:0.14304\tvalidation_1-mlogloss:0.40687\n",
      "[294]\tvalidation_0-mlogloss:0.14219\tvalidation_1-mlogloss:0.40621\n",
      "[295]\tvalidation_0-mlogloss:0.14132\tvalidation_1-mlogloss:0.40519\n",
      "[296]\tvalidation_0-mlogloss:0.14045\tvalidation_1-mlogloss:0.40485\n",
      "[297]\tvalidation_0-mlogloss:0.13955\tvalidation_1-mlogloss:0.40423\n",
      "[298]\tvalidation_0-mlogloss:0.13870\tvalidation_1-mlogloss:0.40380\n",
      "[299]\tvalidation_0-mlogloss:0.13793\tvalidation_1-mlogloss:0.40352\n",
      "[300]\tvalidation_0-mlogloss:0.13706\tvalidation_1-mlogloss:0.40268\n",
      "[301]\tvalidation_0-mlogloss:0.13627\tvalidation_1-mlogloss:0.40233\n",
      "[302]\tvalidation_0-mlogloss:0.13547\tvalidation_1-mlogloss:0.40181\n",
      "[303]\tvalidation_0-mlogloss:0.13458\tvalidation_1-mlogloss:0.40116\n",
      "[304]\tvalidation_0-mlogloss:0.13377\tvalidation_1-mlogloss:0.40092\n",
      "[305]\tvalidation_0-mlogloss:0.13298\tvalidation_1-mlogloss:0.40014\n",
      "[306]\tvalidation_0-mlogloss:0.13219\tvalidation_1-mlogloss:0.39948\n",
      "[307]\tvalidation_0-mlogloss:0.13138\tvalidation_1-mlogloss:0.39839\n",
      "[308]\tvalidation_0-mlogloss:0.13059\tvalidation_1-mlogloss:0.39783\n",
      "[309]\tvalidation_0-mlogloss:0.12978\tvalidation_1-mlogloss:0.39756\n",
      "[310]\tvalidation_0-mlogloss:0.12905\tvalidation_1-mlogloss:0.39724\n",
      "[311]\tvalidation_0-mlogloss:0.12824\tvalidation_1-mlogloss:0.39668\n",
      "[312]\tvalidation_0-mlogloss:0.12745\tvalidation_1-mlogloss:0.39643\n",
      "[313]\tvalidation_0-mlogloss:0.12669\tvalidation_1-mlogloss:0.39597\n",
      "[314]\tvalidation_0-mlogloss:0.12590\tvalidation_1-mlogloss:0.39509\n",
      "[315]\tvalidation_0-mlogloss:0.12527\tvalidation_1-mlogloss:0.39472\n",
      "[316]\tvalidation_0-mlogloss:0.12455\tvalidation_1-mlogloss:0.39453\n",
      "[317]\tvalidation_0-mlogloss:0.12387\tvalidation_1-mlogloss:0.39414\n",
      "[318]\tvalidation_0-mlogloss:0.12324\tvalidation_1-mlogloss:0.39384\n",
      "[319]\tvalidation_0-mlogloss:0.12250\tvalidation_1-mlogloss:0.39360\n",
      "[320]\tvalidation_0-mlogloss:0.12188\tvalidation_1-mlogloss:0.39308\n",
      "[321]\tvalidation_0-mlogloss:0.12119\tvalidation_1-mlogloss:0.39286\n",
      "[322]\tvalidation_0-mlogloss:0.12055\tvalidation_1-mlogloss:0.39251\n",
      "[323]\tvalidation_0-mlogloss:0.11985\tvalidation_1-mlogloss:0.39213\n",
      "[324]\tvalidation_0-mlogloss:0.11912\tvalidation_1-mlogloss:0.39136\n",
      "[325]\tvalidation_0-mlogloss:0.11845\tvalidation_1-mlogloss:0.39122\n",
      "[326]\tvalidation_0-mlogloss:0.11774\tvalidation_1-mlogloss:0.39045\n",
      "[327]\tvalidation_0-mlogloss:0.11705\tvalidation_1-mlogloss:0.38983\n",
      "[328]\tvalidation_0-mlogloss:0.11636\tvalidation_1-mlogloss:0.38962\n",
      "[329]\tvalidation_0-mlogloss:0.11567\tvalidation_1-mlogloss:0.38900\n",
      "[330]\tvalidation_0-mlogloss:0.11501\tvalidation_1-mlogloss:0.38826\n",
      "[331]\tvalidation_0-mlogloss:0.11432\tvalidation_1-mlogloss:0.38780\n",
      "[332]\tvalidation_0-mlogloss:0.11366\tvalidation_1-mlogloss:0.38782\n",
      "[333]\tvalidation_0-mlogloss:0.11302\tvalidation_1-mlogloss:0.38744\n",
      "[334]\tvalidation_0-mlogloss:0.11243\tvalidation_1-mlogloss:0.38689\n",
      "[335]\tvalidation_0-mlogloss:0.11182\tvalidation_1-mlogloss:0.38682\n",
      "[336]\tvalidation_0-mlogloss:0.11120\tvalidation_1-mlogloss:0.38637\n",
      "[337]\tvalidation_0-mlogloss:0.11057\tvalidation_1-mlogloss:0.38610\n",
      "[338]\tvalidation_0-mlogloss:0.10996\tvalidation_1-mlogloss:0.38559\n",
      "[339]\tvalidation_0-mlogloss:0.10934\tvalidation_1-mlogloss:0.38518\n",
      "[340]\tvalidation_0-mlogloss:0.10872\tvalidation_1-mlogloss:0.38497\n",
      "[341]\tvalidation_0-mlogloss:0.10809\tvalidation_1-mlogloss:0.38420\n",
      "[342]\tvalidation_0-mlogloss:0.10755\tvalidation_1-mlogloss:0.38379\n",
      "[343]\tvalidation_0-mlogloss:0.10693\tvalidation_1-mlogloss:0.38299\n",
      "[344]\tvalidation_0-mlogloss:0.10635\tvalidation_1-mlogloss:0.38261\n",
      "[345]\tvalidation_0-mlogloss:0.10574\tvalidation_1-mlogloss:0.38201\n",
      "[346]\tvalidation_0-mlogloss:0.10517\tvalidation_1-mlogloss:0.38171\n",
      "[347]\tvalidation_0-mlogloss:0.10467\tvalidation_1-mlogloss:0.38130\n",
      "[348]\tvalidation_0-mlogloss:0.10406\tvalidation_1-mlogloss:0.38086\n",
      "[349]\tvalidation_0-mlogloss:0.10348\tvalidation_1-mlogloss:0.38019\n",
      "[350]\tvalidation_0-mlogloss:0.10298\tvalidation_1-mlogloss:0.37993\n",
      "[351]\tvalidation_0-mlogloss:0.10244\tvalidation_1-mlogloss:0.37932\n",
      "[352]\tvalidation_0-mlogloss:0.10189\tvalidation_1-mlogloss:0.37884\n",
      "[353]\tvalidation_0-mlogloss:0.10135\tvalidation_1-mlogloss:0.37844\n",
      "[354]\tvalidation_0-mlogloss:0.10085\tvalidation_1-mlogloss:0.37774\n",
      "[355]\tvalidation_0-mlogloss:0.10029\tvalidation_1-mlogloss:0.37723\n",
      "[356]\tvalidation_0-mlogloss:0.09978\tvalidation_1-mlogloss:0.37649\n",
      "[357]\tvalidation_0-mlogloss:0.09927\tvalidation_1-mlogloss:0.37620\n",
      "[358]\tvalidation_0-mlogloss:0.09873\tvalidation_1-mlogloss:0.37587\n",
      "[359]\tvalidation_0-mlogloss:0.09818\tvalidation_1-mlogloss:0.37527\n",
      "[360]\tvalidation_0-mlogloss:0.09768\tvalidation_1-mlogloss:0.37496\n",
      "[361]\tvalidation_0-mlogloss:0.09717\tvalidation_1-mlogloss:0.37497\n",
      "[362]\tvalidation_0-mlogloss:0.09664\tvalidation_1-mlogloss:0.37435\n",
      "[363]\tvalidation_0-mlogloss:0.09614\tvalidation_1-mlogloss:0.37406\n",
      "[364]\tvalidation_0-mlogloss:0.09566\tvalidation_1-mlogloss:0.37381\n",
      "[365]\tvalidation_0-mlogloss:0.09516\tvalidation_1-mlogloss:0.37355\n",
      "[366]\tvalidation_0-mlogloss:0.09468\tvalidation_1-mlogloss:0.37333\n",
      "[367]\tvalidation_0-mlogloss:0.09420\tvalidation_1-mlogloss:0.37288\n",
      "[368]\tvalidation_0-mlogloss:0.09372\tvalidation_1-mlogloss:0.37275\n",
      "[369]\tvalidation_0-mlogloss:0.09325\tvalidation_1-mlogloss:0.37269\n",
      "[370]\tvalidation_0-mlogloss:0.09276\tvalidation_1-mlogloss:0.37229\n",
      "[371]\tvalidation_0-mlogloss:0.09229\tvalidation_1-mlogloss:0.37232\n",
      "[372]\tvalidation_0-mlogloss:0.09182\tvalidation_1-mlogloss:0.37193\n",
      "[373]\tvalidation_0-mlogloss:0.09136\tvalidation_1-mlogloss:0.37160\n",
      "[374]\tvalidation_0-mlogloss:0.09086\tvalidation_1-mlogloss:0.37110\n",
      "[375]\tvalidation_0-mlogloss:0.09035\tvalidation_1-mlogloss:0.37047\n",
      "[376]\tvalidation_0-mlogloss:0.08989\tvalidation_1-mlogloss:0.37034\n",
      "[377]\tvalidation_0-mlogloss:0.08943\tvalidation_1-mlogloss:0.37037\n",
      "[378]\tvalidation_0-mlogloss:0.08897\tvalidation_1-mlogloss:0.37023\n",
      "[379]\tvalidation_0-mlogloss:0.08854\tvalidation_1-mlogloss:0.36974\n",
      "[380]\tvalidation_0-mlogloss:0.08808\tvalidation_1-mlogloss:0.36932\n",
      "[381]\tvalidation_0-mlogloss:0.08768\tvalidation_1-mlogloss:0.36890\n",
      "[382]\tvalidation_0-mlogloss:0.08725\tvalidation_1-mlogloss:0.36857\n",
      "[383]\tvalidation_0-mlogloss:0.08680\tvalidation_1-mlogloss:0.36853\n",
      "[384]\tvalidation_0-mlogloss:0.08644\tvalidation_1-mlogloss:0.36855\n",
      "[385]\tvalidation_0-mlogloss:0.08611\tvalidation_1-mlogloss:0.36831\n",
      "[386]\tvalidation_0-mlogloss:0.08566\tvalidation_1-mlogloss:0.36777\n",
      "[387]\tvalidation_0-mlogloss:0.08524\tvalidation_1-mlogloss:0.36709\n",
      "[388]\tvalidation_0-mlogloss:0.08480\tvalidation_1-mlogloss:0.36680\n",
      "[389]\tvalidation_0-mlogloss:0.08443\tvalidation_1-mlogloss:0.36658\n",
      "[390]\tvalidation_0-mlogloss:0.08402\tvalidation_1-mlogloss:0.36640\n",
      "[391]\tvalidation_0-mlogloss:0.08361\tvalidation_1-mlogloss:0.36640\n",
      "[392]\tvalidation_0-mlogloss:0.08322\tvalidation_1-mlogloss:0.36641\n",
      "[393]\tvalidation_0-mlogloss:0.08286\tvalidation_1-mlogloss:0.36608\n",
      "[394]\tvalidation_0-mlogloss:0.08247\tvalidation_1-mlogloss:0.36572\n",
      "[395]\tvalidation_0-mlogloss:0.08212\tvalidation_1-mlogloss:0.36551\n",
      "[396]\tvalidation_0-mlogloss:0.08172\tvalidation_1-mlogloss:0.36523\n",
      "[397]\tvalidation_0-mlogloss:0.08132\tvalidation_1-mlogloss:0.36490\n",
      "[398]\tvalidation_0-mlogloss:0.08096\tvalidation_1-mlogloss:0.36451\n",
      "[399]\tvalidation_0-mlogloss:0.08060\tvalidation_1-mlogloss:0.36402\n",
      "[400]\tvalidation_0-mlogloss:0.08023\tvalidation_1-mlogloss:0.36402\n",
      "[401]\tvalidation_0-mlogloss:0.07984\tvalidation_1-mlogloss:0.36353\n",
      "[402]\tvalidation_0-mlogloss:0.07950\tvalidation_1-mlogloss:0.36365\n",
      "[403]\tvalidation_0-mlogloss:0.07911\tvalidation_1-mlogloss:0.36366\n",
      "[404]\tvalidation_0-mlogloss:0.07875\tvalidation_1-mlogloss:0.36345\n",
      "[405]\tvalidation_0-mlogloss:0.07837\tvalidation_1-mlogloss:0.36307\n",
      "[406]\tvalidation_0-mlogloss:0.07807\tvalidation_1-mlogloss:0.36290\n",
      "[407]\tvalidation_0-mlogloss:0.07773\tvalidation_1-mlogloss:0.36266\n",
      "[408]\tvalidation_0-mlogloss:0.07739\tvalidation_1-mlogloss:0.36239\n",
      "[409]\tvalidation_0-mlogloss:0.07704\tvalidation_1-mlogloss:0.36191\n",
      "[410]\tvalidation_0-mlogloss:0.07670\tvalidation_1-mlogloss:0.36164\n",
      "[411]\tvalidation_0-mlogloss:0.07636\tvalidation_1-mlogloss:0.36167\n",
      "[412]\tvalidation_0-mlogloss:0.07601\tvalidation_1-mlogloss:0.36138\n",
      "[413]\tvalidation_0-mlogloss:0.07570\tvalidation_1-mlogloss:0.36137\n",
      "[414]\tvalidation_0-mlogloss:0.07537\tvalidation_1-mlogloss:0.36144\n",
      "[415]\tvalidation_0-mlogloss:0.07505\tvalidation_1-mlogloss:0.36094\n",
      "[416]\tvalidation_0-mlogloss:0.07474\tvalidation_1-mlogloss:0.36094\n",
      "[417]\tvalidation_0-mlogloss:0.07439\tvalidation_1-mlogloss:0.36077\n",
      "[418]\tvalidation_0-mlogloss:0.07408\tvalidation_1-mlogloss:0.36081\n",
      "[419]\tvalidation_0-mlogloss:0.07374\tvalidation_1-mlogloss:0.36068\n",
      "[420]\tvalidation_0-mlogloss:0.07343\tvalidation_1-mlogloss:0.36061\n",
      "[421]\tvalidation_0-mlogloss:0.07317\tvalidation_1-mlogloss:0.36045\n",
      "[422]\tvalidation_0-mlogloss:0.07283\tvalidation_1-mlogloss:0.36004\n",
      "[423]\tvalidation_0-mlogloss:0.07250\tvalidation_1-mlogloss:0.35985\n",
      "[424]\tvalidation_0-mlogloss:0.07219\tvalidation_1-mlogloss:0.35953\n",
      "[425]\tvalidation_0-mlogloss:0.07183\tvalidation_1-mlogloss:0.35956\n",
      "[426]\tvalidation_0-mlogloss:0.07157\tvalidation_1-mlogloss:0.35949\n",
      "[427]\tvalidation_0-mlogloss:0.07125\tvalidation_1-mlogloss:0.35957\n",
      "[428]\tvalidation_0-mlogloss:0.07097\tvalidation_1-mlogloss:0.35924\n",
      "[429]\tvalidation_0-mlogloss:0.07070\tvalidation_1-mlogloss:0.35900\n",
      "[430]\tvalidation_0-mlogloss:0.07045\tvalidation_1-mlogloss:0.35912\n",
      "[431]\tvalidation_0-mlogloss:0.07013\tvalidation_1-mlogloss:0.35907\n",
      "[432]\tvalidation_0-mlogloss:0.06986\tvalidation_1-mlogloss:0.35899\n",
      "[433]\tvalidation_0-mlogloss:0.06959\tvalidation_1-mlogloss:0.35884\n",
      "[434]\tvalidation_0-mlogloss:0.06928\tvalidation_1-mlogloss:0.35900\n",
      "[435]\tvalidation_0-mlogloss:0.06898\tvalidation_1-mlogloss:0.35919\n",
      "[436]\tvalidation_0-mlogloss:0.06870\tvalidation_1-mlogloss:0.35918\n",
      "[437]\tvalidation_0-mlogloss:0.06844\tvalidation_1-mlogloss:0.35916\n",
      "[438]\tvalidation_0-mlogloss:0.06819\tvalidation_1-mlogloss:0.35908\n",
      "[439]\tvalidation_0-mlogloss:0.06795\tvalidation_1-mlogloss:0.35906\n",
      "[440]\tvalidation_0-mlogloss:0.06766\tvalidation_1-mlogloss:0.35908\n",
      "[441]\tvalidation_0-mlogloss:0.06737\tvalidation_1-mlogloss:0.35861\n",
      "[442]\tvalidation_0-mlogloss:0.06711\tvalidation_1-mlogloss:0.35859\n",
      "[443]\tvalidation_0-mlogloss:0.06684\tvalidation_1-mlogloss:0.35840\n",
      "[444]\tvalidation_0-mlogloss:0.06663\tvalidation_1-mlogloss:0.35861\n",
      "[445]\tvalidation_0-mlogloss:0.06642\tvalidation_1-mlogloss:0.35853\n",
      "[446]\tvalidation_0-mlogloss:0.06618\tvalidation_1-mlogloss:0.35846\n",
      "[447]\tvalidation_0-mlogloss:0.06599\tvalidation_1-mlogloss:0.35851\n",
      "[448]\tvalidation_0-mlogloss:0.06575\tvalidation_1-mlogloss:0.35824\n",
      "[449]\tvalidation_0-mlogloss:0.06558\tvalidation_1-mlogloss:0.35824\n",
      "[450]\tvalidation_0-mlogloss:0.06533\tvalidation_1-mlogloss:0.35814\n",
      "[451]\tvalidation_0-mlogloss:0.06506\tvalidation_1-mlogloss:0.35816\n",
      "[452]\tvalidation_0-mlogloss:0.06480\tvalidation_1-mlogloss:0.35812\n",
      "[453]\tvalidation_0-mlogloss:0.06456\tvalidation_1-mlogloss:0.35826\n",
      "[454]\tvalidation_0-mlogloss:0.06432\tvalidation_1-mlogloss:0.35828\n",
      "[455]\tvalidation_0-mlogloss:0.06413\tvalidation_1-mlogloss:0.35812\n",
      "[456]\tvalidation_0-mlogloss:0.06388\tvalidation_1-mlogloss:0.35788\n",
      "[457]\tvalidation_0-mlogloss:0.06362\tvalidation_1-mlogloss:0.35780\n",
      "[458]\tvalidation_0-mlogloss:0.06346\tvalidation_1-mlogloss:0.35770\n",
      "[459]\tvalidation_0-mlogloss:0.06318\tvalidation_1-mlogloss:0.35727\n",
      "[460]\tvalidation_0-mlogloss:0.06293\tvalidation_1-mlogloss:0.35714\n",
      "[461]\tvalidation_0-mlogloss:0.06272\tvalidation_1-mlogloss:0.35696\n",
      "[462]\tvalidation_0-mlogloss:0.06255\tvalidation_1-mlogloss:0.35703\n",
      "[463]\tvalidation_0-mlogloss:0.06237\tvalidation_1-mlogloss:0.35685\n",
      "[464]\tvalidation_0-mlogloss:0.06212\tvalidation_1-mlogloss:0.35677\n",
      "[465]\tvalidation_0-mlogloss:0.06187\tvalidation_1-mlogloss:0.35654\n",
      "[466]\tvalidation_0-mlogloss:0.06164\tvalidation_1-mlogloss:0.35674\n",
      "[467]\tvalidation_0-mlogloss:0.06146\tvalidation_1-mlogloss:0.35665\n",
      "[468]\tvalidation_0-mlogloss:0.06125\tvalidation_1-mlogloss:0.35653\n",
      "[469]\tvalidation_0-mlogloss:0.06107\tvalidation_1-mlogloss:0.35654\n",
      "[470]\tvalidation_0-mlogloss:0.06087\tvalidation_1-mlogloss:0.35615\n",
      "[471]\tvalidation_0-mlogloss:0.06074\tvalidation_1-mlogloss:0.35621\n",
      "[472]\tvalidation_0-mlogloss:0.06057\tvalidation_1-mlogloss:0.35622\n",
      "[473]\tvalidation_0-mlogloss:0.06034\tvalidation_1-mlogloss:0.35590\n",
      "[474]\tvalidation_0-mlogloss:0.06013\tvalidation_1-mlogloss:0.35567\n",
      "[475]\tvalidation_0-mlogloss:0.05996\tvalidation_1-mlogloss:0.35569\n",
      "[476]\tvalidation_0-mlogloss:0.05979\tvalidation_1-mlogloss:0.35569\n",
      "[477]\tvalidation_0-mlogloss:0.05965\tvalidation_1-mlogloss:0.35582\n",
      "[478]\tvalidation_0-mlogloss:0.05946\tvalidation_1-mlogloss:0.35550\n",
      "[479]\tvalidation_0-mlogloss:0.05929\tvalidation_1-mlogloss:0.35534\n",
      "[480]\tvalidation_0-mlogloss:0.05912\tvalidation_1-mlogloss:0.35474\n",
      "[481]\tvalidation_0-mlogloss:0.05895\tvalidation_1-mlogloss:0.35454\n",
      "[482]\tvalidation_0-mlogloss:0.05876\tvalidation_1-mlogloss:0.35433\n",
      "[483]\tvalidation_0-mlogloss:0.05857\tvalidation_1-mlogloss:0.35403\n",
      "[484]\tvalidation_0-mlogloss:0.05838\tvalidation_1-mlogloss:0.35416\n",
      "[485]\tvalidation_0-mlogloss:0.05817\tvalidation_1-mlogloss:0.35405\n",
      "[486]\tvalidation_0-mlogloss:0.05798\tvalidation_1-mlogloss:0.35369\n",
      "[487]\tvalidation_0-mlogloss:0.05785\tvalidation_1-mlogloss:0.35362\n",
      "[488]\tvalidation_0-mlogloss:0.05775\tvalidation_1-mlogloss:0.35355\n",
      "[489]\tvalidation_0-mlogloss:0.05758\tvalidation_1-mlogloss:0.35320\n",
      "[490]\tvalidation_0-mlogloss:0.05739\tvalidation_1-mlogloss:0.35289\n",
      "[491]\tvalidation_0-mlogloss:0.05719\tvalidation_1-mlogloss:0.35275\n",
      "[492]\tvalidation_0-mlogloss:0.05705\tvalidation_1-mlogloss:0.35283\n",
      "[493]\tvalidation_0-mlogloss:0.05688\tvalidation_1-mlogloss:0.35234\n",
      "[494]\tvalidation_0-mlogloss:0.05674\tvalidation_1-mlogloss:0.35208\n",
      "[495]\tvalidation_0-mlogloss:0.05653\tvalidation_1-mlogloss:0.35190\n",
      "[496]\tvalidation_0-mlogloss:0.05637\tvalidation_1-mlogloss:0.35184\n",
      "[497]\tvalidation_0-mlogloss:0.05621\tvalidation_1-mlogloss:0.35185\n",
      "[498]\tvalidation_0-mlogloss:0.05607\tvalidation_1-mlogloss:0.35174\n",
      "[499]\tvalidation_0-mlogloss:0.05592\tvalidation_1-mlogloss:0.35169\n",
      "[500]\tvalidation_0-mlogloss:0.05578\tvalidation_1-mlogloss:0.35155\n",
      "[501]\tvalidation_0-mlogloss:0.05562\tvalidation_1-mlogloss:0.35115\n",
      "[502]\tvalidation_0-mlogloss:0.05554\tvalidation_1-mlogloss:0.35112\n",
      "[503]\tvalidation_0-mlogloss:0.05541\tvalidation_1-mlogloss:0.35120\n",
      "[504]\tvalidation_0-mlogloss:0.05526\tvalidation_1-mlogloss:0.35104\n",
      "[505]\tvalidation_0-mlogloss:0.05515\tvalidation_1-mlogloss:0.35088\n",
      "[506]\tvalidation_0-mlogloss:0.05498\tvalidation_1-mlogloss:0.35045\n",
      "[507]\tvalidation_0-mlogloss:0.05482\tvalidation_1-mlogloss:0.35045\n",
      "[508]\tvalidation_0-mlogloss:0.05474\tvalidation_1-mlogloss:0.35041\n",
      "[509]\tvalidation_0-mlogloss:0.05460\tvalidation_1-mlogloss:0.35061\n",
      "[510]\tvalidation_0-mlogloss:0.05444\tvalidation_1-mlogloss:0.35015\n",
      "[511]\tvalidation_0-mlogloss:0.05430\tvalidation_1-mlogloss:0.35002\n",
      "[512]\tvalidation_0-mlogloss:0.05415\tvalidation_1-mlogloss:0.34995\n",
      "[513]\tvalidation_0-mlogloss:0.05404\tvalidation_1-mlogloss:0.34998\n",
      "[514]\tvalidation_0-mlogloss:0.05393\tvalidation_1-mlogloss:0.35002\n",
      "[515]\tvalidation_0-mlogloss:0.05383\tvalidation_1-mlogloss:0.34981\n",
      "[516]\tvalidation_0-mlogloss:0.05374\tvalidation_1-mlogloss:0.34958\n",
      "[517]\tvalidation_0-mlogloss:0.05358\tvalidation_1-mlogloss:0.34909\n",
      "[518]\tvalidation_0-mlogloss:0.05345\tvalidation_1-mlogloss:0.34901\n",
      "[519]\tvalidation_0-mlogloss:0.05335\tvalidation_1-mlogloss:0.34898\n",
      "[520]\tvalidation_0-mlogloss:0.05327\tvalidation_1-mlogloss:0.34888\n",
      "[521]\tvalidation_0-mlogloss:0.05318\tvalidation_1-mlogloss:0.34869\n",
      "[522]\tvalidation_0-mlogloss:0.05309\tvalidation_1-mlogloss:0.34879\n",
      "[523]\tvalidation_0-mlogloss:0.05298\tvalidation_1-mlogloss:0.34874\n",
      "[524]\tvalidation_0-mlogloss:0.05288\tvalidation_1-mlogloss:0.34847\n",
      "[525]\tvalidation_0-mlogloss:0.05274\tvalidation_1-mlogloss:0.34818\n",
      "[526]\tvalidation_0-mlogloss:0.05259\tvalidation_1-mlogloss:0.34800\n",
      "[527]\tvalidation_0-mlogloss:0.05253\tvalidation_1-mlogloss:0.34793\n",
      "[528]\tvalidation_0-mlogloss:0.05244\tvalidation_1-mlogloss:0.34780\n",
      "[529]\tvalidation_0-mlogloss:0.05238\tvalidation_1-mlogloss:0.34777\n",
      "[530]\tvalidation_0-mlogloss:0.05224\tvalidation_1-mlogloss:0.34783\n",
      "[531]\tvalidation_0-mlogloss:0.05211\tvalidation_1-mlogloss:0.34771\n",
      "[532]\tvalidation_0-mlogloss:0.05207\tvalidation_1-mlogloss:0.34749\n",
      "[533]\tvalidation_0-mlogloss:0.05195\tvalidation_1-mlogloss:0.34708\n",
      "[534]\tvalidation_0-mlogloss:0.05182\tvalidation_1-mlogloss:0.34710\n",
      "[535]\tvalidation_0-mlogloss:0.05174\tvalidation_1-mlogloss:0.34718\n",
      "[536]\tvalidation_0-mlogloss:0.05165\tvalidation_1-mlogloss:0.34696\n",
      "[537]\tvalidation_0-mlogloss:0.05155\tvalidation_1-mlogloss:0.34677\n",
      "[538]\tvalidation_0-mlogloss:0.05146\tvalidation_1-mlogloss:0.34657\n",
      "[539]\tvalidation_0-mlogloss:0.05136\tvalidation_1-mlogloss:0.34620\n",
      "[540]\tvalidation_0-mlogloss:0.05123\tvalidation_1-mlogloss:0.34626\n",
      "[541]\tvalidation_0-mlogloss:0.05116\tvalidation_1-mlogloss:0.34620\n",
      "[542]\tvalidation_0-mlogloss:0.05107\tvalidation_1-mlogloss:0.34593\n",
      "[543]\tvalidation_0-mlogloss:0.05100\tvalidation_1-mlogloss:0.34576\n",
      "[544]\tvalidation_0-mlogloss:0.05091\tvalidation_1-mlogloss:0.34536\n",
      "[545]\tvalidation_0-mlogloss:0.05085\tvalidation_1-mlogloss:0.34529\n",
      "[546]\tvalidation_0-mlogloss:0.05078\tvalidation_1-mlogloss:0.34518\n",
      "[547]\tvalidation_0-mlogloss:0.05073\tvalidation_1-mlogloss:0.34520\n",
      "[548]\tvalidation_0-mlogloss:0.05063\tvalidation_1-mlogloss:0.34523\n",
      "[549]\tvalidation_0-mlogloss:0.05055\tvalidation_1-mlogloss:0.34503\n",
      "[550]\tvalidation_0-mlogloss:0.05049\tvalidation_1-mlogloss:0.34480\n",
      "[551]\tvalidation_0-mlogloss:0.05046\tvalidation_1-mlogloss:0.34471\n",
      "[552]\tvalidation_0-mlogloss:0.05038\tvalidation_1-mlogloss:0.34466\n",
      "[553]\tvalidation_0-mlogloss:0.05030\tvalidation_1-mlogloss:0.34464\n",
      "[554]\tvalidation_0-mlogloss:0.05024\tvalidation_1-mlogloss:0.34447\n",
      "[555]\tvalidation_0-mlogloss:0.05014\tvalidation_1-mlogloss:0.34433\n",
      "[556]\tvalidation_0-mlogloss:0.05009\tvalidation_1-mlogloss:0.34442\n",
      "[557]\tvalidation_0-mlogloss:0.05003\tvalidation_1-mlogloss:0.34428\n",
      "[558]\tvalidation_0-mlogloss:0.04996\tvalidation_1-mlogloss:0.34404\n",
      "[559]\tvalidation_0-mlogloss:0.04991\tvalidation_1-mlogloss:0.34391\n",
      "[560]\tvalidation_0-mlogloss:0.04985\tvalidation_1-mlogloss:0.34370\n",
      "[561]\tvalidation_0-mlogloss:0.04980\tvalidation_1-mlogloss:0.34380\n",
      "[562]\tvalidation_0-mlogloss:0.04974\tvalidation_1-mlogloss:0.34362\n",
      "[563]\tvalidation_0-mlogloss:0.04969\tvalidation_1-mlogloss:0.34344\n",
      "[564]\tvalidation_0-mlogloss:0.04963\tvalidation_1-mlogloss:0.34329\n",
      "[565]\tvalidation_0-mlogloss:0.04958\tvalidation_1-mlogloss:0.34345\n",
      "[566]\tvalidation_0-mlogloss:0.04953\tvalidation_1-mlogloss:0.34367\n",
      "[567]\tvalidation_0-mlogloss:0.04947\tvalidation_1-mlogloss:0.34362\n",
      "[568]\tvalidation_0-mlogloss:0.04940\tvalidation_1-mlogloss:0.34362\n",
      "[569]\tvalidation_0-mlogloss:0.04935\tvalidation_1-mlogloss:0.34355\n",
      "[570]\tvalidation_0-mlogloss:0.04928\tvalidation_1-mlogloss:0.34339\n",
      "[571]\tvalidation_0-mlogloss:0.04920\tvalidation_1-mlogloss:0.34338\n",
      "[572]\tvalidation_0-mlogloss:0.04915\tvalidation_1-mlogloss:0.34334\n",
      "[573]\tvalidation_0-mlogloss:0.04911\tvalidation_1-mlogloss:0.34331\n",
      "[574]\tvalidation_0-mlogloss:0.04909\tvalidation_1-mlogloss:0.34340\n",
      "[575]\tvalidation_0-mlogloss:0.04904\tvalidation_1-mlogloss:0.34351\n",
      "[576]\tvalidation_0-mlogloss:0.04898\tvalidation_1-mlogloss:0.34331\n",
      "[577]\tvalidation_0-mlogloss:0.04893\tvalidation_1-mlogloss:0.34330\n",
      "[578]\tvalidation_0-mlogloss:0.04889\tvalidation_1-mlogloss:0.34325\n",
      "[579]\tvalidation_0-mlogloss:0.04885\tvalidation_1-mlogloss:0.34341\n",
      "[580]\tvalidation_0-mlogloss:0.04878\tvalidation_1-mlogloss:0.34339\n",
      "[581]\tvalidation_0-mlogloss:0.04873\tvalidation_1-mlogloss:0.34337\n",
      "[582]\tvalidation_0-mlogloss:0.04864\tvalidation_1-mlogloss:0.34333\n",
      "[583]\tvalidation_0-mlogloss:0.04857\tvalidation_1-mlogloss:0.34317\n",
      "[584]\tvalidation_0-mlogloss:0.04853\tvalidation_1-mlogloss:0.34332\n",
      "[585]\tvalidation_0-mlogloss:0.04850\tvalidation_1-mlogloss:0.34347\n",
      "[586]\tvalidation_0-mlogloss:0.04845\tvalidation_1-mlogloss:0.34344\n",
      "[587]\tvalidation_0-mlogloss:0.04844\tvalidation_1-mlogloss:0.34333\n",
      "[588]\tvalidation_0-mlogloss:0.04840\tvalidation_1-mlogloss:0.34310\n",
      "[589]\tvalidation_0-mlogloss:0.04835\tvalidation_1-mlogloss:0.34319\n",
      "[590]\tvalidation_0-mlogloss:0.04831\tvalidation_1-mlogloss:0.34338\n",
      "[591]\tvalidation_0-mlogloss:0.04829\tvalidation_1-mlogloss:0.34330\n",
      "[592]\tvalidation_0-mlogloss:0.04822\tvalidation_1-mlogloss:0.34337\n",
      "[593]\tvalidation_0-mlogloss:0.04817\tvalidation_1-mlogloss:0.34359\n",
      "[594]\tvalidation_0-mlogloss:0.04811\tvalidation_1-mlogloss:0.34350\n",
      "[595]\tvalidation_0-mlogloss:0.04809\tvalidation_1-mlogloss:0.34342\n",
      "[596]\tvalidation_0-mlogloss:0.04804\tvalidation_1-mlogloss:0.34362\n",
      "[597]\tvalidation_0-mlogloss:0.04796\tvalidation_1-mlogloss:0.34340\n",
      "[598]\tvalidation_0-mlogloss:0.04795\tvalidation_1-mlogloss:0.34325\n",
      "[599]\tvalidation_0-mlogloss:0.04787\tvalidation_1-mlogloss:0.34323\n",
      "[600]\tvalidation_0-mlogloss:0.04785\tvalidation_1-mlogloss:0.34338\n",
      "[601]\tvalidation_0-mlogloss:0.04778\tvalidation_1-mlogloss:0.34334\n",
      "[602]\tvalidation_0-mlogloss:0.04774\tvalidation_1-mlogloss:0.34351\n",
      "[603]\tvalidation_0-mlogloss:0.04770\tvalidation_1-mlogloss:0.34362\n",
      "[604]\tvalidation_0-mlogloss:0.04765\tvalidation_1-mlogloss:0.34363\n",
      "[605]\tvalidation_0-mlogloss:0.04761\tvalidation_1-mlogloss:0.34360\n",
      "[606]\tvalidation_0-mlogloss:0.04760\tvalidation_1-mlogloss:0.34365\n",
      "[607]\tvalidation_0-mlogloss:0.04757\tvalidation_1-mlogloss:0.34384\n",
      "[608]\tvalidation_0-mlogloss:0.04753\tvalidation_1-mlogloss:0.34365\n",
      "[16:53:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-mlogloss:1.59204\tvalidation_1-mlogloss:1.59444\n",
      "[1]\tvalidation_0-mlogloss:1.57490\tvalidation_1-mlogloss:1.58053\n",
      "[2]\tvalidation_0-mlogloss:1.55791\tvalidation_1-mlogloss:1.56711\n",
      "[3]\tvalidation_0-mlogloss:1.54166\tvalidation_1-mlogloss:1.55485\n",
      "[4]\tvalidation_0-mlogloss:1.52523\tvalidation_1-mlogloss:1.54271\n",
      "[5]\tvalidation_0-mlogloss:1.50736\tvalidation_1-mlogloss:1.52761\n",
      "[6]\tvalidation_0-mlogloss:1.49082\tvalidation_1-mlogloss:1.51531\n",
      "[7]\tvalidation_0-mlogloss:1.47429\tvalidation_1-mlogloss:1.50105\n",
      "[8]\tvalidation_0-mlogloss:1.45711\tvalidation_1-mlogloss:1.48580\n",
      "[9]\tvalidation_0-mlogloss:1.44098\tvalidation_1-mlogloss:1.47130\n",
      "[10]\tvalidation_0-mlogloss:1.42572\tvalidation_1-mlogloss:1.45944\n",
      "[11]\tvalidation_0-mlogloss:1.41006\tvalidation_1-mlogloss:1.44760\n",
      "[12]\tvalidation_0-mlogloss:1.39489\tvalidation_1-mlogloss:1.43671\n",
      "[13]\tvalidation_0-mlogloss:1.38057\tvalidation_1-mlogloss:1.42549\n",
      "[14]\tvalidation_0-mlogloss:1.36566\tvalidation_1-mlogloss:1.41413\n",
      "[15]\tvalidation_0-mlogloss:1.35070\tvalidation_1-mlogloss:1.40168\n",
      "[16]\tvalidation_0-mlogloss:1.33652\tvalidation_1-mlogloss:1.38913\n",
      "[17]\tvalidation_0-mlogloss:1.32179\tvalidation_1-mlogloss:1.37575\n",
      "[18]\tvalidation_0-mlogloss:1.30884\tvalidation_1-mlogloss:1.36505\n",
      "[19]\tvalidation_0-mlogloss:1.29512\tvalidation_1-mlogloss:1.35308\n",
      "[20]\tvalidation_0-mlogloss:1.28109\tvalidation_1-mlogloss:1.34133\n",
      "[21]\tvalidation_0-mlogloss:1.26857\tvalidation_1-mlogloss:1.33218\n",
      "[22]\tvalidation_0-mlogloss:1.25651\tvalidation_1-mlogloss:1.32261\n",
      "[23]\tvalidation_0-mlogloss:1.24443\tvalidation_1-mlogloss:1.31272\n",
      "[24]\tvalidation_0-mlogloss:1.23297\tvalidation_1-mlogloss:1.30392\n",
      "[25]\tvalidation_0-mlogloss:1.22038\tvalidation_1-mlogloss:1.29427\n",
      "[26]\tvalidation_0-mlogloss:1.20819\tvalidation_1-mlogloss:1.28542\n",
      "[27]\tvalidation_0-mlogloss:1.19550\tvalidation_1-mlogloss:1.27411\n",
      "[28]\tvalidation_0-mlogloss:1.18415\tvalidation_1-mlogloss:1.26532\n",
      "[29]\tvalidation_0-mlogloss:1.17298\tvalidation_1-mlogloss:1.25717\n",
      "[30]\tvalidation_0-mlogloss:1.16140\tvalidation_1-mlogloss:1.24730\n",
      "[31]\tvalidation_0-mlogloss:1.15035\tvalidation_1-mlogloss:1.23789\n",
      "[32]\tvalidation_0-mlogloss:1.13941\tvalidation_1-mlogloss:1.22894\n",
      "[33]\tvalidation_0-mlogloss:1.12813\tvalidation_1-mlogloss:1.21916\n",
      "[34]\tvalidation_0-mlogloss:1.11717\tvalidation_1-mlogloss:1.21132\n",
      "[35]\tvalidation_0-mlogloss:1.10586\tvalidation_1-mlogloss:1.20029\n",
      "[36]\tvalidation_0-mlogloss:1.09464\tvalidation_1-mlogloss:1.19116\n",
      "[37]\tvalidation_0-mlogloss:1.08418\tvalidation_1-mlogloss:1.18365\n",
      "[38]\tvalidation_0-mlogloss:1.07366\tvalidation_1-mlogloss:1.17620\n",
      "[39]\tvalidation_0-mlogloss:1.06305\tvalidation_1-mlogloss:1.16781\n",
      "[40]\tvalidation_0-mlogloss:1.05252\tvalidation_1-mlogloss:1.16006\n",
      "[41]\tvalidation_0-mlogloss:1.04227\tvalidation_1-mlogloss:1.15239\n",
      "[42]\tvalidation_0-mlogloss:1.03226\tvalidation_1-mlogloss:1.14449\n",
      "[43]\tvalidation_0-mlogloss:1.02210\tvalidation_1-mlogloss:1.13545\n",
      "[44]\tvalidation_0-mlogloss:1.01288\tvalidation_1-mlogloss:1.12864\n",
      "[45]\tvalidation_0-mlogloss:1.00263\tvalidation_1-mlogloss:1.11934\n",
      "[46]\tvalidation_0-mlogloss:0.99276\tvalidation_1-mlogloss:1.11081\n",
      "[47]\tvalidation_0-mlogloss:0.98308\tvalidation_1-mlogloss:1.10250\n",
      "[48]\tvalidation_0-mlogloss:0.97313\tvalidation_1-mlogloss:1.09399\n",
      "[49]\tvalidation_0-mlogloss:0.96360\tvalidation_1-mlogloss:1.08608\n",
      "[50]\tvalidation_0-mlogloss:0.95413\tvalidation_1-mlogloss:1.07831\n",
      "[51]\tvalidation_0-mlogloss:0.94569\tvalidation_1-mlogloss:1.07212\n",
      "[52]\tvalidation_0-mlogloss:0.93666\tvalidation_1-mlogloss:1.06468\n",
      "[53]\tvalidation_0-mlogloss:0.92898\tvalidation_1-mlogloss:1.05944\n",
      "[54]\tvalidation_0-mlogloss:0.92081\tvalidation_1-mlogloss:1.05358\n",
      "[55]\tvalidation_0-mlogloss:0.91231\tvalidation_1-mlogloss:1.04731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56]\tvalidation_0-mlogloss:0.90340\tvalidation_1-mlogloss:1.03921\n",
      "[57]\tvalidation_0-mlogloss:0.89492\tvalidation_1-mlogloss:1.03243\n",
      "[58]\tvalidation_0-mlogloss:0.88643\tvalidation_1-mlogloss:1.02527\n",
      "[59]\tvalidation_0-mlogloss:0.87840\tvalidation_1-mlogloss:1.01846\n",
      "[60]\tvalidation_0-mlogloss:0.86991\tvalidation_1-mlogloss:1.01080\n",
      "[61]\tvalidation_0-mlogloss:0.86210\tvalidation_1-mlogloss:1.00466\n",
      "[62]\tvalidation_0-mlogloss:0.85375\tvalidation_1-mlogloss:0.99736\n",
      "[63]\tvalidation_0-mlogloss:0.84567\tvalidation_1-mlogloss:0.98982\n",
      "[64]\tvalidation_0-mlogloss:0.83783\tvalidation_1-mlogloss:0.98294\n",
      "[65]\tvalidation_0-mlogloss:0.83012\tvalidation_1-mlogloss:0.97788\n",
      "[66]\tvalidation_0-mlogloss:0.82298\tvalidation_1-mlogloss:0.97231\n",
      "[67]\tvalidation_0-mlogloss:0.81536\tvalidation_1-mlogloss:0.96608\n",
      "[68]\tvalidation_0-mlogloss:0.80769\tvalidation_1-mlogloss:0.96014\n",
      "[69]\tvalidation_0-mlogloss:0.80033\tvalidation_1-mlogloss:0.95451\n",
      "[70]\tvalidation_0-mlogloss:0.79293\tvalidation_1-mlogloss:0.94893\n",
      "[71]\tvalidation_0-mlogloss:0.78534\tvalidation_1-mlogloss:0.94148\n",
      "[72]\tvalidation_0-mlogloss:0.77811\tvalidation_1-mlogloss:0.93582\n",
      "[73]\tvalidation_0-mlogloss:0.77098\tvalidation_1-mlogloss:0.93039\n",
      "[74]\tvalidation_0-mlogloss:0.76389\tvalidation_1-mlogloss:0.92389\n",
      "[75]\tvalidation_0-mlogloss:0.75709\tvalidation_1-mlogloss:0.91921\n",
      "[76]\tvalidation_0-mlogloss:0.75006\tvalidation_1-mlogloss:0.91274\n",
      "[77]\tvalidation_0-mlogloss:0.74435\tvalidation_1-mlogloss:0.90822\n",
      "[78]\tvalidation_0-mlogloss:0.73710\tvalidation_1-mlogloss:0.90126\n",
      "[79]\tvalidation_0-mlogloss:0.73080\tvalidation_1-mlogloss:0.89621\n",
      "[80]\tvalidation_0-mlogloss:0.72405\tvalidation_1-mlogloss:0.88976\n",
      "[81]\tvalidation_0-mlogloss:0.71759\tvalidation_1-mlogloss:0.88484\n",
      "[82]\tvalidation_0-mlogloss:0.71153\tvalidation_1-mlogloss:0.88027\n",
      "[83]\tvalidation_0-mlogloss:0.70529\tvalidation_1-mlogloss:0.87501\n",
      "[84]\tvalidation_0-mlogloss:0.69895\tvalidation_1-mlogloss:0.86965\n",
      "[85]\tvalidation_0-mlogloss:0.69275\tvalidation_1-mlogloss:0.86441\n",
      "[86]\tvalidation_0-mlogloss:0.68654\tvalidation_1-mlogloss:0.85874\n",
      "[87]\tvalidation_0-mlogloss:0.68021\tvalidation_1-mlogloss:0.85343\n",
      "[88]\tvalidation_0-mlogloss:0.67399\tvalidation_1-mlogloss:0.84741\n",
      "[89]\tvalidation_0-mlogloss:0.66843\tvalidation_1-mlogloss:0.84320\n",
      "[90]\tvalidation_0-mlogloss:0.66305\tvalidation_1-mlogloss:0.83906\n",
      "[91]\tvalidation_0-mlogloss:0.65766\tvalidation_1-mlogloss:0.83503\n",
      "[92]\tvalidation_0-mlogloss:0.65196\tvalidation_1-mlogloss:0.82957\n",
      "[93]\tvalidation_0-mlogloss:0.64593\tvalidation_1-mlogloss:0.82376\n",
      "[94]\tvalidation_0-mlogloss:0.64038\tvalidation_1-mlogloss:0.81884\n",
      "[95]\tvalidation_0-mlogloss:0.63448\tvalidation_1-mlogloss:0.81291\n",
      "[96]\tvalidation_0-mlogloss:0.62866\tvalidation_1-mlogloss:0.80759\n",
      "[97]\tvalidation_0-mlogloss:0.62288\tvalidation_1-mlogloss:0.80259\n",
      "[98]\tvalidation_0-mlogloss:0.61729\tvalidation_1-mlogloss:0.79717\n",
      "[99]\tvalidation_0-mlogloss:0.61162\tvalidation_1-mlogloss:0.79230\n",
      "[100]\tvalidation_0-mlogloss:0.60649\tvalidation_1-mlogloss:0.78821\n",
      "[101]\tvalidation_0-mlogloss:0.60130\tvalidation_1-mlogloss:0.78334\n",
      "[102]\tvalidation_0-mlogloss:0.59618\tvalidation_1-mlogloss:0.77902\n",
      "[103]\tvalidation_0-mlogloss:0.59072\tvalidation_1-mlogloss:0.77333\n",
      "[104]\tvalidation_0-mlogloss:0.58623\tvalidation_1-mlogloss:0.76921\n",
      "[105]\tvalidation_0-mlogloss:0.58103\tvalidation_1-mlogloss:0.76545\n",
      "[106]\tvalidation_0-mlogloss:0.57601\tvalidation_1-mlogloss:0.76129\n",
      "[107]\tvalidation_0-mlogloss:0.57097\tvalidation_1-mlogloss:0.75739\n",
      "[108]\tvalidation_0-mlogloss:0.56607\tvalidation_1-mlogloss:0.75357\n",
      "[109]\tvalidation_0-mlogloss:0.56136\tvalidation_1-mlogloss:0.74980\n",
      "[110]\tvalidation_0-mlogloss:0.55654\tvalidation_1-mlogloss:0.74594\n",
      "[111]\tvalidation_0-mlogloss:0.55195\tvalidation_1-mlogloss:0.74202\n",
      "[112]\tvalidation_0-mlogloss:0.54723\tvalidation_1-mlogloss:0.73676\n",
      "[113]\tvalidation_0-mlogloss:0.54273\tvalidation_1-mlogloss:0.73390\n",
      "[114]\tvalidation_0-mlogloss:0.53833\tvalidation_1-mlogloss:0.73015\n",
      "[115]\tvalidation_0-mlogloss:0.53390\tvalidation_1-mlogloss:0.72634\n",
      "[116]\tvalidation_0-mlogloss:0.52941\tvalidation_1-mlogloss:0.72174\n",
      "[117]\tvalidation_0-mlogloss:0.52509\tvalidation_1-mlogloss:0.71830\n",
      "[118]\tvalidation_0-mlogloss:0.52060\tvalidation_1-mlogloss:0.71494\n",
      "[119]\tvalidation_0-mlogloss:0.51631\tvalidation_1-mlogloss:0.71135\n",
      "[120]\tvalidation_0-mlogloss:0.51189\tvalidation_1-mlogloss:0.70755\n",
      "[121]\tvalidation_0-mlogloss:0.50770\tvalidation_1-mlogloss:0.70420\n",
      "[122]\tvalidation_0-mlogloss:0.50361\tvalidation_1-mlogloss:0.70120\n",
      "[123]\tvalidation_0-mlogloss:0.49928\tvalidation_1-mlogloss:0.69787\n",
      "[124]\tvalidation_0-mlogloss:0.49485\tvalidation_1-mlogloss:0.69404\n",
      "[125]\tvalidation_0-mlogloss:0.49057\tvalidation_1-mlogloss:0.68978\n",
      "[126]\tvalidation_0-mlogloss:0.48638\tvalidation_1-mlogloss:0.68647\n",
      "[127]\tvalidation_0-mlogloss:0.48227\tvalidation_1-mlogloss:0.68361\n",
      "[128]\tvalidation_0-mlogloss:0.47822\tvalidation_1-mlogloss:0.67940\n",
      "[129]\tvalidation_0-mlogloss:0.47416\tvalidation_1-mlogloss:0.67655\n",
      "[130]\tvalidation_0-mlogloss:0.47021\tvalidation_1-mlogloss:0.67223\n",
      "[131]\tvalidation_0-mlogloss:0.46625\tvalidation_1-mlogloss:0.66848\n",
      "[132]\tvalidation_0-mlogloss:0.46224\tvalidation_1-mlogloss:0.66456\n",
      "[133]\tvalidation_0-mlogloss:0.45849\tvalidation_1-mlogloss:0.66149\n",
      "[134]\tvalidation_0-mlogloss:0.45467\tvalidation_1-mlogloss:0.65891\n",
      "[135]\tvalidation_0-mlogloss:0.45092\tvalidation_1-mlogloss:0.65642\n",
      "[136]\tvalidation_0-mlogloss:0.44731\tvalidation_1-mlogloss:0.65396\n",
      "[137]\tvalidation_0-mlogloss:0.44359\tvalidation_1-mlogloss:0.65137\n",
      "[138]\tvalidation_0-mlogloss:0.43971\tvalidation_1-mlogloss:0.64793\n",
      "[139]\tvalidation_0-mlogloss:0.43618\tvalidation_1-mlogloss:0.64499\n",
      "[140]\tvalidation_0-mlogloss:0.43259\tvalidation_1-mlogloss:0.64222\n",
      "[141]\tvalidation_0-mlogloss:0.42910\tvalidation_1-mlogloss:0.63936\n",
      "[142]\tvalidation_0-mlogloss:0.42553\tvalidation_1-mlogloss:0.63496\n",
      "[143]\tvalidation_0-mlogloss:0.42212\tvalidation_1-mlogloss:0.63248\n",
      "[144]\tvalidation_0-mlogloss:0.41881\tvalidation_1-mlogloss:0.63018\n",
      "[145]\tvalidation_0-mlogloss:0.41541\tvalidation_1-mlogloss:0.62734\n",
      "[146]\tvalidation_0-mlogloss:0.41214\tvalidation_1-mlogloss:0.62513\n",
      "[147]\tvalidation_0-mlogloss:0.40881\tvalidation_1-mlogloss:0.62309\n",
      "[148]\tvalidation_0-mlogloss:0.40546\tvalidation_1-mlogloss:0.62022\n",
      "[149]\tvalidation_0-mlogloss:0.40210\tvalidation_1-mlogloss:0.61718\n",
      "[150]\tvalidation_0-mlogloss:0.39877\tvalidation_1-mlogloss:0.61380\n",
      "[151]\tvalidation_0-mlogloss:0.39549\tvalidation_1-mlogloss:0.61119\n",
      "[152]\tvalidation_0-mlogloss:0.39232\tvalidation_1-mlogloss:0.60838\n",
      "[153]\tvalidation_0-mlogloss:0.38917\tvalidation_1-mlogloss:0.60618\n",
      "[154]\tvalidation_0-mlogloss:0.38603\tvalidation_1-mlogloss:0.60344\n",
      "[155]\tvalidation_0-mlogloss:0.38289\tvalidation_1-mlogloss:0.60080\n",
      "[156]\tvalidation_0-mlogloss:0.37990\tvalidation_1-mlogloss:0.59836\n",
      "[157]\tvalidation_0-mlogloss:0.37706\tvalidation_1-mlogloss:0.59664\n",
      "[158]\tvalidation_0-mlogloss:0.37384\tvalidation_1-mlogloss:0.59335\n",
      "[159]\tvalidation_0-mlogloss:0.37091\tvalidation_1-mlogloss:0.59121\n",
      "[160]\tvalidation_0-mlogloss:0.36803\tvalidation_1-mlogloss:0.58883\n",
      "[161]\tvalidation_0-mlogloss:0.36544\tvalidation_1-mlogloss:0.58726\n",
      "[162]\tvalidation_0-mlogloss:0.36254\tvalidation_1-mlogloss:0.58450\n",
      "[163]\tvalidation_0-mlogloss:0.35959\tvalidation_1-mlogloss:0.58112\n",
      "[164]\tvalidation_0-mlogloss:0.35686\tvalidation_1-mlogloss:0.57971\n",
      "[165]\tvalidation_0-mlogloss:0.35419\tvalidation_1-mlogloss:0.57698\n",
      "[166]\tvalidation_0-mlogloss:0.35148\tvalidation_1-mlogloss:0.57517\n",
      "[167]\tvalidation_0-mlogloss:0.34856\tvalidation_1-mlogloss:0.57274\n",
      "[168]\tvalidation_0-mlogloss:0.34596\tvalidation_1-mlogloss:0.57088\n",
      "[169]\tvalidation_0-mlogloss:0.34330\tvalidation_1-mlogloss:0.56879\n",
      "[170]\tvalidation_0-mlogloss:0.34079\tvalidation_1-mlogloss:0.56714\n",
      "[171]\tvalidation_0-mlogloss:0.33807\tvalidation_1-mlogloss:0.56438\n",
      "[172]\tvalidation_0-mlogloss:0.33548\tvalidation_1-mlogloss:0.56252\n",
      "[173]\tvalidation_0-mlogloss:0.33310\tvalidation_1-mlogloss:0.56076\n",
      "[174]\tvalidation_0-mlogloss:0.33052\tvalidation_1-mlogloss:0.55870\n",
      "[175]\tvalidation_0-mlogloss:0.32804\tvalidation_1-mlogloss:0.55614\n",
      "[176]\tvalidation_0-mlogloss:0.32551\tvalidation_1-mlogloss:0.55413\n",
      "[177]\tvalidation_0-mlogloss:0.32300\tvalidation_1-mlogloss:0.55269\n",
      "[178]\tvalidation_0-mlogloss:0.32038\tvalidation_1-mlogloss:0.55021\n",
      "[179]\tvalidation_0-mlogloss:0.31782\tvalidation_1-mlogloss:0.54790\n",
      "[180]\tvalidation_0-mlogloss:0.31539\tvalidation_1-mlogloss:0.54584\n",
      "[181]\tvalidation_0-mlogloss:0.31291\tvalidation_1-mlogloss:0.54358\n",
      "[182]\tvalidation_0-mlogloss:0.31052\tvalidation_1-mlogloss:0.54093\n",
      "[183]\tvalidation_0-mlogloss:0.30814\tvalidation_1-mlogloss:0.53906\n",
      "[184]\tvalidation_0-mlogloss:0.30568\tvalidation_1-mlogloss:0.53631\n",
      "[185]\tvalidation_0-mlogloss:0.30331\tvalidation_1-mlogloss:0.53403\n",
      "[186]\tvalidation_0-mlogloss:0.30088\tvalidation_1-mlogloss:0.53167\n",
      "[187]\tvalidation_0-mlogloss:0.29858\tvalidation_1-mlogloss:0.52974\n",
      "[188]\tvalidation_0-mlogloss:0.29627\tvalidation_1-mlogloss:0.52797\n",
      "[189]\tvalidation_0-mlogloss:0.29408\tvalidation_1-mlogloss:0.52594\n",
      "[190]\tvalidation_0-mlogloss:0.29178\tvalidation_1-mlogloss:0.52428\n",
      "[191]\tvalidation_0-mlogloss:0.28986\tvalidation_1-mlogloss:0.52304\n",
      "[192]\tvalidation_0-mlogloss:0.28769\tvalidation_1-mlogloss:0.52118\n",
      "[193]\tvalidation_0-mlogloss:0.28541\tvalidation_1-mlogloss:0.51914\n",
      "[194]\tvalidation_0-mlogloss:0.28316\tvalidation_1-mlogloss:0.51700\n",
      "[195]\tvalidation_0-mlogloss:0.28099\tvalidation_1-mlogloss:0.51519\n",
      "[196]\tvalidation_0-mlogloss:0.27899\tvalidation_1-mlogloss:0.51321\n",
      "[197]\tvalidation_0-mlogloss:0.27694\tvalidation_1-mlogloss:0.51162\n",
      "[198]\tvalidation_0-mlogloss:0.27497\tvalidation_1-mlogloss:0.51010\n",
      "[199]\tvalidation_0-mlogloss:0.27288\tvalidation_1-mlogloss:0.50794\n",
      "[200]\tvalidation_0-mlogloss:0.27084\tvalidation_1-mlogloss:0.50659\n",
      "[201]\tvalidation_0-mlogloss:0.26891\tvalidation_1-mlogloss:0.50546\n",
      "[202]\tvalidation_0-mlogloss:0.26687\tvalidation_1-mlogloss:0.50367\n",
      "[203]\tvalidation_0-mlogloss:0.26480\tvalidation_1-mlogloss:0.50123\n",
      "[204]\tvalidation_0-mlogloss:0.26279\tvalidation_1-mlogloss:0.49932\n",
      "[205]\tvalidation_0-mlogloss:0.26078\tvalidation_1-mlogloss:0.49735\n",
      "[206]\tvalidation_0-mlogloss:0.25885\tvalidation_1-mlogloss:0.49616\n",
      "[207]\tvalidation_0-mlogloss:0.25708\tvalidation_1-mlogloss:0.49468\n",
      "[208]\tvalidation_0-mlogloss:0.25512\tvalidation_1-mlogloss:0.49291\n",
      "[209]\tvalidation_0-mlogloss:0.25322\tvalidation_1-mlogloss:0.49177\n",
      "[210]\tvalidation_0-mlogloss:0.25149\tvalidation_1-mlogloss:0.49069\n",
      "[211]\tvalidation_0-mlogloss:0.24968\tvalidation_1-mlogloss:0.48928\n",
      "[212]\tvalidation_0-mlogloss:0.24792\tvalidation_1-mlogloss:0.48747\n",
      "[213]\tvalidation_0-mlogloss:0.24610\tvalidation_1-mlogloss:0.48602\n",
      "[214]\tvalidation_0-mlogloss:0.24428\tvalidation_1-mlogloss:0.48414\n",
      "[215]\tvalidation_0-mlogloss:0.24251\tvalidation_1-mlogloss:0.48335\n",
      "[216]\tvalidation_0-mlogloss:0.24082\tvalidation_1-mlogloss:0.48223\n",
      "[217]\tvalidation_0-mlogloss:0.23905\tvalidation_1-mlogloss:0.48117\n",
      "[218]\tvalidation_0-mlogloss:0.23734\tvalidation_1-mlogloss:0.47967\n",
      "[219]\tvalidation_0-mlogloss:0.23555\tvalidation_1-mlogloss:0.47755\n",
      "[220]\tvalidation_0-mlogloss:0.23377\tvalidation_1-mlogloss:0.47539\n",
      "[221]\tvalidation_0-mlogloss:0.23215\tvalidation_1-mlogloss:0.47416\n",
      "[222]\tvalidation_0-mlogloss:0.23051\tvalidation_1-mlogloss:0.47278\n",
      "[223]\tvalidation_0-mlogloss:0.22893\tvalidation_1-mlogloss:0.47098\n",
      "[224]\tvalidation_0-mlogloss:0.22734\tvalidation_1-mlogloss:0.46984\n",
      "[225]\tvalidation_0-mlogloss:0.22579\tvalidation_1-mlogloss:0.46882\n",
      "[226]\tvalidation_0-mlogloss:0.22412\tvalidation_1-mlogloss:0.46741\n",
      "[227]\tvalidation_0-mlogloss:0.22257\tvalidation_1-mlogloss:0.46616\n",
      "[228]\tvalidation_0-mlogloss:0.22100\tvalidation_1-mlogloss:0.46512\n",
      "[229]\tvalidation_0-mlogloss:0.21940\tvalidation_1-mlogloss:0.46309\n",
      "[230]\tvalidation_0-mlogloss:0.21782\tvalidation_1-mlogloss:0.46195\n",
      "[231]\tvalidation_0-mlogloss:0.21627\tvalidation_1-mlogloss:0.46091\n",
      "[232]\tvalidation_0-mlogloss:0.21468\tvalidation_1-mlogloss:0.45926\n",
      "[233]\tvalidation_0-mlogloss:0.21325\tvalidation_1-mlogloss:0.45876\n",
      "[234]\tvalidation_0-mlogloss:0.21165\tvalidation_1-mlogloss:0.45708\n",
      "[235]\tvalidation_0-mlogloss:0.21017\tvalidation_1-mlogloss:0.45633\n",
      "[236]\tvalidation_0-mlogloss:0.20867\tvalidation_1-mlogloss:0.45504\n",
      "[237]\tvalidation_0-mlogloss:0.20718\tvalidation_1-mlogloss:0.45420\n",
      "[238]\tvalidation_0-mlogloss:0.20570\tvalidation_1-mlogloss:0.45276\n",
      "[239]\tvalidation_0-mlogloss:0.20430\tvalidation_1-mlogloss:0.45172\n",
      "[240]\tvalidation_0-mlogloss:0.20289\tvalidation_1-mlogloss:0.45089\n",
      "[241]\tvalidation_0-mlogloss:0.20148\tvalidation_1-mlogloss:0.45021\n",
      "[242]\tvalidation_0-mlogloss:0.20018\tvalidation_1-mlogloss:0.44935\n",
      "[243]\tvalidation_0-mlogloss:0.19876\tvalidation_1-mlogloss:0.44790\n",
      "[244]\tvalidation_0-mlogloss:0.19755\tvalidation_1-mlogloss:0.44695\n",
      "[245]\tvalidation_0-mlogloss:0.19637\tvalidation_1-mlogloss:0.44626\n",
      "[246]\tvalidation_0-mlogloss:0.19505\tvalidation_1-mlogloss:0.44565\n",
      "[247]\tvalidation_0-mlogloss:0.19372\tvalidation_1-mlogloss:0.44432\n",
      "[248]\tvalidation_0-mlogloss:0.19240\tvalidation_1-mlogloss:0.44307\n",
      "[249]\tvalidation_0-mlogloss:0.19102\tvalidation_1-mlogloss:0.44171\n",
      "[250]\tvalidation_0-mlogloss:0.18973\tvalidation_1-mlogloss:0.44063\n",
      "[251]\tvalidation_0-mlogloss:0.18845\tvalidation_1-mlogloss:0.43969\n",
      "[252]\tvalidation_0-mlogloss:0.18716\tvalidation_1-mlogloss:0.43861\n",
      "[253]\tvalidation_0-mlogloss:0.18599\tvalidation_1-mlogloss:0.43799\n",
      "[254]\tvalidation_0-mlogloss:0.18480\tvalidation_1-mlogloss:0.43716\n",
      "[255]\tvalidation_0-mlogloss:0.18352\tvalidation_1-mlogloss:0.43584\n",
      "[256]\tvalidation_0-mlogloss:0.18226\tvalidation_1-mlogloss:0.43468\n",
      "[257]\tvalidation_0-mlogloss:0.18109\tvalidation_1-mlogloss:0.43424\n",
      "[258]\tvalidation_0-mlogloss:0.17992\tvalidation_1-mlogloss:0.43352\n",
      "[259]\tvalidation_0-mlogloss:0.17868\tvalidation_1-mlogloss:0.43269\n",
      "[260]\tvalidation_0-mlogloss:0.17756\tvalidation_1-mlogloss:0.43206\n",
      "[261]\tvalidation_0-mlogloss:0.17640\tvalidation_1-mlogloss:0.43112\n",
      "[262]\tvalidation_0-mlogloss:0.17526\tvalidation_1-mlogloss:0.43028\n",
      "[263]\tvalidation_0-mlogloss:0.17413\tvalidation_1-mlogloss:0.42963\n",
      "[264]\tvalidation_0-mlogloss:0.17311\tvalidation_1-mlogloss:0.42925\n",
      "[265]\tvalidation_0-mlogloss:0.17201\tvalidation_1-mlogloss:0.42864\n",
      "[266]\tvalidation_0-mlogloss:0.17088\tvalidation_1-mlogloss:0.42757\n",
      "[267]\tvalidation_0-mlogloss:0.16971\tvalidation_1-mlogloss:0.42639\n",
      "[268]\tvalidation_0-mlogloss:0.16860\tvalidation_1-mlogloss:0.42514\n",
      "[269]\tvalidation_0-mlogloss:0.16753\tvalidation_1-mlogloss:0.42431\n",
      "[270]\tvalidation_0-mlogloss:0.16640\tvalidation_1-mlogloss:0.42310\n",
      "[271]\tvalidation_0-mlogloss:0.16536\tvalidation_1-mlogloss:0.42244\n",
      "[272]\tvalidation_0-mlogloss:0.16427\tvalidation_1-mlogloss:0.42130\n",
      "[273]\tvalidation_0-mlogloss:0.16321\tvalidation_1-mlogloss:0.42019\n",
      "[274]\tvalidation_0-mlogloss:0.16215\tvalidation_1-mlogloss:0.41957\n",
      "[275]\tvalidation_0-mlogloss:0.16106\tvalidation_1-mlogloss:0.41833\n",
      "[276]\tvalidation_0-mlogloss:0.16016\tvalidation_1-mlogloss:0.41686\n",
      "[277]\tvalidation_0-mlogloss:0.15909\tvalidation_1-mlogloss:0.41622\n",
      "[278]\tvalidation_0-mlogloss:0.15813\tvalidation_1-mlogloss:0.41567\n",
      "[279]\tvalidation_0-mlogloss:0.15705\tvalidation_1-mlogloss:0.41486\n",
      "[280]\tvalidation_0-mlogloss:0.15607\tvalidation_1-mlogloss:0.41454\n",
      "[281]\tvalidation_0-mlogloss:0.15507\tvalidation_1-mlogloss:0.41342\n",
      "[282]\tvalidation_0-mlogloss:0.15408\tvalidation_1-mlogloss:0.41309\n",
      "[283]\tvalidation_0-mlogloss:0.15319\tvalidation_1-mlogloss:0.41254\n",
      "[284]\tvalidation_0-mlogloss:0.15225\tvalidation_1-mlogloss:0.41163\n",
      "[285]\tvalidation_0-mlogloss:0.15137\tvalidation_1-mlogloss:0.41106\n",
      "[286]\tvalidation_0-mlogloss:0.15048\tvalidation_1-mlogloss:0.41069\n",
      "[287]\tvalidation_0-mlogloss:0.14951\tvalidation_1-mlogloss:0.40963\n",
      "[288]\tvalidation_0-mlogloss:0.14853\tvalidation_1-mlogloss:0.40880\n",
      "[289]\tvalidation_0-mlogloss:0.14759\tvalidation_1-mlogloss:0.40826\n",
      "[290]\tvalidation_0-mlogloss:0.14670\tvalidation_1-mlogloss:0.40769\n",
      "[291]\tvalidation_0-mlogloss:0.14577\tvalidation_1-mlogloss:0.40680\n",
      "[292]\tvalidation_0-mlogloss:0.14486\tvalidation_1-mlogloss:0.40602\n",
      "[293]\tvalidation_0-mlogloss:0.14400\tvalidation_1-mlogloss:0.40563\n",
      "[294]\tvalidation_0-mlogloss:0.14323\tvalidation_1-mlogloss:0.40466\n",
      "[295]\tvalidation_0-mlogloss:0.14232\tvalidation_1-mlogloss:0.40357\n",
      "[296]\tvalidation_0-mlogloss:0.14144\tvalidation_1-mlogloss:0.40327\n",
      "[297]\tvalidation_0-mlogloss:0.14055\tvalidation_1-mlogloss:0.40241\n",
      "[298]\tvalidation_0-mlogloss:0.13969\tvalidation_1-mlogloss:0.40163\n",
      "[299]\tvalidation_0-mlogloss:0.13882\tvalidation_1-mlogloss:0.40069\n",
      "[300]\tvalidation_0-mlogloss:0.13797\tvalidation_1-mlogloss:0.40004\n",
      "[301]\tvalidation_0-mlogloss:0.13717\tvalidation_1-mlogloss:0.39956\n",
      "[302]\tvalidation_0-mlogloss:0.13632\tvalidation_1-mlogloss:0.39873\n",
      "[303]\tvalidation_0-mlogloss:0.13545\tvalidation_1-mlogloss:0.39772\n",
      "[304]\tvalidation_0-mlogloss:0.13463\tvalidation_1-mlogloss:0.39709\n",
      "[305]\tvalidation_0-mlogloss:0.13382\tvalidation_1-mlogloss:0.39683\n",
      "[306]\tvalidation_0-mlogloss:0.13298\tvalidation_1-mlogloss:0.39624\n",
      "[307]\tvalidation_0-mlogloss:0.13215\tvalidation_1-mlogloss:0.39581\n",
      "[308]\tvalidation_0-mlogloss:0.13135\tvalidation_1-mlogloss:0.39529\n",
      "[309]\tvalidation_0-mlogloss:0.13056\tvalidation_1-mlogloss:0.39480\n",
      "[310]\tvalidation_0-mlogloss:0.12977\tvalidation_1-mlogloss:0.39421\n",
      "[311]\tvalidation_0-mlogloss:0.12904\tvalidation_1-mlogloss:0.39387\n",
      "[312]\tvalidation_0-mlogloss:0.12825\tvalidation_1-mlogloss:0.39320\n",
      "[313]\tvalidation_0-mlogloss:0.12751\tvalidation_1-mlogloss:0.39282\n",
      "[314]\tvalidation_0-mlogloss:0.12676\tvalidation_1-mlogloss:0.39195\n",
      "[315]\tvalidation_0-mlogloss:0.12603\tvalidation_1-mlogloss:0.39133\n",
      "[316]\tvalidation_0-mlogloss:0.12531\tvalidation_1-mlogloss:0.39113\n",
      "[317]\tvalidation_0-mlogloss:0.12457\tvalidation_1-mlogloss:0.39077\n",
      "[318]\tvalidation_0-mlogloss:0.12386\tvalidation_1-mlogloss:0.39032\n",
      "[319]\tvalidation_0-mlogloss:0.12310\tvalidation_1-mlogloss:0.38949\n",
      "[320]\tvalidation_0-mlogloss:0.12244\tvalidation_1-mlogloss:0.38871\n",
      "[321]\tvalidation_0-mlogloss:0.12174\tvalidation_1-mlogloss:0.38848\n",
      "[322]\tvalidation_0-mlogloss:0.12103\tvalidation_1-mlogloss:0.38770\n",
      "[323]\tvalidation_0-mlogloss:0.12029\tvalidation_1-mlogloss:0.38732\n",
      "[324]\tvalidation_0-mlogloss:0.11959\tvalidation_1-mlogloss:0.38710\n",
      "[325]\tvalidation_0-mlogloss:0.11893\tvalidation_1-mlogloss:0.38676\n",
      "[326]\tvalidation_0-mlogloss:0.11834\tvalidation_1-mlogloss:0.38644\n",
      "[327]\tvalidation_0-mlogloss:0.11768\tvalidation_1-mlogloss:0.38638\n",
      "[328]\tvalidation_0-mlogloss:0.11709\tvalidation_1-mlogloss:0.38603\n",
      "[329]\tvalidation_0-mlogloss:0.11650\tvalidation_1-mlogloss:0.38580\n",
      "[330]\tvalidation_0-mlogloss:0.11581\tvalidation_1-mlogloss:0.38493\n",
      "[331]\tvalidation_0-mlogloss:0.11516\tvalidation_1-mlogloss:0.38476\n",
      "[332]\tvalidation_0-mlogloss:0.11453\tvalidation_1-mlogloss:0.38404\n",
      "[333]\tvalidation_0-mlogloss:0.11390\tvalidation_1-mlogloss:0.38343\n",
      "[334]\tvalidation_0-mlogloss:0.11331\tvalidation_1-mlogloss:0.38314\n",
      "[335]\tvalidation_0-mlogloss:0.11266\tvalidation_1-mlogloss:0.38254\n",
      "[336]\tvalidation_0-mlogloss:0.11212\tvalidation_1-mlogloss:0.38246\n",
      "[337]\tvalidation_0-mlogloss:0.11145\tvalidation_1-mlogloss:0.38199\n",
      "[338]\tvalidation_0-mlogloss:0.11088\tvalidation_1-mlogloss:0.38128\n",
      "[339]\tvalidation_0-mlogloss:0.11028\tvalidation_1-mlogloss:0.38084\n",
      "[340]\tvalidation_0-mlogloss:0.10965\tvalidation_1-mlogloss:0.38037\n",
      "[341]\tvalidation_0-mlogloss:0.10909\tvalidation_1-mlogloss:0.38004\n",
      "[342]\tvalidation_0-mlogloss:0.10855\tvalidation_1-mlogloss:0.37969\n",
      "[343]\tvalidation_0-mlogloss:0.10795\tvalidation_1-mlogloss:0.37909\n",
      "[344]\tvalidation_0-mlogloss:0.10738\tvalidation_1-mlogloss:0.37876\n",
      "[345]\tvalidation_0-mlogloss:0.10686\tvalidation_1-mlogloss:0.37854\n",
      "[346]\tvalidation_0-mlogloss:0.10630\tvalidation_1-mlogloss:0.37793\n",
      "[347]\tvalidation_0-mlogloss:0.10573\tvalidation_1-mlogloss:0.37751\n",
      "[348]\tvalidation_0-mlogloss:0.10516\tvalidation_1-mlogloss:0.37753\n",
      "[349]\tvalidation_0-mlogloss:0.10461\tvalidation_1-mlogloss:0.37704\n",
      "[350]\tvalidation_0-mlogloss:0.10405\tvalidation_1-mlogloss:0.37687\n",
      "[351]\tvalidation_0-mlogloss:0.10348\tvalidation_1-mlogloss:0.37676\n",
      "[352]\tvalidation_0-mlogloss:0.10290\tvalidation_1-mlogloss:0.37636\n",
      "[353]\tvalidation_0-mlogloss:0.10238\tvalidation_1-mlogloss:0.37590\n",
      "[354]\tvalidation_0-mlogloss:0.10182\tvalidation_1-mlogloss:0.37530\n",
      "[355]\tvalidation_0-mlogloss:0.10126\tvalidation_1-mlogloss:0.37488\n",
      "[356]\tvalidation_0-mlogloss:0.10072\tvalidation_1-mlogloss:0.37460\n",
      "[357]\tvalidation_0-mlogloss:0.10023\tvalidation_1-mlogloss:0.37447\n",
      "[358]\tvalidation_0-mlogloss:0.09971\tvalidation_1-mlogloss:0.37414\n",
      "[359]\tvalidation_0-mlogloss:0.09920\tvalidation_1-mlogloss:0.37420\n",
      "[360]\tvalidation_0-mlogloss:0.09869\tvalidation_1-mlogloss:0.37357\n",
      "[361]\tvalidation_0-mlogloss:0.09814\tvalidation_1-mlogloss:0.37326\n",
      "[362]\tvalidation_0-mlogloss:0.09762\tvalidation_1-mlogloss:0.37302\n",
      "[363]\tvalidation_0-mlogloss:0.09715\tvalidation_1-mlogloss:0.37232\n",
      "[364]\tvalidation_0-mlogloss:0.09665\tvalidation_1-mlogloss:0.37220\n",
      "[365]\tvalidation_0-mlogloss:0.09613\tvalidation_1-mlogloss:0.37202\n",
      "[366]\tvalidation_0-mlogloss:0.09561\tvalidation_1-mlogloss:0.37161\n",
      "[367]\tvalidation_0-mlogloss:0.09515\tvalidation_1-mlogloss:0.37129\n",
      "[368]\tvalidation_0-mlogloss:0.09472\tvalidation_1-mlogloss:0.37127\n",
      "[369]\tvalidation_0-mlogloss:0.09424\tvalidation_1-mlogloss:0.37137\n",
      "[370]\tvalidation_0-mlogloss:0.09377\tvalidation_1-mlogloss:0.37106\n",
      "[371]\tvalidation_0-mlogloss:0.09332\tvalidation_1-mlogloss:0.37100\n",
      "[372]\tvalidation_0-mlogloss:0.09282\tvalidation_1-mlogloss:0.37074\n",
      "[373]\tvalidation_0-mlogloss:0.09234\tvalidation_1-mlogloss:0.37031\n",
      "[374]\tvalidation_0-mlogloss:0.09183\tvalidation_1-mlogloss:0.37013\n",
      "[375]\tvalidation_0-mlogloss:0.09140\tvalidation_1-mlogloss:0.36984\n",
      "[376]\tvalidation_0-mlogloss:0.09094\tvalidation_1-mlogloss:0.36948\n",
      "[377]\tvalidation_0-mlogloss:0.09049\tvalidation_1-mlogloss:0.36933\n",
      "[378]\tvalidation_0-mlogloss:0.09003\tvalidation_1-mlogloss:0.36886\n",
      "[379]\tvalidation_0-mlogloss:0.08959\tvalidation_1-mlogloss:0.36847\n",
      "[380]\tvalidation_0-mlogloss:0.08915\tvalidation_1-mlogloss:0.36831\n",
      "[381]\tvalidation_0-mlogloss:0.08868\tvalidation_1-mlogloss:0.36777\n",
      "[382]\tvalidation_0-mlogloss:0.08823\tvalidation_1-mlogloss:0.36743\n",
      "[383]\tvalidation_0-mlogloss:0.08779\tvalidation_1-mlogloss:0.36715\n",
      "[384]\tvalidation_0-mlogloss:0.08735\tvalidation_1-mlogloss:0.36724\n",
      "[385]\tvalidation_0-mlogloss:0.08695\tvalidation_1-mlogloss:0.36710\n",
      "[386]\tvalidation_0-mlogloss:0.08650\tvalidation_1-mlogloss:0.36680\n",
      "[387]\tvalidation_0-mlogloss:0.08610\tvalidation_1-mlogloss:0.36683\n",
      "[388]\tvalidation_0-mlogloss:0.08570\tvalidation_1-mlogloss:0.36680\n",
      "[389]\tvalidation_0-mlogloss:0.08529\tvalidation_1-mlogloss:0.36654\n",
      "[390]\tvalidation_0-mlogloss:0.08489\tvalidation_1-mlogloss:0.36611\n",
      "[391]\tvalidation_0-mlogloss:0.08446\tvalidation_1-mlogloss:0.36578\n",
      "[392]\tvalidation_0-mlogloss:0.08405\tvalidation_1-mlogloss:0.36539\n",
      "[393]\tvalidation_0-mlogloss:0.08367\tvalidation_1-mlogloss:0.36525\n",
      "[394]\tvalidation_0-mlogloss:0.08331\tvalidation_1-mlogloss:0.36476\n",
      "[395]\tvalidation_0-mlogloss:0.08291\tvalidation_1-mlogloss:0.36429\n",
      "[396]\tvalidation_0-mlogloss:0.08250\tvalidation_1-mlogloss:0.36387\n",
      "[397]\tvalidation_0-mlogloss:0.08214\tvalidation_1-mlogloss:0.36344\n",
      "[398]\tvalidation_0-mlogloss:0.08176\tvalidation_1-mlogloss:0.36329\n",
      "[399]\tvalidation_0-mlogloss:0.08139\tvalidation_1-mlogloss:0.36313\n",
      "[400]\tvalidation_0-mlogloss:0.08103\tvalidation_1-mlogloss:0.36322\n",
      "[401]\tvalidation_0-mlogloss:0.08069\tvalidation_1-mlogloss:0.36285\n",
      "[402]\tvalidation_0-mlogloss:0.08030\tvalidation_1-mlogloss:0.36285\n",
      "[403]\tvalidation_0-mlogloss:0.07992\tvalidation_1-mlogloss:0.36290\n",
      "[404]\tvalidation_0-mlogloss:0.07953\tvalidation_1-mlogloss:0.36261\n",
      "[405]\tvalidation_0-mlogloss:0.07915\tvalidation_1-mlogloss:0.36242\n",
      "[406]\tvalidation_0-mlogloss:0.07878\tvalidation_1-mlogloss:0.36192\n",
      "[407]\tvalidation_0-mlogloss:0.07840\tvalidation_1-mlogloss:0.36183\n",
      "[408]\tvalidation_0-mlogloss:0.07805\tvalidation_1-mlogloss:0.36155\n",
      "[409]\tvalidation_0-mlogloss:0.07770\tvalidation_1-mlogloss:0.36116\n",
      "[410]\tvalidation_0-mlogloss:0.07744\tvalidation_1-mlogloss:0.36116\n",
      "[411]\tvalidation_0-mlogloss:0.07712\tvalidation_1-mlogloss:0.36081\n",
      "[412]\tvalidation_0-mlogloss:0.07673\tvalidation_1-mlogloss:0.36058\n",
      "[413]\tvalidation_0-mlogloss:0.07644\tvalidation_1-mlogloss:0.36049\n",
      "[414]\tvalidation_0-mlogloss:0.07614\tvalidation_1-mlogloss:0.36054\n",
      "[415]\tvalidation_0-mlogloss:0.07580\tvalidation_1-mlogloss:0.36006\n",
      "[416]\tvalidation_0-mlogloss:0.07547\tvalidation_1-mlogloss:0.35995\n",
      "[417]\tvalidation_0-mlogloss:0.07514\tvalidation_1-mlogloss:0.36005\n",
      "[418]\tvalidation_0-mlogloss:0.07482\tvalidation_1-mlogloss:0.35971\n",
      "[419]\tvalidation_0-mlogloss:0.07452\tvalidation_1-mlogloss:0.35985\n",
      "[420]\tvalidation_0-mlogloss:0.07424\tvalidation_1-mlogloss:0.35976\n",
      "[421]\tvalidation_0-mlogloss:0.07393\tvalidation_1-mlogloss:0.35966\n",
      "[422]\tvalidation_0-mlogloss:0.07358\tvalidation_1-mlogloss:0.35942\n",
      "[423]\tvalidation_0-mlogloss:0.07326\tvalidation_1-mlogloss:0.35915\n",
      "[424]\tvalidation_0-mlogloss:0.07291\tvalidation_1-mlogloss:0.35909\n",
      "[425]\tvalidation_0-mlogloss:0.07258\tvalidation_1-mlogloss:0.35879\n",
      "[426]\tvalidation_0-mlogloss:0.07227\tvalidation_1-mlogloss:0.35853\n",
      "[427]\tvalidation_0-mlogloss:0.07200\tvalidation_1-mlogloss:0.35845\n",
      "[428]\tvalidation_0-mlogloss:0.07172\tvalidation_1-mlogloss:0.35844\n",
      "[429]\tvalidation_0-mlogloss:0.07143\tvalidation_1-mlogloss:0.35850\n",
      "[430]\tvalidation_0-mlogloss:0.07113\tvalidation_1-mlogloss:0.35846\n",
      "[431]\tvalidation_0-mlogloss:0.07083\tvalidation_1-mlogloss:0.35851\n",
      "[432]\tvalidation_0-mlogloss:0.07056\tvalidation_1-mlogloss:0.35871\n",
      "[433]\tvalidation_0-mlogloss:0.07025\tvalidation_1-mlogloss:0.35842\n",
      "[434]\tvalidation_0-mlogloss:0.07002\tvalidation_1-mlogloss:0.35836\n",
      "[435]\tvalidation_0-mlogloss:0.06973\tvalidation_1-mlogloss:0.35815\n",
      "[436]\tvalidation_0-mlogloss:0.06947\tvalidation_1-mlogloss:0.35782\n",
      "[437]\tvalidation_0-mlogloss:0.06916\tvalidation_1-mlogloss:0.35772\n",
      "[438]\tvalidation_0-mlogloss:0.06896\tvalidation_1-mlogloss:0.35762\n",
      "[439]\tvalidation_0-mlogloss:0.06865\tvalidation_1-mlogloss:0.35738\n",
      "[440]\tvalidation_0-mlogloss:0.06839\tvalidation_1-mlogloss:0.35732\n",
      "[441]\tvalidation_0-mlogloss:0.06811\tvalidation_1-mlogloss:0.35711\n",
      "[442]\tvalidation_0-mlogloss:0.06781\tvalidation_1-mlogloss:0.35638\n",
      "[443]\tvalidation_0-mlogloss:0.06755\tvalidation_1-mlogloss:0.35638\n",
      "[444]\tvalidation_0-mlogloss:0.06729\tvalidation_1-mlogloss:0.35597\n",
      "[445]\tvalidation_0-mlogloss:0.06701\tvalidation_1-mlogloss:0.35555\n",
      "[446]\tvalidation_0-mlogloss:0.06675\tvalidation_1-mlogloss:0.35528\n",
      "[447]\tvalidation_0-mlogloss:0.06650\tvalidation_1-mlogloss:0.35515\n",
      "[448]\tvalidation_0-mlogloss:0.06628\tvalidation_1-mlogloss:0.35518\n",
      "[449]\tvalidation_0-mlogloss:0.06600\tvalidation_1-mlogloss:0.35520\n",
      "[450]\tvalidation_0-mlogloss:0.06573\tvalidation_1-mlogloss:0.35479\n",
      "[451]\tvalidation_0-mlogloss:0.06548\tvalidation_1-mlogloss:0.35451\n",
      "[452]\tvalidation_0-mlogloss:0.06528\tvalidation_1-mlogloss:0.35464\n",
      "[453]\tvalidation_0-mlogloss:0.06511\tvalidation_1-mlogloss:0.35423\n",
      "[454]\tvalidation_0-mlogloss:0.06486\tvalidation_1-mlogloss:0.35395\n",
      "[455]\tvalidation_0-mlogloss:0.06466\tvalidation_1-mlogloss:0.35414\n",
      "[456]\tvalidation_0-mlogloss:0.06440\tvalidation_1-mlogloss:0.35421\n",
      "[457]\tvalidation_0-mlogloss:0.06422\tvalidation_1-mlogloss:0.35405\n",
      "[458]\tvalidation_0-mlogloss:0.06399\tvalidation_1-mlogloss:0.35397\n",
      "[459]\tvalidation_0-mlogloss:0.06375\tvalidation_1-mlogloss:0.35349\n",
      "[460]\tvalidation_0-mlogloss:0.06351\tvalidation_1-mlogloss:0.35319\n",
      "[461]\tvalidation_0-mlogloss:0.06332\tvalidation_1-mlogloss:0.35318\n",
      "[462]\tvalidation_0-mlogloss:0.06314\tvalidation_1-mlogloss:0.35338\n",
      "[463]\tvalidation_0-mlogloss:0.06288\tvalidation_1-mlogloss:0.35343\n",
      "[464]\tvalidation_0-mlogloss:0.06268\tvalidation_1-mlogloss:0.35337\n",
      "[465]\tvalidation_0-mlogloss:0.06247\tvalidation_1-mlogloss:0.35330\n",
      "[466]\tvalidation_0-mlogloss:0.06229\tvalidation_1-mlogloss:0.35311\n",
      "[467]\tvalidation_0-mlogloss:0.06208\tvalidation_1-mlogloss:0.35290\n",
      "[468]\tvalidation_0-mlogloss:0.06186\tvalidation_1-mlogloss:0.35250\n",
      "[469]\tvalidation_0-mlogloss:0.06159\tvalidation_1-mlogloss:0.35227\n",
      "[470]\tvalidation_0-mlogloss:0.06133\tvalidation_1-mlogloss:0.35198\n",
      "[471]\tvalidation_0-mlogloss:0.06113\tvalidation_1-mlogloss:0.35209\n",
      "[472]\tvalidation_0-mlogloss:0.06090\tvalidation_1-mlogloss:0.35185\n",
      "[473]\tvalidation_0-mlogloss:0.06066\tvalidation_1-mlogloss:0.35172\n",
      "[474]\tvalidation_0-mlogloss:0.06048\tvalidation_1-mlogloss:0.35133\n",
      "[475]\tvalidation_0-mlogloss:0.06029\tvalidation_1-mlogloss:0.35115\n",
      "[476]\tvalidation_0-mlogloss:0.06016\tvalidation_1-mlogloss:0.35105\n",
      "[477]\tvalidation_0-mlogloss:0.05996\tvalidation_1-mlogloss:0.35059\n",
      "[478]\tvalidation_0-mlogloss:0.05976\tvalidation_1-mlogloss:0.35059\n",
      "[479]\tvalidation_0-mlogloss:0.05955\tvalidation_1-mlogloss:0.35038\n",
      "[480]\tvalidation_0-mlogloss:0.05938\tvalidation_1-mlogloss:0.34992\n",
      "[481]\tvalidation_0-mlogloss:0.05915\tvalidation_1-mlogloss:0.34969\n",
      "[482]\tvalidation_0-mlogloss:0.05901\tvalidation_1-mlogloss:0.34957\n",
      "[483]\tvalidation_0-mlogloss:0.05884\tvalidation_1-mlogloss:0.34940\n",
      "[484]\tvalidation_0-mlogloss:0.05871\tvalidation_1-mlogloss:0.34945\n",
      "[485]\tvalidation_0-mlogloss:0.05857\tvalidation_1-mlogloss:0.34936\n",
      "[486]\tvalidation_0-mlogloss:0.05838\tvalidation_1-mlogloss:0.34921\n",
      "[487]\tvalidation_0-mlogloss:0.05820\tvalidation_1-mlogloss:0.34909\n",
      "[488]\tvalidation_0-mlogloss:0.05804\tvalidation_1-mlogloss:0.34924\n",
      "[489]\tvalidation_0-mlogloss:0.05787\tvalidation_1-mlogloss:0.34924\n",
      "[490]\tvalidation_0-mlogloss:0.05773\tvalidation_1-mlogloss:0.34911\n",
      "[491]\tvalidation_0-mlogloss:0.05759\tvalidation_1-mlogloss:0.34895\n",
      "[492]\tvalidation_0-mlogloss:0.05739\tvalidation_1-mlogloss:0.34865\n",
      "[493]\tvalidation_0-mlogloss:0.05723\tvalidation_1-mlogloss:0.34857\n",
      "[494]\tvalidation_0-mlogloss:0.05708\tvalidation_1-mlogloss:0.34859\n",
      "[495]\tvalidation_0-mlogloss:0.05690\tvalidation_1-mlogloss:0.34801\n",
      "[496]\tvalidation_0-mlogloss:0.05672\tvalidation_1-mlogloss:0.34790\n",
      "[497]\tvalidation_0-mlogloss:0.05656\tvalidation_1-mlogloss:0.34750\n",
      "[498]\tvalidation_0-mlogloss:0.05639\tvalidation_1-mlogloss:0.34732\n",
      "[499]\tvalidation_0-mlogloss:0.05621\tvalidation_1-mlogloss:0.34731\n",
      "[500]\tvalidation_0-mlogloss:0.05611\tvalidation_1-mlogloss:0.34709\n",
      "[501]\tvalidation_0-mlogloss:0.05595\tvalidation_1-mlogloss:0.34718\n",
      "[502]\tvalidation_0-mlogloss:0.05580\tvalidation_1-mlogloss:0.34708\n",
      "[503]\tvalidation_0-mlogloss:0.05568\tvalidation_1-mlogloss:0.34730\n",
      "[504]\tvalidation_0-mlogloss:0.05557\tvalidation_1-mlogloss:0.34724\n",
      "[505]\tvalidation_0-mlogloss:0.05545\tvalidation_1-mlogloss:0.34693\n",
      "[506]\tvalidation_0-mlogloss:0.05534\tvalidation_1-mlogloss:0.34681\n",
      "[507]\tvalidation_0-mlogloss:0.05524\tvalidation_1-mlogloss:0.34679\n",
      "[508]\tvalidation_0-mlogloss:0.05506\tvalidation_1-mlogloss:0.34694\n",
      "[509]\tvalidation_0-mlogloss:0.05494\tvalidation_1-mlogloss:0.34690\n",
      "[510]\tvalidation_0-mlogloss:0.05479\tvalidation_1-mlogloss:0.34679\n",
      "[511]\tvalidation_0-mlogloss:0.05469\tvalidation_1-mlogloss:0.34646\n",
      "[512]\tvalidation_0-mlogloss:0.05451\tvalidation_1-mlogloss:0.34626\n",
      "[513]\tvalidation_0-mlogloss:0.05439\tvalidation_1-mlogloss:0.34631\n",
      "[514]\tvalidation_0-mlogloss:0.05429\tvalidation_1-mlogloss:0.34618\n",
      "[515]\tvalidation_0-mlogloss:0.05418\tvalidation_1-mlogloss:0.34593\n",
      "[516]\tvalidation_0-mlogloss:0.05400\tvalidation_1-mlogloss:0.34599\n",
      "[517]\tvalidation_0-mlogloss:0.05390\tvalidation_1-mlogloss:0.34586\n",
      "[518]\tvalidation_0-mlogloss:0.05382\tvalidation_1-mlogloss:0.34579\n",
      "[519]\tvalidation_0-mlogloss:0.05373\tvalidation_1-mlogloss:0.34588\n",
      "[520]\tvalidation_0-mlogloss:0.05363\tvalidation_1-mlogloss:0.34572\n",
      "[521]\tvalidation_0-mlogloss:0.05348\tvalidation_1-mlogloss:0.34560\n",
      "[522]\tvalidation_0-mlogloss:0.05342\tvalidation_1-mlogloss:0.34557\n",
      "[523]\tvalidation_0-mlogloss:0.05332\tvalidation_1-mlogloss:0.34549\n",
      "[524]\tvalidation_0-mlogloss:0.05322\tvalidation_1-mlogloss:0.34563\n",
      "[525]\tvalidation_0-mlogloss:0.05315\tvalidation_1-mlogloss:0.34555\n",
      "[526]\tvalidation_0-mlogloss:0.05303\tvalidation_1-mlogloss:0.34507\n",
      "[527]\tvalidation_0-mlogloss:0.05288\tvalidation_1-mlogloss:0.34499\n",
      "[528]\tvalidation_0-mlogloss:0.05277\tvalidation_1-mlogloss:0.34472\n",
      "[529]\tvalidation_0-mlogloss:0.05268\tvalidation_1-mlogloss:0.34450\n",
      "[530]\tvalidation_0-mlogloss:0.05253\tvalidation_1-mlogloss:0.34407\n",
      "[531]\tvalidation_0-mlogloss:0.05243\tvalidation_1-mlogloss:0.34395\n",
      "[532]\tvalidation_0-mlogloss:0.05238\tvalidation_1-mlogloss:0.34408\n",
      "[533]\tvalidation_0-mlogloss:0.05223\tvalidation_1-mlogloss:0.34385\n",
      "[534]\tvalidation_0-mlogloss:0.05214\tvalidation_1-mlogloss:0.34363\n",
      "[535]\tvalidation_0-mlogloss:0.05207\tvalidation_1-mlogloss:0.34344\n",
      "[536]\tvalidation_0-mlogloss:0.05197\tvalidation_1-mlogloss:0.34346\n",
      "[537]\tvalidation_0-mlogloss:0.05191\tvalidation_1-mlogloss:0.34347\n",
      "[538]\tvalidation_0-mlogloss:0.05182\tvalidation_1-mlogloss:0.34331\n",
      "[539]\tvalidation_0-mlogloss:0.05172\tvalidation_1-mlogloss:0.34305\n",
      "[540]\tvalidation_0-mlogloss:0.05169\tvalidation_1-mlogloss:0.34290\n",
      "[541]\tvalidation_0-mlogloss:0.05161\tvalidation_1-mlogloss:0.34268\n",
      "[542]\tvalidation_0-mlogloss:0.05152\tvalidation_1-mlogloss:0.34250\n",
      "[543]\tvalidation_0-mlogloss:0.05143\tvalidation_1-mlogloss:0.34239\n",
      "[544]\tvalidation_0-mlogloss:0.05133\tvalidation_1-mlogloss:0.34204\n",
      "[545]\tvalidation_0-mlogloss:0.05127\tvalidation_1-mlogloss:0.34187\n",
      "[546]\tvalidation_0-mlogloss:0.05115\tvalidation_1-mlogloss:0.34161\n",
      "[547]\tvalidation_0-mlogloss:0.05107\tvalidation_1-mlogloss:0.34148\n",
      "[548]\tvalidation_0-mlogloss:0.05098\tvalidation_1-mlogloss:0.34135\n",
      "[549]\tvalidation_0-mlogloss:0.05089\tvalidation_1-mlogloss:0.34110\n",
      "[550]\tvalidation_0-mlogloss:0.05080\tvalidation_1-mlogloss:0.34073\n",
      "[551]\tvalidation_0-mlogloss:0.05075\tvalidation_1-mlogloss:0.34068\n",
      "[552]\tvalidation_0-mlogloss:0.05071\tvalidation_1-mlogloss:0.34078\n",
      "[553]\tvalidation_0-mlogloss:0.05066\tvalidation_1-mlogloss:0.34060\n",
      "[554]\tvalidation_0-mlogloss:0.05061\tvalidation_1-mlogloss:0.34061\n",
      "[555]\tvalidation_0-mlogloss:0.05056\tvalidation_1-mlogloss:0.34078\n",
      "[556]\tvalidation_0-mlogloss:0.05053\tvalidation_1-mlogloss:0.34087\n",
      "[557]\tvalidation_0-mlogloss:0.05044\tvalidation_1-mlogloss:0.34077\n",
      "[558]\tvalidation_0-mlogloss:0.05039\tvalidation_1-mlogloss:0.34072\n",
      "[559]\tvalidation_0-mlogloss:0.05032\tvalidation_1-mlogloss:0.34041\n",
      "[560]\tvalidation_0-mlogloss:0.05027\tvalidation_1-mlogloss:0.34036\n",
      "[561]\tvalidation_0-mlogloss:0.05020\tvalidation_1-mlogloss:0.34029\n",
      "[562]\tvalidation_0-mlogloss:0.05011\tvalidation_1-mlogloss:0.34008\n",
      "[563]\tvalidation_0-mlogloss:0.05006\tvalidation_1-mlogloss:0.34004\n",
      "[564]\tvalidation_0-mlogloss:0.04999\tvalidation_1-mlogloss:0.34006\n",
      "[565]\tvalidation_0-mlogloss:0.04991\tvalidation_1-mlogloss:0.34003\n",
      "[566]\tvalidation_0-mlogloss:0.04989\tvalidation_1-mlogloss:0.34014\n",
      "[567]\tvalidation_0-mlogloss:0.04981\tvalidation_1-mlogloss:0.34009\n",
      "[568]\tvalidation_0-mlogloss:0.04976\tvalidation_1-mlogloss:0.33991\n",
      "[569]\tvalidation_0-mlogloss:0.04970\tvalidation_1-mlogloss:0.34014\n",
      "[570]\tvalidation_0-mlogloss:0.04964\tvalidation_1-mlogloss:0.33988\n",
      "[571]\tvalidation_0-mlogloss:0.04961\tvalidation_1-mlogloss:0.34001\n",
      "[572]\tvalidation_0-mlogloss:0.04956\tvalidation_1-mlogloss:0.33992\n",
      "[573]\tvalidation_0-mlogloss:0.04951\tvalidation_1-mlogloss:0.33985\n",
      "[574]\tvalidation_0-mlogloss:0.04942\tvalidation_1-mlogloss:0.33985\n",
      "[575]\tvalidation_0-mlogloss:0.04940\tvalidation_1-mlogloss:0.33996\n",
      "[576]\tvalidation_0-mlogloss:0.04936\tvalidation_1-mlogloss:0.33994\n",
      "[577]\tvalidation_0-mlogloss:0.04930\tvalidation_1-mlogloss:0.34003\n",
      "[578]\tvalidation_0-mlogloss:0.04922\tvalidation_1-mlogloss:0.34006\n",
      "[579]\tvalidation_0-mlogloss:0.04916\tvalidation_1-mlogloss:0.33982\n",
      "[580]\tvalidation_0-mlogloss:0.04909\tvalidation_1-mlogloss:0.33977\n",
      "[581]\tvalidation_0-mlogloss:0.04906\tvalidation_1-mlogloss:0.33964\n",
      "[582]\tvalidation_0-mlogloss:0.04902\tvalidation_1-mlogloss:0.33979\n",
      "[583]\tvalidation_0-mlogloss:0.04897\tvalidation_1-mlogloss:0.33975\n",
      "[584]\tvalidation_0-mlogloss:0.04895\tvalidation_1-mlogloss:0.33962\n",
      "[585]\tvalidation_0-mlogloss:0.04890\tvalidation_1-mlogloss:0.33984\n",
      "[586]\tvalidation_0-mlogloss:0.04884\tvalidation_1-mlogloss:0.33983\n",
      "[587]\tvalidation_0-mlogloss:0.04877\tvalidation_1-mlogloss:0.33984\n",
      "[588]\tvalidation_0-mlogloss:0.04875\tvalidation_1-mlogloss:0.33987\n",
      "[589]\tvalidation_0-mlogloss:0.04869\tvalidation_1-mlogloss:0.33976\n",
      "[590]\tvalidation_0-mlogloss:0.04865\tvalidation_1-mlogloss:0.33958\n",
      "[591]\tvalidation_0-mlogloss:0.04857\tvalidation_1-mlogloss:0.33938\n",
      "[592]\tvalidation_0-mlogloss:0.04849\tvalidation_1-mlogloss:0.33905\n",
      "[593]\tvalidation_0-mlogloss:0.04839\tvalidation_1-mlogloss:0.33883\n",
      "[594]\tvalidation_0-mlogloss:0.04833\tvalidation_1-mlogloss:0.33902\n",
      "[595]\tvalidation_0-mlogloss:0.04826\tvalidation_1-mlogloss:0.33885\n",
      "[596]\tvalidation_0-mlogloss:0.04819\tvalidation_1-mlogloss:0.33863\n",
      "[597]\tvalidation_0-mlogloss:0.04814\tvalidation_1-mlogloss:0.33856\n",
      "[598]\tvalidation_0-mlogloss:0.04809\tvalidation_1-mlogloss:0.33852\n",
      "[599]\tvalidation_0-mlogloss:0.04805\tvalidation_1-mlogloss:0.33865\n",
      "[600]\tvalidation_0-mlogloss:0.04799\tvalidation_1-mlogloss:0.33843\n",
      "[601]\tvalidation_0-mlogloss:0.04790\tvalidation_1-mlogloss:0.33838\n",
      "[602]\tvalidation_0-mlogloss:0.04786\tvalidation_1-mlogloss:0.33850\n",
      "[603]\tvalidation_0-mlogloss:0.04779\tvalidation_1-mlogloss:0.33849\n",
      "[604]\tvalidation_0-mlogloss:0.04776\tvalidation_1-mlogloss:0.33845\n",
      "[605]\tvalidation_0-mlogloss:0.04774\tvalidation_1-mlogloss:0.33838\n",
      "[606]\tvalidation_0-mlogloss:0.04772\tvalidation_1-mlogloss:0.33841\n",
      "[607]\tvalidation_0-mlogloss:0.04768\tvalidation_1-mlogloss:0.33850\n",
      "[608]\tvalidation_0-mlogloss:0.04763\tvalidation_1-mlogloss:0.33872\n",
      "[609]\tvalidation_0-mlogloss:0.04758\tvalidation_1-mlogloss:0.33869\n",
      "[610]\tvalidation_0-mlogloss:0.04754\tvalidation_1-mlogloss:0.33888\n",
      "[611]\tvalidation_0-mlogloss:0.04749\tvalidation_1-mlogloss:0.33884\n",
      "[612]\tvalidation_0-mlogloss:0.04746\tvalidation_1-mlogloss:0.33885\n",
      "[613]\tvalidation_0-mlogloss:0.04744\tvalidation_1-mlogloss:0.33896\n",
      "[614]\tvalidation_0-mlogloss:0.04737\tvalidation_1-mlogloss:0.33889\n",
      "[615]\tvalidation_0-mlogloss:0.04733\tvalidation_1-mlogloss:0.33890\n",
      "[616]\tvalidation_0-mlogloss:0.04729\tvalidation_1-mlogloss:0.33874\n",
      "[617]\tvalidation_0-mlogloss:0.04727\tvalidation_1-mlogloss:0.33860\n",
      "[618]\tvalidation_0-mlogloss:0.04720\tvalidation_1-mlogloss:0.33832\n",
      "[619]\tvalidation_0-mlogloss:0.04716\tvalidation_1-mlogloss:0.33810\n",
      "[620]\tvalidation_0-mlogloss:0.04713\tvalidation_1-mlogloss:0.33823\n",
      "[621]\tvalidation_0-mlogloss:0.04710\tvalidation_1-mlogloss:0.33816\n",
      "[622]\tvalidation_0-mlogloss:0.04704\tvalidation_1-mlogloss:0.33785\n",
      "[623]\tvalidation_0-mlogloss:0.04702\tvalidation_1-mlogloss:0.33791\n",
      "[624]\tvalidation_0-mlogloss:0.04699\tvalidation_1-mlogloss:0.33806\n",
      "[625]\tvalidation_0-mlogloss:0.04694\tvalidation_1-mlogloss:0.33781\n",
      "[626]\tvalidation_0-mlogloss:0.04689\tvalidation_1-mlogloss:0.33790\n",
      "[627]\tvalidation_0-mlogloss:0.04686\tvalidation_1-mlogloss:0.33802\n",
      "[628]\tvalidation_0-mlogloss:0.04683\tvalidation_1-mlogloss:0.33812\n",
      "[629]\tvalidation_0-mlogloss:0.04678\tvalidation_1-mlogloss:0.33805\n",
      "[630]\tvalidation_0-mlogloss:0.04675\tvalidation_1-mlogloss:0.33814\n",
      "[631]\tvalidation_0-mlogloss:0.04673\tvalidation_1-mlogloss:0.33823\n",
      "[632]\tvalidation_0-mlogloss:0.04670\tvalidation_1-mlogloss:0.33827\n",
      "[633]\tvalidation_0-mlogloss:0.04667\tvalidation_1-mlogloss:0.33846\n",
      "[634]\tvalidation_0-mlogloss:0.04664\tvalidation_1-mlogloss:0.33829\n",
      "[635]\tvalidation_0-mlogloss:0.04660\tvalidation_1-mlogloss:0.33836\n",
      "[636]\tvalidation_0-mlogloss:0.04655\tvalidation_1-mlogloss:0.33837\n",
      "[637]\tvalidation_0-mlogloss:0.04651\tvalidation_1-mlogloss:0.33833\n",
      "[638]\tvalidation_0-mlogloss:0.04647\tvalidation_1-mlogloss:0.33825\n",
      "[639]\tvalidation_0-mlogloss:0.04644\tvalidation_1-mlogloss:0.33840\n",
      "[640]\tvalidation_0-mlogloss:0.04641\tvalidation_1-mlogloss:0.33843\n",
      "[641]\tvalidation_0-mlogloss:0.04636\tvalidation_1-mlogloss:0.33834\n",
      "[642]\tvalidation_0-mlogloss:0.04635\tvalidation_1-mlogloss:0.33841\n",
      "[643]\tvalidation_0-mlogloss:0.04631\tvalidation_1-mlogloss:0.33859\n",
      "[644]\tvalidation_0-mlogloss:0.04629\tvalidation_1-mlogloss:0.33869\n",
      "[16:53:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-mlogloss:1.59240\tvalidation_1-mlogloss:1.59495\n",
      "[1]\tvalidation_0-mlogloss:1.57443\tvalidation_1-mlogloss:1.58191\n",
      "[2]\tvalidation_0-mlogloss:1.55679\tvalidation_1-mlogloss:1.56782\n",
      "[3]\tvalidation_0-mlogloss:1.53846\tvalidation_1-mlogloss:1.55425\n",
      "[4]\tvalidation_0-mlogloss:1.52155\tvalidation_1-mlogloss:1.54222\n",
      "[5]\tvalidation_0-mlogloss:1.50545\tvalidation_1-mlogloss:1.52931\n",
      "[6]\tvalidation_0-mlogloss:1.48908\tvalidation_1-mlogloss:1.51642\n",
      "[7]\tvalidation_0-mlogloss:1.47260\tvalidation_1-mlogloss:1.50363\n",
      "[8]\tvalidation_0-mlogloss:1.45667\tvalidation_1-mlogloss:1.49073\n",
      "[9]\tvalidation_0-mlogloss:1.44081\tvalidation_1-mlogloss:1.47851\n",
      "[10]\tvalidation_0-mlogloss:1.42618\tvalidation_1-mlogloss:1.46721\n",
      "[11]\tvalidation_0-mlogloss:1.41082\tvalidation_1-mlogloss:1.45462\n",
      "[12]\tvalidation_0-mlogloss:1.39538\tvalidation_1-mlogloss:1.44208\n",
      "[13]\tvalidation_0-mlogloss:1.38061\tvalidation_1-mlogloss:1.42887\n",
      "[14]\tvalidation_0-mlogloss:1.36620\tvalidation_1-mlogloss:1.41722\n",
      "[15]\tvalidation_0-mlogloss:1.35092\tvalidation_1-mlogloss:1.40417\n",
      "[16]\tvalidation_0-mlogloss:1.33614\tvalidation_1-mlogloss:1.39210\n",
      "[17]\tvalidation_0-mlogloss:1.32284\tvalidation_1-mlogloss:1.38058\n",
      "[18]\tvalidation_0-mlogloss:1.30916\tvalidation_1-mlogloss:1.37073\n",
      "[19]\tvalidation_0-mlogloss:1.29541\tvalidation_1-mlogloss:1.36046\n",
      "[20]\tvalidation_0-mlogloss:1.28205\tvalidation_1-mlogloss:1.34957\n",
      "[21]\tvalidation_0-mlogloss:1.26812\tvalidation_1-mlogloss:1.33818\n",
      "[22]\tvalidation_0-mlogloss:1.25492\tvalidation_1-mlogloss:1.32686\n",
      "[23]\tvalidation_0-mlogloss:1.24189\tvalidation_1-mlogloss:1.31769\n",
      "[24]\tvalidation_0-mlogloss:1.22885\tvalidation_1-mlogloss:1.30879\n",
      "[25]\tvalidation_0-mlogloss:1.21681\tvalidation_1-mlogloss:1.29915\n",
      "[26]\tvalidation_0-mlogloss:1.20397\tvalidation_1-mlogloss:1.28782\n",
      "[27]\tvalidation_0-mlogloss:1.19250\tvalidation_1-mlogloss:1.27861\n",
      "[28]\tvalidation_0-mlogloss:1.18063\tvalidation_1-mlogloss:1.26882\n",
      "[29]\tvalidation_0-mlogloss:1.16887\tvalidation_1-mlogloss:1.26017\n",
      "[30]\tvalidation_0-mlogloss:1.15761\tvalidation_1-mlogloss:1.25094\n",
      "[31]\tvalidation_0-mlogloss:1.14551\tvalidation_1-mlogloss:1.24056\n",
      "[32]\tvalidation_0-mlogloss:1.13440\tvalidation_1-mlogloss:1.23057\n",
      "[33]\tvalidation_0-mlogloss:1.12305\tvalidation_1-mlogloss:1.22071\n",
      "[34]\tvalidation_0-mlogloss:1.11209\tvalidation_1-mlogloss:1.21033\n",
      "[35]\tvalidation_0-mlogloss:1.10170\tvalidation_1-mlogloss:1.20309\n",
      "[36]\tvalidation_0-mlogloss:1.09058\tvalidation_1-mlogloss:1.19378\n",
      "[37]\tvalidation_0-mlogloss:1.08010\tvalidation_1-mlogloss:1.18386\n",
      "[38]\tvalidation_0-mlogloss:1.06961\tvalidation_1-mlogloss:1.17412\n",
      "[39]\tvalidation_0-mlogloss:1.05975\tvalidation_1-mlogloss:1.16700\n",
      "[40]\tvalidation_0-mlogloss:1.04929\tvalidation_1-mlogloss:1.15825\n",
      "[41]\tvalidation_0-mlogloss:1.03863\tvalidation_1-mlogloss:1.14886\n",
      "[42]\tvalidation_0-mlogloss:1.02908\tvalidation_1-mlogloss:1.14176\n",
      "[43]\tvalidation_0-mlogloss:1.01922\tvalidation_1-mlogloss:1.13456\n",
      "[44]\tvalidation_0-mlogloss:1.00957\tvalidation_1-mlogloss:1.12685\n",
      "[45]\tvalidation_0-mlogloss:0.99994\tvalidation_1-mlogloss:1.11997\n",
      "[46]\tvalidation_0-mlogloss:0.99098\tvalidation_1-mlogloss:1.11287\n",
      "[47]\tvalidation_0-mlogloss:0.98154\tvalidation_1-mlogloss:1.10541\n",
      "[48]\tvalidation_0-mlogloss:0.97183\tvalidation_1-mlogloss:1.09602\n",
      "[49]\tvalidation_0-mlogloss:0.96230\tvalidation_1-mlogloss:1.08811\n",
      "[50]\tvalidation_0-mlogloss:0.95325\tvalidation_1-mlogloss:1.08213\n",
      "[51]\tvalidation_0-mlogloss:0.94396\tvalidation_1-mlogloss:1.07476\n",
      "[52]\tvalidation_0-mlogloss:0.93471\tvalidation_1-mlogloss:1.06797\n",
      "[53]\tvalidation_0-mlogloss:0.92633\tvalidation_1-mlogloss:1.06154\n",
      "[54]\tvalidation_0-mlogloss:0.91794\tvalidation_1-mlogloss:1.05495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55]\tvalidation_0-mlogloss:0.90946\tvalidation_1-mlogloss:1.04947\n",
      "[56]\tvalidation_0-mlogloss:0.90145\tvalidation_1-mlogloss:1.04369\n",
      "[57]\tvalidation_0-mlogloss:0.89306\tvalidation_1-mlogloss:1.03709\n",
      "[58]\tvalidation_0-mlogloss:0.88481\tvalidation_1-mlogloss:1.02998\n",
      "[59]\tvalidation_0-mlogloss:0.87664\tvalidation_1-mlogloss:1.02430\n",
      "[60]\tvalidation_0-mlogloss:0.86851\tvalidation_1-mlogloss:1.01870\n",
      "[61]\tvalidation_0-mlogloss:0.86032\tvalidation_1-mlogloss:1.01138\n",
      "[62]\tvalidation_0-mlogloss:0.85342\tvalidation_1-mlogloss:1.00619\n",
      "[63]\tvalidation_0-mlogloss:0.84545\tvalidation_1-mlogloss:0.99974\n",
      "[64]\tvalidation_0-mlogloss:0.83762\tvalidation_1-mlogloss:0.99346\n",
      "[65]\tvalidation_0-mlogloss:0.82985\tvalidation_1-mlogloss:0.98732\n",
      "[66]\tvalidation_0-mlogloss:0.82199\tvalidation_1-mlogloss:0.98090\n",
      "[67]\tvalidation_0-mlogloss:0.81391\tvalidation_1-mlogloss:0.97401\n",
      "[68]\tvalidation_0-mlogloss:0.80633\tvalidation_1-mlogloss:0.96693\n",
      "[69]\tvalidation_0-mlogloss:0.79904\tvalidation_1-mlogloss:0.96124\n",
      "[70]\tvalidation_0-mlogloss:0.79126\tvalidation_1-mlogloss:0.95408\n",
      "[71]\tvalidation_0-mlogloss:0.78400\tvalidation_1-mlogloss:0.94825\n",
      "[72]\tvalidation_0-mlogloss:0.77759\tvalidation_1-mlogloss:0.94353\n",
      "[73]\tvalidation_0-mlogloss:0.77049\tvalidation_1-mlogloss:0.93815\n",
      "[74]\tvalidation_0-mlogloss:0.76333\tvalidation_1-mlogloss:0.93269\n",
      "[75]\tvalidation_0-mlogloss:0.75654\tvalidation_1-mlogloss:0.92787\n",
      "[76]\tvalidation_0-mlogloss:0.74960\tvalidation_1-mlogloss:0.92129\n",
      "[77]\tvalidation_0-mlogloss:0.74278\tvalidation_1-mlogloss:0.91598\n",
      "[78]\tvalidation_0-mlogloss:0.73612\tvalidation_1-mlogloss:0.90996\n",
      "[79]\tvalidation_0-mlogloss:0.72955\tvalidation_1-mlogloss:0.90433\n",
      "[80]\tvalidation_0-mlogloss:0.72270\tvalidation_1-mlogloss:0.89849\n",
      "[81]\tvalidation_0-mlogloss:0.71624\tvalidation_1-mlogloss:0.89312\n",
      "[82]\tvalidation_0-mlogloss:0.70979\tvalidation_1-mlogloss:0.88784\n",
      "[83]\tvalidation_0-mlogloss:0.70309\tvalidation_1-mlogloss:0.88147\n",
      "[84]\tvalidation_0-mlogloss:0.69712\tvalidation_1-mlogloss:0.87705\n",
      "[85]\tvalidation_0-mlogloss:0.69088\tvalidation_1-mlogloss:0.87227\n",
      "[86]\tvalidation_0-mlogloss:0.68458\tvalidation_1-mlogloss:0.86650\n",
      "[87]\tvalidation_0-mlogloss:0.67847\tvalidation_1-mlogloss:0.86208\n",
      "[88]\tvalidation_0-mlogloss:0.67248\tvalidation_1-mlogloss:0.85735\n",
      "[89]\tvalidation_0-mlogloss:0.66649\tvalidation_1-mlogloss:0.85178\n",
      "[90]\tvalidation_0-mlogloss:0.66057\tvalidation_1-mlogloss:0.84660\n",
      "[91]\tvalidation_0-mlogloss:0.65513\tvalidation_1-mlogloss:0.84186\n",
      "[92]\tvalidation_0-mlogloss:0.64980\tvalidation_1-mlogloss:0.83800\n",
      "[93]\tvalidation_0-mlogloss:0.64405\tvalidation_1-mlogloss:0.83323\n",
      "[94]\tvalidation_0-mlogloss:0.63855\tvalidation_1-mlogloss:0.82817\n",
      "[95]\tvalidation_0-mlogloss:0.63285\tvalidation_1-mlogloss:0.82303\n",
      "[96]\tvalidation_0-mlogloss:0.62748\tvalidation_1-mlogloss:0.81853\n",
      "[97]\tvalidation_0-mlogloss:0.62209\tvalidation_1-mlogloss:0.81499\n",
      "[98]\tvalidation_0-mlogloss:0.61661\tvalidation_1-mlogloss:0.80996\n",
      "[99]\tvalidation_0-mlogloss:0.61128\tvalidation_1-mlogloss:0.80507\n",
      "[100]\tvalidation_0-mlogloss:0.60622\tvalidation_1-mlogloss:0.80126\n",
      "[101]\tvalidation_0-mlogloss:0.60076\tvalidation_1-mlogloss:0.79634\n",
      "[102]\tvalidation_0-mlogloss:0.59554\tvalidation_1-mlogloss:0.79149\n",
      "[103]\tvalidation_0-mlogloss:0.59059\tvalidation_1-mlogloss:0.78826\n",
      "[104]\tvalidation_0-mlogloss:0.58523\tvalidation_1-mlogloss:0.78310\n",
      "[105]\tvalidation_0-mlogloss:0.58017\tvalidation_1-mlogloss:0.77937\n",
      "[106]\tvalidation_0-mlogloss:0.57494\tvalidation_1-mlogloss:0.77470\n",
      "[107]\tvalidation_0-mlogloss:0.56997\tvalidation_1-mlogloss:0.77096\n",
      "[108]\tvalidation_0-mlogloss:0.56497\tvalidation_1-mlogloss:0.76680\n",
      "[109]\tvalidation_0-mlogloss:0.56028\tvalidation_1-mlogloss:0.76293\n",
      "[110]\tvalidation_0-mlogloss:0.55537\tvalidation_1-mlogloss:0.75873\n",
      "[111]\tvalidation_0-mlogloss:0.55051\tvalidation_1-mlogloss:0.75463\n",
      "[112]\tvalidation_0-mlogloss:0.54583\tvalidation_1-mlogloss:0.75094\n",
      "[113]\tvalidation_0-mlogloss:0.54102\tvalidation_1-mlogloss:0.74616\n",
      "[114]\tvalidation_0-mlogloss:0.53621\tvalidation_1-mlogloss:0.74183\n",
      "[115]\tvalidation_0-mlogloss:0.53157\tvalidation_1-mlogloss:0.73731\n",
      "[116]\tvalidation_0-mlogloss:0.52701\tvalidation_1-mlogloss:0.73274\n",
      "[117]\tvalidation_0-mlogloss:0.52250\tvalidation_1-mlogloss:0.72885\n",
      "[118]\tvalidation_0-mlogloss:0.51809\tvalidation_1-mlogloss:0.72506\n",
      "[119]\tvalidation_0-mlogloss:0.51381\tvalidation_1-mlogloss:0.72162\n",
      "[120]\tvalidation_0-mlogloss:0.50925\tvalidation_1-mlogloss:0.71768\n",
      "[121]\tvalidation_0-mlogloss:0.50481\tvalidation_1-mlogloss:0.71346\n",
      "[122]\tvalidation_0-mlogloss:0.50080\tvalidation_1-mlogloss:0.71026\n",
      "[123]\tvalidation_0-mlogloss:0.49661\tvalidation_1-mlogloss:0.70683\n",
      "[124]\tvalidation_0-mlogloss:0.49248\tvalidation_1-mlogloss:0.70363\n",
      "[125]\tvalidation_0-mlogloss:0.48842\tvalidation_1-mlogloss:0.70042\n",
      "[126]\tvalidation_0-mlogloss:0.48415\tvalidation_1-mlogloss:0.69669\n",
      "[127]\tvalidation_0-mlogloss:0.47994\tvalidation_1-mlogloss:0.69284\n",
      "[128]\tvalidation_0-mlogloss:0.47579\tvalidation_1-mlogloss:0.68883\n",
      "[129]\tvalidation_0-mlogloss:0.47160\tvalidation_1-mlogloss:0.68515\n",
      "[130]\tvalidation_0-mlogloss:0.46780\tvalidation_1-mlogloss:0.68223\n",
      "[131]\tvalidation_0-mlogloss:0.46389\tvalidation_1-mlogloss:0.67858\n",
      "[132]\tvalidation_0-mlogloss:0.45993\tvalidation_1-mlogloss:0.67520\n",
      "[133]\tvalidation_0-mlogloss:0.45615\tvalidation_1-mlogloss:0.67299\n",
      "[134]\tvalidation_0-mlogloss:0.45224\tvalidation_1-mlogloss:0.66898\n",
      "[135]\tvalidation_0-mlogloss:0.44847\tvalidation_1-mlogloss:0.66593\n",
      "[136]\tvalidation_0-mlogloss:0.44478\tvalidation_1-mlogloss:0.66289\n",
      "[137]\tvalidation_0-mlogloss:0.44113\tvalidation_1-mlogloss:0.65913\n",
      "[138]\tvalidation_0-mlogloss:0.43739\tvalidation_1-mlogloss:0.65536\n",
      "[139]\tvalidation_0-mlogloss:0.43385\tvalidation_1-mlogloss:0.65254\n",
      "[140]\tvalidation_0-mlogloss:0.43045\tvalidation_1-mlogloss:0.65043\n",
      "[141]\tvalidation_0-mlogloss:0.42671\tvalidation_1-mlogloss:0.64690\n",
      "[142]\tvalidation_0-mlogloss:0.42324\tvalidation_1-mlogloss:0.64474\n",
      "[143]\tvalidation_0-mlogloss:0.41977\tvalidation_1-mlogloss:0.64245\n",
      "[144]\tvalidation_0-mlogloss:0.41635\tvalidation_1-mlogloss:0.63952\n",
      "[145]\tvalidation_0-mlogloss:0.41280\tvalidation_1-mlogloss:0.63588\n",
      "[146]\tvalidation_0-mlogloss:0.40925\tvalidation_1-mlogloss:0.63238\n",
      "[147]\tvalidation_0-mlogloss:0.40586\tvalidation_1-mlogloss:0.62969\n",
      "[148]\tvalidation_0-mlogloss:0.40243\tvalidation_1-mlogloss:0.62634\n",
      "[149]\tvalidation_0-mlogloss:0.39932\tvalidation_1-mlogloss:0.62401\n",
      "[150]\tvalidation_0-mlogloss:0.39633\tvalidation_1-mlogloss:0.62199\n",
      "[151]\tvalidation_0-mlogloss:0.39308\tvalidation_1-mlogloss:0.61898\n",
      "[152]\tvalidation_0-mlogloss:0.38975\tvalidation_1-mlogloss:0.61542\n",
      "[153]\tvalidation_0-mlogloss:0.38659\tvalidation_1-mlogloss:0.61288\n",
      "[154]\tvalidation_0-mlogloss:0.38340\tvalidation_1-mlogloss:0.60992\n",
      "[155]\tvalidation_0-mlogloss:0.38026\tvalidation_1-mlogloss:0.60734\n",
      "[156]\tvalidation_0-mlogloss:0.37731\tvalidation_1-mlogloss:0.60501\n",
      "[157]\tvalidation_0-mlogloss:0.37426\tvalidation_1-mlogloss:0.60253\n",
      "[158]\tvalidation_0-mlogloss:0.37120\tvalidation_1-mlogloss:0.59922\n",
      "[159]\tvalidation_0-mlogloss:0.36827\tvalidation_1-mlogloss:0.59679\n",
      "[160]\tvalidation_0-mlogloss:0.36540\tvalidation_1-mlogloss:0.59417\n",
      "[161]\tvalidation_0-mlogloss:0.36254\tvalidation_1-mlogloss:0.59236\n",
      "[162]\tvalidation_0-mlogloss:0.35982\tvalidation_1-mlogloss:0.59023\n",
      "[163]\tvalidation_0-mlogloss:0.35704\tvalidation_1-mlogloss:0.58799\n",
      "[164]\tvalidation_0-mlogloss:0.35428\tvalidation_1-mlogloss:0.58536\n",
      "[165]\tvalidation_0-mlogloss:0.35141\tvalidation_1-mlogloss:0.58333\n",
      "[166]\tvalidation_0-mlogloss:0.34862\tvalidation_1-mlogloss:0.58054\n",
      "[167]\tvalidation_0-mlogloss:0.34597\tvalidation_1-mlogloss:0.57846\n",
      "[168]\tvalidation_0-mlogloss:0.34341\tvalidation_1-mlogloss:0.57612\n",
      "[169]\tvalidation_0-mlogloss:0.34074\tvalidation_1-mlogloss:0.57446\n",
      "[170]\tvalidation_0-mlogloss:0.33812\tvalidation_1-mlogloss:0.57214\n",
      "[171]\tvalidation_0-mlogloss:0.33558\tvalidation_1-mlogloss:0.57045\n",
      "[172]\tvalidation_0-mlogloss:0.33310\tvalidation_1-mlogloss:0.56768\n",
      "[173]\tvalidation_0-mlogloss:0.33053\tvalidation_1-mlogloss:0.56529\n",
      "[174]\tvalidation_0-mlogloss:0.32788\tvalidation_1-mlogloss:0.56266\n",
      "[175]\tvalidation_0-mlogloss:0.32544\tvalidation_1-mlogloss:0.56021\n",
      "[176]\tvalidation_0-mlogloss:0.32316\tvalidation_1-mlogloss:0.55843\n",
      "[177]\tvalidation_0-mlogloss:0.32053\tvalidation_1-mlogloss:0.55570\n",
      "[178]\tvalidation_0-mlogloss:0.31815\tvalidation_1-mlogloss:0.55337\n",
      "[179]\tvalidation_0-mlogloss:0.31561\tvalidation_1-mlogloss:0.55090\n",
      "[180]\tvalidation_0-mlogloss:0.31326\tvalidation_1-mlogloss:0.54971\n",
      "[181]\tvalidation_0-mlogloss:0.31080\tvalidation_1-mlogloss:0.54782\n",
      "[182]\tvalidation_0-mlogloss:0.30846\tvalidation_1-mlogloss:0.54611\n",
      "[183]\tvalidation_0-mlogloss:0.30611\tvalidation_1-mlogloss:0.54480\n",
      "[184]\tvalidation_0-mlogloss:0.30395\tvalidation_1-mlogloss:0.54328\n",
      "[185]\tvalidation_0-mlogloss:0.30164\tvalidation_1-mlogloss:0.54110\n",
      "[186]\tvalidation_0-mlogloss:0.29942\tvalidation_1-mlogloss:0.53928\n",
      "[187]\tvalidation_0-mlogloss:0.29711\tvalidation_1-mlogloss:0.53647\n",
      "[188]\tvalidation_0-mlogloss:0.29476\tvalidation_1-mlogloss:0.53438\n",
      "[189]\tvalidation_0-mlogloss:0.29249\tvalidation_1-mlogloss:0.53256\n",
      "[190]\tvalidation_0-mlogloss:0.29035\tvalidation_1-mlogloss:0.53010\n",
      "[191]\tvalidation_0-mlogloss:0.28811\tvalidation_1-mlogloss:0.52891\n",
      "[192]\tvalidation_0-mlogloss:0.28591\tvalidation_1-mlogloss:0.52689\n",
      "[193]\tvalidation_0-mlogloss:0.28389\tvalidation_1-mlogloss:0.52527\n",
      "[194]\tvalidation_0-mlogloss:0.28179\tvalidation_1-mlogloss:0.52356\n",
      "[195]\tvalidation_0-mlogloss:0.27963\tvalidation_1-mlogloss:0.52114\n",
      "[196]\tvalidation_0-mlogloss:0.27762\tvalidation_1-mlogloss:0.51950\n",
      "[197]\tvalidation_0-mlogloss:0.27553\tvalidation_1-mlogloss:0.51764\n",
      "[198]\tvalidation_0-mlogloss:0.27353\tvalidation_1-mlogloss:0.51644\n",
      "[199]\tvalidation_0-mlogloss:0.27154\tvalidation_1-mlogloss:0.51484\n",
      "[200]\tvalidation_0-mlogloss:0.26949\tvalidation_1-mlogloss:0.51281\n",
      "[201]\tvalidation_0-mlogloss:0.26746\tvalidation_1-mlogloss:0.51114\n",
      "[202]\tvalidation_0-mlogloss:0.26550\tvalidation_1-mlogloss:0.50927\n",
      "[203]\tvalidation_0-mlogloss:0.26356\tvalidation_1-mlogloss:0.50783\n",
      "[204]\tvalidation_0-mlogloss:0.26152\tvalidation_1-mlogloss:0.50542\n",
      "[205]\tvalidation_0-mlogloss:0.25965\tvalidation_1-mlogloss:0.50370\n",
      "[206]\tvalidation_0-mlogloss:0.25770\tvalidation_1-mlogloss:0.50236\n",
      "[207]\tvalidation_0-mlogloss:0.25580\tvalidation_1-mlogloss:0.50078\n",
      "[208]\tvalidation_0-mlogloss:0.25397\tvalidation_1-mlogloss:0.49870\n",
      "[209]\tvalidation_0-mlogloss:0.25205\tvalidation_1-mlogloss:0.49703\n",
      "[210]\tvalidation_0-mlogloss:0.25025\tvalidation_1-mlogloss:0.49519\n",
      "[211]\tvalidation_0-mlogloss:0.24837\tvalidation_1-mlogloss:0.49303\n",
      "[212]\tvalidation_0-mlogloss:0.24653\tvalidation_1-mlogloss:0.49167\n",
      "[213]\tvalidation_0-mlogloss:0.24464\tvalidation_1-mlogloss:0.48999\n",
      "[214]\tvalidation_0-mlogloss:0.24283\tvalidation_1-mlogloss:0.48815\n",
      "[215]\tvalidation_0-mlogloss:0.24097\tvalidation_1-mlogloss:0.48667\n",
      "[216]\tvalidation_0-mlogloss:0.23919\tvalidation_1-mlogloss:0.48449\n",
      "[217]\tvalidation_0-mlogloss:0.23752\tvalidation_1-mlogloss:0.48352\n",
      "[218]\tvalidation_0-mlogloss:0.23578\tvalidation_1-mlogloss:0.48235\n",
      "[219]\tvalidation_0-mlogloss:0.23410\tvalidation_1-mlogloss:0.48072\n",
      "[220]\tvalidation_0-mlogloss:0.23239\tvalidation_1-mlogloss:0.47916\n",
      "[221]\tvalidation_0-mlogloss:0.23072\tvalidation_1-mlogloss:0.47779\n",
      "[222]\tvalidation_0-mlogloss:0.22904\tvalidation_1-mlogloss:0.47537\n",
      "[223]\tvalidation_0-mlogloss:0.22737\tvalidation_1-mlogloss:0.47339\n",
      "[224]\tvalidation_0-mlogloss:0.22575\tvalidation_1-mlogloss:0.47260\n",
      "[225]\tvalidation_0-mlogloss:0.22418\tvalidation_1-mlogloss:0.47150\n",
      "[226]\tvalidation_0-mlogloss:0.22266\tvalidation_1-mlogloss:0.47022\n",
      "[227]\tvalidation_0-mlogloss:0.22108\tvalidation_1-mlogloss:0.46901\n",
      "[228]\tvalidation_0-mlogloss:0.21957\tvalidation_1-mlogloss:0.46768\n",
      "[229]\tvalidation_0-mlogloss:0.21801\tvalidation_1-mlogloss:0.46626\n",
      "[230]\tvalidation_0-mlogloss:0.21648\tvalidation_1-mlogloss:0.46499\n",
      "[231]\tvalidation_0-mlogloss:0.21491\tvalidation_1-mlogloss:0.46406\n",
      "[232]\tvalidation_0-mlogloss:0.21347\tvalidation_1-mlogloss:0.46270\n",
      "[233]\tvalidation_0-mlogloss:0.21206\tvalidation_1-mlogloss:0.46134\n",
      "[234]\tvalidation_0-mlogloss:0.21057\tvalidation_1-mlogloss:0.46012\n",
      "[235]\tvalidation_0-mlogloss:0.20916\tvalidation_1-mlogloss:0.45892\n",
      "[236]\tvalidation_0-mlogloss:0.20773\tvalidation_1-mlogloss:0.45774\n",
      "[237]\tvalidation_0-mlogloss:0.20624\tvalidation_1-mlogloss:0.45661\n",
      "[238]\tvalidation_0-mlogloss:0.20484\tvalidation_1-mlogloss:0.45513\n",
      "[239]\tvalidation_0-mlogloss:0.20346\tvalidation_1-mlogloss:0.45367\n",
      "[240]\tvalidation_0-mlogloss:0.20207\tvalidation_1-mlogloss:0.45274\n",
      "[241]\tvalidation_0-mlogloss:0.20066\tvalidation_1-mlogloss:0.45128\n",
      "[242]\tvalidation_0-mlogloss:0.19922\tvalidation_1-mlogloss:0.44972\n",
      "[243]\tvalidation_0-mlogloss:0.19790\tvalidation_1-mlogloss:0.44891\n",
      "[244]\tvalidation_0-mlogloss:0.19654\tvalidation_1-mlogloss:0.44772\n",
      "[245]\tvalidation_0-mlogloss:0.19518\tvalidation_1-mlogloss:0.44704\n",
      "[246]\tvalidation_0-mlogloss:0.19388\tvalidation_1-mlogloss:0.44540\n",
      "[247]\tvalidation_0-mlogloss:0.19253\tvalidation_1-mlogloss:0.44400\n",
      "[248]\tvalidation_0-mlogloss:0.19119\tvalidation_1-mlogloss:0.44264\n",
      "[249]\tvalidation_0-mlogloss:0.18986\tvalidation_1-mlogloss:0.44128\n",
      "[250]\tvalidation_0-mlogloss:0.18853\tvalidation_1-mlogloss:0.43973\n",
      "[251]\tvalidation_0-mlogloss:0.18734\tvalidation_1-mlogloss:0.43900\n",
      "[252]\tvalidation_0-mlogloss:0.18604\tvalidation_1-mlogloss:0.43798\n",
      "[253]\tvalidation_0-mlogloss:0.18495\tvalidation_1-mlogloss:0.43749\n",
      "[254]\tvalidation_0-mlogloss:0.18367\tvalidation_1-mlogloss:0.43638\n",
      "[255]\tvalidation_0-mlogloss:0.18241\tvalidation_1-mlogloss:0.43557\n",
      "[256]\tvalidation_0-mlogloss:0.18120\tvalidation_1-mlogloss:0.43437\n",
      "[257]\tvalidation_0-mlogloss:0.18006\tvalidation_1-mlogloss:0.43344\n",
      "[258]\tvalidation_0-mlogloss:0.17887\tvalidation_1-mlogloss:0.43271\n",
      "[259]\tvalidation_0-mlogloss:0.17766\tvalidation_1-mlogloss:0.43141\n",
      "[260]\tvalidation_0-mlogloss:0.17650\tvalidation_1-mlogloss:0.43076\n",
      "[261]\tvalidation_0-mlogloss:0.17537\tvalidation_1-mlogloss:0.43007\n",
      "[262]\tvalidation_0-mlogloss:0.17421\tvalidation_1-mlogloss:0.42943\n",
      "[263]\tvalidation_0-mlogloss:0.17308\tvalidation_1-mlogloss:0.42851\n",
      "[264]\tvalidation_0-mlogloss:0.17193\tvalidation_1-mlogloss:0.42733\n",
      "[265]\tvalidation_0-mlogloss:0.17079\tvalidation_1-mlogloss:0.42630\n",
      "[266]\tvalidation_0-mlogloss:0.16963\tvalidation_1-mlogloss:0.42546\n",
      "[267]\tvalidation_0-mlogloss:0.16867\tvalidation_1-mlogloss:0.42481\n",
      "[268]\tvalidation_0-mlogloss:0.16759\tvalidation_1-mlogloss:0.42444\n",
      "[269]\tvalidation_0-mlogloss:0.16661\tvalidation_1-mlogloss:0.42382\n",
      "[270]\tvalidation_0-mlogloss:0.16552\tvalidation_1-mlogloss:0.42279\n",
      "[271]\tvalidation_0-mlogloss:0.16444\tvalidation_1-mlogloss:0.42184\n",
      "[272]\tvalidation_0-mlogloss:0.16331\tvalidation_1-mlogloss:0.42078\n",
      "[273]\tvalidation_0-mlogloss:0.16224\tvalidation_1-mlogloss:0.41987\n",
      "[274]\tvalidation_0-mlogloss:0.16123\tvalidation_1-mlogloss:0.41922\n",
      "[275]\tvalidation_0-mlogloss:0.16022\tvalidation_1-mlogloss:0.41809\n",
      "[276]\tvalidation_0-mlogloss:0.15919\tvalidation_1-mlogloss:0.41706\n",
      "[277]\tvalidation_0-mlogloss:0.15814\tvalidation_1-mlogloss:0.41633\n",
      "[278]\tvalidation_0-mlogloss:0.15705\tvalidation_1-mlogloss:0.41570\n",
      "[279]\tvalidation_0-mlogloss:0.15598\tvalidation_1-mlogloss:0.41478\n",
      "[280]\tvalidation_0-mlogloss:0.15497\tvalidation_1-mlogloss:0.41412\n",
      "[281]\tvalidation_0-mlogloss:0.15399\tvalidation_1-mlogloss:0.41333\n",
      "[282]\tvalidation_0-mlogloss:0.15306\tvalidation_1-mlogloss:0.41281\n",
      "[283]\tvalidation_0-mlogloss:0.15206\tvalidation_1-mlogloss:0.41207\n",
      "[284]\tvalidation_0-mlogloss:0.15105\tvalidation_1-mlogloss:0.41134\n",
      "[285]\tvalidation_0-mlogloss:0.15004\tvalidation_1-mlogloss:0.41026\n",
      "[286]\tvalidation_0-mlogloss:0.14910\tvalidation_1-mlogloss:0.40954\n",
      "[287]\tvalidation_0-mlogloss:0.14812\tvalidation_1-mlogloss:0.40862\n",
      "[288]\tvalidation_0-mlogloss:0.14721\tvalidation_1-mlogloss:0.40820\n",
      "[289]\tvalidation_0-mlogloss:0.14627\tvalidation_1-mlogloss:0.40773\n",
      "[290]\tvalidation_0-mlogloss:0.14533\tvalidation_1-mlogloss:0.40694\n",
      "[291]\tvalidation_0-mlogloss:0.14438\tvalidation_1-mlogloss:0.40587\n",
      "[292]\tvalidation_0-mlogloss:0.14346\tvalidation_1-mlogloss:0.40524\n",
      "[293]\tvalidation_0-mlogloss:0.14256\tvalidation_1-mlogloss:0.40446\n",
      "[294]\tvalidation_0-mlogloss:0.14168\tvalidation_1-mlogloss:0.40414\n",
      "[295]\tvalidation_0-mlogloss:0.14091\tvalidation_1-mlogloss:0.40349\n",
      "[296]\tvalidation_0-mlogloss:0.14008\tvalidation_1-mlogloss:0.40295\n",
      "[297]\tvalidation_0-mlogloss:0.13929\tvalidation_1-mlogloss:0.40183\n",
      "[298]\tvalidation_0-mlogloss:0.13848\tvalidation_1-mlogloss:0.40157\n",
      "[299]\tvalidation_0-mlogloss:0.13762\tvalidation_1-mlogloss:0.40064\n",
      "[300]\tvalidation_0-mlogloss:0.13679\tvalidation_1-mlogloss:0.40047\n",
      "[301]\tvalidation_0-mlogloss:0.13596\tvalidation_1-mlogloss:0.39964\n",
      "[302]\tvalidation_0-mlogloss:0.13514\tvalidation_1-mlogloss:0.39937\n",
      "[303]\tvalidation_0-mlogloss:0.13426\tvalidation_1-mlogloss:0.39885\n",
      "[304]\tvalidation_0-mlogloss:0.13348\tvalidation_1-mlogloss:0.39812\n",
      "[305]\tvalidation_0-mlogloss:0.13266\tvalidation_1-mlogloss:0.39744\n",
      "[306]\tvalidation_0-mlogloss:0.13186\tvalidation_1-mlogloss:0.39687\n",
      "[307]\tvalidation_0-mlogloss:0.13107\tvalidation_1-mlogloss:0.39607\n",
      "[308]\tvalidation_0-mlogloss:0.13029\tvalidation_1-mlogloss:0.39532\n",
      "[309]\tvalidation_0-mlogloss:0.12949\tvalidation_1-mlogloss:0.39490\n",
      "[310]\tvalidation_0-mlogloss:0.12872\tvalidation_1-mlogloss:0.39436\n",
      "[311]\tvalidation_0-mlogloss:0.12795\tvalidation_1-mlogloss:0.39391\n",
      "[312]\tvalidation_0-mlogloss:0.12723\tvalidation_1-mlogloss:0.39359\n",
      "[313]\tvalidation_0-mlogloss:0.12649\tvalidation_1-mlogloss:0.39271\n",
      "[314]\tvalidation_0-mlogloss:0.12575\tvalidation_1-mlogloss:0.39233\n",
      "[315]\tvalidation_0-mlogloss:0.12500\tvalidation_1-mlogloss:0.39139\n",
      "[316]\tvalidation_0-mlogloss:0.12430\tvalidation_1-mlogloss:0.39115\n",
      "[317]\tvalidation_0-mlogloss:0.12355\tvalidation_1-mlogloss:0.39079\n",
      "[318]\tvalidation_0-mlogloss:0.12287\tvalidation_1-mlogloss:0.38985\n",
      "[319]\tvalidation_0-mlogloss:0.12215\tvalidation_1-mlogloss:0.38933\n",
      "[320]\tvalidation_0-mlogloss:0.12149\tvalidation_1-mlogloss:0.38862\n",
      "[321]\tvalidation_0-mlogloss:0.12079\tvalidation_1-mlogloss:0.38791\n",
      "[322]\tvalidation_0-mlogloss:0.12018\tvalidation_1-mlogloss:0.38724\n",
      "[323]\tvalidation_0-mlogloss:0.11949\tvalidation_1-mlogloss:0.38691\n",
      "[324]\tvalidation_0-mlogloss:0.11879\tvalidation_1-mlogloss:0.38596\n",
      "[325]\tvalidation_0-mlogloss:0.11815\tvalidation_1-mlogloss:0.38588\n",
      "[326]\tvalidation_0-mlogloss:0.11752\tvalidation_1-mlogloss:0.38550\n",
      "[327]\tvalidation_0-mlogloss:0.11683\tvalidation_1-mlogloss:0.38497\n",
      "[328]\tvalidation_0-mlogloss:0.11617\tvalidation_1-mlogloss:0.38482\n",
      "[329]\tvalidation_0-mlogloss:0.11550\tvalidation_1-mlogloss:0.38440\n",
      "[330]\tvalidation_0-mlogloss:0.11490\tvalidation_1-mlogloss:0.38374\n",
      "[331]\tvalidation_0-mlogloss:0.11424\tvalidation_1-mlogloss:0.38357\n",
      "[332]\tvalidation_0-mlogloss:0.11365\tvalidation_1-mlogloss:0.38349\n",
      "[333]\tvalidation_0-mlogloss:0.11300\tvalidation_1-mlogloss:0.38270\n",
      "[334]\tvalidation_0-mlogloss:0.11244\tvalidation_1-mlogloss:0.38208\n",
      "[335]\tvalidation_0-mlogloss:0.11177\tvalidation_1-mlogloss:0.38148\n",
      "[336]\tvalidation_0-mlogloss:0.11117\tvalidation_1-mlogloss:0.38104\n",
      "[337]\tvalidation_0-mlogloss:0.11062\tvalidation_1-mlogloss:0.38076\n",
      "[338]\tvalidation_0-mlogloss:0.11010\tvalidation_1-mlogloss:0.38026\n",
      "[339]\tvalidation_0-mlogloss:0.10951\tvalidation_1-mlogloss:0.37988\n",
      "[340]\tvalidation_0-mlogloss:0.10889\tvalidation_1-mlogloss:0.37929\n",
      "[341]\tvalidation_0-mlogloss:0.10829\tvalidation_1-mlogloss:0.37849\n",
      "[342]\tvalidation_0-mlogloss:0.10772\tvalidation_1-mlogloss:0.37779\n",
      "[343]\tvalidation_0-mlogloss:0.10709\tvalidation_1-mlogloss:0.37742\n",
      "[344]\tvalidation_0-mlogloss:0.10648\tvalidation_1-mlogloss:0.37679\n",
      "[345]\tvalidation_0-mlogloss:0.10588\tvalidation_1-mlogloss:0.37650\n",
      "[346]\tvalidation_0-mlogloss:0.10527\tvalidation_1-mlogloss:0.37624\n",
      "[347]\tvalidation_0-mlogloss:0.10475\tvalidation_1-mlogloss:0.37595\n",
      "[348]\tvalidation_0-mlogloss:0.10426\tvalidation_1-mlogloss:0.37576\n",
      "[349]\tvalidation_0-mlogloss:0.10372\tvalidation_1-mlogloss:0.37544\n",
      "[350]\tvalidation_0-mlogloss:0.10318\tvalidation_1-mlogloss:0.37537\n",
      "[351]\tvalidation_0-mlogloss:0.10262\tvalidation_1-mlogloss:0.37517\n",
      "[352]\tvalidation_0-mlogloss:0.10205\tvalidation_1-mlogloss:0.37505\n",
      "[353]\tvalidation_0-mlogloss:0.10152\tvalidation_1-mlogloss:0.37428\n",
      "[354]\tvalidation_0-mlogloss:0.10099\tvalidation_1-mlogloss:0.37411\n",
      "[355]\tvalidation_0-mlogloss:0.10042\tvalidation_1-mlogloss:0.37379\n",
      "[356]\tvalidation_0-mlogloss:0.09988\tvalidation_1-mlogloss:0.37329\n",
      "[357]\tvalidation_0-mlogloss:0.09941\tvalidation_1-mlogloss:0.37304\n",
      "[358]\tvalidation_0-mlogloss:0.09894\tvalidation_1-mlogloss:0.37297\n",
      "[359]\tvalidation_0-mlogloss:0.09843\tvalidation_1-mlogloss:0.37282\n",
      "[360]\tvalidation_0-mlogloss:0.09794\tvalidation_1-mlogloss:0.37219\n",
      "[361]\tvalidation_0-mlogloss:0.09739\tvalidation_1-mlogloss:0.37185\n",
      "[362]\tvalidation_0-mlogloss:0.09688\tvalidation_1-mlogloss:0.37137\n",
      "[363]\tvalidation_0-mlogloss:0.09641\tvalidation_1-mlogloss:0.37122\n",
      "[364]\tvalidation_0-mlogloss:0.09591\tvalidation_1-mlogloss:0.37062\n",
      "[365]\tvalidation_0-mlogloss:0.09538\tvalidation_1-mlogloss:0.37035\n",
      "[366]\tvalidation_0-mlogloss:0.09491\tvalidation_1-mlogloss:0.36969\n",
      "[367]\tvalidation_0-mlogloss:0.09445\tvalidation_1-mlogloss:0.36963\n",
      "[368]\tvalidation_0-mlogloss:0.09399\tvalidation_1-mlogloss:0.36947\n",
      "[369]\tvalidation_0-mlogloss:0.09356\tvalidation_1-mlogloss:0.36923\n",
      "[370]\tvalidation_0-mlogloss:0.09314\tvalidation_1-mlogloss:0.36900\n",
      "[371]\tvalidation_0-mlogloss:0.09272\tvalidation_1-mlogloss:0.36871\n",
      "[372]\tvalidation_0-mlogloss:0.09227\tvalidation_1-mlogloss:0.36873\n",
      "[373]\tvalidation_0-mlogloss:0.09184\tvalidation_1-mlogloss:0.36848\n",
      "[374]\tvalidation_0-mlogloss:0.09138\tvalidation_1-mlogloss:0.36809\n",
      "[375]\tvalidation_0-mlogloss:0.09092\tvalidation_1-mlogloss:0.36786\n",
      "[376]\tvalidation_0-mlogloss:0.09045\tvalidation_1-mlogloss:0.36782\n",
      "[377]\tvalidation_0-mlogloss:0.09004\tvalidation_1-mlogloss:0.36756\n",
      "[378]\tvalidation_0-mlogloss:0.08962\tvalidation_1-mlogloss:0.36730\n",
      "[379]\tvalidation_0-mlogloss:0.08916\tvalidation_1-mlogloss:0.36717\n",
      "[380]\tvalidation_0-mlogloss:0.08870\tvalidation_1-mlogloss:0.36693\n",
      "[381]\tvalidation_0-mlogloss:0.08825\tvalidation_1-mlogloss:0.36702\n",
      "[382]\tvalidation_0-mlogloss:0.08781\tvalidation_1-mlogloss:0.36661\n",
      "[383]\tvalidation_0-mlogloss:0.08741\tvalidation_1-mlogloss:0.36645\n",
      "[384]\tvalidation_0-mlogloss:0.08702\tvalidation_1-mlogloss:0.36608\n",
      "[385]\tvalidation_0-mlogloss:0.08659\tvalidation_1-mlogloss:0.36538\n",
      "[386]\tvalidation_0-mlogloss:0.08617\tvalidation_1-mlogloss:0.36541\n",
      "[387]\tvalidation_0-mlogloss:0.08579\tvalidation_1-mlogloss:0.36512\n",
      "[388]\tvalidation_0-mlogloss:0.08534\tvalidation_1-mlogloss:0.36507\n",
      "[389]\tvalidation_0-mlogloss:0.08492\tvalidation_1-mlogloss:0.36443\n",
      "[390]\tvalidation_0-mlogloss:0.08455\tvalidation_1-mlogloss:0.36377\n",
      "[391]\tvalidation_0-mlogloss:0.08416\tvalidation_1-mlogloss:0.36354\n",
      "[392]\tvalidation_0-mlogloss:0.08375\tvalidation_1-mlogloss:0.36360\n",
      "[393]\tvalidation_0-mlogloss:0.08334\tvalidation_1-mlogloss:0.36348\n",
      "[394]\tvalidation_0-mlogloss:0.08291\tvalidation_1-mlogloss:0.36310\n",
      "[395]\tvalidation_0-mlogloss:0.08253\tvalidation_1-mlogloss:0.36269\n",
      "[396]\tvalidation_0-mlogloss:0.08217\tvalidation_1-mlogloss:0.36256\n",
      "[397]\tvalidation_0-mlogloss:0.08175\tvalidation_1-mlogloss:0.36200\n",
      "[398]\tvalidation_0-mlogloss:0.08138\tvalidation_1-mlogloss:0.36151\n",
      "[399]\tvalidation_0-mlogloss:0.08102\tvalidation_1-mlogloss:0.36157\n",
      "[400]\tvalidation_0-mlogloss:0.08064\tvalidation_1-mlogloss:0.36105\n",
      "[401]\tvalidation_0-mlogloss:0.08025\tvalidation_1-mlogloss:0.36077\n",
      "[402]\tvalidation_0-mlogloss:0.07991\tvalidation_1-mlogloss:0.36074\n",
      "[403]\tvalidation_0-mlogloss:0.07955\tvalidation_1-mlogloss:0.36040\n",
      "[404]\tvalidation_0-mlogloss:0.07919\tvalidation_1-mlogloss:0.36047\n",
      "[405]\tvalidation_0-mlogloss:0.07880\tvalidation_1-mlogloss:0.36004\n",
      "[406]\tvalidation_0-mlogloss:0.07842\tvalidation_1-mlogloss:0.35969\n",
      "[407]\tvalidation_0-mlogloss:0.07805\tvalidation_1-mlogloss:0.35940\n",
      "[408]\tvalidation_0-mlogloss:0.07771\tvalidation_1-mlogloss:0.35905\n",
      "[409]\tvalidation_0-mlogloss:0.07734\tvalidation_1-mlogloss:0.35891\n",
      "[410]\tvalidation_0-mlogloss:0.07696\tvalidation_1-mlogloss:0.35858\n",
      "[411]\tvalidation_0-mlogloss:0.07662\tvalidation_1-mlogloss:0.35875\n",
      "[412]\tvalidation_0-mlogloss:0.07624\tvalidation_1-mlogloss:0.35822\n",
      "[413]\tvalidation_0-mlogloss:0.07589\tvalidation_1-mlogloss:0.35794\n",
      "[414]\tvalidation_0-mlogloss:0.07553\tvalidation_1-mlogloss:0.35731\n",
      "[415]\tvalidation_0-mlogloss:0.07523\tvalidation_1-mlogloss:0.35738\n",
      "[416]\tvalidation_0-mlogloss:0.07488\tvalidation_1-mlogloss:0.35710\n",
      "[417]\tvalidation_0-mlogloss:0.07454\tvalidation_1-mlogloss:0.35726\n",
      "[418]\tvalidation_0-mlogloss:0.07422\tvalidation_1-mlogloss:0.35700\n",
      "[419]\tvalidation_0-mlogloss:0.07393\tvalidation_1-mlogloss:0.35715\n",
      "[420]\tvalidation_0-mlogloss:0.07359\tvalidation_1-mlogloss:0.35697\n",
      "[421]\tvalidation_0-mlogloss:0.07325\tvalidation_1-mlogloss:0.35632\n",
      "[422]\tvalidation_0-mlogloss:0.07301\tvalidation_1-mlogloss:0.35585\n",
      "[423]\tvalidation_0-mlogloss:0.07269\tvalidation_1-mlogloss:0.35589\n",
      "[424]\tvalidation_0-mlogloss:0.07238\tvalidation_1-mlogloss:0.35537\n",
      "[425]\tvalidation_0-mlogloss:0.07212\tvalidation_1-mlogloss:0.35502\n",
      "[426]\tvalidation_0-mlogloss:0.07182\tvalidation_1-mlogloss:0.35486\n",
      "[427]\tvalidation_0-mlogloss:0.07150\tvalidation_1-mlogloss:0.35489\n",
      "[428]\tvalidation_0-mlogloss:0.07119\tvalidation_1-mlogloss:0.35493\n",
      "[429]\tvalidation_0-mlogloss:0.07085\tvalidation_1-mlogloss:0.35469\n",
      "[430]\tvalidation_0-mlogloss:0.07058\tvalidation_1-mlogloss:0.35450\n",
      "[431]\tvalidation_0-mlogloss:0.07027\tvalidation_1-mlogloss:0.35474\n",
      "[432]\tvalidation_0-mlogloss:0.07001\tvalidation_1-mlogloss:0.35463\n",
      "[433]\tvalidation_0-mlogloss:0.06974\tvalidation_1-mlogloss:0.35451\n",
      "[434]\tvalidation_0-mlogloss:0.06946\tvalidation_1-mlogloss:0.35456\n",
      "[435]\tvalidation_0-mlogloss:0.06919\tvalidation_1-mlogloss:0.35441\n",
      "[436]\tvalidation_0-mlogloss:0.06893\tvalidation_1-mlogloss:0.35406\n",
      "[437]\tvalidation_0-mlogloss:0.06863\tvalidation_1-mlogloss:0.35396\n",
      "[438]\tvalidation_0-mlogloss:0.06835\tvalidation_1-mlogloss:0.35378\n",
      "[439]\tvalidation_0-mlogloss:0.06808\tvalidation_1-mlogloss:0.35362\n",
      "[440]\tvalidation_0-mlogloss:0.06779\tvalidation_1-mlogloss:0.35352\n",
      "[441]\tvalidation_0-mlogloss:0.06752\tvalidation_1-mlogloss:0.35349\n",
      "[442]\tvalidation_0-mlogloss:0.06724\tvalidation_1-mlogloss:0.35364\n",
      "[443]\tvalidation_0-mlogloss:0.06696\tvalidation_1-mlogloss:0.35362\n",
      "[444]\tvalidation_0-mlogloss:0.06670\tvalidation_1-mlogloss:0.35362\n",
      "[445]\tvalidation_0-mlogloss:0.06646\tvalidation_1-mlogloss:0.35357\n",
      "[446]\tvalidation_0-mlogloss:0.06618\tvalidation_1-mlogloss:0.35293\n",
      "[447]\tvalidation_0-mlogloss:0.06595\tvalidation_1-mlogloss:0.35304\n",
      "[448]\tvalidation_0-mlogloss:0.06569\tvalidation_1-mlogloss:0.35288\n",
      "[449]\tvalidation_0-mlogloss:0.06544\tvalidation_1-mlogloss:0.35288\n",
      "[450]\tvalidation_0-mlogloss:0.06514\tvalidation_1-mlogloss:0.35271\n",
      "[451]\tvalidation_0-mlogloss:0.06492\tvalidation_1-mlogloss:0.35260\n",
      "[452]\tvalidation_0-mlogloss:0.06464\tvalidation_1-mlogloss:0.35231\n",
      "[453]\tvalidation_0-mlogloss:0.06451\tvalidation_1-mlogloss:0.35255\n",
      "[454]\tvalidation_0-mlogloss:0.06424\tvalidation_1-mlogloss:0.35219\n",
      "[455]\tvalidation_0-mlogloss:0.06404\tvalidation_1-mlogloss:0.35193\n",
      "[456]\tvalidation_0-mlogloss:0.06376\tvalidation_1-mlogloss:0.35194\n",
      "[457]\tvalidation_0-mlogloss:0.06354\tvalidation_1-mlogloss:0.35183\n",
      "[458]\tvalidation_0-mlogloss:0.06328\tvalidation_1-mlogloss:0.35152\n",
      "[459]\tvalidation_0-mlogloss:0.06300\tvalidation_1-mlogloss:0.35140\n",
      "[460]\tvalidation_0-mlogloss:0.06282\tvalidation_1-mlogloss:0.35079\n",
      "[461]\tvalidation_0-mlogloss:0.06261\tvalidation_1-mlogloss:0.35097\n",
      "[462]\tvalidation_0-mlogloss:0.06242\tvalidation_1-mlogloss:0.35114\n",
      "[463]\tvalidation_0-mlogloss:0.06224\tvalidation_1-mlogloss:0.35099\n",
      "[464]\tvalidation_0-mlogloss:0.06208\tvalidation_1-mlogloss:0.35089\n",
      "[465]\tvalidation_0-mlogloss:0.06195\tvalidation_1-mlogloss:0.35104\n",
      "[466]\tvalidation_0-mlogloss:0.06170\tvalidation_1-mlogloss:0.35076\n",
      "[467]\tvalidation_0-mlogloss:0.06153\tvalidation_1-mlogloss:0.35073\n",
      "[468]\tvalidation_0-mlogloss:0.06130\tvalidation_1-mlogloss:0.35061\n",
      "[469]\tvalidation_0-mlogloss:0.06106\tvalidation_1-mlogloss:0.35020\n",
      "[470]\tvalidation_0-mlogloss:0.06083\tvalidation_1-mlogloss:0.34955\n",
      "[471]\tvalidation_0-mlogloss:0.06069\tvalidation_1-mlogloss:0.34962\n",
      "[472]\tvalidation_0-mlogloss:0.06048\tvalidation_1-mlogloss:0.34930\n",
      "[473]\tvalidation_0-mlogloss:0.06030\tvalidation_1-mlogloss:0.34871\n",
      "[474]\tvalidation_0-mlogloss:0.06010\tvalidation_1-mlogloss:0.34822\n",
      "[475]\tvalidation_0-mlogloss:0.05988\tvalidation_1-mlogloss:0.34790\n",
      "[476]\tvalidation_0-mlogloss:0.05972\tvalidation_1-mlogloss:0.34783\n",
      "[477]\tvalidation_0-mlogloss:0.05953\tvalidation_1-mlogloss:0.34746\n",
      "[478]\tvalidation_0-mlogloss:0.05939\tvalidation_1-mlogloss:0.34727\n",
      "[479]\tvalidation_0-mlogloss:0.05922\tvalidation_1-mlogloss:0.34714\n",
      "[480]\tvalidation_0-mlogloss:0.05903\tvalidation_1-mlogloss:0.34704\n",
      "[481]\tvalidation_0-mlogloss:0.05879\tvalidation_1-mlogloss:0.34704\n",
      "[482]\tvalidation_0-mlogloss:0.05858\tvalidation_1-mlogloss:0.34697\n",
      "[483]\tvalidation_0-mlogloss:0.05838\tvalidation_1-mlogloss:0.34678\n",
      "[484]\tvalidation_0-mlogloss:0.05831\tvalidation_1-mlogloss:0.34667\n",
      "[485]\tvalidation_0-mlogloss:0.05809\tvalidation_1-mlogloss:0.34621\n",
      "[486]\tvalidation_0-mlogloss:0.05795\tvalidation_1-mlogloss:0.34603\n",
      "[487]\tvalidation_0-mlogloss:0.05776\tvalidation_1-mlogloss:0.34567\n",
      "[488]\tvalidation_0-mlogloss:0.05763\tvalidation_1-mlogloss:0.34563\n",
      "[489]\tvalidation_0-mlogloss:0.05752\tvalidation_1-mlogloss:0.34540\n",
      "[490]\tvalidation_0-mlogloss:0.05740\tvalidation_1-mlogloss:0.34544\n",
      "[491]\tvalidation_0-mlogloss:0.05729\tvalidation_1-mlogloss:0.34547\n",
      "[492]\tvalidation_0-mlogloss:0.05708\tvalidation_1-mlogloss:0.34537\n",
      "[493]\tvalidation_0-mlogloss:0.05691\tvalidation_1-mlogloss:0.34523\n",
      "[494]\tvalidation_0-mlogloss:0.05677\tvalidation_1-mlogloss:0.34483\n",
      "[495]\tvalidation_0-mlogloss:0.05656\tvalidation_1-mlogloss:0.34472\n",
      "[496]\tvalidation_0-mlogloss:0.05636\tvalidation_1-mlogloss:0.34435\n",
      "[497]\tvalidation_0-mlogloss:0.05625\tvalidation_1-mlogloss:0.34429\n",
      "[498]\tvalidation_0-mlogloss:0.05614\tvalidation_1-mlogloss:0.34407\n",
      "[499]\tvalidation_0-mlogloss:0.05601\tvalidation_1-mlogloss:0.34374\n",
      "[500]\tvalidation_0-mlogloss:0.05592\tvalidation_1-mlogloss:0.34368\n",
      "[501]\tvalidation_0-mlogloss:0.05580\tvalidation_1-mlogloss:0.34345\n",
      "[502]\tvalidation_0-mlogloss:0.05568\tvalidation_1-mlogloss:0.34338\n",
      "[503]\tvalidation_0-mlogloss:0.05555\tvalidation_1-mlogloss:0.34335\n",
      "[504]\tvalidation_0-mlogloss:0.05543\tvalidation_1-mlogloss:0.34290\n",
      "[505]\tvalidation_0-mlogloss:0.05537\tvalidation_1-mlogloss:0.34274\n",
      "[506]\tvalidation_0-mlogloss:0.05523\tvalidation_1-mlogloss:0.34265\n",
      "[507]\tvalidation_0-mlogloss:0.05511\tvalidation_1-mlogloss:0.34274\n",
      "[508]\tvalidation_0-mlogloss:0.05496\tvalidation_1-mlogloss:0.34266\n",
      "[509]\tvalidation_0-mlogloss:0.05490\tvalidation_1-mlogloss:0.34274\n",
      "[510]\tvalidation_0-mlogloss:0.05479\tvalidation_1-mlogloss:0.34284\n",
      "[511]\tvalidation_0-mlogloss:0.05465\tvalidation_1-mlogloss:0.34238\n",
      "[512]\tvalidation_0-mlogloss:0.05454\tvalidation_1-mlogloss:0.34229\n",
      "[513]\tvalidation_0-mlogloss:0.05445\tvalidation_1-mlogloss:0.34212\n",
      "[514]\tvalidation_0-mlogloss:0.05433\tvalidation_1-mlogloss:0.34224\n",
      "[515]\tvalidation_0-mlogloss:0.05425\tvalidation_1-mlogloss:0.34215\n",
      "[516]\tvalidation_0-mlogloss:0.05415\tvalidation_1-mlogloss:0.34193\n",
      "[517]\tvalidation_0-mlogloss:0.05399\tvalidation_1-mlogloss:0.34203\n",
      "[518]\tvalidation_0-mlogloss:0.05389\tvalidation_1-mlogloss:0.34192\n",
      "[519]\tvalidation_0-mlogloss:0.05378\tvalidation_1-mlogloss:0.34193\n",
      "[520]\tvalidation_0-mlogloss:0.05365\tvalidation_1-mlogloss:0.34189\n",
      "[521]\tvalidation_0-mlogloss:0.05359\tvalidation_1-mlogloss:0.34169\n",
      "[522]\tvalidation_0-mlogloss:0.05344\tvalidation_1-mlogloss:0.34176\n",
      "[523]\tvalidation_0-mlogloss:0.05334\tvalidation_1-mlogloss:0.34159\n",
      "[524]\tvalidation_0-mlogloss:0.05322\tvalidation_1-mlogloss:0.34169\n",
      "[525]\tvalidation_0-mlogloss:0.05310\tvalidation_1-mlogloss:0.34159\n",
      "[526]\tvalidation_0-mlogloss:0.05300\tvalidation_1-mlogloss:0.34135\n",
      "[527]\tvalidation_0-mlogloss:0.05289\tvalidation_1-mlogloss:0.34114\n",
      "[528]\tvalidation_0-mlogloss:0.05276\tvalidation_1-mlogloss:0.34118\n",
      "[529]\tvalidation_0-mlogloss:0.05270\tvalidation_1-mlogloss:0.34101\n",
      "[530]\tvalidation_0-mlogloss:0.05254\tvalidation_1-mlogloss:0.34066\n",
      "[531]\tvalidation_0-mlogloss:0.05238\tvalidation_1-mlogloss:0.34047\n",
      "[532]\tvalidation_0-mlogloss:0.05230\tvalidation_1-mlogloss:0.34033\n",
      "[533]\tvalidation_0-mlogloss:0.05221\tvalidation_1-mlogloss:0.34027\n",
      "[534]\tvalidation_0-mlogloss:0.05215\tvalidation_1-mlogloss:0.34041\n",
      "[535]\tvalidation_0-mlogloss:0.05203\tvalidation_1-mlogloss:0.34039\n",
      "[536]\tvalidation_0-mlogloss:0.05194\tvalidation_1-mlogloss:0.34020\n",
      "[537]\tvalidation_0-mlogloss:0.05186\tvalidation_1-mlogloss:0.34023\n",
      "[538]\tvalidation_0-mlogloss:0.05177\tvalidation_1-mlogloss:0.34001\n",
      "[539]\tvalidation_0-mlogloss:0.05167\tvalidation_1-mlogloss:0.33993\n",
      "[540]\tvalidation_0-mlogloss:0.05155\tvalidation_1-mlogloss:0.33970\n",
      "[541]\tvalidation_0-mlogloss:0.05145\tvalidation_1-mlogloss:0.33979\n",
      "[542]\tvalidation_0-mlogloss:0.05137\tvalidation_1-mlogloss:0.33968\n",
      "[543]\tvalidation_0-mlogloss:0.05130\tvalidation_1-mlogloss:0.33947\n",
      "[544]\tvalidation_0-mlogloss:0.05121\tvalidation_1-mlogloss:0.33941\n",
      "[545]\tvalidation_0-mlogloss:0.05113\tvalidation_1-mlogloss:0.33941\n",
      "[546]\tvalidation_0-mlogloss:0.05107\tvalidation_1-mlogloss:0.33919\n",
      "[547]\tvalidation_0-mlogloss:0.05101\tvalidation_1-mlogloss:0.33913\n",
      "[548]\tvalidation_0-mlogloss:0.05095\tvalidation_1-mlogloss:0.33938\n",
      "[549]\tvalidation_0-mlogloss:0.05084\tvalidation_1-mlogloss:0.33943\n",
      "[550]\tvalidation_0-mlogloss:0.05078\tvalidation_1-mlogloss:0.33934\n",
      "[551]\tvalidation_0-mlogloss:0.05070\tvalidation_1-mlogloss:0.33914\n",
      "[552]\tvalidation_0-mlogloss:0.05064\tvalidation_1-mlogloss:0.33903\n",
      "[553]\tvalidation_0-mlogloss:0.05056\tvalidation_1-mlogloss:0.33885\n",
      "[554]\tvalidation_0-mlogloss:0.05052\tvalidation_1-mlogloss:0.33874\n",
      "[555]\tvalidation_0-mlogloss:0.05048\tvalidation_1-mlogloss:0.33883\n",
      "[556]\tvalidation_0-mlogloss:0.05039\tvalidation_1-mlogloss:0.33857\n",
      "[557]\tvalidation_0-mlogloss:0.05029\tvalidation_1-mlogloss:0.33870\n",
      "[558]\tvalidation_0-mlogloss:0.05021\tvalidation_1-mlogloss:0.33861\n",
      "[559]\tvalidation_0-mlogloss:0.05014\tvalidation_1-mlogloss:0.33859\n",
      "[560]\tvalidation_0-mlogloss:0.05012\tvalidation_1-mlogloss:0.33848\n",
      "[561]\tvalidation_0-mlogloss:0.05006\tvalidation_1-mlogloss:0.33838\n",
      "[562]\tvalidation_0-mlogloss:0.05001\tvalidation_1-mlogloss:0.33837\n",
      "[563]\tvalidation_0-mlogloss:0.04992\tvalidation_1-mlogloss:0.33812\n",
      "[564]\tvalidation_0-mlogloss:0.04981\tvalidation_1-mlogloss:0.33808\n",
      "[565]\tvalidation_0-mlogloss:0.04972\tvalidation_1-mlogloss:0.33790\n",
      "[566]\tvalidation_0-mlogloss:0.04970\tvalidation_1-mlogloss:0.33782\n",
      "[567]\tvalidation_0-mlogloss:0.04966\tvalidation_1-mlogloss:0.33791\n",
      "[568]\tvalidation_0-mlogloss:0.04961\tvalidation_1-mlogloss:0.33805\n",
      "[569]\tvalidation_0-mlogloss:0.04956\tvalidation_1-mlogloss:0.33799\n",
      "[570]\tvalidation_0-mlogloss:0.04947\tvalidation_1-mlogloss:0.33789\n",
      "[571]\tvalidation_0-mlogloss:0.04942\tvalidation_1-mlogloss:0.33787\n",
      "[572]\tvalidation_0-mlogloss:0.04935\tvalidation_1-mlogloss:0.33770\n",
      "[573]\tvalidation_0-mlogloss:0.04930\tvalidation_1-mlogloss:0.33767\n",
      "[574]\tvalidation_0-mlogloss:0.04926\tvalidation_1-mlogloss:0.33779\n",
      "[575]\tvalidation_0-mlogloss:0.04919\tvalidation_1-mlogloss:0.33762\n",
      "[576]\tvalidation_0-mlogloss:0.04915\tvalidation_1-mlogloss:0.33766\n",
      "[577]\tvalidation_0-mlogloss:0.04910\tvalidation_1-mlogloss:0.33749\n",
      "[578]\tvalidation_0-mlogloss:0.04901\tvalidation_1-mlogloss:0.33741\n",
      "[579]\tvalidation_0-mlogloss:0.04896\tvalidation_1-mlogloss:0.33715\n",
      "[580]\tvalidation_0-mlogloss:0.04888\tvalidation_1-mlogloss:0.33695\n",
      "[581]\tvalidation_0-mlogloss:0.04886\tvalidation_1-mlogloss:0.33678\n",
      "[582]\tvalidation_0-mlogloss:0.04882\tvalidation_1-mlogloss:0.33660\n",
      "[583]\tvalidation_0-mlogloss:0.04877\tvalidation_1-mlogloss:0.33659\n",
      "[584]\tvalidation_0-mlogloss:0.04871\tvalidation_1-mlogloss:0.33666\n",
      "[585]\tvalidation_0-mlogloss:0.04866\tvalidation_1-mlogloss:0.33645\n",
      "[586]\tvalidation_0-mlogloss:0.04862\tvalidation_1-mlogloss:0.33647\n",
      "[587]\tvalidation_0-mlogloss:0.04855\tvalidation_1-mlogloss:0.33644\n",
      "[588]\tvalidation_0-mlogloss:0.04852\tvalidation_1-mlogloss:0.33635\n",
      "[589]\tvalidation_0-mlogloss:0.04845\tvalidation_1-mlogloss:0.33624\n",
      "[590]\tvalidation_0-mlogloss:0.04844\tvalidation_1-mlogloss:0.33629\n",
      "[591]\tvalidation_0-mlogloss:0.04840\tvalidation_1-mlogloss:0.33640\n",
      "[592]\tvalidation_0-mlogloss:0.04838\tvalidation_1-mlogloss:0.33649\n",
      "[593]\tvalidation_0-mlogloss:0.04831\tvalidation_1-mlogloss:0.33647\n",
      "[594]\tvalidation_0-mlogloss:0.04827\tvalidation_1-mlogloss:0.33626\n",
      "[595]\tvalidation_0-mlogloss:0.04825\tvalidation_1-mlogloss:0.33638\n",
      "[596]\tvalidation_0-mlogloss:0.04821\tvalidation_1-mlogloss:0.33621\n",
      "[597]\tvalidation_0-mlogloss:0.04819\tvalidation_1-mlogloss:0.33628\n",
      "[598]\tvalidation_0-mlogloss:0.04812\tvalidation_1-mlogloss:0.33603\n",
      "[599]\tvalidation_0-mlogloss:0.04807\tvalidation_1-mlogloss:0.33622\n",
      "[600]\tvalidation_0-mlogloss:0.04803\tvalidation_1-mlogloss:0.33625\n",
      "[601]\tvalidation_0-mlogloss:0.04798\tvalidation_1-mlogloss:0.33623\n",
      "[602]\tvalidation_0-mlogloss:0.04793\tvalidation_1-mlogloss:0.33631\n",
      "[603]\tvalidation_0-mlogloss:0.04784\tvalidation_1-mlogloss:0.33610\n",
      "[604]\tvalidation_0-mlogloss:0.04777\tvalidation_1-mlogloss:0.33593\n",
      "[605]\tvalidation_0-mlogloss:0.04772\tvalidation_1-mlogloss:0.33589\n",
      "[606]\tvalidation_0-mlogloss:0.04768\tvalidation_1-mlogloss:0.33600\n",
      "[607]\tvalidation_0-mlogloss:0.04762\tvalidation_1-mlogloss:0.33579\n",
      "[608]\tvalidation_0-mlogloss:0.04758\tvalidation_1-mlogloss:0.33575\n",
      "[609]\tvalidation_0-mlogloss:0.04756\tvalidation_1-mlogloss:0.33563\n",
      "[610]\tvalidation_0-mlogloss:0.04754\tvalidation_1-mlogloss:0.33569\n",
      "[611]\tvalidation_0-mlogloss:0.04752\tvalidation_1-mlogloss:0.33552\n",
      "[612]\tvalidation_0-mlogloss:0.04748\tvalidation_1-mlogloss:0.33566\n",
      "[613]\tvalidation_0-mlogloss:0.04745\tvalidation_1-mlogloss:0.33576\n",
      "[614]\tvalidation_0-mlogloss:0.04741\tvalidation_1-mlogloss:0.33594\n",
      "[615]\tvalidation_0-mlogloss:0.04734\tvalidation_1-mlogloss:0.33579\n",
      "[616]\tvalidation_0-mlogloss:0.04729\tvalidation_1-mlogloss:0.33575\n",
      "[617]\tvalidation_0-mlogloss:0.04727\tvalidation_1-mlogloss:0.33581\n",
      "[618]\tvalidation_0-mlogloss:0.04723\tvalidation_1-mlogloss:0.33572\n",
      "[619]\tvalidation_0-mlogloss:0.04719\tvalidation_1-mlogloss:0.33575\n",
      "[620]\tvalidation_0-mlogloss:0.04717\tvalidation_1-mlogloss:0.33563\n",
      "[621]\tvalidation_0-mlogloss:0.04713\tvalidation_1-mlogloss:0.33536\n",
      "[622]\tvalidation_0-mlogloss:0.04709\tvalidation_1-mlogloss:0.33534\n",
      "[623]\tvalidation_0-mlogloss:0.04705\tvalidation_1-mlogloss:0.33552\n",
      "[624]\tvalidation_0-mlogloss:0.04704\tvalidation_1-mlogloss:0.33565\n",
      "[625]\tvalidation_0-mlogloss:0.04699\tvalidation_1-mlogloss:0.33544\n",
      "[626]\tvalidation_0-mlogloss:0.04695\tvalidation_1-mlogloss:0.33556\n",
      "[627]\tvalidation_0-mlogloss:0.04692\tvalidation_1-mlogloss:0.33561\n",
      "[628]\tvalidation_0-mlogloss:0.04690\tvalidation_1-mlogloss:0.33568\n",
      "[629]\tvalidation_0-mlogloss:0.04686\tvalidation_1-mlogloss:0.33579\n",
      "[630]\tvalidation_0-mlogloss:0.04683\tvalidation_1-mlogloss:0.33585\n",
      "[631]\tvalidation_0-mlogloss:0.04681\tvalidation_1-mlogloss:0.33576\n",
      "[632]\tvalidation_0-mlogloss:0.04677\tvalidation_1-mlogloss:0.33588\n",
      "[633]\tvalidation_0-mlogloss:0.04674\tvalidation_1-mlogloss:0.33586\n",
      "[634]\tvalidation_0-mlogloss:0.04667\tvalidation_1-mlogloss:0.33583\n",
      "[635]\tvalidation_0-mlogloss:0.04665\tvalidation_1-mlogloss:0.33586\n",
      "[636]\tvalidation_0-mlogloss:0.04662\tvalidation_1-mlogloss:0.33582\n",
      "[637]\tvalidation_0-mlogloss:0.04657\tvalidation_1-mlogloss:0.33573\n",
      "[638]\tvalidation_0-mlogloss:0.04655\tvalidation_1-mlogloss:0.33557\n",
      "[639]\tvalidation_0-mlogloss:0.04648\tvalidation_1-mlogloss:0.33559\n",
      "[640]\tvalidation_0-mlogloss:0.04644\tvalidation_1-mlogloss:0.33574\n",
      "[641]\tvalidation_0-mlogloss:0.04640\tvalidation_1-mlogloss:0.33587\n",
      "[642]\tvalidation_0-mlogloss:0.04637\tvalidation_1-mlogloss:0.33600\n",
      "[16:53:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-mlogloss:1.59272\tvalidation_1-mlogloss:1.59658\n",
      "[1]\tvalidation_0-mlogloss:1.57447\tvalidation_1-mlogloss:1.58126\n",
      "[2]\tvalidation_0-mlogloss:1.55682\tvalidation_1-mlogloss:1.56794\n",
      "[3]\tvalidation_0-mlogloss:1.53944\tvalidation_1-mlogloss:1.55295\n",
      "[4]\tvalidation_0-mlogloss:1.52277\tvalidation_1-mlogloss:1.54054\n",
      "[5]\tvalidation_0-mlogloss:1.50755\tvalidation_1-mlogloss:1.52745\n",
      "[6]\tvalidation_0-mlogloss:1.49006\tvalidation_1-mlogloss:1.51299\n",
      "[7]\tvalidation_0-mlogloss:1.47471\tvalidation_1-mlogloss:1.50074\n",
      "[8]\tvalidation_0-mlogloss:1.45791\tvalidation_1-mlogloss:1.48556\n",
      "[9]\tvalidation_0-mlogloss:1.44235\tvalidation_1-mlogloss:1.47529\n",
      "[10]\tvalidation_0-mlogloss:1.42633\tvalidation_1-mlogloss:1.46037\n",
      "[11]\tvalidation_0-mlogloss:1.40985\tvalidation_1-mlogloss:1.44538\n",
      "[12]\tvalidation_0-mlogloss:1.39479\tvalidation_1-mlogloss:1.43227\n",
      "[13]\tvalidation_0-mlogloss:1.38064\tvalidation_1-mlogloss:1.42148\n",
      "[14]\tvalidation_0-mlogloss:1.36546\tvalidation_1-mlogloss:1.40828\n",
      "[15]\tvalidation_0-mlogloss:1.35155\tvalidation_1-mlogloss:1.39826\n",
      "[16]\tvalidation_0-mlogloss:1.33767\tvalidation_1-mlogloss:1.38528\n",
      "[17]\tvalidation_0-mlogloss:1.32384\tvalidation_1-mlogloss:1.37524\n",
      "[18]\tvalidation_0-mlogloss:1.31027\tvalidation_1-mlogloss:1.36533\n",
      "[19]\tvalidation_0-mlogloss:1.29596\tvalidation_1-mlogloss:1.35352\n",
      "[20]\tvalidation_0-mlogloss:1.28285\tvalidation_1-mlogloss:1.34325\n",
      "[21]\tvalidation_0-mlogloss:1.26936\tvalidation_1-mlogloss:1.33252\n",
      "[22]\tvalidation_0-mlogloss:1.25568\tvalidation_1-mlogloss:1.32102\n",
      "[23]\tvalidation_0-mlogloss:1.24222\tvalidation_1-mlogloss:1.31014\n",
      "[24]\tvalidation_0-mlogloss:1.22938\tvalidation_1-mlogloss:1.29913\n",
      "[25]\tvalidation_0-mlogloss:1.21703\tvalidation_1-mlogloss:1.28985\n",
      "[26]\tvalidation_0-mlogloss:1.20510\tvalidation_1-mlogloss:1.28020\n",
      "[27]\tvalidation_0-mlogloss:1.19300\tvalidation_1-mlogloss:1.27114\n",
      "[28]\tvalidation_0-mlogloss:1.18089\tvalidation_1-mlogloss:1.26134\n",
      "[29]\tvalidation_0-mlogloss:1.16887\tvalidation_1-mlogloss:1.25064\n",
      "[30]\tvalidation_0-mlogloss:1.15660\tvalidation_1-mlogloss:1.23953\n",
      "[31]\tvalidation_0-mlogloss:1.14474\tvalidation_1-mlogloss:1.22934\n",
      "[32]\tvalidation_0-mlogloss:1.13341\tvalidation_1-mlogloss:1.22006\n",
      "[33]\tvalidation_0-mlogloss:1.12269\tvalidation_1-mlogloss:1.21253\n",
      "[34]\tvalidation_0-mlogloss:1.11129\tvalidation_1-mlogloss:1.20411\n",
      "[35]\tvalidation_0-mlogloss:1.10041\tvalidation_1-mlogloss:1.19481\n",
      "[36]\tvalidation_0-mlogloss:1.08957\tvalidation_1-mlogloss:1.18705\n",
      "[37]\tvalidation_0-mlogloss:1.07988\tvalidation_1-mlogloss:1.18026\n",
      "[38]\tvalidation_0-mlogloss:1.06904\tvalidation_1-mlogloss:1.17088\n",
      "[39]\tvalidation_0-mlogloss:1.05868\tvalidation_1-mlogloss:1.16303\n",
      "[40]\tvalidation_0-mlogloss:1.04857\tvalidation_1-mlogloss:1.15538\n",
      "[41]\tvalidation_0-mlogloss:1.03796\tvalidation_1-mlogloss:1.14608\n",
      "[42]\tvalidation_0-mlogloss:1.02759\tvalidation_1-mlogloss:1.13682\n",
      "[43]\tvalidation_0-mlogloss:1.01759\tvalidation_1-mlogloss:1.12831\n",
      "[44]\tvalidation_0-mlogloss:1.00737\tvalidation_1-mlogloss:1.11933\n",
      "[45]\tvalidation_0-mlogloss:0.99747\tvalidation_1-mlogloss:1.11170\n",
      "[46]\tvalidation_0-mlogloss:0.98809\tvalidation_1-mlogloss:1.10365\n",
      "[47]\tvalidation_0-mlogloss:0.97843\tvalidation_1-mlogloss:1.09609\n",
      "[48]\tvalidation_0-mlogloss:0.96925\tvalidation_1-mlogloss:1.08869\n",
      "[49]\tvalidation_0-mlogloss:0.95965\tvalidation_1-mlogloss:1.08150\n",
      "[50]\tvalidation_0-mlogloss:0.95048\tvalidation_1-mlogloss:1.07285\n",
      "[51]\tvalidation_0-mlogloss:0.94161\tvalidation_1-mlogloss:1.06656\n",
      "[52]\tvalidation_0-mlogloss:0.93234\tvalidation_1-mlogloss:1.05904\n",
      "[53]\tvalidation_0-mlogloss:0.92381\tvalidation_1-mlogloss:1.05298\n",
      "[54]\tvalidation_0-mlogloss:0.91525\tvalidation_1-mlogloss:1.04522\n",
      "[55]\tvalidation_0-mlogloss:0.90679\tvalidation_1-mlogloss:1.03849\n",
      "[56]\tvalidation_0-mlogloss:0.89928\tvalidation_1-mlogloss:1.03252\n",
      "[57]\tvalidation_0-mlogloss:0.89089\tvalidation_1-mlogloss:1.02610\n",
      "[58]\tvalidation_0-mlogloss:0.88337\tvalidation_1-mlogloss:1.01989\n",
      "[59]\tvalidation_0-mlogloss:0.87514\tvalidation_1-mlogloss:1.01302\n",
      "[60]\tvalidation_0-mlogloss:0.86720\tvalidation_1-mlogloss:1.00632\n",
      "[61]\tvalidation_0-mlogloss:0.85889\tvalidation_1-mlogloss:0.99848\n",
      "[62]\tvalidation_0-mlogloss:0.85091\tvalidation_1-mlogloss:0.99188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63]\tvalidation_0-mlogloss:0.84273\tvalidation_1-mlogloss:0.98540\n",
      "[64]\tvalidation_0-mlogloss:0.83462\tvalidation_1-mlogloss:0.97782\n",
      "[65]\tvalidation_0-mlogloss:0.82720\tvalidation_1-mlogloss:0.97128\n",
      "[66]\tvalidation_0-mlogloss:0.81995\tvalidation_1-mlogloss:0.96544\n",
      "[67]\tvalidation_0-mlogloss:0.81256\tvalidation_1-mlogloss:0.96017\n",
      "[68]\tvalidation_0-mlogloss:0.80487\tvalidation_1-mlogloss:0.95393\n",
      "[69]\tvalidation_0-mlogloss:0.79719\tvalidation_1-mlogloss:0.94724\n",
      "[70]\tvalidation_0-mlogloss:0.78990\tvalidation_1-mlogloss:0.94107\n",
      "[71]\tvalidation_0-mlogloss:0.78272\tvalidation_1-mlogloss:0.93449\n",
      "[72]\tvalidation_0-mlogloss:0.77552\tvalidation_1-mlogloss:0.92801\n",
      "[73]\tvalidation_0-mlogloss:0.76854\tvalidation_1-mlogloss:0.92348\n",
      "[74]\tvalidation_0-mlogloss:0.76194\tvalidation_1-mlogloss:0.91802\n",
      "[75]\tvalidation_0-mlogloss:0.75504\tvalidation_1-mlogloss:0.91159\n",
      "[76]\tvalidation_0-mlogloss:0.74860\tvalidation_1-mlogloss:0.90711\n",
      "[77]\tvalidation_0-mlogloss:0.74184\tvalidation_1-mlogloss:0.90314\n",
      "[78]\tvalidation_0-mlogloss:0.73568\tvalidation_1-mlogloss:0.89799\n",
      "[79]\tvalidation_0-mlogloss:0.72921\tvalidation_1-mlogloss:0.89300\n",
      "[80]\tvalidation_0-mlogloss:0.72289\tvalidation_1-mlogloss:0.88768\n",
      "[81]\tvalidation_0-mlogloss:0.71636\tvalidation_1-mlogloss:0.88253\n",
      "[82]\tvalidation_0-mlogloss:0.70994\tvalidation_1-mlogloss:0.87655\n",
      "[83]\tvalidation_0-mlogloss:0.70384\tvalidation_1-mlogloss:0.87257\n",
      "[84]\tvalidation_0-mlogloss:0.69755\tvalidation_1-mlogloss:0.86763\n",
      "[85]\tvalidation_0-mlogloss:0.69123\tvalidation_1-mlogloss:0.86288\n",
      "[86]\tvalidation_0-mlogloss:0.68516\tvalidation_1-mlogloss:0.85768\n",
      "[87]\tvalidation_0-mlogloss:0.67876\tvalidation_1-mlogloss:0.85211\n",
      "[88]\tvalidation_0-mlogloss:0.67244\tvalidation_1-mlogloss:0.84606\n",
      "[89]\tvalidation_0-mlogloss:0.66664\tvalidation_1-mlogloss:0.84196\n",
      "[90]\tvalidation_0-mlogloss:0.66058\tvalidation_1-mlogloss:0.83682\n",
      "[91]\tvalidation_0-mlogloss:0.65476\tvalidation_1-mlogloss:0.83208\n",
      "[92]\tvalidation_0-mlogloss:0.64863\tvalidation_1-mlogloss:0.82599\n",
      "[93]\tvalidation_0-mlogloss:0.64331\tvalidation_1-mlogloss:0.82268\n",
      "[94]\tvalidation_0-mlogloss:0.63776\tvalidation_1-mlogloss:0.81814\n",
      "[95]\tvalidation_0-mlogloss:0.63185\tvalidation_1-mlogloss:0.81244\n",
      "[96]\tvalidation_0-mlogloss:0.62606\tvalidation_1-mlogloss:0.80701\n",
      "[97]\tvalidation_0-mlogloss:0.62065\tvalidation_1-mlogloss:0.80194\n",
      "[98]\tvalidation_0-mlogloss:0.61507\tvalidation_1-mlogloss:0.79585\n",
      "[99]\tvalidation_0-mlogloss:0.60957\tvalidation_1-mlogloss:0.79170\n",
      "[100]\tvalidation_0-mlogloss:0.60434\tvalidation_1-mlogloss:0.78799\n",
      "[101]\tvalidation_0-mlogloss:0.59917\tvalidation_1-mlogloss:0.78385\n",
      "[102]\tvalidation_0-mlogloss:0.59418\tvalidation_1-mlogloss:0.77991\n",
      "[103]\tvalidation_0-mlogloss:0.58905\tvalidation_1-mlogloss:0.77604\n",
      "[104]\tvalidation_0-mlogloss:0.58366\tvalidation_1-mlogloss:0.77089\n",
      "[105]\tvalidation_0-mlogloss:0.57894\tvalidation_1-mlogloss:0.76756\n",
      "[106]\tvalidation_0-mlogloss:0.57373\tvalidation_1-mlogloss:0.76211\n",
      "[107]\tvalidation_0-mlogloss:0.56845\tvalidation_1-mlogloss:0.75696\n",
      "[108]\tvalidation_0-mlogloss:0.56400\tvalidation_1-mlogloss:0.75346\n",
      "[109]\tvalidation_0-mlogloss:0.55905\tvalidation_1-mlogloss:0.74904\n",
      "[110]\tvalidation_0-mlogloss:0.55418\tvalidation_1-mlogloss:0.74439\n",
      "[111]\tvalidation_0-mlogloss:0.54993\tvalidation_1-mlogloss:0.74043\n",
      "[112]\tvalidation_0-mlogloss:0.54532\tvalidation_1-mlogloss:0.73604\n",
      "[113]\tvalidation_0-mlogloss:0.54073\tvalidation_1-mlogloss:0.73249\n",
      "[114]\tvalidation_0-mlogloss:0.53597\tvalidation_1-mlogloss:0.72761\n",
      "[115]\tvalidation_0-mlogloss:0.53124\tvalidation_1-mlogloss:0.72308\n",
      "[116]\tvalidation_0-mlogloss:0.52657\tvalidation_1-mlogloss:0.71847\n",
      "[117]\tvalidation_0-mlogloss:0.52198\tvalidation_1-mlogloss:0.71464\n",
      "[118]\tvalidation_0-mlogloss:0.51766\tvalidation_1-mlogloss:0.71163\n",
      "[119]\tvalidation_0-mlogloss:0.51334\tvalidation_1-mlogloss:0.70843\n",
      "[120]\tvalidation_0-mlogloss:0.50891\tvalidation_1-mlogloss:0.70456\n",
      "[121]\tvalidation_0-mlogloss:0.50467\tvalidation_1-mlogloss:0.70052\n",
      "[122]\tvalidation_0-mlogloss:0.50050\tvalidation_1-mlogloss:0.69773\n",
      "[123]\tvalidation_0-mlogloss:0.49628\tvalidation_1-mlogloss:0.69474\n",
      "[124]\tvalidation_0-mlogloss:0.49215\tvalidation_1-mlogloss:0.69016\n",
      "[125]\tvalidation_0-mlogloss:0.48778\tvalidation_1-mlogloss:0.68635\n",
      "[126]\tvalidation_0-mlogloss:0.48346\tvalidation_1-mlogloss:0.68184\n",
      "[127]\tvalidation_0-mlogloss:0.47960\tvalidation_1-mlogloss:0.67893\n",
      "[128]\tvalidation_0-mlogloss:0.47545\tvalidation_1-mlogloss:0.67448\n",
      "[129]\tvalidation_0-mlogloss:0.47149\tvalidation_1-mlogloss:0.67091\n",
      "[130]\tvalidation_0-mlogloss:0.46759\tvalidation_1-mlogloss:0.66769\n",
      "[131]\tvalidation_0-mlogloss:0.46370\tvalidation_1-mlogloss:0.66497\n",
      "[132]\tvalidation_0-mlogloss:0.45977\tvalidation_1-mlogloss:0.66174\n",
      "[133]\tvalidation_0-mlogloss:0.45599\tvalidation_1-mlogloss:0.65861\n",
      "[134]\tvalidation_0-mlogloss:0.45256\tvalidation_1-mlogloss:0.65622\n",
      "[135]\tvalidation_0-mlogloss:0.44879\tvalidation_1-mlogloss:0.65236\n",
      "[136]\tvalidation_0-mlogloss:0.44517\tvalidation_1-mlogloss:0.64931\n",
      "[137]\tvalidation_0-mlogloss:0.44148\tvalidation_1-mlogloss:0.64638\n",
      "[138]\tvalidation_0-mlogloss:0.43803\tvalidation_1-mlogloss:0.64343\n",
      "[139]\tvalidation_0-mlogloss:0.43445\tvalidation_1-mlogloss:0.64025\n",
      "[140]\tvalidation_0-mlogloss:0.43082\tvalidation_1-mlogloss:0.63721\n",
      "[141]\tvalidation_0-mlogloss:0.42757\tvalidation_1-mlogloss:0.63447\n",
      "[142]\tvalidation_0-mlogloss:0.42408\tvalidation_1-mlogloss:0.63132\n",
      "[143]\tvalidation_0-mlogloss:0.42079\tvalidation_1-mlogloss:0.62902\n",
      "[144]\tvalidation_0-mlogloss:0.41748\tvalidation_1-mlogloss:0.62607\n",
      "[145]\tvalidation_0-mlogloss:0.41422\tvalidation_1-mlogloss:0.62367\n",
      "[146]\tvalidation_0-mlogloss:0.41107\tvalidation_1-mlogloss:0.62106\n",
      "[147]\tvalidation_0-mlogloss:0.40783\tvalidation_1-mlogloss:0.61874\n",
      "[148]\tvalidation_0-mlogloss:0.40485\tvalidation_1-mlogloss:0.61692\n",
      "[149]\tvalidation_0-mlogloss:0.40147\tvalidation_1-mlogloss:0.61460\n",
      "[150]\tvalidation_0-mlogloss:0.39812\tvalidation_1-mlogloss:0.61130\n",
      "[151]\tvalidation_0-mlogloss:0.39489\tvalidation_1-mlogloss:0.60807\n",
      "[152]\tvalidation_0-mlogloss:0.39161\tvalidation_1-mlogloss:0.60485\n",
      "[153]\tvalidation_0-mlogloss:0.38853\tvalidation_1-mlogloss:0.60262\n",
      "[154]\tvalidation_0-mlogloss:0.38541\tvalidation_1-mlogloss:0.60040\n",
      "[155]\tvalidation_0-mlogloss:0.38226\tvalidation_1-mlogloss:0.59778\n",
      "[156]\tvalidation_0-mlogloss:0.37921\tvalidation_1-mlogloss:0.59546\n",
      "[157]\tvalidation_0-mlogloss:0.37624\tvalidation_1-mlogloss:0.59265\n",
      "[158]\tvalidation_0-mlogloss:0.37310\tvalidation_1-mlogloss:0.58989\n",
      "[159]\tvalidation_0-mlogloss:0.37006\tvalidation_1-mlogloss:0.58692\n",
      "[160]\tvalidation_0-mlogloss:0.36719\tvalidation_1-mlogloss:0.58492\n",
      "[161]\tvalidation_0-mlogloss:0.36440\tvalidation_1-mlogloss:0.58282\n",
      "[162]\tvalidation_0-mlogloss:0.36142\tvalidation_1-mlogloss:0.58047\n",
      "[163]\tvalidation_0-mlogloss:0.35856\tvalidation_1-mlogloss:0.57864\n",
      "[164]\tvalidation_0-mlogloss:0.35566\tvalidation_1-mlogloss:0.57587\n",
      "[165]\tvalidation_0-mlogloss:0.35274\tvalidation_1-mlogloss:0.57287\n",
      "[166]\tvalidation_0-mlogloss:0.34997\tvalidation_1-mlogloss:0.57070\n",
      "[167]\tvalidation_0-mlogloss:0.34732\tvalidation_1-mlogloss:0.56865\n",
      "[168]\tvalidation_0-mlogloss:0.34460\tvalidation_1-mlogloss:0.56600\n",
      "[169]\tvalidation_0-mlogloss:0.34176\tvalidation_1-mlogloss:0.56347\n",
      "[170]\tvalidation_0-mlogloss:0.33897\tvalidation_1-mlogloss:0.56087\n",
      "[171]\tvalidation_0-mlogloss:0.33638\tvalidation_1-mlogloss:0.55825\n",
      "[172]\tvalidation_0-mlogloss:0.33381\tvalidation_1-mlogloss:0.55603\n",
      "[173]\tvalidation_0-mlogloss:0.33132\tvalidation_1-mlogloss:0.55411\n",
      "[174]\tvalidation_0-mlogloss:0.32866\tvalidation_1-mlogloss:0.55154\n",
      "[175]\tvalidation_0-mlogloss:0.32613\tvalidation_1-mlogloss:0.54961\n",
      "[176]\tvalidation_0-mlogloss:0.32353\tvalidation_1-mlogloss:0.54763\n",
      "[177]\tvalidation_0-mlogloss:0.32102\tvalidation_1-mlogloss:0.54564\n",
      "[178]\tvalidation_0-mlogloss:0.31842\tvalidation_1-mlogloss:0.54289\n",
      "[179]\tvalidation_0-mlogloss:0.31596\tvalidation_1-mlogloss:0.54083\n",
      "[180]\tvalidation_0-mlogloss:0.31351\tvalidation_1-mlogloss:0.53895\n",
      "[181]\tvalidation_0-mlogloss:0.31101\tvalidation_1-mlogloss:0.53639\n",
      "[182]\tvalidation_0-mlogloss:0.30877\tvalidation_1-mlogloss:0.53516\n",
      "[183]\tvalidation_0-mlogloss:0.30626\tvalidation_1-mlogloss:0.53231\n",
      "[184]\tvalidation_0-mlogloss:0.30389\tvalidation_1-mlogloss:0.52996\n",
      "[185]\tvalidation_0-mlogloss:0.30158\tvalidation_1-mlogloss:0.52778\n",
      "[186]\tvalidation_0-mlogloss:0.29930\tvalidation_1-mlogloss:0.52603\n",
      "[187]\tvalidation_0-mlogloss:0.29705\tvalidation_1-mlogloss:0.52478\n",
      "[188]\tvalidation_0-mlogloss:0.29484\tvalidation_1-mlogloss:0.52257\n",
      "[189]\tvalidation_0-mlogloss:0.29267\tvalidation_1-mlogloss:0.52129\n",
      "[190]\tvalidation_0-mlogloss:0.29050\tvalidation_1-mlogloss:0.51936\n",
      "[191]\tvalidation_0-mlogloss:0.28826\tvalidation_1-mlogloss:0.51729\n",
      "[192]\tvalidation_0-mlogloss:0.28616\tvalidation_1-mlogloss:0.51535\n",
      "[193]\tvalidation_0-mlogloss:0.28394\tvalidation_1-mlogloss:0.51281\n",
      "[194]\tvalidation_0-mlogloss:0.28180\tvalidation_1-mlogloss:0.51183\n",
      "[195]\tvalidation_0-mlogloss:0.27960\tvalidation_1-mlogloss:0.50925\n",
      "[196]\tvalidation_0-mlogloss:0.27748\tvalidation_1-mlogloss:0.50751\n",
      "[197]\tvalidation_0-mlogloss:0.27540\tvalidation_1-mlogloss:0.50586\n",
      "[198]\tvalidation_0-mlogloss:0.27334\tvalidation_1-mlogloss:0.50370\n",
      "[199]\tvalidation_0-mlogloss:0.27128\tvalidation_1-mlogloss:0.50234\n",
      "[200]\tvalidation_0-mlogloss:0.26926\tvalidation_1-mlogloss:0.50083\n",
      "[201]\tvalidation_0-mlogloss:0.26735\tvalidation_1-mlogloss:0.49965\n",
      "[202]\tvalidation_0-mlogloss:0.26539\tvalidation_1-mlogloss:0.49821\n",
      "[203]\tvalidation_0-mlogloss:0.26353\tvalidation_1-mlogloss:0.49695\n",
      "[204]\tvalidation_0-mlogloss:0.26170\tvalidation_1-mlogloss:0.49495\n",
      "[205]\tvalidation_0-mlogloss:0.25997\tvalidation_1-mlogloss:0.49363\n",
      "[206]\tvalidation_0-mlogloss:0.25800\tvalidation_1-mlogloss:0.49178\n",
      "[207]\tvalidation_0-mlogloss:0.25623\tvalidation_1-mlogloss:0.49023\n",
      "[208]\tvalidation_0-mlogloss:0.25438\tvalidation_1-mlogloss:0.48884\n",
      "[209]\tvalidation_0-mlogloss:0.25247\tvalidation_1-mlogloss:0.48702\n",
      "[210]\tvalidation_0-mlogloss:0.25059\tvalidation_1-mlogloss:0.48598\n",
      "[211]\tvalidation_0-mlogloss:0.24882\tvalidation_1-mlogloss:0.48484\n",
      "[212]\tvalidation_0-mlogloss:0.24703\tvalidation_1-mlogloss:0.48325\n",
      "[213]\tvalidation_0-mlogloss:0.24534\tvalidation_1-mlogloss:0.48208\n",
      "[214]\tvalidation_0-mlogloss:0.24359\tvalidation_1-mlogloss:0.48071\n",
      "[215]\tvalidation_0-mlogloss:0.24185\tvalidation_1-mlogloss:0.47958\n",
      "[216]\tvalidation_0-mlogloss:0.24009\tvalidation_1-mlogloss:0.47829\n",
      "[217]\tvalidation_0-mlogloss:0.23841\tvalidation_1-mlogloss:0.47737\n",
      "[218]\tvalidation_0-mlogloss:0.23676\tvalidation_1-mlogloss:0.47645\n",
      "[219]\tvalidation_0-mlogloss:0.23510\tvalidation_1-mlogloss:0.47431\n",
      "[220]\tvalidation_0-mlogloss:0.23347\tvalidation_1-mlogloss:0.47317\n",
      "[221]\tvalidation_0-mlogloss:0.23182\tvalidation_1-mlogloss:0.47195\n",
      "[222]\tvalidation_0-mlogloss:0.23021\tvalidation_1-mlogloss:0.47044\n",
      "[223]\tvalidation_0-mlogloss:0.22852\tvalidation_1-mlogloss:0.46897\n",
      "[224]\tvalidation_0-mlogloss:0.22698\tvalidation_1-mlogloss:0.46791\n",
      "[225]\tvalidation_0-mlogloss:0.22530\tvalidation_1-mlogloss:0.46661\n",
      "[226]\tvalidation_0-mlogloss:0.22361\tvalidation_1-mlogloss:0.46489\n",
      "[227]\tvalidation_0-mlogloss:0.22200\tvalidation_1-mlogloss:0.46342\n",
      "[228]\tvalidation_0-mlogloss:0.22045\tvalidation_1-mlogloss:0.46231\n",
      "[229]\tvalidation_0-mlogloss:0.21881\tvalidation_1-mlogloss:0.46058\n",
      "[230]\tvalidation_0-mlogloss:0.21729\tvalidation_1-mlogloss:0.45930\n",
      "[231]\tvalidation_0-mlogloss:0.21582\tvalidation_1-mlogloss:0.45847\n",
      "[232]\tvalidation_0-mlogloss:0.21444\tvalidation_1-mlogloss:0.45707\n",
      "[233]\tvalidation_0-mlogloss:0.21303\tvalidation_1-mlogloss:0.45556\n",
      "[234]\tvalidation_0-mlogloss:0.21155\tvalidation_1-mlogloss:0.45448\n",
      "[235]\tvalidation_0-mlogloss:0.21007\tvalidation_1-mlogloss:0.45284\n",
      "[236]\tvalidation_0-mlogloss:0.20857\tvalidation_1-mlogloss:0.45141\n",
      "[237]\tvalidation_0-mlogloss:0.20716\tvalidation_1-mlogloss:0.44952\n",
      "[238]\tvalidation_0-mlogloss:0.20571\tvalidation_1-mlogloss:0.44833\n",
      "[239]\tvalidation_0-mlogloss:0.20434\tvalidation_1-mlogloss:0.44767\n",
      "[240]\tvalidation_0-mlogloss:0.20298\tvalidation_1-mlogloss:0.44643\n",
      "[241]\tvalidation_0-mlogloss:0.20162\tvalidation_1-mlogloss:0.44534\n",
      "[242]\tvalidation_0-mlogloss:0.20030\tvalidation_1-mlogloss:0.44438\n",
      "[243]\tvalidation_0-mlogloss:0.19892\tvalidation_1-mlogloss:0.44334\n",
      "[244]\tvalidation_0-mlogloss:0.19763\tvalidation_1-mlogloss:0.44218\n",
      "[245]\tvalidation_0-mlogloss:0.19629\tvalidation_1-mlogloss:0.44120\n",
      "[246]\tvalidation_0-mlogloss:0.19492\tvalidation_1-mlogloss:0.44015\n",
      "[247]\tvalidation_0-mlogloss:0.19354\tvalidation_1-mlogloss:0.43907\n",
      "[248]\tvalidation_0-mlogloss:0.19241\tvalidation_1-mlogloss:0.43840\n",
      "[249]\tvalidation_0-mlogloss:0.19104\tvalidation_1-mlogloss:0.43725\n",
      "[250]\tvalidation_0-mlogloss:0.18975\tvalidation_1-mlogloss:0.43581\n",
      "[251]\tvalidation_0-mlogloss:0.18844\tvalidation_1-mlogloss:0.43441\n",
      "[252]\tvalidation_0-mlogloss:0.18732\tvalidation_1-mlogloss:0.43352\n",
      "[253]\tvalidation_0-mlogloss:0.18609\tvalidation_1-mlogloss:0.43229\n",
      "[254]\tvalidation_0-mlogloss:0.18492\tvalidation_1-mlogloss:0.43145\n",
      "[255]\tvalidation_0-mlogloss:0.18369\tvalidation_1-mlogloss:0.43047\n",
      "[256]\tvalidation_0-mlogloss:0.18241\tvalidation_1-mlogloss:0.42914\n",
      "[257]\tvalidation_0-mlogloss:0.18118\tvalidation_1-mlogloss:0.42807\n",
      "[258]\tvalidation_0-mlogloss:0.17993\tvalidation_1-mlogloss:0.42680\n",
      "[259]\tvalidation_0-mlogloss:0.17869\tvalidation_1-mlogloss:0.42551\n",
      "[260]\tvalidation_0-mlogloss:0.17746\tvalidation_1-mlogloss:0.42416\n",
      "[261]\tvalidation_0-mlogloss:0.17641\tvalidation_1-mlogloss:0.42345\n",
      "[262]\tvalidation_0-mlogloss:0.17534\tvalidation_1-mlogloss:0.42256\n",
      "[263]\tvalidation_0-mlogloss:0.17421\tvalidation_1-mlogloss:0.42175\n",
      "[264]\tvalidation_0-mlogloss:0.17301\tvalidation_1-mlogloss:0.42052\n",
      "[265]\tvalidation_0-mlogloss:0.17180\tvalidation_1-mlogloss:0.41959\n",
      "[266]\tvalidation_0-mlogloss:0.17066\tvalidation_1-mlogloss:0.41882\n",
      "[267]\tvalidation_0-mlogloss:0.16956\tvalidation_1-mlogloss:0.41789\n",
      "[268]\tvalidation_0-mlogloss:0.16838\tvalidation_1-mlogloss:0.41663\n",
      "[269]\tvalidation_0-mlogloss:0.16725\tvalidation_1-mlogloss:0.41557\n",
      "[270]\tvalidation_0-mlogloss:0.16612\tvalidation_1-mlogloss:0.41505\n",
      "[271]\tvalidation_0-mlogloss:0.16507\tvalidation_1-mlogloss:0.41375\n",
      "[272]\tvalidation_0-mlogloss:0.16401\tvalidation_1-mlogloss:0.41299\n",
      "[273]\tvalidation_0-mlogloss:0.16292\tvalidation_1-mlogloss:0.41247\n",
      "[274]\tvalidation_0-mlogloss:0.16192\tvalidation_1-mlogloss:0.41214\n",
      "[275]\tvalidation_0-mlogloss:0.16086\tvalidation_1-mlogloss:0.41124\n",
      "[276]\tvalidation_0-mlogloss:0.15979\tvalidation_1-mlogloss:0.41046\n",
      "[277]\tvalidation_0-mlogloss:0.15875\tvalidation_1-mlogloss:0.40995\n",
      "[278]\tvalidation_0-mlogloss:0.15772\tvalidation_1-mlogloss:0.40939\n",
      "[279]\tvalidation_0-mlogloss:0.15681\tvalidation_1-mlogloss:0.40894\n",
      "[280]\tvalidation_0-mlogloss:0.15582\tvalidation_1-mlogloss:0.40823\n",
      "[281]\tvalidation_0-mlogloss:0.15482\tvalidation_1-mlogloss:0.40733\n",
      "[282]\tvalidation_0-mlogloss:0.15378\tvalidation_1-mlogloss:0.40653\n",
      "[283]\tvalidation_0-mlogloss:0.15281\tvalidation_1-mlogloss:0.40580\n",
      "[284]\tvalidation_0-mlogloss:0.15183\tvalidation_1-mlogloss:0.40508\n",
      "[285]\tvalidation_0-mlogloss:0.15089\tvalidation_1-mlogloss:0.40422\n",
      "[286]\tvalidation_0-mlogloss:0.14995\tvalidation_1-mlogloss:0.40357\n",
      "[287]\tvalidation_0-mlogloss:0.14898\tvalidation_1-mlogloss:0.40253\n",
      "[288]\tvalidation_0-mlogloss:0.14809\tvalidation_1-mlogloss:0.40175\n",
      "[289]\tvalidation_0-mlogloss:0.14717\tvalidation_1-mlogloss:0.40134\n",
      "[290]\tvalidation_0-mlogloss:0.14619\tvalidation_1-mlogloss:0.40013\n",
      "[291]\tvalidation_0-mlogloss:0.14524\tvalidation_1-mlogloss:0.39943\n",
      "[292]\tvalidation_0-mlogloss:0.14438\tvalidation_1-mlogloss:0.39855\n",
      "[293]\tvalidation_0-mlogloss:0.14345\tvalidation_1-mlogloss:0.39770\n",
      "[294]\tvalidation_0-mlogloss:0.14250\tvalidation_1-mlogloss:0.39670\n",
      "[295]\tvalidation_0-mlogloss:0.14160\tvalidation_1-mlogloss:0.39580\n",
      "[296]\tvalidation_0-mlogloss:0.14074\tvalidation_1-mlogloss:0.39513\n",
      "[297]\tvalidation_0-mlogloss:0.13982\tvalidation_1-mlogloss:0.39446\n",
      "[298]\tvalidation_0-mlogloss:0.13891\tvalidation_1-mlogloss:0.39384\n",
      "[299]\tvalidation_0-mlogloss:0.13805\tvalidation_1-mlogloss:0.39348\n",
      "[300]\tvalidation_0-mlogloss:0.13735\tvalidation_1-mlogloss:0.39308\n",
      "[301]\tvalidation_0-mlogloss:0.13646\tvalidation_1-mlogloss:0.39246\n",
      "[302]\tvalidation_0-mlogloss:0.13567\tvalidation_1-mlogloss:0.39138\n",
      "[303]\tvalidation_0-mlogloss:0.13488\tvalidation_1-mlogloss:0.39090\n",
      "[304]\tvalidation_0-mlogloss:0.13406\tvalidation_1-mlogloss:0.39025\n",
      "[305]\tvalidation_0-mlogloss:0.13321\tvalidation_1-mlogloss:0.38985\n",
      "[306]\tvalidation_0-mlogloss:0.13236\tvalidation_1-mlogloss:0.38913\n",
      "[307]\tvalidation_0-mlogloss:0.13151\tvalidation_1-mlogloss:0.38862\n",
      "[308]\tvalidation_0-mlogloss:0.13070\tvalidation_1-mlogloss:0.38810\n",
      "[309]\tvalidation_0-mlogloss:0.12995\tvalidation_1-mlogloss:0.38722\n",
      "[310]\tvalidation_0-mlogloss:0.12922\tvalidation_1-mlogloss:0.38685\n",
      "[311]\tvalidation_0-mlogloss:0.12848\tvalidation_1-mlogloss:0.38593\n",
      "[312]\tvalidation_0-mlogloss:0.12771\tvalidation_1-mlogloss:0.38563\n",
      "[313]\tvalidation_0-mlogloss:0.12700\tvalidation_1-mlogloss:0.38489\n",
      "[314]\tvalidation_0-mlogloss:0.12625\tvalidation_1-mlogloss:0.38402\n",
      "[315]\tvalidation_0-mlogloss:0.12552\tvalidation_1-mlogloss:0.38363\n",
      "[316]\tvalidation_0-mlogloss:0.12481\tvalidation_1-mlogloss:0.38332\n",
      "[317]\tvalidation_0-mlogloss:0.12408\tvalidation_1-mlogloss:0.38281\n",
      "[318]\tvalidation_0-mlogloss:0.12335\tvalidation_1-mlogloss:0.38244\n",
      "[319]\tvalidation_0-mlogloss:0.12264\tvalidation_1-mlogloss:0.38185\n",
      "[320]\tvalidation_0-mlogloss:0.12190\tvalidation_1-mlogloss:0.38149\n",
      "[321]\tvalidation_0-mlogloss:0.12118\tvalidation_1-mlogloss:0.38112\n",
      "[322]\tvalidation_0-mlogloss:0.12048\tvalidation_1-mlogloss:0.38070\n",
      "[323]\tvalidation_0-mlogloss:0.11977\tvalidation_1-mlogloss:0.38007\n",
      "[324]\tvalidation_0-mlogloss:0.11904\tvalidation_1-mlogloss:0.37931\n",
      "[325]\tvalidation_0-mlogloss:0.11843\tvalidation_1-mlogloss:0.37900\n",
      "[326]\tvalidation_0-mlogloss:0.11771\tvalidation_1-mlogloss:0.37826\n",
      "[327]\tvalidation_0-mlogloss:0.11702\tvalidation_1-mlogloss:0.37774\n",
      "[328]\tvalidation_0-mlogloss:0.11633\tvalidation_1-mlogloss:0.37730\n",
      "[329]\tvalidation_0-mlogloss:0.11567\tvalidation_1-mlogloss:0.37666\n",
      "[330]\tvalidation_0-mlogloss:0.11507\tvalidation_1-mlogloss:0.37647\n",
      "[331]\tvalidation_0-mlogloss:0.11439\tvalidation_1-mlogloss:0.37583\n",
      "[332]\tvalidation_0-mlogloss:0.11370\tvalidation_1-mlogloss:0.37540\n",
      "[333]\tvalidation_0-mlogloss:0.11305\tvalidation_1-mlogloss:0.37493\n",
      "[334]\tvalidation_0-mlogloss:0.11244\tvalidation_1-mlogloss:0.37482\n",
      "[335]\tvalidation_0-mlogloss:0.11182\tvalidation_1-mlogloss:0.37444\n",
      "[336]\tvalidation_0-mlogloss:0.11120\tvalidation_1-mlogloss:0.37386\n",
      "[337]\tvalidation_0-mlogloss:0.11058\tvalidation_1-mlogloss:0.37360\n",
      "[338]\tvalidation_0-mlogloss:0.11003\tvalidation_1-mlogloss:0.37309\n",
      "[339]\tvalidation_0-mlogloss:0.10940\tvalidation_1-mlogloss:0.37245\n",
      "[340]\tvalidation_0-mlogloss:0.10880\tvalidation_1-mlogloss:0.37170\n",
      "[341]\tvalidation_0-mlogloss:0.10820\tvalidation_1-mlogloss:0.37108\n",
      "[342]\tvalidation_0-mlogloss:0.10759\tvalidation_1-mlogloss:0.37092\n",
      "[343]\tvalidation_0-mlogloss:0.10701\tvalidation_1-mlogloss:0.37072\n",
      "[344]\tvalidation_0-mlogloss:0.10644\tvalidation_1-mlogloss:0.37022\n",
      "[345]\tvalidation_0-mlogloss:0.10589\tvalidation_1-mlogloss:0.36999\n",
      "[346]\tvalidation_0-mlogloss:0.10534\tvalidation_1-mlogloss:0.36988\n",
      "[347]\tvalidation_0-mlogloss:0.10475\tvalidation_1-mlogloss:0.36943\n",
      "[348]\tvalidation_0-mlogloss:0.10416\tvalidation_1-mlogloss:0.36937\n",
      "[349]\tvalidation_0-mlogloss:0.10359\tvalidation_1-mlogloss:0.36900\n",
      "[350]\tvalidation_0-mlogloss:0.10303\tvalidation_1-mlogloss:0.36872\n",
      "[351]\tvalidation_0-mlogloss:0.10244\tvalidation_1-mlogloss:0.36820\n",
      "[352]\tvalidation_0-mlogloss:0.10192\tvalidation_1-mlogloss:0.36820\n",
      "[353]\tvalidation_0-mlogloss:0.10135\tvalidation_1-mlogloss:0.36769\n",
      "[354]\tvalidation_0-mlogloss:0.10086\tvalidation_1-mlogloss:0.36762\n",
      "[355]\tvalidation_0-mlogloss:0.10032\tvalidation_1-mlogloss:0.36709\n",
      "[356]\tvalidation_0-mlogloss:0.09978\tvalidation_1-mlogloss:0.36693\n",
      "[357]\tvalidation_0-mlogloss:0.09924\tvalidation_1-mlogloss:0.36632\n",
      "[358]\tvalidation_0-mlogloss:0.09870\tvalidation_1-mlogloss:0.36627\n",
      "[359]\tvalidation_0-mlogloss:0.09819\tvalidation_1-mlogloss:0.36608\n",
      "[360]\tvalidation_0-mlogloss:0.09769\tvalidation_1-mlogloss:0.36555\n",
      "[361]\tvalidation_0-mlogloss:0.09715\tvalidation_1-mlogloss:0.36498\n",
      "[362]\tvalidation_0-mlogloss:0.09660\tvalidation_1-mlogloss:0.36463\n",
      "[363]\tvalidation_0-mlogloss:0.09607\tvalidation_1-mlogloss:0.36412\n",
      "[364]\tvalidation_0-mlogloss:0.09558\tvalidation_1-mlogloss:0.36388\n",
      "[365]\tvalidation_0-mlogloss:0.09509\tvalidation_1-mlogloss:0.36378\n",
      "[366]\tvalidation_0-mlogloss:0.09457\tvalidation_1-mlogloss:0.36340\n",
      "[367]\tvalidation_0-mlogloss:0.09409\tvalidation_1-mlogloss:0.36271\n",
      "[368]\tvalidation_0-mlogloss:0.09360\tvalidation_1-mlogloss:0.36236\n",
      "[369]\tvalidation_0-mlogloss:0.09314\tvalidation_1-mlogloss:0.36212\n",
      "[370]\tvalidation_0-mlogloss:0.09266\tvalidation_1-mlogloss:0.36164\n",
      "[371]\tvalidation_0-mlogloss:0.09218\tvalidation_1-mlogloss:0.36113\n",
      "[372]\tvalidation_0-mlogloss:0.09176\tvalidation_1-mlogloss:0.36066\n",
      "[373]\tvalidation_0-mlogloss:0.09130\tvalidation_1-mlogloss:0.36013\n",
      "[374]\tvalidation_0-mlogloss:0.09092\tvalidation_1-mlogloss:0.36007\n",
      "[375]\tvalidation_0-mlogloss:0.09046\tvalidation_1-mlogloss:0.35971\n",
      "[376]\tvalidation_0-mlogloss:0.09003\tvalidation_1-mlogloss:0.35931\n",
      "[377]\tvalidation_0-mlogloss:0.08956\tvalidation_1-mlogloss:0.35936\n",
      "[378]\tvalidation_0-mlogloss:0.08913\tvalidation_1-mlogloss:0.35896\n",
      "[379]\tvalidation_0-mlogloss:0.08869\tvalidation_1-mlogloss:0.35858\n",
      "[380]\tvalidation_0-mlogloss:0.08824\tvalidation_1-mlogloss:0.35849\n",
      "[381]\tvalidation_0-mlogloss:0.08777\tvalidation_1-mlogloss:0.35820\n",
      "[382]\tvalidation_0-mlogloss:0.08736\tvalidation_1-mlogloss:0.35828\n",
      "[383]\tvalidation_0-mlogloss:0.08698\tvalidation_1-mlogloss:0.35811\n",
      "[384]\tvalidation_0-mlogloss:0.08655\tvalidation_1-mlogloss:0.35801\n",
      "[385]\tvalidation_0-mlogloss:0.08613\tvalidation_1-mlogloss:0.35784\n",
      "[386]\tvalidation_0-mlogloss:0.08577\tvalidation_1-mlogloss:0.35755\n",
      "[387]\tvalidation_0-mlogloss:0.08535\tvalidation_1-mlogloss:0.35731\n",
      "[388]\tvalidation_0-mlogloss:0.08494\tvalidation_1-mlogloss:0.35702\n",
      "[389]\tvalidation_0-mlogloss:0.08453\tvalidation_1-mlogloss:0.35685\n",
      "[390]\tvalidation_0-mlogloss:0.08414\tvalidation_1-mlogloss:0.35642\n",
      "[391]\tvalidation_0-mlogloss:0.08374\tvalidation_1-mlogloss:0.35638\n",
      "[392]\tvalidation_0-mlogloss:0.08332\tvalidation_1-mlogloss:0.35610\n",
      "[393]\tvalidation_0-mlogloss:0.08293\tvalidation_1-mlogloss:0.35594\n",
      "[394]\tvalidation_0-mlogloss:0.08254\tvalidation_1-mlogloss:0.35563\n",
      "[395]\tvalidation_0-mlogloss:0.08213\tvalidation_1-mlogloss:0.35509\n",
      "[396]\tvalidation_0-mlogloss:0.08176\tvalidation_1-mlogloss:0.35490\n",
      "[397]\tvalidation_0-mlogloss:0.08145\tvalidation_1-mlogloss:0.35466\n",
      "[398]\tvalidation_0-mlogloss:0.08108\tvalidation_1-mlogloss:0.35449\n",
      "[399]\tvalidation_0-mlogloss:0.08070\tvalidation_1-mlogloss:0.35432\n",
      "[400]\tvalidation_0-mlogloss:0.08036\tvalidation_1-mlogloss:0.35397\n",
      "[401]\tvalidation_0-mlogloss:0.07998\tvalidation_1-mlogloss:0.35367\n",
      "[402]\tvalidation_0-mlogloss:0.07963\tvalidation_1-mlogloss:0.35346\n",
      "[403]\tvalidation_0-mlogloss:0.07926\tvalidation_1-mlogloss:0.35313\n",
      "[404]\tvalidation_0-mlogloss:0.07890\tvalidation_1-mlogloss:0.35279\n",
      "[405]\tvalidation_0-mlogloss:0.07853\tvalidation_1-mlogloss:0.35223\n",
      "[406]\tvalidation_0-mlogloss:0.07820\tvalidation_1-mlogloss:0.35196\n",
      "[407]\tvalidation_0-mlogloss:0.07782\tvalidation_1-mlogloss:0.35181\n",
      "[408]\tvalidation_0-mlogloss:0.07749\tvalidation_1-mlogloss:0.35173\n",
      "[409]\tvalidation_0-mlogloss:0.07713\tvalidation_1-mlogloss:0.35123\n",
      "[410]\tvalidation_0-mlogloss:0.07677\tvalidation_1-mlogloss:0.35132\n",
      "[411]\tvalidation_0-mlogloss:0.07641\tvalidation_1-mlogloss:0.35141\n",
      "[412]\tvalidation_0-mlogloss:0.07608\tvalidation_1-mlogloss:0.35136\n",
      "[413]\tvalidation_0-mlogloss:0.07570\tvalidation_1-mlogloss:0.35139\n",
      "[414]\tvalidation_0-mlogloss:0.07539\tvalidation_1-mlogloss:0.35123\n",
      "[415]\tvalidation_0-mlogloss:0.07507\tvalidation_1-mlogloss:0.35138\n",
      "[416]\tvalidation_0-mlogloss:0.07476\tvalidation_1-mlogloss:0.35140\n",
      "[417]\tvalidation_0-mlogloss:0.07447\tvalidation_1-mlogloss:0.35137\n",
      "[418]\tvalidation_0-mlogloss:0.07420\tvalidation_1-mlogloss:0.35109\n",
      "[419]\tvalidation_0-mlogloss:0.07388\tvalidation_1-mlogloss:0.35101\n",
      "[420]\tvalidation_0-mlogloss:0.07354\tvalidation_1-mlogloss:0.35067\n",
      "[421]\tvalidation_0-mlogloss:0.07323\tvalidation_1-mlogloss:0.35084\n",
      "[422]\tvalidation_0-mlogloss:0.07295\tvalidation_1-mlogloss:0.35074\n",
      "[423]\tvalidation_0-mlogloss:0.07269\tvalidation_1-mlogloss:0.35061\n",
      "[424]\tvalidation_0-mlogloss:0.07240\tvalidation_1-mlogloss:0.35039\n",
      "[425]\tvalidation_0-mlogloss:0.07210\tvalidation_1-mlogloss:0.35009\n",
      "[426]\tvalidation_0-mlogloss:0.07176\tvalidation_1-mlogloss:0.34978\n",
      "[427]\tvalidation_0-mlogloss:0.07146\tvalidation_1-mlogloss:0.34948\n",
      "[428]\tvalidation_0-mlogloss:0.07120\tvalidation_1-mlogloss:0.34949\n",
      "[429]\tvalidation_0-mlogloss:0.07093\tvalidation_1-mlogloss:0.34953\n",
      "[430]\tvalidation_0-mlogloss:0.07067\tvalidation_1-mlogloss:0.34929\n",
      "[431]\tvalidation_0-mlogloss:0.07035\tvalidation_1-mlogloss:0.34933\n",
      "[432]\tvalidation_0-mlogloss:0.07001\tvalidation_1-mlogloss:0.34865\n",
      "[433]\tvalidation_0-mlogloss:0.06972\tvalidation_1-mlogloss:0.34851\n",
      "[434]\tvalidation_0-mlogloss:0.06942\tvalidation_1-mlogloss:0.34855\n",
      "[435]\tvalidation_0-mlogloss:0.06913\tvalidation_1-mlogloss:0.34849\n",
      "[436]\tvalidation_0-mlogloss:0.06884\tvalidation_1-mlogloss:0.34814\n",
      "[437]\tvalidation_0-mlogloss:0.06855\tvalidation_1-mlogloss:0.34817\n",
      "[438]\tvalidation_0-mlogloss:0.06827\tvalidation_1-mlogloss:0.34815\n",
      "[439]\tvalidation_0-mlogloss:0.06801\tvalidation_1-mlogloss:0.34788\n",
      "[440]\tvalidation_0-mlogloss:0.06777\tvalidation_1-mlogloss:0.34759\n",
      "[441]\tvalidation_0-mlogloss:0.06747\tvalidation_1-mlogloss:0.34749\n",
      "[442]\tvalidation_0-mlogloss:0.06719\tvalidation_1-mlogloss:0.34745\n",
      "[443]\tvalidation_0-mlogloss:0.06695\tvalidation_1-mlogloss:0.34726\n",
      "[444]\tvalidation_0-mlogloss:0.06668\tvalidation_1-mlogloss:0.34691\n",
      "[445]\tvalidation_0-mlogloss:0.06640\tvalidation_1-mlogloss:0.34672\n",
      "[446]\tvalidation_0-mlogloss:0.06613\tvalidation_1-mlogloss:0.34681\n",
      "[447]\tvalidation_0-mlogloss:0.06589\tvalidation_1-mlogloss:0.34682\n",
      "[448]\tvalidation_0-mlogloss:0.06562\tvalidation_1-mlogloss:0.34689\n",
      "[449]\tvalidation_0-mlogloss:0.06536\tvalidation_1-mlogloss:0.34670\n",
      "[450]\tvalidation_0-mlogloss:0.06511\tvalidation_1-mlogloss:0.34658\n",
      "[451]\tvalidation_0-mlogloss:0.06486\tvalidation_1-mlogloss:0.34654\n",
      "[452]\tvalidation_0-mlogloss:0.06464\tvalidation_1-mlogloss:0.34669\n",
      "[453]\tvalidation_0-mlogloss:0.06447\tvalidation_1-mlogloss:0.34681\n",
      "[454]\tvalidation_0-mlogloss:0.06429\tvalidation_1-mlogloss:0.34690\n",
      "[455]\tvalidation_0-mlogloss:0.06407\tvalidation_1-mlogloss:0.34682\n",
      "[456]\tvalidation_0-mlogloss:0.06382\tvalidation_1-mlogloss:0.34677\n",
      "[457]\tvalidation_0-mlogloss:0.06359\tvalidation_1-mlogloss:0.34675\n",
      "[458]\tvalidation_0-mlogloss:0.06331\tvalidation_1-mlogloss:0.34655\n",
      "[459]\tvalidation_0-mlogloss:0.06305\tvalidation_1-mlogloss:0.34635\n",
      "[460]\tvalidation_0-mlogloss:0.06281\tvalidation_1-mlogloss:0.34595\n",
      "[461]\tvalidation_0-mlogloss:0.06259\tvalidation_1-mlogloss:0.34562\n",
      "[462]\tvalidation_0-mlogloss:0.06239\tvalidation_1-mlogloss:0.34566\n",
      "[463]\tvalidation_0-mlogloss:0.06215\tvalidation_1-mlogloss:0.34552\n",
      "[464]\tvalidation_0-mlogloss:0.06188\tvalidation_1-mlogloss:0.34572\n",
      "[465]\tvalidation_0-mlogloss:0.06170\tvalidation_1-mlogloss:0.34585\n",
      "[466]\tvalidation_0-mlogloss:0.06146\tvalidation_1-mlogloss:0.34569\n",
      "[467]\tvalidation_0-mlogloss:0.06126\tvalidation_1-mlogloss:0.34555\n",
      "[468]\tvalidation_0-mlogloss:0.06106\tvalidation_1-mlogloss:0.34549\n",
      "[469]\tvalidation_0-mlogloss:0.06083\tvalidation_1-mlogloss:0.34526\n",
      "[470]\tvalidation_0-mlogloss:0.06063\tvalidation_1-mlogloss:0.34506\n",
      "[471]\tvalidation_0-mlogloss:0.06042\tvalidation_1-mlogloss:0.34525\n",
      "[472]\tvalidation_0-mlogloss:0.06025\tvalidation_1-mlogloss:0.34496\n",
      "[473]\tvalidation_0-mlogloss:0.06002\tvalidation_1-mlogloss:0.34437\n",
      "[474]\tvalidation_0-mlogloss:0.05984\tvalidation_1-mlogloss:0.34418\n",
      "[475]\tvalidation_0-mlogloss:0.05961\tvalidation_1-mlogloss:0.34399\n",
      "[476]\tvalidation_0-mlogloss:0.05946\tvalidation_1-mlogloss:0.34412\n",
      "[477]\tvalidation_0-mlogloss:0.05929\tvalidation_1-mlogloss:0.34412\n",
      "[478]\tvalidation_0-mlogloss:0.05909\tvalidation_1-mlogloss:0.34406\n",
      "[479]\tvalidation_0-mlogloss:0.05896\tvalidation_1-mlogloss:0.34395\n",
      "[480]\tvalidation_0-mlogloss:0.05882\tvalidation_1-mlogloss:0.34386\n",
      "[481]\tvalidation_0-mlogloss:0.05868\tvalidation_1-mlogloss:0.34403\n",
      "[482]\tvalidation_0-mlogloss:0.05851\tvalidation_1-mlogloss:0.34382\n",
      "[483]\tvalidation_0-mlogloss:0.05834\tvalidation_1-mlogloss:0.34353\n",
      "[484]\tvalidation_0-mlogloss:0.05814\tvalidation_1-mlogloss:0.34333\n",
      "[485]\tvalidation_0-mlogloss:0.05792\tvalidation_1-mlogloss:0.34323\n",
      "[486]\tvalidation_0-mlogloss:0.05775\tvalidation_1-mlogloss:0.34313\n",
      "[487]\tvalidation_0-mlogloss:0.05758\tvalidation_1-mlogloss:0.34291\n",
      "[488]\tvalidation_0-mlogloss:0.05744\tvalidation_1-mlogloss:0.34285\n",
      "[489]\tvalidation_0-mlogloss:0.05733\tvalidation_1-mlogloss:0.34272\n",
      "[490]\tvalidation_0-mlogloss:0.05718\tvalidation_1-mlogloss:0.34255\n",
      "[491]\tvalidation_0-mlogloss:0.05702\tvalidation_1-mlogloss:0.34262\n",
      "[492]\tvalidation_0-mlogloss:0.05691\tvalidation_1-mlogloss:0.34243\n",
      "[493]\tvalidation_0-mlogloss:0.05679\tvalidation_1-mlogloss:0.34232\n",
      "[494]\tvalidation_0-mlogloss:0.05666\tvalidation_1-mlogloss:0.34201\n",
      "[495]\tvalidation_0-mlogloss:0.05655\tvalidation_1-mlogloss:0.34181\n",
      "[496]\tvalidation_0-mlogloss:0.05642\tvalidation_1-mlogloss:0.34158\n",
      "[497]\tvalidation_0-mlogloss:0.05631\tvalidation_1-mlogloss:0.34149\n",
      "[498]\tvalidation_0-mlogloss:0.05617\tvalidation_1-mlogloss:0.34114\n",
      "[499]\tvalidation_0-mlogloss:0.05600\tvalidation_1-mlogloss:0.34120\n",
      "[500]\tvalidation_0-mlogloss:0.05588\tvalidation_1-mlogloss:0.34119\n",
      "[501]\tvalidation_0-mlogloss:0.05577\tvalidation_1-mlogloss:0.34118\n",
      "[502]\tvalidation_0-mlogloss:0.05565\tvalidation_1-mlogloss:0.34089\n",
      "[503]\tvalidation_0-mlogloss:0.05553\tvalidation_1-mlogloss:0.34080\n",
      "[504]\tvalidation_0-mlogloss:0.05538\tvalidation_1-mlogloss:0.34099\n",
      "[505]\tvalidation_0-mlogloss:0.05526\tvalidation_1-mlogloss:0.34075\n",
      "[506]\tvalidation_0-mlogloss:0.05514\tvalidation_1-mlogloss:0.34046\n",
      "[507]\tvalidation_0-mlogloss:0.05505\tvalidation_1-mlogloss:0.34026\n",
      "[508]\tvalidation_0-mlogloss:0.05493\tvalidation_1-mlogloss:0.34007\n",
      "[509]\tvalidation_0-mlogloss:0.05484\tvalidation_1-mlogloss:0.34000\n",
      "[510]\tvalidation_0-mlogloss:0.05473\tvalidation_1-mlogloss:0.33990\n",
      "[511]\tvalidation_0-mlogloss:0.05460\tvalidation_1-mlogloss:0.33992\n",
      "[512]\tvalidation_0-mlogloss:0.05450\tvalidation_1-mlogloss:0.33975\n",
      "[513]\tvalidation_0-mlogloss:0.05443\tvalidation_1-mlogloss:0.33968\n",
      "[514]\tvalidation_0-mlogloss:0.05433\tvalidation_1-mlogloss:0.33960\n",
      "[515]\tvalidation_0-mlogloss:0.05423\tvalidation_1-mlogloss:0.33945\n",
      "[516]\tvalidation_0-mlogloss:0.05406\tvalidation_1-mlogloss:0.33934\n",
      "[517]\tvalidation_0-mlogloss:0.05395\tvalidation_1-mlogloss:0.33922\n",
      "[518]\tvalidation_0-mlogloss:0.05384\tvalidation_1-mlogloss:0.33887\n",
      "[519]\tvalidation_0-mlogloss:0.05379\tvalidation_1-mlogloss:0.33896\n",
      "[520]\tvalidation_0-mlogloss:0.05365\tvalidation_1-mlogloss:0.33885\n",
      "[521]\tvalidation_0-mlogloss:0.05356\tvalidation_1-mlogloss:0.33903\n",
      "[522]\tvalidation_0-mlogloss:0.05338\tvalidation_1-mlogloss:0.33902\n",
      "[523]\tvalidation_0-mlogloss:0.05329\tvalidation_1-mlogloss:0.33885\n",
      "[524]\tvalidation_0-mlogloss:0.05319\tvalidation_1-mlogloss:0.33874\n",
      "[525]\tvalidation_0-mlogloss:0.05309\tvalidation_1-mlogloss:0.33881\n",
      "[526]\tvalidation_0-mlogloss:0.05300\tvalidation_1-mlogloss:0.33866\n",
      "[527]\tvalidation_0-mlogloss:0.05291\tvalidation_1-mlogloss:0.33857\n",
      "[528]\tvalidation_0-mlogloss:0.05277\tvalidation_1-mlogloss:0.33812\n",
      "[529]\tvalidation_0-mlogloss:0.05269\tvalidation_1-mlogloss:0.33813\n",
      "[530]\tvalidation_0-mlogloss:0.05259\tvalidation_1-mlogloss:0.33779\n",
      "[531]\tvalidation_0-mlogloss:0.05248\tvalidation_1-mlogloss:0.33753\n",
      "[532]\tvalidation_0-mlogloss:0.05239\tvalidation_1-mlogloss:0.33734\n",
      "[533]\tvalidation_0-mlogloss:0.05231\tvalidation_1-mlogloss:0.33698\n",
      "[534]\tvalidation_0-mlogloss:0.05217\tvalidation_1-mlogloss:0.33670\n",
      "[535]\tvalidation_0-mlogloss:0.05211\tvalidation_1-mlogloss:0.33666\n",
      "[536]\tvalidation_0-mlogloss:0.05202\tvalidation_1-mlogloss:0.33666\n",
      "[537]\tvalidation_0-mlogloss:0.05197\tvalidation_1-mlogloss:0.33645\n",
      "[538]\tvalidation_0-mlogloss:0.05180\tvalidation_1-mlogloss:0.33592\n",
      "[539]\tvalidation_0-mlogloss:0.05172\tvalidation_1-mlogloss:0.33600\n",
      "[540]\tvalidation_0-mlogloss:0.05164\tvalidation_1-mlogloss:0.33590\n",
      "[541]\tvalidation_0-mlogloss:0.05155\tvalidation_1-mlogloss:0.33574\n",
      "[542]\tvalidation_0-mlogloss:0.05146\tvalidation_1-mlogloss:0.33580\n",
      "[543]\tvalidation_0-mlogloss:0.05136\tvalidation_1-mlogloss:0.33576\n",
      "[544]\tvalidation_0-mlogloss:0.05128\tvalidation_1-mlogloss:0.33558\n",
      "[545]\tvalidation_0-mlogloss:0.05118\tvalidation_1-mlogloss:0.33560\n",
      "[546]\tvalidation_0-mlogloss:0.05110\tvalidation_1-mlogloss:0.33557\n",
      "[547]\tvalidation_0-mlogloss:0.05104\tvalidation_1-mlogloss:0.33540\n",
      "[548]\tvalidation_0-mlogloss:0.05095\tvalidation_1-mlogloss:0.33516\n",
      "[549]\tvalidation_0-mlogloss:0.05086\tvalidation_1-mlogloss:0.33499\n",
      "[550]\tvalidation_0-mlogloss:0.05080\tvalidation_1-mlogloss:0.33499\n",
      "[551]\tvalidation_0-mlogloss:0.05075\tvalidation_1-mlogloss:0.33513\n",
      "[552]\tvalidation_0-mlogloss:0.05066\tvalidation_1-mlogloss:0.33504\n",
      "[553]\tvalidation_0-mlogloss:0.05061\tvalidation_1-mlogloss:0.33505\n",
      "[554]\tvalidation_0-mlogloss:0.05056\tvalidation_1-mlogloss:0.33505\n",
      "[555]\tvalidation_0-mlogloss:0.05046\tvalidation_1-mlogloss:0.33497\n",
      "[556]\tvalidation_0-mlogloss:0.05042\tvalidation_1-mlogloss:0.33504\n",
      "[557]\tvalidation_0-mlogloss:0.05034\tvalidation_1-mlogloss:0.33508\n",
      "[558]\tvalidation_0-mlogloss:0.05026\tvalidation_1-mlogloss:0.33487\n",
      "[559]\tvalidation_0-mlogloss:0.05018\tvalidation_1-mlogloss:0.33489\n",
      "[560]\tvalidation_0-mlogloss:0.05009\tvalidation_1-mlogloss:0.33474\n",
      "[561]\tvalidation_0-mlogloss:0.05001\tvalidation_1-mlogloss:0.33458\n",
      "[562]\tvalidation_0-mlogloss:0.04993\tvalidation_1-mlogloss:0.33427\n",
      "[563]\tvalidation_0-mlogloss:0.04988\tvalidation_1-mlogloss:0.33428\n",
      "[564]\tvalidation_0-mlogloss:0.04979\tvalidation_1-mlogloss:0.33412\n",
      "[565]\tvalidation_0-mlogloss:0.04974\tvalidation_1-mlogloss:0.33414\n",
      "[566]\tvalidation_0-mlogloss:0.04966\tvalidation_1-mlogloss:0.33397\n",
      "[567]\tvalidation_0-mlogloss:0.04961\tvalidation_1-mlogloss:0.33382\n",
      "[568]\tvalidation_0-mlogloss:0.04959\tvalidation_1-mlogloss:0.33398\n",
      "[569]\tvalidation_0-mlogloss:0.04955\tvalidation_1-mlogloss:0.33389\n",
      "[570]\tvalidation_0-mlogloss:0.04946\tvalidation_1-mlogloss:0.33367\n",
      "[571]\tvalidation_0-mlogloss:0.04938\tvalidation_1-mlogloss:0.33349\n",
      "[572]\tvalidation_0-mlogloss:0.04934\tvalidation_1-mlogloss:0.33355\n",
      "[573]\tvalidation_0-mlogloss:0.04926\tvalidation_1-mlogloss:0.33340\n",
      "[574]\tvalidation_0-mlogloss:0.04922\tvalidation_1-mlogloss:0.33357\n",
      "[575]\tvalidation_0-mlogloss:0.04914\tvalidation_1-mlogloss:0.33345\n",
      "[576]\tvalidation_0-mlogloss:0.04910\tvalidation_1-mlogloss:0.33336\n",
      "[577]\tvalidation_0-mlogloss:0.04904\tvalidation_1-mlogloss:0.33341\n",
      "[578]\tvalidation_0-mlogloss:0.04900\tvalidation_1-mlogloss:0.33340\n",
      "[579]\tvalidation_0-mlogloss:0.04895\tvalidation_1-mlogloss:0.33332\n",
      "[580]\tvalidation_0-mlogloss:0.04888\tvalidation_1-mlogloss:0.33316\n",
      "[581]\tvalidation_0-mlogloss:0.04886\tvalidation_1-mlogloss:0.33330\n",
      "[582]\tvalidation_0-mlogloss:0.04880\tvalidation_1-mlogloss:0.33309\n",
      "[583]\tvalidation_0-mlogloss:0.04876\tvalidation_1-mlogloss:0.33322\n",
      "[584]\tvalidation_0-mlogloss:0.04868\tvalidation_1-mlogloss:0.33315\n",
      "[585]\tvalidation_0-mlogloss:0.04867\tvalidation_1-mlogloss:0.33320\n",
      "[586]\tvalidation_0-mlogloss:0.04862\tvalidation_1-mlogloss:0.33302\n",
      "[587]\tvalidation_0-mlogloss:0.04855\tvalidation_1-mlogloss:0.33288\n",
      "[588]\tvalidation_0-mlogloss:0.04850\tvalidation_1-mlogloss:0.33294\n",
      "[589]\tvalidation_0-mlogloss:0.04846\tvalidation_1-mlogloss:0.33306\n",
      "[590]\tvalidation_0-mlogloss:0.04842\tvalidation_1-mlogloss:0.33303\n",
      "[591]\tvalidation_0-mlogloss:0.04837\tvalidation_1-mlogloss:0.33321\n",
      "[592]\tvalidation_0-mlogloss:0.04832\tvalidation_1-mlogloss:0.33317\n",
      "[593]\tvalidation_0-mlogloss:0.04828\tvalidation_1-mlogloss:0.33327\n",
      "[594]\tvalidation_0-mlogloss:0.04824\tvalidation_1-mlogloss:0.33338\n",
      "[595]\tvalidation_0-mlogloss:0.04820\tvalidation_1-mlogloss:0.33340\n",
      "[596]\tvalidation_0-mlogloss:0.04817\tvalidation_1-mlogloss:0.33357\n",
      "[597]\tvalidation_0-mlogloss:0.04812\tvalidation_1-mlogloss:0.33355\n",
      "[598]\tvalidation_0-mlogloss:0.04811\tvalidation_1-mlogloss:0.33358\n",
      "[599]\tvalidation_0-mlogloss:0.04807\tvalidation_1-mlogloss:0.33370\n",
      "[600]\tvalidation_0-mlogloss:0.04805\tvalidation_1-mlogloss:0.33381\n",
      "[601]\tvalidation_0-mlogloss:0.04802\tvalidation_1-mlogloss:0.33394\n",
      "[602]\tvalidation_0-mlogloss:0.04797\tvalidation_1-mlogloss:0.33392\n",
      "[603]\tvalidation_0-mlogloss:0.04788\tvalidation_1-mlogloss:0.33379\n",
      "[604]\tvalidation_0-mlogloss:0.04785\tvalidation_1-mlogloss:0.33362\n",
      "[605]\tvalidation_0-mlogloss:0.04781\tvalidation_1-mlogloss:0.33371\n",
      "[606]\tvalidation_0-mlogloss:0.04777\tvalidation_1-mlogloss:0.33384\n",
      "[16:53:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-mlogloss:1.59188\tvalidation_1-mlogloss:1.59710\n",
      "[1]\tvalidation_0-mlogloss:1.57424\tvalidation_1-mlogloss:1.58304\n",
      "[2]\tvalidation_0-mlogloss:1.55713\tvalidation_1-mlogloss:1.56898\n",
      "[3]\tvalidation_0-mlogloss:1.54028\tvalidation_1-mlogloss:1.55560\n",
      "[4]\tvalidation_0-mlogloss:1.52279\tvalidation_1-mlogloss:1.54231\n",
      "[5]\tvalidation_0-mlogloss:1.50518\tvalidation_1-mlogloss:1.52655\n",
      "[6]\tvalidation_0-mlogloss:1.48810\tvalidation_1-mlogloss:1.51356\n",
      "[7]\tvalidation_0-mlogloss:1.47201\tvalidation_1-mlogloss:1.49997\n",
      "[8]\tvalidation_0-mlogloss:1.45548\tvalidation_1-mlogloss:1.48526\n",
      "[9]\tvalidation_0-mlogloss:1.43956\tvalidation_1-mlogloss:1.47260\n",
      "[10]\tvalidation_0-mlogloss:1.42556\tvalidation_1-mlogloss:1.46098\n",
      "[11]\tvalidation_0-mlogloss:1.41097\tvalidation_1-mlogloss:1.44853\n",
      "[12]\tvalidation_0-mlogloss:1.39523\tvalidation_1-mlogloss:1.43500\n",
      "[13]\tvalidation_0-mlogloss:1.37972\tvalidation_1-mlogloss:1.42107\n",
      "[14]\tvalidation_0-mlogloss:1.36547\tvalidation_1-mlogloss:1.40989\n",
      "[15]\tvalidation_0-mlogloss:1.35041\tvalidation_1-mlogloss:1.39669\n",
      "[16]\tvalidation_0-mlogloss:1.33594\tvalidation_1-mlogloss:1.38494\n",
      "[17]\tvalidation_0-mlogloss:1.32149\tvalidation_1-mlogloss:1.37185\n",
      "[18]\tvalidation_0-mlogloss:1.30838\tvalidation_1-mlogloss:1.36102\n",
      "[19]\tvalidation_0-mlogloss:1.29428\tvalidation_1-mlogloss:1.34920\n",
      "[20]\tvalidation_0-mlogloss:1.28063\tvalidation_1-mlogloss:1.33733\n",
      "[21]\tvalidation_0-mlogloss:1.26720\tvalidation_1-mlogloss:1.32567\n",
      "[22]\tvalidation_0-mlogloss:1.25453\tvalidation_1-mlogloss:1.31683\n",
      "[23]\tvalidation_0-mlogloss:1.24173\tvalidation_1-mlogloss:1.30600\n",
      "[24]\tvalidation_0-mlogloss:1.22851\tvalidation_1-mlogloss:1.29419\n",
      "[25]\tvalidation_0-mlogloss:1.21554\tvalidation_1-mlogloss:1.28260\n",
      "[26]\tvalidation_0-mlogloss:1.20342\tvalidation_1-mlogloss:1.27175\n",
      "[27]\tvalidation_0-mlogloss:1.19081\tvalidation_1-mlogloss:1.26043\n",
      "[28]\tvalidation_0-mlogloss:1.17903\tvalidation_1-mlogloss:1.25132\n",
      "[29]\tvalidation_0-mlogloss:1.16804\tvalidation_1-mlogloss:1.24272\n",
      "[30]\tvalidation_0-mlogloss:1.15725\tvalidation_1-mlogloss:1.23335\n",
      "[31]\tvalidation_0-mlogloss:1.14567\tvalidation_1-mlogloss:1.22404\n",
      "[32]\tvalidation_0-mlogloss:1.13420\tvalidation_1-mlogloss:1.21436\n",
      "[33]\tvalidation_0-mlogloss:1.12283\tvalidation_1-mlogloss:1.20476\n",
      "[34]\tvalidation_0-mlogloss:1.11144\tvalidation_1-mlogloss:1.19487\n",
      "[35]\tvalidation_0-mlogloss:1.10007\tvalidation_1-mlogloss:1.18525\n",
      "[36]\tvalidation_0-mlogloss:1.08987\tvalidation_1-mlogloss:1.17791\n",
      "[37]\tvalidation_0-mlogloss:1.07946\tvalidation_1-mlogloss:1.17128\n",
      "[38]\tvalidation_0-mlogloss:1.06867\tvalidation_1-mlogloss:1.16325\n",
      "[39]\tvalidation_0-mlogloss:1.05814\tvalidation_1-mlogloss:1.15574\n",
      "[40]\tvalidation_0-mlogloss:1.04805\tvalidation_1-mlogloss:1.14757\n",
      "[41]\tvalidation_0-mlogloss:1.03868\tvalidation_1-mlogloss:1.14011\n",
      "[42]\tvalidation_0-mlogloss:1.02941\tvalidation_1-mlogloss:1.13256\n",
      "[43]\tvalidation_0-mlogloss:1.01946\tvalidation_1-mlogloss:1.12427\n",
      "[44]\tvalidation_0-mlogloss:1.00924\tvalidation_1-mlogloss:1.11600\n",
      "[45]\tvalidation_0-mlogloss:0.99959\tvalidation_1-mlogloss:1.10893\n",
      "[46]\tvalidation_0-mlogloss:0.99078\tvalidation_1-mlogloss:1.10142\n",
      "[47]\tvalidation_0-mlogloss:0.98127\tvalidation_1-mlogloss:1.09204\n",
      "[48]\tvalidation_0-mlogloss:0.97226\tvalidation_1-mlogloss:1.08534\n",
      "[49]\tvalidation_0-mlogloss:0.96313\tvalidation_1-mlogloss:1.07761\n",
      "[50]\tvalidation_0-mlogloss:0.95389\tvalidation_1-mlogloss:1.06939\n",
      "[51]\tvalidation_0-mlogloss:0.94515\tvalidation_1-mlogloss:1.06293\n",
      "[52]\tvalidation_0-mlogloss:0.93606\tvalidation_1-mlogloss:1.05642\n",
      "[53]\tvalidation_0-mlogloss:0.92701\tvalidation_1-mlogloss:1.04822\n",
      "[54]\tvalidation_0-mlogloss:0.91864\tvalidation_1-mlogloss:1.04116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55]\tvalidation_0-mlogloss:0.90990\tvalidation_1-mlogloss:1.03489\n",
      "[56]\tvalidation_0-mlogloss:0.90165\tvalidation_1-mlogloss:1.02834\n",
      "[57]\tvalidation_0-mlogloss:0.89323\tvalidation_1-mlogloss:1.02301\n",
      "[58]\tvalidation_0-mlogloss:0.88484\tvalidation_1-mlogloss:1.01583\n",
      "[59]\tvalidation_0-mlogloss:0.87670\tvalidation_1-mlogloss:1.00936\n",
      "[60]\tvalidation_0-mlogloss:0.86858\tvalidation_1-mlogloss:1.00239\n",
      "[61]\tvalidation_0-mlogloss:0.86035\tvalidation_1-mlogloss:0.99495\n",
      "[62]\tvalidation_0-mlogloss:0.85260\tvalidation_1-mlogloss:0.98877\n",
      "[63]\tvalidation_0-mlogloss:0.84482\tvalidation_1-mlogloss:0.98252\n",
      "[64]\tvalidation_0-mlogloss:0.83703\tvalidation_1-mlogloss:0.97633\n",
      "[65]\tvalidation_0-mlogloss:0.82934\tvalidation_1-mlogloss:0.96951\n",
      "[66]\tvalidation_0-mlogloss:0.82199\tvalidation_1-mlogloss:0.96282\n",
      "[67]\tvalidation_0-mlogloss:0.81464\tvalidation_1-mlogloss:0.95738\n",
      "[68]\tvalidation_0-mlogloss:0.80753\tvalidation_1-mlogloss:0.95227\n",
      "[69]\tvalidation_0-mlogloss:0.80016\tvalidation_1-mlogloss:0.94627\n",
      "[70]\tvalidation_0-mlogloss:0.79256\tvalidation_1-mlogloss:0.94087\n",
      "[71]\tvalidation_0-mlogloss:0.78507\tvalidation_1-mlogloss:0.93439\n",
      "[72]\tvalidation_0-mlogloss:0.77742\tvalidation_1-mlogloss:0.92779\n",
      "[73]\tvalidation_0-mlogloss:0.77043\tvalidation_1-mlogloss:0.92199\n",
      "[74]\tvalidation_0-mlogloss:0.76376\tvalidation_1-mlogloss:0.91626\n",
      "[75]\tvalidation_0-mlogloss:0.75688\tvalidation_1-mlogloss:0.91050\n",
      "[76]\tvalidation_0-mlogloss:0.75005\tvalidation_1-mlogloss:0.90466\n",
      "[77]\tvalidation_0-mlogloss:0.74333\tvalidation_1-mlogloss:0.89843\n",
      "[78]\tvalidation_0-mlogloss:0.73704\tvalidation_1-mlogloss:0.89293\n",
      "[79]\tvalidation_0-mlogloss:0.73035\tvalidation_1-mlogloss:0.88716\n",
      "[80]\tvalidation_0-mlogloss:0.72369\tvalidation_1-mlogloss:0.88172\n",
      "[81]\tvalidation_0-mlogloss:0.71715\tvalidation_1-mlogloss:0.87548\n",
      "[82]\tvalidation_0-mlogloss:0.71096\tvalidation_1-mlogloss:0.87121\n",
      "[83]\tvalidation_0-mlogloss:0.70466\tvalidation_1-mlogloss:0.86625\n",
      "[84]\tvalidation_0-mlogloss:0.69802\tvalidation_1-mlogloss:0.86039\n",
      "[85]\tvalidation_0-mlogloss:0.69165\tvalidation_1-mlogloss:0.85549\n",
      "[86]\tvalidation_0-mlogloss:0.68555\tvalidation_1-mlogloss:0.85026\n",
      "[87]\tvalidation_0-mlogloss:0.67917\tvalidation_1-mlogloss:0.84570\n",
      "[88]\tvalidation_0-mlogloss:0.67303\tvalidation_1-mlogloss:0.84072\n",
      "[89]\tvalidation_0-mlogloss:0.66704\tvalidation_1-mlogloss:0.83637\n",
      "[90]\tvalidation_0-mlogloss:0.66109\tvalidation_1-mlogloss:0.83084\n",
      "[91]\tvalidation_0-mlogloss:0.65549\tvalidation_1-mlogloss:0.82607\n",
      "[92]\tvalidation_0-mlogloss:0.64964\tvalidation_1-mlogloss:0.82029\n",
      "[93]\tvalidation_0-mlogloss:0.64395\tvalidation_1-mlogloss:0.81575\n",
      "[94]\tvalidation_0-mlogloss:0.63891\tvalidation_1-mlogloss:0.81153\n",
      "[95]\tvalidation_0-mlogloss:0.63307\tvalidation_1-mlogloss:0.80666\n",
      "[96]\tvalidation_0-mlogloss:0.62723\tvalidation_1-mlogloss:0.80105\n",
      "[97]\tvalidation_0-mlogloss:0.62203\tvalidation_1-mlogloss:0.79721\n",
      "[98]\tvalidation_0-mlogloss:0.61646\tvalidation_1-mlogloss:0.79335\n",
      "[99]\tvalidation_0-mlogloss:0.61129\tvalidation_1-mlogloss:0.78957\n",
      "[100]\tvalidation_0-mlogloss:0.60587\tvalidation_1-mlogloss:0.78524\n",
      "[101]\tvalidation_0-mlogloss:0.60058\tvalidation_1-mlogloss:0.78069\n",
      "[102]\tvalidation_0-mlogloss:0.59523\tvalidation_1-mlogloss:0.77577\n",
      "[103]\tvalidation_0-mlogloss:0.58973\tvalidation_1-mlogloss:0.77051\n",
      "[104]\tvalidation_0-mlogloss:0.58450\tvalidation_1-mlogloss:0.76640\n",
      "[105]\tvalidation_0-mlogloss:0.57940\tvalidation_1-mlogloss:0.76213\n",
      "[106]\tvalidation_0-mlogloss:0.57431\tvalidation_1-mlogloss:0.75729\n",
      "[107]\tvalidation_0-mlogloss:0.56958\tvalidation_1-mlogloss:0.75334\n",
      "[108]\tvalidation_0-mlogloss:0.56487\tvalidation_1-mlogloss:0.74914\n",
      "[109]\tvalidation_0-mlogloss:0.55991\tvalidation_1-mlogloss:0.74585\n",
      "[110]\tvalidation_0-mlogloss:0.55483\tvalidation_1-mlogloss:0.74054\n",
      "[111]\tvalidation_0-mlogloss:0.54996\tvalidation_1-mlogloss:0.73656\n",
      "[112]\tvalidation_0-mlogloss:0.54510\tvalidation_1-mlogloss:0.73201\n",
      "[113]\tvalidation_0-mlogloss:0.54035\tvalidation_1-mlogloss:0.72735\n",
      "[114]\tvalidation_0-mlogloss:0.53590\tvalidation_1-mlogloss:0.72409\n",
      "[115]\tvalidation_0-mlogloss:0.53144\tvalidation_1-mlogloss:0.72135\n",
      "[116]\tvalidation_0-mlogloss:0.52700\tvalidation_1-mlogloss:0.71797\n",
      "[117]\tvalidation_0-mlogloss:0.52266\tvalidation_1-mlogloss:0.71476\n",
      "[118]\tvalidation_0-mlogloss:0.51834\tvalidation_1-mlogloss:0.71120\n",
      "[119]\tvalidation_0-mlogloss:0.51400\tvalidation_1-mlogloss:0.70775\n",
      "[120]\tvalidation_0-mlogloss:0.51001\tvalidation_1-mlogloss:0.70535\n",
      "[121]\tvalidation_0-mlogloss:0.50562\tvalidation_1-mlogloss:0.70232\n",
      "[122]\tvalidation_0-mlogloss:0.50125\tvalidation_1-mlogloss:0.69924\n",
      "[123]\tvalidation_0-mlogloss:0.49688\tvalidation_1-mlogloss:0.69535\n",
      "[124]\tvalidation_0-mlogloss:0.49273\tvalidation_1-mlogloss:0.69275\n",
      "[125]\tvalidation_0-mlogloss:0.48836\tvalidation_1-mlogloss:0.68947\n",
      "[126]\tvalidation_0-mlogloss:0.48407\tvalidation_1-mlogloss:0.68527\n",
      "[127]\tvalidation_0-mlogloss:0.47984\tvalidation_1-mlogloss:0.68162\n",
      "[128]\tvalidation_0-mlogloss:0.47568\tvalidation_1-mlogloss:0.67740\n",
      "[129]\tvalidation_0-mlogloss:0.47171\tvalidation_1-mlogloss:0.67414\n",
      "[130]\tvalidation_0-mlogloss:0.46774\tvalidation_1-mlogloss:0.67091\n",
      "[131]\tvalidation_0-mlogloss:0.46394\tvalidation_1-mlogloss:0.66764\n",
      "[132]\tvalidation_0-mlogloss:0.46012\tvalidation_1-mlogloss:0.66396\n",
      "[133]\tvalidation_0-mlogloss:0.45649\tvalidation_1-mlogloss:0.66063\n",
      "[134]\tvalidation_0-mlogloss:0.45249\tvalidation_1-mlogloss:0.65672\n",
      "[135]\tvalidation_0-mlogloss:0.44872\tvalidation_1-mlogloss:0.65323\n",
      "[136]\tvalidation_0-mlogloss:0.44502\tvalidation_1-mlogloss:0.64969\n",
      "[137]\tvalidation_0-mlogloss:0.44159\tvalidation_1-mlogloss:0.64649\n",
      "[138]\tvalidation_0-mlogloss:0.43782\tvalidation_1-mlogloss:0.64322\n",
      "[139]\tvalidation_0-mlogloss:0.43438\tvalidation_1-mlogloss:0.64075\n",
      "[140]\tvalidation_0-mlogloss:0.43061\tvalidation_1-mlogloss:0.63694\n",
      "[141]\tvalidation_0-mlogloss:0.42717\tvalidation_1-mlogloss:0.63430\n",
      "[142]\tvalidation_0-mlogloss:0.42364\tvalidation_1-mlogloss:0.63118\n",
      "[143]\tvalidation_0-mlogloss:0.42013\tvalidation_1-mlogloss:0.62812\n",
      "[144]\tvalidation_0-mlogloss:0.41672\tvalidation_1-mlogloss:0.62546\n",
      "[145]\tvalidation_0-mlogloss:0.41349\tvalidation_1-mlogloss:0.62352\n",
      "[146]\tvalidation_0-mlogloss:0.41022\tvalidation_1-mlogloss:0.62114\n",
      "[147]\tvalidation_0-mlogloss:0.40695\tvalidation_1-mlogloss:0.61872\n",
      "[148]\tvalidation_0-mlogloss:0.40357\tvalidation_1-mlogloss:0.61572\n",
      "[149]\tvalidation_0-mlogloss:0.40047\tvalidation_1-mlogloss:0.61277\n",
      "[150]\tvalidation_0-mlogloss:0.39724\tvalidation_1-mlogloss:0.60973\n",
      "[151]\tvalidation_0-mlogloss:0.39384\tvalidation_1-mlogloss:0.60686\n",
      "[152]\tvalidation_0-mlogloss:0.39067\tvalidation_1-mlogloss:0.60376\n",
      "[153]\tvalidation_0-mlogloss:0.38758\tvalidation_1-mlogloss:0.60105\n",
      "[154]\tvalidation_0-mlogloss:0.38433\tvalidation_1-mlogloss:0.59825\n",
      "[155]\tvalidation_0-mlogloss:0.38111\tvalidation_1-mlogloss:0.59505\n",
      "[156]\tvalidation_0-mlogloss:0.37793\tvalidation_1-mlogloss:0.59218\n",
      "[157]\tvalidation_0-mlogloss:0.37481\tvalidation_1-mlogloss:0.58906\n",
      "[158]\tvalidation_0-mlogloss:0.37179\tvalidation_1-mlogloss:0.58716\n",
      "[159]\tvalidation_0-mlogloss:0.36890\tvalidation_1-mlogloss:0.58458\n",
      "[160]\tvalidation_0-mlogloss:0.36603\tvalidation_1-mlogloss:0.58214\n",
      "[161]\tvalidation_0-mlogloss:0.36339\tvalidation_1-mlogloss:0.58055\n",
      "[162]\tvalidation_0-mlogloss:0.36047\tvalidation_1-mlogloss:0.57861\n",
      "[163]\tvalidation_0-mlogloss:0.35745\tvalidation_1-mlogloss:0.57561\n",
      "[164]\tvalidation_0-mlogloss:0.35469\tvalidation_1-mlogloss:0.57370\n",
      "[165]\tvalidation_0-mlogloss:0.35178\tvalidation_1-mlogloss:0.57119\n",
      "[166]\tvalidation_0-mlogloss:0.34884\tvalidation_1-mlogloss:0.56841\n",
      "[167]\tvalidation_0-mlogloss:0.34600\tvalidation_1-mlogloss:0.56614\n",
      "[168]\tvalidation_0-mlogloss:0.34323\tvalidation_1-mlogloss:0.56392\n",
      "[169]\tvalidation_0-mlogloss:0.34055\tvalidation_1-mlogloss:0.56170\n",
      "[170]\tvalidation_0-mlogloss:0.33794\tvalidation_1-mlogloss:0.55903\n",
      "[171]\tvalidation_0-mlogloss:0.33542\tvalidation_1-mlogloss:0.55741\n",
      "[172]\tvalidation_0-mlogloss:0.33269\tvalidation_1-mlogloss:0.55502\n",
      "[173]\tvalidation_0-mlogloss:0.33013\tvalidation_1-mlogloss:0.55334\n",
      "[174]\tvalidation_0-mlogloss:0.32753\tvalidation_1-mlogloss:0.55163\n",
      "[175]\tvalidation_0-mlogloss:0.32519\tvalidation_1-mlogloss:0.55052\n",
      "[176]\tvalidation_0-mlogloss:0.32262\tvalidation_1-mlogloss:0.54857\n",
      "[177]\tvalidation_0-mlogloss:0.32022\tvalidation_1-mlogloss:0.54629\n",
      "[178]\tvalidation_0-mlogloss:0.31763\tvalidation_1-mlogloss:0.54337\n",
      "[179]\tvalidation_0-mlogloss:0.31507\tvalidation_1-mlogloss:0.54116\n",
      "[180]\tvalidation_0-mlogloss:0.31259\tvalidation_1-mlogloss:0.53956\n",
      "[181]\tvalidation_0-mlogloss:0.31021\tvalidation_1-mlogloss:0.53776\n",
      "[182]\tvalidation_0-mlogloss:0.30795\tvalidation_1-mlogloss:0.53574\n",
      "[183]\tvalidation_0-mlogloss:0.30558\tvalidation_1-mlogloss:0.53390\n",
      "[184]\tvalidation_0-mlogloss:0.30340\tvalidation_1-mlogloss:0.53284\n",
      "[185]\tvalidation_0-mlogloss:0.30100\tvalidation_1-mlogloss:0.53078\n",
      "[186]\tvalidation_0-mlogloss:0.29858\tvalidation_1-mlogloss:0.52851\n",
      "[187]\tvalidation_0-mlogloss:0.29626\tvalidation_1-mlogloss:0.52642\n",
      "[188]\tvalidation_0-mlogloss:0.29395\tvalidation_1-mlogloss:0.52481\n",
      "[189]\tvalidation_0-mlogloss:0.29169\tvalidation_1-mlogloss:0.52274\n",
      "[190]\tvalidation_0-mlogloss:0.28936\tvalidation_1-mlogloss:0.52063\n",
      "[191]\tvalidation_0-mlogloss:0.28707\tvalidation_1-mlogloss:0.51866\n",
      "[192]\tvalidation_0-mlogloss:0.28492\tvalidation_1-mlogloss:0.51718\n",
      "[193]\tvalidation_0-mlogloss:0.28265\tvalidation_1-mlogloss:0.51451\n",
      "[194]\tvalidation_0-mlogloss:0.28067\tvalidation_1-mlogloss:0.51314\n",
      "[195]\tvalidation_0-mlogloss:0.27864\tvalidation_1-mlogloss:0.51148\n",
      "[196]\tvalidation_0-mlogloss:0.27652\tvalidation_1-mlogloss:0.50932\n",
      "[197]\tvalidation_0-mlogloss:0.27450\tvalidation_1-mlogloss:0.50782\n",
      "[198]\tvalidation_0-mlogloss:0.27248\tvalidation_1-mlogloss:0.50647\n",
      "[199]\tvalidation_0-mlogloss:0.27052\tvalidation_1-mlogloss:0.50551\n",
      "[200]\tvalidation_0-mlogloss:0.26841\tvalidation_1-mlogloss:0.50343\n",
      "[201]\tvalidation_0-mlogloss:0.26636\tvalidation_1-mlogloss:0.50171\n",
      "[202]\tvalidation_0-mlogloss:0.26432\tvalidation_1-mlogloss:0.49961\n",
      "[203]\tvalidation_0-mlogloss:0.26237\tvalidation_1-mlogloss:0.49758\n",
      "[204]\tvalidation_0-mlogloss:0.26034\tvalidation_1-mlogloss:0.49563\n",
      "[205]\tvalidation_0-mlogloss:0.25843\tvalidation_1-mlogloss:0.49421\n",
      "[206]\tvalidation_0-mlogloss:0.25642\tvalidation_1-mlogloss:0.49258\n",
      "[207]\tvalidation_0-mlogloss:0.25457\tvalidation_1-mlogloss:0.49075\n",
      "[208]\tvalidation_0-mlogloss:0.25265\tvalidation_1-mlogloss:0.48895\n",
      "[209]\tvalidation_0-mlogloss:0.25079\tvalidation_1-mlogloss:0.48755\n",
      "[210]\tvalidation_0-mlogloss:0.24903\tvalidation_1-mlogloss:0.48638\n",
      "[211]\tvalidation_0-mlogloss:0.24717\tvalidation_1-mlogloss:0.48502\n",
      "[212]\tvalidation_0-mlogloss:0.24532\tvalidation_1-mlogloss:0.48279\n",
      "[213]\tvalidation_0-mlogloss:0.24352\tvalidation_1-mlogloss:0.48130\n",
      "[214]\tvalidation_0-mlogloss:0.24178\tvalidation_1-mlogloss:0.48006\n",
      "[215]\tvalidation_0-mlogloss:0.24004\tvalidation_1-mlogloss:0.47860\n",
      "[216]\tvalidation_0-mlogloss:0.23827\tvalidation_1-mlogloss:0.47707\n",
      "[217]\tvalidation_0-mlogloss:0.23649\tvalidation_1-mlogloss:0.47589\n",
      "[218]\tvalidation_0-mlogloss:0.23481\tvalidation_1-mlogloss:0.47479\n",
      "[219]\tvalidation_0-mlogloss:0.23312\tvalidation_1-mlogloss:0.47317\n",
      "[220]\tvalidation_0-mlogloss:0.23143\tvalidation_1-mlogloss:0.47145\n",
      "[221]\tvalidation_0-mlogloss:0.22975\tvalidation_1-mlogloss:0.46982\n",
      "[222]\tvalidation_0-mlogloss:0.22800\tvalidation_1-mlogloss:0.46801\n",
      "[223]\tvalidation_0-mlogloss:0.22639\tvalidation_1-mlogloss:0.46729\n",
      "[224]\tvalidation_0-mlogloss:0.22480\tvalidation_1-mlogloss:0.46582\n",
      "[225]\tvalidation_0-mlogloss:0.22322\tvalidation_1-mlogloss:0.46503\n",
      "[226]\tvalidation_0-mlogloss:0.22170\tvalidation_1-mlogloss:0.46436\n",
      "[227]\tvalidation_0-mlogloss:0.22010\tvalidation_1-mlogloss:0.46311\n",
      "[228]\tvalidation_0-mlogloss:0.21861\tvalidation_1-mlogloss:0.46195\n",
      "[229]\tvalidation_0-mlogloss:0.21717\tvalidation_1-mlogloss:0.46113\n",
      "[230]\tvalidation_0-mlogloss:0.21569\tvalidation_1-mlogloss:0.46026\n",
      "[231]\tvalidation_0-mlogloss:0.21424\tvalidation_1-mlogloss:0.45910\n",
      "[232]\tvalidation_0-mlogloss:0.21274\tvalidation_1-mlogloss:0.45828\n",
      "[233]\tvalidation_0-mlogloss:0.21122\tvalidation_1-mlogloss:0.45704\n",
      "[234]\tvalidation_0-mlogloss:0.20976\tvalidation_1-mlogloss:0.45581\n",
      "[235]\tvalidation_0-mlogloss:0.20828\tvalidation_1-mlogloss:0.45473\n",
      "[236]\tvalidation_0-mlogloss:0.20679\tvalidation_1-mlogloss:0.45316\n",
      "[237]\tvalidation_0-mlogloss:0.20532\tvalidation_1-mlogloss:0.45166\n",
      "[238]\tvalidation_0-mlogloss:0.20387\tvalidation_1-mlogloss:0.45034\n",
      "[239]\tvalidation_0-mlogloss:0.20251\tvalidation_1-mlogloss:0.44885\n",
      "[240]\tvalidation_0-mlogloss:0.20118\tvalidation_1-mlogloss:0.44804\n",
      "[241]\tvalidation_0-mlogloss:0.19982\tvalidation_1-mlogloss:0.44733\n",
      "[242]\tvalidation_0-mlogloss:0.19842\tvalidation_1-mlogloss:0.44573\n",
      "[243]\tvalidation_0-mlogloss:0.19697\tvalidation_1-mlogloss:0.44423\n",
      "[244]\tvalidation_0-mlogloss:0.19569\tvalidation_1-mlogloss:0.44362\n",
      "[245]\tvalidation_0-mlogloss:0.19433\tvalidation_1-mlogloss:0.44289\n",
      "[246]\tvalidation_0-mlogloss:0.19302\tvalidation_1-mlogloss:0.44200\n",
      "[247]\tvalidation_0-mlogloss:0.19170\tvalidation_1-mlogloss:0.44121\n",
      "[248]\tvalidation_0-mlogloss:0.19036\tvalidation_1-mlogloss:0.44044\n",
      "[249]\tvalidation_0-mlogloss:0.18903\tvalidation_1-mlogloss:0.43939\n",
      "[250]\tvalidation_0-mlogloss:0.18781\tvalidation_1-mlogloss:0.43829\n",
      "[251]\tvalidation_0-mlogloss:0.18648\tvalidation_1-mlogloss:0.43693\n",
      "[252]\tvalidation_0-mlogloss:0.18518\tvalidation_1-mlogloss:0.43573\n",
      "[253]\tvalidation_0-mlogloss:0.18393\tvalidation_1-mlogloss:0.43486\n",
      "[254]\tvalidation_0-mlogloss:0.18260\tvalidation_1-mlogloss:0.43349\n",
      "[255]\tvalidation_0-mlogloss:0.18134\tvalidation_1-mlogloss:0.43267\n",
      "[256]\tvalidation_0-mlogloss:0.18004\tvalidation_1-mlogloss:0.43111\n",
      "[257]\tvalidation_0-mlogloss:0.17884\tvalidation_1-mlogloss:0.43007\n",
      "[258]\tvalidation_0-mlogloss:0.17774\tvalidation_1-mlogloss:0.42932\n",
      "[259]\tvalidation_0-mlogloss:0.17656\tvalidation_1-mlogloss:0.42822\n",
      "[260]\tvalidation_0-mlogloss:0.17542\tvalidation_1-mlogloss:0.42707\n",
      "[261]\tvalidation_0-mlogloss:0.17427\tvalidation_1-mlogloss:0.42626\n",
      "[262]\tvalidation_0-mlogloss:0.17313\tvalidation_1-mlogloss:0.42522\n",
      "[263]\tvalidation_0-mlogloss:0.17192\tvalidation_1-mlogloss:0.42437\n",
      "[264]\tvalidation_0-mlogloss:0.17073\tvalidation_1-mlogloss:0.42312\n",
      "[265]\tvalidation_0-mlogloss:0.16967\tvalidation_1-mlogloss:0.42200\n",
      "[266]\tvalidation_0-mlogloss:0.16854\tvalidation_1-mlogloss:0.42108\n",
      "[267]\tvalidation_0-mlogloss:0.16739\tvalidation_1-mlogloss:0.42019\n",
      "[268]\tvalidation_0-mlogloss:0.16642\tvalidation_1-mlogloss:0.41925\n",
      "[269]\tvalidation_0-mlogloss:0.16528\tvalidation_1-mlogloss:0.41809\n",
      "[270]\tvalidation_0-mlogloss:0.16424\tvalidation_1-mlogloss:0.41726\n",
      "[271]\tvalidation_0-mlogloss:0.16320\tvalidation_1-mlogloss:0.41682\n",
      "[272]\tvalidation_0-mlogloss:0.16209\tvalidation_1-mlogloss:0.41628\n",
      "[273]\tvalidation_0-mlogloss:0.16101\tvalidation_1-mlogloss:0.41521\n",
      "[274]\tvalidation_0-mlogloss:0.15998\tvalidation_1-mlogloss:0.41438\n",
      "[275]\tvalidation_0-mlogloss:0.15906\tvalidation_1-mlogloss:0.41379\n",
      "[276]\tvalidation_0-mlogloss:0.15810\tvalidation_1-mlogloss:0.41341\n",
      "[277]\tvalidation_0-mlogloss:0.15704\tvalidation_1-mlogloss:0.41225\n",
      "[278]\tvalidation_0-mlogloss:0.15601\tvalidation_1-mlogloss:0.41154\n",
      "[279]\tvalidation_0-mlogloss:0.15498\tvalidation_1-mlogloss:0.41081\n",
      "[280]\tvalidation_0-mlogloss:0.15400\tvalidation_1-mlogloss:0.41000\n",
      "[281]\tvalidation_0-mlogloss:0.15308\tvalidation_1-mlogloss:0.40916\n",
      "[282]\tvalidation_0-mlogloss:0.15218\tvalidation_1-mlogloss:0.40832\n",
      "[283]\tvalidation_0-mlogloss:0.15124\tvalidation_1-mlogloss:0.40772\n",
      "[284]\tvalidation_0-mlogloss:0.15032\tvalidation_1-mlogloss:0.40699\n",
      "[285]\tvalidation_0-mlogloss:0.14934\tvalidation_1-mlogloss:0.40587\n",
      "[286]\tvalidation_0-mlogloss:0.14843\tvalidation_1-mlogloss:0.40517\n",
      "[287]\tvalidation_0-mlogloss:0.14749\tvalidation_1-mlogloss:0.40454\n",
      "[288]\tvalidation_0-mlogloss:0.14661\tvalidation_1-mlogloss:0.40406\n",
      "[289]\tvalidation_0-mlogloss:0.14572\tvalidation_1-mlogloss:0.40325\n",
      "[290]\tvalidation_0-mlogloss:0.14483\tvalidation_1-mlogloss:0.40288\n",
      "[291]\tvalidation_0-mlogloss:0.14386\tvalidation_1-mlogloss:0.40212\n",
      "[292]\tvalidation_0-mlogloss:0.14304\tvalidation_1-mlogloss:0.40164\n",
      "[293]\tvalidation_0-mlogloss:0.14213\tvalidation_1-mlogloss:0.40100\n",
      "[294]\tvalidation_0-mlogloss:0.14121\tvalidation_1-mlogloss:0.40030\n",
      "[295]\tvalidation_0-mlogloss:0.14033\tvalidation_1-mlogloss:0.39926\n",
      "[296]\tvalidation_0-mlogloss:0.13947\tvalidation_1-mlogloss:0.39867\n",
      "[297]\tvalidation_0-mlogloss:0.13863\tvalidation_1-mlogloss:0.39851\n",
      "[298]\tvalidation_0-mlogloss:0.13777\tvalidation_1-mlogloss:0.39791\n",
      "[299]\tvalidation_0-mlogloss:0.13689\tvalidation_1-mlogloss:0.39708\n",
      "[300]\tvalidation_0-mlogloss:0.13601\tvalidation_1-mlogloss:0.39628\n",
      "[301]\tvalidation_0-mlogloss:0.13522\tvalidation_1-mlogloss:0.39610\n",
      "[302]\tvalidation_0-mlogloss:0.13439\tvalidation_1-mlogloss:0.39589\n",
      "[303]\tvalidation_0-mlogloss:0.13353\tvalidation_1-mlogloss:0.39533\n",
      "[304]\tvalidation_0-mlogloss:0.13269\tvalidation_1-mlogloss:0.39438\n",
      "[305]\tvalidation_0-mlogloss:0.13188\tvalidation_1-mlogloss:0.39414\n",
      "[306]\tvalidation_0-mlogloss:0.13106\tvalidation_1-mlogloss:0.39365\n",
      "[307]\tvalidation_0-mlogloss:0.13022\tvalidation_1-mlogloss:0.39267\n",
      "[308]\tvalidation_0-mlogloss:0.12947\tvalidation_1-mlogloss:0.39245\n",
      "[309]\tvalidation_0-mlogloss:0.12866\tvalidation_1-mlogloss:0.39195\n",
      "[310]\tvalidation_0-mlogloss:0.12790\tvalidation_1-mlogloss:0.39168\n",
      "[311]\tvalidation_0-mlogloss:0.12714\tvalidation_1-mlogloss:0.39103\n",
      "[312]\tvalidation_0-mlogloss:0.12640\tvalidation_1-mlogloss:0.39041\n",
      "[313]\tvalidation_0-mlogloss:0.12567\tvalidation_1-mlogloss:0.39002\n",
      "[314]\tvalidation_0-mlogloss:0.12498\tvalidation_1-mlogloss:0.38935\n",
      "[315]\tvalidation_0-mlogloss:0.12426\tvalidation_1-mlogloss:0.38860\n",
      "[316]\tvalidation_0-mlogloss:0.12350\tvalidation_1-mlogloss:0.38797\n",
      "[317]\tvalidation_0-mlogloss:0.12279\tvalidation_1-mlogloss:0.38748\n",
      "[318]\tvalidation_0-mlogloss:0.12209\tvalidation_1-mlogloss:0.38712\n",
      "[319]\tvalidation_0-mlogloss:0.12139\tvalidation_1-mlogloss:0.38663\n",
      "[320]\tvalidation_0-mlogloss:0.12066\tvalidation_1-mlogloss:0.38607\n",
      "[321]\tvalidation_0-mlogloss:0.11999\tvalidation_1-mlogloss:0.38541\n",
      "[322]\tvalidation_0-mlogloss:0.11934\tvalidation_1-mlogloss:0.38524\n",
      "[323]\tvalidation_0-mlogloss:0.11861\tvalidation_1-mlogloss:0.38451\n",
      "[324]\tvalidation_0-mlogloss:0.11793\tvalidation_1-mlogloss:0.38407\n",
      "[325]\tvalidation_0-mlogloss:0.11723\tvalidation_1-mlogloss:0.38331\n",
      "[326]\tvalidation_0-mlogloss:0.11662\tvalidation_1-mlogloss:0.38292\n",
      "[327]\tvalidation_0-mlogloss:0.11593\tvalidation_1-mlogloss:0.38241\n",
      "[328]\tvalidation_0-mlogloss:0.11528\tvalidation_1-mlogloss:0.38196\n",
      "[329]\tvalidation_0-mlogloss:0.11462\tvalidation_1-mlogloss:0.38133\n",
      "[330]\tvalidation_0-mlogloss:0.11395\tvalidation_1-mlogloss:0.38084\n",
      "[331]\tvalidation_0-mlogloss:0.11339\tvalidation_1-mlogloss:0.38054\n",
      "[332]\tvalidation_0-mlogloss:0.11278\tvalidation_1-mlogloss:0.37999\n",
      "[333]\tvalidation_0-mlogloss:0.11218\tvalidation_1-mlogloss:0.37990\n",
      "[334]\tvalidation_0-mlogloss:0.11160\tvalidation_1-mlogloss:0.37921\n",
      "[335]\tvalidation_0-mlogloss:0.11100\tvalidation_1-mlogloss:0.37909\n",
      "[336]\tvalidation_0-mlogloss:0.11041\tvalidation_1-mlogloss:0.37836\n",
      "[337]\tvalidation_0-mlogloss:0.10978\tvalidation_1-mlogloss:0.37809\n",
      "[338]\tvalidation_0-mlogloss:0.10919\tvalidation_1-mlogloss:0.37772\n",
      "[339]\tvalidation_0-mlogloss:0.10860\tvalidation_1-mlogloss:0.37766\n",
      "[340]\tvalidation_0-mlogloss:0.10807\tvalidation_1-mlogloss:0.37738\n",
      "[341]\tvalidation_0-mlogloss:0.10753\tvalidation_1-mlogloss:0.37703\n",
      "[342]\tvalidation_0-mlogloss:0.10697\tvalidation_1-mlogloss:0.37681\n",
      "[343]\tvalidation_0-mlogloss:0.10635\tvalidation_1-mlogloss:0.37650\n",
      "[344]\tvalidation_0-mlogloss:0.10578\tvalidation_1-mlogloss:0.37649\n",
      "[345]\tvalidation_0-mlogloss:0.10524\tvalidation_1-mlogloss:0.37621\n",
      "[346]\tvalidation_0-mlogloss:0.10470\tvalidation_1-mlogloss:0.37614\n",
      "[347]\tvalidation_0-mlogloss:0.10417\tvalidation_1-mlogloss:0.37609\n",
      "[348]\tvalidation_0-mlogloss:0.10360\tvalidation_1-mlogloss:0.37553\n",
      "[349]\tvalidation_0-mlogloss:0.10302\tvalidation_1-mlogloss:0.37490\n",
      "[350]\tvalidation_0-mlogloss:0.10244\tvalidation_1-mlogloss:0.37409\n",
      "[351]\tvalidation_0-mlogloss:0.10187\tvalidation_1-mlogloss:0.37386\n",
      "[352]\tvalidation_0-mlogloss:0.10139\tvalidation_1-mlogloss:0.37325\n",
      "[353]\tvalidation_0-mlogloss:0.10084\tvalidation_1-mlogloss:0.37275\n",
      "[354]\tvalidation_0-mlogloss:0.10030\tvalidation_1-mlogloss:0.37239\n",
      "[355]\tvalidation_0-mlogloss:0.09975\tvalidation_1-mlogloss:0.37214\n",
      "[356]\tvalidation_0-mlogloss:0.09926\tvalidation_1-mlogloss:0.37169\n",
      "[357]\tvalidation_0-mlogloss:0.09876\tvalidation_1-mlogloss:0.37134\n",
      "[358]\tvalidation_0-mlogloss:0.09823\tvalidation_1-mlogloss:0.37065\n",
      "[359]\tvalidation_0-mlogloss:0.09771\tvalidation_1-mlogloss:0.37030\n",
      "[360]\tvalidation_0-mlogloss:0.09718\tvalidation_1-mlogloss:0.36978\n",
      "[361]\tvalidation_0-mlogloss:0.09666\tvalidation_1-mlogloss:0.36933\n",
      "[362]\tvalidation_0-mlogloss:0.09617\tvalidation_1-mlogloss:0.36931\n",
      "[363]\tvalidation_0-mlogloss:0.09568\tvalidation_1-mlogloss:0.36902\n",
      "[364]\tvalidation_0-mlogloss:0.09516\tvalidation_1-mlogloss:0.36859\n",
      "[365]\tvalidation_0-mlogloss:0.09473\tvalidation_1-mlogloss:0.36856\n",
      "[366]\tvalidation_0-mlogloss:0.09432\tvalidation_1-mlogloss:0.36854\n",
      "[367]\tvalidation_0-mlogloss:0.09383\tvalidation_1-mlogloss:0.36813\n",
      "[368]\tvalidation_0-mlogloss:0.09336\tvalidation_1-mlogloss:0.36768\n",
      "[369]\tvalidation_0-mlogloss:0.09291\tvalidation_1-mlogloss:0.36764\n",
      "[370]\tvalidation_0-mlogloss:0.09249\tvalidation_1-mlogloss:0.36754\n",
      "[371]\tvalidation_0-mlogloss:0.09199\tvalidation_1-mlogloss:0.36689\n",
      "[372]\tvalidation_0-mlogloss:0.09155\tvalidation_1-mlogloss:0.36687\n",
      "[373]\tvalidation_0-mlogloss:0.09108\tvalidation_1-mlogloss:0.36662\n",
      "[374]\tvalidation_0-mlogloss:0.09064\tvalidation_1-mlogloss:0.36645\n",
      "[375]\tvalidation_0-mlogloss:0.09020\tvalidation_1-mlogloss:0.36599\n",
      "[376]\tvalidation_0-mlogloss:0.08974\tvalidation_1-mlogloss:0.36596\n",
      "[377]\tvalidation_0-mlogloss:0.08929\tvalidation_1-mlogloss:0.36583\n",
      "[378]\tvalidation_0-mlogloss:0.08884\tvalidation_1-mlogloss:0.36539\n",
      "[379]\tvalidation_0-mlogloss:0.08838\tvalidation_1-mlogloss:0.36495\n",
      "[380]\tvalidation_0-mlogloss:0.08797\tvalidation_1-mlogloss:0.36480\n",
      "[381]\tvalidation_0-mlogloss:0.08760\tvalidation_1-mlogloss:0.36464\n",
      "[382]\tvalidation_0-mlogloss:0.08716\tvalidation_1-mlogloss:0.36399\n",
      "[383]\tvalidation_0-mlogloss:0.08671\tvalidation_1-mlogloss:0.36355\n",
      "[384]\tvalidation_0-mlogloss:0.08629\tvalidation_1-mlogloss:0.36363\n",
      "[385]\tvalidation_0-mlogloss:0.08588\tvalidation_1-mlogloss:0.36358\n",
      "[386]\tvalidation_0-mlogloss:0.08548\tvalidation_1-mlogloss:0.36346\n",
      "[387]\tvalidation_0-mlogloss:0.08515\tvalidation_1-mlogloss:0.36335\n",
      "[388]\tvalidation_0-mlogloss:0.08472\tvalidation_1-mlogloss:0.36320\n",
      "[389]\tvalidation_0-mlogloss:0.08430\tvalidation_1-mlogloss:0.36298\n",
      "[390]\tvalidation_0-mlogloss:0.08392\tvalidation_1-mlogloss:0.36288\n",
      "[391]\tvalidation_0-mlogloss:0.08355\tvalidation_1-mlogloss:0.36254\n",
      "[392]\tvalidation_0-mlogloss:0.08314\tvalidation_1-mlogloss:0.36250\n",
      "[393]\tvalidation_0-mlogloss:0.08277\tvalidation_1-mlogloss:0.36242\n",
      "[394]\tvalidation_0-mlogloss:0.08239\tvalidation_1-mlogloss:0.36196\n",
      "[395]\tvalidation_0-mlogloss:0.08200\tvalidation_1-mlogloss:0.36162\n",
      "[396]\tvalidation_0-mlogloss:0.08163\tvalidation_1-mlogloss:0.36177\n",
      "[397]\tvalidation_0-mlogloss:0.08122\tvalidation_1-mlogloss:0.36175\n",
      "[398]\tvalidation_0-mlogloss:0.08084\tvalidation_1-mlogloss:0.36149\n",
      "[399]\tvalidation_0-mlogloss:0.08043\tvalidation_1-mlogloss:0.36121\n",
      "[400]\tvalidation_0-mlogloss:0.08011\tvalidation_1-mlogloss:0.36108\n",
      "[401]\tvalidation_0-mlogloss:0.07978\tvalidation_1-mlogloss:0.36107\n",
      "[402]\tvalidation_0-mlogloss:0.07941\tvalidation_1-mlogloss:0.36092\n",
      "[403]\tvalidation_0-mlogloss:0.07908\tvalidation_1-mlogloss:0.36101\n",
      "[404]\tvalidation_0-mlogloss:0.07872\tvalidation_1-mlogloss:0.36111\n",
      "[405]\tvalidation_0-mlogloss:0.07837\tvalidation_1-mlogloss:0.36071\n",
      "[406]\tvalidation_0-mlogloss:0.07797\tvalidation_1-mlogloss:0.36027\n",
      "[407]\tvalidation_0-mlogloss:0.07766\tvalidation_1-mlogloss:0.36012\n",
      "[408]\tvalidation_0-mlogloss:0.07730\tvalidation_1-mlogloss:0.36022\n",
      "[409]\tvalidation_0-mlogloss:0.07696\tvalidation_1-mlogloss:0.35953\n",
      "[410]\tvalidation_0-mlogloss:0.07659\tvalidation_1-mlogloss:0.35927\n",
      "[411]\tvalidation_0-mlogloss:0.07623\tvalidation_1-mlogloss:0.35858\n",
      "[412]\tvalidation_0-mlogloss:0.07589\tvalidation_1-mlogloss:0.35822\n",
      "[413]\tvalidation_0-mlogloss:0.07555\tvalidation_1-mlogloss:0.35790\n",
      "[414]\tvalidation_0-mlogloss:0.07523\tvalidation_1-mlogloss:0.35767\n",
      "[415]\tvalidation_0-mlogloss:0.07489\tvalidation_1-mlogloss:0.35744\n",
      "[416]\tvalidation_0-mlogloss:0.07459\tvalidation_1-mlogloss:0.35732\n",
      "[417]\tvalidation_0-mlogloss:0.07424\tvalidation_1-mlogloss:0.35747\n",
      "[418]\tvalidation_0-mlogloss:0.07388\tvalidation_1-mlogloss:0.35738\n",
      "[419]\tvalidation_0-mlogloss:0.07354\tvalidation_1-mlogloss:0.35699\n",
      "[420]\tvalidation_0-mlogloss:0.07323\tvalidation_1-mlogloss:0.35692\n",
      "[421]\tvalidation_0-mlogloss:0.07287\tvalidation_1-mlogloss:0.35625\n",
      "[422]\tvalidation_0-mlogloss:0.07257\tvalidation_1-mlogloss:0.35569\n",
      "[423]\tvalidation_0-mlogloss:0.07224\tvalidation_1-mlogloss:0.35531\n",
      "[424]\tvalidation_0-mlogloss:0.07194\tvalidation_1-mlogloss:0.35509\n",
      "[425]\tvalidation_0-mlogloss:0.07163\tvalidation_1-mlogloss:0.35474\n",
      "[426]\tvalidation_0-mlogloss:0.07132\tvalidation_1-mlogloss:0.35444\n",
      "[427]\tvalidation_0-mlogloss:0.07101\tvalidation_1-mlogloss:0.35418\n",
      "[428]\tvalidation_0-mlogloss:0.07068\tvalidation_1-mlogloss:0.35426\n",
      "[429]\tvalidation_0-mlogloss:0.07036\tvalidation_1-mlogloss:0.35419\n",
      "[430]\tvalidation_0-mlogloss:0.07006\tvalidation_1-mlogloss:0.35392\n",
      "[431]\tvalidation_0-mlogloss:0.06980\tvalidation_1-mlogloss:0.35353\n",
      "[432]\tvalidation_0-mlogloss:0.06954\tvalidation_1-mlogloss:0.35333\n",
      "[433]\tvalidation_0-mlogloss:0.06925\tvalidation_1-mlogloss:0.35319\n",
      "[434]\tvalidation_0-mlogloss:0.06903\tvalidation_1-mlogloss:0.35310\n",
      "[435]\tvalidation_0-mlogloss:0.06875\tvalidation_1-mlogloss:0.35296\n",
      "[436]\tvalidation_0-mlogloss:0.06843\tvalidation_1-mlogloss:0.35287\n",
      "[437]\tvalidation_0-mlogloss:0.06814\tvalidation_1-mlogloss:0.35225\n",
      "[438]\tvalidation_0-mlogloss:0.06783\tvalidation_1-mlogloss:0.35171\n",
      "[439]\tvalidation_0-mlogloss:0.06754\tvalidation_1-mlogloss:0.35158\n",
      "[440]\tvalidation_0-mlogloss:0.06732\tvalidation_1-mlogloss:0.35163\n",
      "[441]\tvalidation_0-mlogloss:0.06710\tvalidation_1-mlogloss:0.35114\n",
      "[442]\tvalidation_0-mlogloss:0.06692\tvalidation_1-mlogloss:0.35112\n",
      "[443]\tvalidation_0-mlogloss:0.06665\tvalidation_1-mlogloss:0.35074\n",
      "[444]\tvalidation_0-mlogloss:0.06644\tvalidation_1-mlogloss:0.35070\n",
      "[445]\tvalidation_0-mlogloss:0.06620\tvalidation_1-mlogloss:0.35060\n",
      "[446]\tvalidation_0-mlogloss:0.06596\tvalidation_1-mlogloss:0.35052\n",
      "[447]\tvalidation_0-mlogloss:0.06572\tvalidation_1-mlogloss:0.35058\n",
      "[448]\tvalidation_0-mlogloss:0.06545\tvalidation_1-mlogloss:0.35067\n",
      "[449]\tvalidation_0-mlogloss:0.06528\tvalidation_1-mlogloss:0.35051\n",
      "[450]\tvalidation_0-mlogloss:0.06502\tvalidation_1-mlogloss:0.35020\n",
      "[451]\tvalidation_0-mlogloss:0.06476\tvalidation_1-mlogloss:0.35022\n",
      "[452]\tvalidation_0-mlogloss:0.06450\tvalidation_1-mlogloss:0.34979\n",
      "[453]\tvalidation_0-mlogloss:0.06421\tvalidation_1-mlogloss:0.34959\n",
      "[454]\tvalidation_0-mlogloss:0.06404\tvalidation_1-mlogloss:0.34950\n",
      "[455]\tvalidation_0-mlogloss:0.06376\tvalidation_1-mlogloss:0.34948\n",
      "[456]\tvalidation_0-mlogloss:0.06357\tvalidation_1-mlogloss:0.34914\n",
      "[457]\tvalidation_0-mlogloss:0.06331\tvalidation_1-mlogloss:0.34911\n",
      "[458]\tvalidation_0-mlogloss:0.06307\tvalidation_1-mlogloss:0.34910\n",
      "[459]\tvalidation_0-mlogloss:0.06286\tvalidation_1-mlogloss:0.34879\n",
      "[460]\tvalidation_0-mlogloss:0.06267\tvalidation_1-mlogloss:0.34869\n",
      "[461]\tvalidation_0-mlogloss:0.06242\tvalidation_1-mlogloss:0.34871\n",
      "[462]\tvalidation_0-mlogloss:0.06218\tvalidation_1-mlogloss:0.34877\n",
      "[463]\tvalidation_0-mlogloss:0.06190\tvalidation_1-mlogloss:0.34871\n",
      "[464]\tvalidation_0-mlogloss:0.06170\tvalidation_1-mlogloss:0.34855\n",
      "[465]\tvalidation_0-mlogloss:0.06155\tvalidation_1-mlogloss:0.34832\n",
      "[466]\tvalidation_0-mlogloss:0.06141\tvalidation_1-mlogloss:0.34823\n",
      "[467]\tvalidation_0-mlogloss:0.06121\tvalidation_1-mlogloss:0.34817\n",
      "[468]\tvalidation_0-mlogloss:0.06101\tvalidation_1-mlogloss:0.34802\n",
      "[469]\tvalidation_0-mlogloss:0.06079\tvalidation_1-mlogloss:0.34765\n",
      "[470]\tvalidation_0-mlogloss:0.06059\tvalidation_1-mlogloss:0.34755\n",
      "[471]\tvalidation_0-mlogloss:0.06037\tvalidation_1-mlogloss:0.34713\n",
      "[472]\tvalidation_0-mlogloss:0.06018\tvalidation_1-mlogloss:0.34717\n",
      "[473]\tvalidation_0-mlogloss:0.05994\tvalidation_1-mlogloss:0.34676\n",
      "[474]\tvalidation_0-mlogloss:0.05975\tvalidation_1-mlogloss:0.34663\n",
      "[475]\tvalidation_0-mlogloss:0.05959\tvalidation_1-mlogloss:0.34672\n",
      "[476]\tvalidation_0-mlogloss:0.05936\tvalidation_1-mlogloss:0.34625\n",
      "[477]\tvalidation_0-mlogloss:0.05921\tvalidation_1-mlogloss:0.34623\n",
      "[478]\tvalidation_0-mlogloss:0.05909\tvalidation_1-mlogloss:0.34608\n",
      "[479]\tvalidation_0-mlogloss:0.05888\tvalidation_1-mlogloss:0.34587\n",
      "[480]\tvalidation_0-mlogloss:0.05872\tvalidation_1-mlogloss:0.34570\n",
      "[481]\tvalidation_0-mlogloss:0.05860\tvalidation_1-mlogloss:0.34578\n",
      "[482]\tvalidation_0-mlogloss:0.05847\tvalidation_1-mlogloss:0.34564\n",
      "[483]\tvalidation_0-mlogloss:0.05827\tvalidation_1-mlogloss:0.34566\n",
      "[484]\tvalidation_0-mlogloss:0.05808\tvalidation_1-mlogloss:0.34536\n",
      "[485]\tvalidation_0-mlogloss:0.05784\tvalidation_1-mlogloss:0.34533\n",
      "[486]\tvalidation_0-mlogloss:0.05766\tvalidation_1-mlogloss:0.34505\n",
      "[487]\tvalidation_0-mlogloss:0.05751\tvalidation_1-mlogloss:0.34497\n",
      "[488]\tvalidation_0-mlogloss:0.05738\tvalidation_1-mlogloss:0.34511\n",
      "[489]\tvalidation_0-mlogloss:0.05727\tvalidation_1-mlogloss:0.34501\n",
      "[490]\tvalidation_0-mlogloss:0.05716\tvalidation_1-mlogloss:0.34482\n",
      "[491]\tvalidation_0-mlogloss:0.05695\tvalidation_1-mlogloss:0.34471\n",
      "[492]\tvalidation_0-mlogloss:0.05681\tvalidation_1-mlogloss:0.34469\n",
      "[493]\tvalidation_0-mlogloss:0.05665\tvalidation_1-mlogloss:0.34438\n",
      "[494]\tvalidation_0-mlogloss:0.05651\tvalidation_1-mlogloss:0.34450\n",
      "[495]\tvalidation_0-mlogloss:0.05633\tvalidation_1-mlogloss:0.34445\n",
      "[496]\tvalidation_0-mlogloss:0.05622\tvalidation_1-mlogloss:0.34433\n",
      "[497]\tvalidation_0-mlogloss:0.05610\tvalidation_1-mlogloss:0.34406\n",
      "[498]\tvalidation_0-mlogloss:0.05599\tvalidation_1-mlogloss:0.34389\n",
      "[499]\tvalidation_0-mlogloss:0.05579\tvalidation_1-mlogloss:0.34356\n",
      "[500]\tvalidation_0-mlogloss:0.05561\tvalidation_1-mlogloss:0.34351\n",
      "[501]\tvalidation_0-mlogloss:0.05551\tvalidation_1-mlogloss:0.34344\n",
      "[502]\tvalidation_0-mlogloss:0.05535\tvalidation_1-mlogloss:0.34315\n",
      "[503]\tvalidation_0-mlogloss:0.05524\tvalidation_1-mlogloss:0.34318\n",
      "[504]\tvalidation_0-mlogloss:0.05513\tvalidation_1-mlogloss:0.34315\n",
      "[505]\tvalidation_0-mlogloss:0.05502\tvalidation_1-mlogloss:0.34319\n",
      "[506]\tvalidation_0-mlogloss:0.05491\tvalidation_1-mlogloss:0.34325\n",
      "[507]\tvalidation_0-mlogloss:0.05477\tvalidation_1-mlogloss:0.34288\n",
      "[508]\tvalidation_0-mlogloss:0.05467\tvalidation_1-mlogloss:0.34269\n",
      "[509]\tvalidation_0-mlogloss:0.05457\tvalidation_1-mlogloss:0.34227\n",
      "[510]\tvalidation_0-mlogloss:0.05446\tvalidation_1-mlogloss:0.34196\n",
      "[511]\tvalidation_0-mlogloss:0.05436\tvalidation_1-mlogloss:0.34170\n",
      "[512]\tvalidation_0-mlogloss:0.05426\tvalidation_1-mlogloss:0.34158\n",
      "[513]\tvalidation_0-mlogloss:0.05415\tvalidation_1-mlogloss:0.34155\n",
      "[514]\tvalidation_0-mlogloss:0.05395\tvalidation_1-mlogloss:0.34123\n",
      "[515]\tvalidation_0-mlogloss:0.05389\tvalidation_1-mlogloss:0.34133\n",
      "[516]\tvalidation_0-mlogloss:0.05374\tvalidation_1-mlogloss:0.34110\n",
      "[517]\tvalidation_0-mlogloss:0.05364\tvalidation_1-mlogloss:0.34089\n",
      "[518]\tvalidation_0-mlogloss:0.05353\tvalidation_1-mlogloss:0.34079\n",
      "[519]\tvalidation_0-mlogloss:0.05338\tvalidation_1-mlogloss:0.34094\n",
      "[520]\tvalidation_0-mlogloss:0.05325\tvalidation_1-mlogloss:0.34077\n",
      "[521]\tvalidation_0-mlogloss:0.05316\tvalidation_1-mlogloss:0.34070\n",
      "[522]\tvalidation_0-mlogloss:0.05305\tvalidation_1-mlogloss:0.34061\n",
      "[523]\tvalidation_0-mlogloss:0.05292\tvalidation_1-mlogloss:0.34041\n",
      "[524]\tvalidation_0-mlogloss:0.05282\tvalidation_1-mlogloss:0.34066\n",
      "[525]\tvalidation_0-mlogloss:0.05272\tvalidation_1-mlogloss:0.34050\n",
      "[526]\tvalidation_0-mlogloss:0.05261\tvalidation_1-mlogloss:0.34049\n",
      "[527]\tvalidation_0-mlogloss:0.05251\tvalidation_1-mlogloss:0.34017\n",
      "[528]\tvalidation_0-mlogloss:0.05242\tvalidation_1-mlogloss:0.34013\n",
      "[529]\tvalidation_0-mlogloss:0.05232\tvalidation_1-mlogloss:0.33995\n",
      "[530]\tvalidation_0-mlogloss:0.05223\tvalidation_1-mlogloss:0.33991\n",
      "[531]\tvalidation_0-mlogloss:0.05213\tvalidation_1-mlogloss:0.33962\n",
      "[532]\tvalidation_0-mlogloss:0.05207\tvalidation_1-mlogloss:0.33970\n",
      "[533]\tvalidation_0-mlogloss:0.05198\tvalidation_1-mlogloss:0.33932\n",
      "[534]\tvalidation_0-mlogloss:0.05192\tvalidation_1-mlogloss:0.33915\n",
      "[535]\tvalidation_0-mlogloss:0.05186\tvalidation_1-mlogloss:0.33912\n",
      "[536]\tvalidation_0-mlogloss:0.05177\tvalidation_1-mlogloss:0.33886\n",
      "[537]\tvalidation_0-mlogloss:0.05171\tvalidation_1-mlogloss:0.33909\n",
      "[538]\tvalidation_0-mlogloss:0.05164\tvalidation_1-mlogloss:0.33888\n",
      "[539]\tvalidation_0-mlogloss:0.05155\tvalidation_1-mlogloss:0.33880\n",
      "[540]\tvalidation_0-mlogloss:0.05148\tvalidation_1-mlogloss:0.33862\n",
      "[541]\tvalidation_0-mlogloss:0.05138\tvalidation_1-mlogloss:0.33865\n",
      "[542]\tvalidation_0-mlogloss:0.05131\tvalidation_1-mlogloss:0.33866\n",
      "[543]\tvalidation_0-mlogloss:0.05127\tvalidation_1-mlogloss:0.33862\n",
      "[544]\tvalidation_0-mlogloss:0.05121\tvalidation_1-mlogloss:0.33878\n",
      "[545]\tvalidation_0-mlogloss:0.05113\tvalidation_1-mlogloss:0.33869\n",
      "[546]\tvalidation_0-mlogloss:0.05104\tvalidation_1-mlogloss:0.33867\n",
      "[547]\tvalidation_0-mlogloss:0.05090\tvalidation_1-mlogloss:0.33843\n",
      "[548]\tvalidation_0-mlogloss:0.05085\tvalidation_1-mlogloss:0.33850\n",
      "[549]\tvalidation_0-mlogloss:0.05077\tvalidation_1-mlogloss:0.33820\n",
      "[550]\tvalidation_0-mlogloss:0.05068\tvalidation_1-mlogloss:0.33811\n",
      "[551]\tvalidation_0-mlogloss:0.05059\tvalidation_1-mlogloss:0.33813\n",
      "[552]\tvalidation_0-mlogloss:0.05051\tvalidation_1-mlogloss:0.33814\n",
      "[553]\tvalidation_0-mlogloss:0.05041\tvalidation_1-mlogloss:0.33815\n",
      "[554]\tvalidation_0-mlogloss:0.05035\tvalidation_1-mlogloss:0.33811\n",
      "[555]\tvalidation_0-mlogloss:0.05030\tvalidation_1-mlogloss:0.33810\n",
      "[556]\tvalidation_0-mlogloss:0.05023\tvalidation_1-mlogloss:0.33808\n",
      "[557]\tvalidation_0-mlogloss:0.05017\tvalidation_1-mlogloss:0.33789\n",
      "[558]\tvalidation_0-mlogloss:0.05008\tvalidation_1-mlogloss:0.33766\n",
      "[559]\tvalidation_0-mlogloss:0.04999\tvalidation_1-mlogloss:0.33768\n",
      "[560]\tvalidation_0-mlogloss:0.04992\tvalidation_1-mlogloss:0.33749\n",
      "[561]\tvalidation_0-mlogloss:0.04987\tvalidation_1-mlogloss:0.33726\n",
      "[562]\tvalidation_0-mlogloss:0.04980\tvalidation_1-mlogloss:0.33712\n",
      "[563]\tvalidation_0-mlogloss:0.04972\tvalidation_1-mlogloss:0.33712\n",
      "[564]\tvalidation_0-mlogloss:0.04963\tvalidation_1-mlogloss:0.33709\n",
      "[565]\tvalidation_0-mlogloss:0.04958\tvalidation_1-mlogloss:0.33685\n",
      "[566]\tvalidation_0-mlogloss:0.04951\tvalidation_1-mlogloss:0.33678\n",
      "[567]\tvalidation_0-mlogloss:0.04942\tvalidation_1-mlogloss:0.33669\n",
      "[568]\tvalidation_0-mlogloss:0.04937\tvalidation_1-mlogloss:0.33669\n",
      "[569]\tvalidation_0-mlogloss:0.04935\tvalidation_1-mlogloss:0.33666\n",
      "[570]\tvalidation_0-mlogloss:0.04927\tvalidation_1-mlogloss:0.33670\n",
      "[571]\tvalidation_0-mlogloss:0.04917\tvalidation_1-mlogloss:0.33677\n",
      "[572]\tvalidation_0-mlogloss:0.04912\tvalidation_1-mlogloss:0.33671\n",
      "[573]\tvalidation_0-mlogloss:0.04908\tvalidation_1-mlogloss:0.33662\n",
      "[574]\tvalidation_0-mlogloss:0.04900\tvalidation_1-mlogloss:0.33670\n",
      "[575]\tvalidation_0-mlogloss:0.04892\tvalidation_1-mlogloss:0.33677\n",
      "[576]\tvalidation_0-mlogloss:0.04888\tvalidation_1-mlogloss:0.33694\n",
      "[577]\tvalidation_0-mlogloss:0.04880\tvalidation_1-mlogloss:0.33675\n",
      "[578]\tvalidation_0-mlogloss:0.04879\tvalidation_1-mlogloss:0.33678\n",
      "[579]\tvalidation_0-mlogloss:0.04872\tvalidation_1-mlogloss:0.33670\n",
      "[580]\tvalidation_0-mlogloss:0.04865\tvalidation_1-mlogloss:0.33654\n",
      "[581]\tvalidation_0-mlogloss:0.04861\tvalidation_1-mlogloss:0.33666\n",
      "[582]\tvalidation_0-mlogloss:0.04853\tvalidation_1-mlogloss:0.33628\n",
      "[583]\tvalidation_0-mlogloss:0.04848\tvalidation_1-mlogloss:0.33607\n",
      "[584]\tvalidation_0-mlogloss:0.04843\tvalidation_1-mlogloss:0.33601\n",
      "[585]\tvalidation_0-mlogloss:0.04838\tvalidation_1-mlogloss:0.33615\n",
      "[586]\tvalidation_0-mlogloss:0.04831\tvalidation_1-mlogloss:0.33594\n",
      "[587]\tvalidation_0-mlogloss:0.04829\tvalidation_1-mlogloss:0.33604\n",
      "[588]\tvalidation_0-mlogloss:0.04827\tvalidation_1-mlogloss:0.33612\n",
      "[589]\tvalidation_0-mlogloss:0.04823\tvalidation_1-mlogloss:0.33629\n",
      "[590]\tvalidation_0-mlogloss:0.04819\tvalidation_1-mlogloss:0.33610\n",
      "[591]\tvalidation_0-mlogloss:0.04817\tvalidation_1-mlogloss:0.33599\n",
      "[592]\tvalidation_0-mlogloss:0.04811\tvalidation_1-mlogloss:0.33582\n",
      "[593]\tvalidation_0-mlogloss:0.04804\tvalidation_1-mlogloss:0.33569\n",
      "[594]\tvalidation_0-mlogloss:0.04800\tvalidation_1-mlogloss:0.33581\n",
      "[595]\tvalidation_0-mlogloss:0.04798\tvalidation_1-mlogloss:0.33594\n",
      "[596]\tvalidation_0-mlogloss:0.04794\tvalidation_1-mlogloss:0.33573\n",
      "[597]\tvalidation_0-mlogloss:0.04789\tvalidation_1-mlogloss:0.33571\n",
      "[598]\tvalidation_0-mlogloss:0.04782\tvalidation_1-mlogloss:0.33572\n",
      "[599]\tvalidation_0-mlogloss:0.04779\tvalidation_1-mlogloss:0.33568\n",
      "[600]\tvalidation_0-mlogloss:0.04775\tvalidation_1-mlogloss:0.33574\n",
      "[601]\tvalidation_0-mlogloss:0.04772\tvalidation_1-mlogloss:0.33572\n",
      "[602]\tvalidation_0-mlogloss:0.04770\tvalidation_1-mlogloss:0.33579\n",
      "[603]\tvalidation_0-mlogloss:0.04768\tvalidation_1-mlogloss:0.33592\n",
      "[604]\tvalidation_0-mlogloss:0.04766\tvalidation_1-mlogloss:0.33579\n",
      "[605]\tvalidation_0-mlogloss:0.04763\tvalidation_1-mlogloss:0.33574\n",
      "[606]\tvalidation_0-mlogloss:0.04759\tvalidation_1-mlogloss:0.33588\n",
      "[607]\tvalidation_0-mlogloss:0.04754\tvalidation_1-mlogloss:0.33598\n",
      "[608]\tvalidation_0-mlogloss:0.04752\tvalidation_1-mlogloss:0.33603\n",
      "[609]\tvalidation_0-mlogloss:0.04748\tvalidation_1-mlogloss:0.33615\n",
      "[610]\tvalidation_0-mlogloss:0.04743\tvalidation_1-mlogloss:0.33634\n",
      "[611]\tvalidation_0-mlogloss:0.04735\tvalidation_1-mlogloss:0.33611\n",
      "[612]\tvalidation_0-mlogloss:0.04730\tvalidation_1-mlogloss:0.33609\n",
      "[613]\tvalidation_0-mlogloss:0.04728\tvalidation_1-mlogloss:0.33600\n",
      "[614]\tvalidation_0-mlogloss:0.04721\tvalidation_1-mlogloss:0.33593\n",
      "[615]\tvalidation_0-mlogloss:0.04714\tvalidation_1-mlogloss:0.33592\n",
      "[616]\tvalidation_0-mlogloss:0.04712\tvalidation_1-mlogloss:0.33583\n",
      "[617]\tvalidation_0-mlogloss:0.04709\tvalidation_1-mlogloss:0.33598\n",
      "[618]\tvalidation_0-mlogloss:0.04705\tvalidation_1-mlogloss:0.33591\n",
      "[619]\tvalidation_0-mlogloss:0.04702\tvalidation_1-mlogloss:0.33592\n",
      "[16:53:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"reg_alpha_l1\", \"reg_lambda_l2\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-mlogloss:1.59176\tvalidation_1-mlogloss:1.59661\n",
      "[1]\tvalidation_0-mlogloss:1.57405\tvalidation_1-mlogloss:1.58270\n",
      "[2]\tvalidation_0-mlogloss:1.55599\tvalidation_1-mlogloss:1.56708\n",
      "[3]\tvalidation_0-mlogloss:1.53933\tvalidation_1-mlogloss:1.55482\n",
      "[4]\tvalidation_0-mlogloss:1.52327\tvalidation_1-mlogloss:1.54053\n",
      "[5]\tvalidation_0-mlogloss:1.50560\tvalidation_1-mlogloss:1.52476\n",
      "[6]\tvalidation_0-mlogloss:1.48807\tvalidation_1-mlogloss:1.50904\n",
      "[7]\tvalidation_0-mlogloss:1.47244\tvalidation_1-mlogloss:1.49522\n",
      "[8]\tvalidation_0-mlogloss:1.45620\tvalidation_1-mlogloss:1.48344\n",
      "[9]\tvalidation_0-mlogloss:1.44044\tvalidation_1-mlogloss:1.47171\n",
      "[10]\tvalidation_0-mlogloss:1.42570\tvalidation_1-mlogloss:1.46026\n",
      "[11]\tvalidation_0-mlogloss:1.41022\tvalidation_1-mlogloss:1.44853\n",
      "[12]\tvalidation_0-mlogloss:1.39473\tvalidation_1-mlogloss:1.43519\n",
      "[13]\tvalidation_0-mlogloss:1.37996\tvalidation_1-mlogloss:1.42294\n",
      "[14]\tvalidation_0-mlogloss:1.36571\tvalidation_1-mlogloss:1.41184\n",
      "[15]\tvalidation_0-mlogloss:1.35079\tvalidation_1-mlogloss:1.39942\n",
      "[16]\tvalidation_0-mlogloss:1.33721\tvalidation_1-mlogloss:1.38907\n",
      "[17]\tvalidation_0-mlogloss:1.32357\tvalidation_1-mlogloss:1.37797\n",
      "[18]\tvalidation_0-mlogloss:1.30929\tvalidation_1-mlogloss:1.36604\n",
      "[19]\tvalidation_0-mlogloss:1.29619\tvalidation_1-mlogloss:1.35670\n",
      "[20]\tvalidation_0-mlogloss:1.28311\tvalidation_1-mlogloss:1.34617\n",
      "[21]\tvalidation_0-mlogloss:1.27012\tvalidation_1-mlogloss:1.33559\n",
      "[22]\tvalidation_0-mlogloss:1.25761\tvalidation_1-mlogloss:1.32685\n",
      "[23]\tvalidation_0-mlogloss:1.24474\tvalidation_1-mlogloss:1.31688\n",
      "[24]\tvalidation_0-mlogloss:1.23311\tvalidation_1-mlogloss:1.30817\n",
      "[25]\tvalidation_0-mlogloss:1.22142\tvalidation_1-mlogloss:1.29954\n",
      "[26]\tvalidation_0-mlogloss:1.20843\tvalidation_1-mlogloss:1.28802\n",
      "[27]\tvalidation_0-mlogloss:1.19639\tvalidation_1-mlogloss:1.27831\n",
      "[28]\tvalidation_0-mlogloss:1.18467\tvalidation_1-mlogloss:1.27010\n",
      "[29]\tvalidation_0-mlogloss:1.17242\tvalidation_1-mlogloss:1.26144\n",
      "[30]\tvalidation_0-mlogloss:1.16081\tvalidation_1-mlogloss:1.25148\n",
      "[31]\tvalidation_0-mlogloss:1.14989\tvalidation_1-mlogloss:1.24272\n",
      "[32]\tvalidation_0-mlogloss:1.13767\tvalidation_1-mlogloss:1.23091\n",
      "[33]\tvalidation_0-mlogloss:1.12720\tvalidation_1-mlogloss:1.22243\n",
      "[34]\tvalidation_0-mlogloss:1.11615\tvalidation_1-mlogloss:1.21259\n",
      "[35]\tvalidation_0-mlogloss:1.10568\tvalidation_1-mlogloss:1.20407\n",
      "[36]\tvalidation_0-mlogloss:1.09547\tvalidation_1-mlogloss:1.19419\n",
      "[37]\tvalidation_0-mlogloss:1.08511\tvalidation_1-mlogloss:1.18725\n",
      "[38]\tvalidation_0-mlogloss:1.07370\tvalidation_1-mlogloss:1.17722\n",
      "[39]\tvalidation_0-mlogloss:1.06313\tvalidation_1-mlogloss:1.16848\n",
      "[40]\tvalidation_0-mlogloss:1.05301\tvalidation_1-mlogloss:1.16015\n",
      "[41]\tvalidation_0-mlogloss:1.04227\tvalidation_1-mlogloss:1.15074\n",
      "[42]\tvalidation_0-mlogloss:1.03217\tvalidation_1-mlogloss:1.14344\n",
      "[43]\tvalidation_0-mlogloss:1.02263\tvalidation_1-mlogloss:1.13635\n",
      "[44]\tvalidation_0-mlogloss:1.01290\tvalidation_1-mlogloss:1.12897\n",
      "[45]\tvalidation_0-mlogloss:1.00362\tvalidation_1-mlogloss:1.12162\n",
      "[46]\tvalidation_0-mlogloss:0.99363\tvalidation_1-mlogloss:1.11244\n",
      "[47]\tvalidation_0-mlogloss:0.98482\tvalidation_1-mlogloss:1.10504\n",
      "[48]\tvalidation_0-mlogloss:0.97504\tvalidation_1-mlogloss:1.09620\n",
      "[49]\tvalidation_0-mlogloss:0.96537\tvalidation_1-mlogloss:1.08728\n",
      "[50]\tvalidation_0-mlogloss:0.95626\tvalidation_1-mlogloss:1.07898\n",
      "[51]\tvalidation_0-mlogloss:0.94697\tvalidation_1-mlogloss:1.07144\n",
      "[52]\tvalidation_0-mlogloss:0.93819\tvalidation_1-mlogloss:1.06422\n",
      "[53]\tvalidation_0-mlogloss:0.92924\tvalidation_1-mlogloss:1.05551\n",
      "[54]\tvalidation_0-mlogloss:0.92083\tvalidation_1-mlogloss:1.04908\n",
      "[55]\tvalidation_0-mlogloss:0.91204\tvalidation_1-mlogloss:1.04211\n",
      "[56]\tvalidation_0-mlogloss:0.90345\tvalidation_1-mlogloss:1.03537\n",
      "[57]\tvalidation_0-mlogloss:0.89539\tvalidation_1-mlogloss:1.02883\n",
      "[58]\tvalidation_0-mlogloss:0.88713\tvalidation_1-mlogloss:1.02282\n",
      "[59]\tvalidation_0-mlogloss:0.87849\tvalidation_1-mlogloss:1.01512\n",
      "[60]\tvalidation_0-mlogloss:0.87023\tvalidation_1-mlogloss:1.00951\n",
      "[61]\tvalidation_0-mlogloss:0.86205\tvalidation_1-mlogloss:1.00217\n",
      "[62]\tvalidation_0-mlogloss:0.85472\tvalidation_1-mlogloss:0.99575\n",
      "[63]\tvalidation_0-mlogloss:0.84690\tvalidation_1-mlogloss:0.98964\n",
      "[64]\tvalidation_0-mlogloss:0.83873\tvalidation_1-mlogloss:0.98204\n",
      "[65]\tvalidation_0-mlogloss:0.83104\tvalidation_1-mlogloss:0.97667\n",
      "[66]\tvalidation_0-mlogloss:0.82363\tvalidation_1-mlogloss:0.97183\n",
      "[67]\tvalidation_0-mlogloss:0.81604\tvalidation_1-mlogloss:0.96664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[68]\tvalidation_0-mlogloss:0.80865\tvalidation_1-mlogloss:0.96180\n",
      "[69]\tvalidation_0-mlogloss:0.80146\tvalidation_1-mlogloss:0.95541\n",
      "[70]\tvalidation_0-mlogloss:0.79372\tvalidation_1-mlogloss:0.94804\n",
      "[71]\tvalidation_0-mlogloss:0.78663\tvalidation_1-mlogloss:0.94137\n",
      "[72]\tvalidation_0-mlogloss:0.77919\tvalidation_1-mlogloss:0.93549\n",
      "[73]\tvalidation_0-mlogloss:0.77245\tvalidation_1-mlogloss:0.92968\n",
      "[74]\tvalidation_0-mlogloss:0.76519\tvalidation_1-mlogloss:0.92354\n",
      "[75]\tvalidation_0-mlogloss:0.75832\tvalidation_1-mlogloss:0.91772\n",
      "[76]\tvalidation_0-mlogloss:0.75162\tvalidation_1-mlogloss:0.91238\n",
      "[77]\tvalidation_0-mlogloss:0.74528\tvalidation_1-mlogloss:0.90777\n",
      "[78]\tvalidation_0-mlogloss:0.73872\tvalidation_1-mlogloss:0.90204\n",
      "[79]\tvalidation_0-mlogloss:0.73176\tvalidation_1-mlogloss:0.89590\n",
      "[80]\tvalidation_0-mlogloss:0.72492\tvalidation_1-mlogloss:0.88965\n",
      "[81]\tvalidation_0-mlogloss:0.71816\tvalidation_1-mlogloss:0.88380\n",
      "[82]\tvalidation_0-mlogloss:0.71178\tvalidation_1-mlogloss:0.87835\n",
      "[83]\tvalidation_0-mlogloss:0.70532\tvalidation_1-mlogloss:0.87303\n",
      "[84]\tvalidation_0-mlogloss:0.69909\tvalidation_1-mlogloss:0.86816\n",
      "[85]\tvalidation_0-mlogloss:0.69270\tvalidation_1-mlogloss:0.86325\n",
      "[86]\tvalidation_0-mlogloss:0.68658\tvalidation_1-mlogloss:0.85784\n",
      "[87]\tvalidation_0-mlogloss:0.68054\tvalidation_1-mlogloss:0.85223\n",
      "[88]\tvalidation_0-mlogloss:0.67446\tvalidation_1-mlogloss:0.84730\n",
      "[89]\tvalidation_0-mlogloss:0.66829\tvalidation_1-mlogloss:0.84198\n",
      "[90]\tvalidation_0-mlogloss:0.66242\tvalidation_1-mlogloss:0.83661\n",
      "[91]\tvalidation_0-mlogloss:0.65699\tvalidation_1-mlogloss:0.83279\n",
      "[92]\tvalidation_0-mlogloss:0.65089\tvalidation_1-mlogloss:0.82693\n",
      "[93]\tvalidation_0-mlogloss:0.64499\tvalidation_1-mlogloss:0.82237\n",
      "[94]\tvalidation_0-mlogloss:0.63929\tvalidation_1-mlogloss:0.81662\n",
      "[95]\tvalidation_0-mlogloss:0.63382\tvalidation_1-mlogloss:0.81263\n",
      "[96]\tvalidation_0-mlogloss:0.62821\tvalidation_1-mlogloss:0.80761\n",
      "[97]\tvalidation_0-mlogloss:0.62255\tvalidation_1-mlogloss:0.80299\n",
      "[98]\tvalidation_0-mlogloss:0.61692\tvalidation_1-mlogloss:0.79793\n",
      "[99]\tvalidation_0-mlogloss:0.61184\tvalidation_1-mlogloss:0.79387\n",
      "[100]\tvalidation_0-mlogloss:0.60649\tvalidation_1-mlogloss:0.78916\n",
      "[101]\tvalidation_0-mlogloss:0.60105\tvalidation_1-mlogloss:0.78394\n",
      "[102]\tvalidation_0-mlogloss:0.59572\tvalidation_1-mlogloss:0.78001\n",
      "[103]\tvalidation_0-mlogloss:0.59048\tvalidation_1-mlogloss:0.77573\n",
      "[104]\tvalidation_0-mlogloss:0.58526\tvalidation_1-mlogloss:0.77112\n",
      "[105]\tvalidation_0-mlogloss:0.58008\tvalidation_1-mlogloss:0.76704\n",
      "[106]\tvalidation_0-mlogloss:0.57510\tvalidation_1-mlogloss:0.76270\n",
      "[107]\tvalidation_0-mlogloss:0.57005\tvalidation_1-mlogloss:0.75814\n",
      "[108]\tvalidation_0-mlogloss:0.56493\tvalidation_1-mlogloss:0.75346\n",
      "[109]\tvalidation_0-mlogloss:0.56001\tvalidation_1-mlogloss:0.74924\n",
      "[110]\tvalidation_0-mlogloss:0.55523\tvalidation_1-mlogloss:0.74517\n",
      "[111]\tvalidation_0-mlogloss:0.55056\tvalidation_1-mlogloss:0.74179\n",
      "[112]\tvalidation_0-mlogloss:0.54570\tvalidation_1-mlogloss:0.73730\n",
      "[113]\tvalidation_0-mlogloss:0.54098\tvalidation_1-mlogloss:0.73264\n",
      "[114]\tvalidation_0-mlogloss:0.53625\tvalidation_1-mlogloss:0.72845\n",
      "[115]\tvalidation_0-mlogloss:0.53169\tvalidation_1-mlogloss:0.72458\n",
      "[116]\tvalidation_0-mlogloss:0.52697\tvalidation_1-mlogloss:0.72005\n",
      "[117]\tvalidation_0-mlogloss:0.52275\tvalidation_1-mlogloss:0.71657\n",
      "[118]\tvalidation_0-mlogloss:0.51823\tvalidation_1-mlogloss:0.71336\n",
      "[119]\tvalidation_0-mlogloss:0.51371\tvalidation_1-mlogloss:0.70943\n",
      "[120]\tvalidation_0-mlogloss:0.50934\tvalidation_1-mlogloss:0.70627\n",
      "[121]\tvalidation_0-mlogloss:0.50539\tvalidation_1-mlogloss:0.70346\n",
      "[122]\tvalidation_0-mlogloss:0.50107\tvalidation_1-mlogloss:0.70005\n",
      "[123]\tvalidation_0-mlogloss:0.49685\tvalidation_1-mlogloss:0.69666\n",
      "[124]\tvalidation_0-mlogloss:0.49284\tvalidation_1-mlogloss:0.69366\n",
      "[125]\tvalidation_0-mlogloss:0.48866\tvalidation_1-mlogloss:0.68982\n",
      "[126]\tvalidation_0-mlogloss:0.48445\tvalidation_1-mlogloss:0.68610\n",
      "[127]\tvalidation_0-mlogloss:0.48033\tvalidation_1-mlogloss:0.68249\n",
      "[128]\tvalidation_0-mlogloss:0.47639\tvalidation_1-mlogloss:0.67935\n",
      "[129]\tvalidation_0-mlogloss:0.47235\tvalidation_1-mlogloss:0.67613\n",
      "[130]\tvalidation_0-mlogloss:0.46819\tvalidation_1-mlogloss:0.67242\n",
      "[131]\tvalidation_0-mlogloss:0.46431\tvalidation_1-mlogloss:0.66905\n",
      "[132]\tvalidation_0-mlogloss:0.46042\tvalidation_1-mlogloss:0.66470\n",
      "[133]\tvalidation_0-mlogloss:0.45664\tvalidation_1-mlogloss:0.66078\n",
      "[134]\tvalidation_0-mlogloss:0.45268\tvalidation_1-mlogloss:0.65731\n",
      "[135]\tvalidation_0-mlogloss:0.44896\tvalidation_1-mlogloss:0.65378\n",
      "[136]\tvalidation_0-mlogloss:0.44532\tvalidation_1-mlogloss:0.65093\n",
      "[137]\tvalidation_0-mlogloss:0.44180\tvalidation_1-mlogloss:0.64770\n",
      "[138]\tvalidation_0-mlogloss:0.43817\tvalidation_1-mlogloss:0.64480\n",
      "[139]\tvalidation_0-mlogloss:0.43442\tvalidation_1-mlogloss:0.64212\n",
      "[140]\tvalidation_0-mlogloss:0.43081\tvalidation_1-mlogloss:0.63873\n",
      "[141]\tvalidation_0-mlogloss:0.42724\tvalidation_1-mlogloss:0.63585\n",
      "[142]\tvalidation_0-mlogloss:0.42367\tvalidation_1-mlogloss:0.63220\n",
      "[143]\tvalidation_0-mlogloss:0.42001\tvalidation_1-mlogloss:0.62847\n",
      "[144]\tvalidation_0-mlogloss:0.41670\tvalidation_1-mlogloss:0.62608\n",
      "[145]\tvalidation_0-mlogloss:0.41347\tvalidation_1-mlogloss:0.62415\n",
      "[146]\tvalidation_0-mlogloss:0.41023\tvalidation_1-mlogloss:0.62177\n",
      "[147]\tvalidation_0-mlogloss:0.40704\tvalidation_1-mlogloss:0.61929\n",
      "[148]\tvalidation_0-mlogloss:0.40371\tvalidation_1-mlogloss:0.61657\n",
      "[149]\tvalidation_0-mlogloss:0.40049\tvalidation_1-mlogloss:0.61425\n",
      "[150]\tvalidation_0-mlogloss:0.39735\tvalidation_1-mlogloss:0.61254\n",
      "[151]\tvalidation_0-mlogloss:0.39411\tvalidation_1-mlogloss:0.60953\n",
      "[152]\tvalidation_0-mlogloss:0.39098\tvalidation_1-mlogloss:0.60619\n",
      "[153]\tvalidation_0-mlogloss:0.38794\tvalidation_1-mlogloss:0.60308\n",
      "[154]\tvalidation_0-mlogloss:0.38477\tvalidation_1-mlogloss:0.60014\n",
      "[155]\tvalidation_0-mlogloss:0.38158\tvalidation_1-mlogloss:0.59698\n",
      "[156]\tvalidation_0-mlogloss:0.37854\tvalidation_1-mlogloss:0.59463\n",
      "[157]\tvalidation_0-mlogloss:0.37542\tvalidation_1-mlogloss:0.59148\n",
      "[158]\tvalidation_0-mlogloss:0.37246\tvalidation_1-mlogloss:0.58830\n",
      "[159]\tvalidation_0-mlogloss:0.36934\tvalidation_1-mlogloss:0.58548\n",
      "[160]\tvalidation_0-mlogloss:0.36631\tvalidation_1-mlogloss:0.58309\n",
      "[161]\tvalidation_0-mlogloss:0.36354\tvalidation_1-mlogloss:0.58069\n",
      "[162]\tvalidation_0-mlogloss:0.36062\tvalidation_1-mlogloss:0.57798\n",
      "[163]\tvalidation_0-mlogloss:0.35769\tvalidation_1-mlogloss:0.57558\n",
      "[164]\tvalidation_0-mlogloss:0.35478\tvalidation_1-mlogloss:0.57257\n",
      "[165]\tvalidation_0-mlogloss:0.35204\tvalidation_1-mlogloss:0.57018\n",
      "[166]\tvalidation_0-mlogloss:0.34934\tvalidation_1-mlogloss:0.56848\n",
      "[167]\tvalidation_0-mlogloss:0.34649\tvalidation_1-mlogloss:0.56595\n",
      "[168]\tvalidation_0-mlogloss:0.34378\tvalidation_1-mlogloss:0.56421\n",
      "[169]\tvalidation_0-mlogloss:0.34110\tvalidation_1-mlogloss:0.56211\n",
      "[170]\tvalidation_0-mlogloss:0.33854\tvalidation_1-mlogloss:0.56005\n",
      "[171]\tvalidation_0-mlogloss:0.33604\tvalidation_1-mlogloss:0.55821\n",
      "[172]\tvalidation_0-mlogloss:0.33333\tvalidation_1-mlogloss:0.55595\n",
      "[173]\tvalidation_0-mlogloss:0.33068\tvalidation_1-mlogloss:0.55329\n",
      "[174]\tvalidation_0-mlogloss:0.32809\tvalidation_1-mlogloss:0.55134\n",
      "[175]\tvalidation_0-mlogloss:0.32559\tvalidation_1-mlogloss:0.54950\n",
      "[176]\tvalidation_0-mlogloss:0.32320\tvalidation_1-mlogloss:0.54725\n",
      "[177]\tvalidation_0-mlogloss:0.32055\tvalidation_1-mlogloss:0.54505\n",
      "[178]\tvalidation_0-mlogloss:0.31808\tvalidation_1-mlogloss:0.54289\n",
      "[179]\tvalidation_0-mlogloss:0.31552\tvalidation_1-mlogloss:0.54049\n",
      "[180]\tvalidation_0-mlogloss:0.31309\tvalidation_1-mlogloss:0.53853\n",
      "[181]\tvalidation_0-mlogloss:0.31053\tvalidation_1-mlogloss:0.53596\n",
      "[182]\tvalidation_0-mlogloss:0.30825\tvalidation_1-mlogloss:0.53453\n",
      "[183]\tvalidation_0-mlogloss:0.30594\tvalidation_1-mlogloss:0.53278\n",
      "[184]\tvalidation_0-mlogloss:0.30358\tvalidation_1-mlogloss:0.53111\n",
      "[185]\tvalidation_0-mlogloss:0.30116\tvalidation_1-mlogloss:0.52923\n",
      "[186]\tvalidation_0-mlogloss:0.29898\tvalidation_1-mlogloss:0.52791\n",
      "[187]\tvalidation_0-mlogloss:0.29661\tvalidation_1-mlogloss:0.52553\n",
      "[188]\tvalidation_0-mlogloss:0.29436\tvalidation_1-mlogloss:0.52387\n",
      "[189]\tvalidation_0-mlogloss:0.29216\tvalidation_1-mlogloss:0.52212\n",
      "[190]\tvalidation_0-mlogloss:0.28994\tvalidation_1-mlogloss:0.52013\n",
      "[191]\tvalidation_0-mlogloss:0.28771\tvalidation_1-mlogloss:0.51792\n",
      "[192]\tvalidation_0-mlogloss:0.28554\tvalidation_1-mlogloss:0.51596\n",
      "[193]\tvalidation_0-mlogloss:0.28341\tvalidation_1-mlogloss:0.51396\n",
      "[194]\tvalidation_0-mlogloss:0.28134\tvalidation_1-mlogloss:0.51290\n",
      "[195]\tvalidation_0-mlogloss:0.27925\tvalidation_1-mlogloss:0.51159\n",
      "[196]\tvalidation_0-mlogloss:0.27724\tvalidation_1-mlogloss:0.51022\n",
      "[197]\tvalidation_0-mlogloss:0.27516\tvalidation_1-mlogloss:0.50882\n",
      "[198]\tvalidation_0-mlogloss:0.27308\tvalidation_1-mlogloss:0.50749\n",
      "[199]\tvalidation_0-mlogloss:0.27107\tvalidation_1-mlogloss:0.50551\n",
      "[200]\tvalidation_0-mlogloss:0.26902\tvalidation_1-mlogloss:0.50332\n",
      "[201]\tvalidation_0-mlogloss:0.26697\tvalidation_1-mlogloss:0.50166\n",
      "[202]\tvalidation_0-mlogloss:0.26497\tvalidation_1-mlogloss:0.49953\n",
      "[203]\tvalidation_0-mlogloss:0.26305\tvalidation_1-mlogloss:0.49802\n",
      "[204]\tvalidation_0-mlogloss:0.26102\tvalidation_1-mlogloss:0.49610\n",
      "[205]\tvalidation_0-mlogloss:0.25914\tvalidation_1-mlogloss:0.49448\n",
      "[206]\tvalidation_0-mlogloss:0.25726\tvalidation_1-mlogloss:0.49259\n",
      "[207]\tvalidation_0-mlogloss:0.25537\tvalidation_1-mlogloss:0.49080\n",
      "[208]\tvalidation_0-mlogloss:0.25357\tvalidation_1-mlogloss:0.48920\n",
      "[209]\tvalidation_0-mlogloss:0.25169\tvalidation_1-mlogloss:0.48771\n",
      "[210]\tvalidation_0-mlogloss:0.24988\tvalidation_1-mlogloss:0.48626\n",
      "[211]\tvalidation_0-mlogloss:0.24808\tvalidation_1-mlogloss:0.48475\n",
      "[212]\tvalidation_0-mlogloss:0.24629\tvalidation_1-mlogloss:0.48379\n",
      "[213]\tvalidation_0-mlogloss:0.24444\tvalidation_1-mlogloss:0.48220\n",
      "[214]\tvalidation_0-mlogloss:0.24275\tvalidation_1-mlogloss:0.48099\n",
      "[215]\tvalidation_0-mlogloss:0.24098\tvalidation_1-mlogloss:0.47926\n",
      "[216]\tvalidation_0-mlogloss:0.23934\tvalidation_1-mlogloss:0.47851\n",
      "[217]\tvalidation_0-mlogloss:0.23771\tvalidation_1-mlogloss:0.47745\n",
      "[218]\tvalidation_0-mlogloss:0.23598\tvalidation_1-mlogloss:0.47608\n",
      "[219]\tvalidation_0-mlogloss:0.23435\tvalidation_1-mlogloss:0.47465\n",
      "[220]\tvalidation_0-mlogloss:0.23293\tvalidation_1-mlogloss:0.47335\n",
      "[221]\tvalidation_0-mlogloss:0.23125\tvalidation_1-mlogloss:0.47208\n",
      "[222]\tvalidation_0-mlogloss:0.22962\tvalidation_1-mlogloss:0.47071\n",
      "[223]\tvalidation_0-mlogloss:0.22797\tvalidation_1-mlogloss:0.46942\n",
      "[224]\tvalidation_0-mlogloss:0.22636\tvalidation_1-mlogloss:0.46832\n",
      "[225]\tvalidation_0-mlogloss:0.22474\tvalidation_1-mlogloss:0.46660\n",
      "[226]\tvalidation_0-mlogloss:0.22312\tvalidation_1-mlogloss:0.46519\n",
      "[227]\tvalidation_0-mlogloss:0.22147\tvalidation_1-mlogloss:0.46356\n",
      "[228]\tvalidation_0-mlogloss:0.21990\tvalidation_1-mlogloss:0.46201\n",
      "[229]\tvalidation_0-mlogloss:0.21826\tvalidation_1-mlogloss:0.46095\n",
      "[230]\tvalidation_0-mlogloss:0.21675\tvalidation_1-mlogloss:0.45950\n",
      "[231]\tvalidation_0-mlogloss:0.21528\tvalidation_1-mlogloss:0.45842\n",
      "[232]\tvalidation_0-mlogloss:0.21383\tvalidation_1-mlogloss:0.45695\n",
      "[233]\tvalidation_0-mlogloss:0.21246\tvalidation_1-mlogloss:0.45619\n",
      "[234]\tvalidation_0-mlogloss:0.21096\tvalidation_1-mlogloss:0.45490\n",
      "[235]\tvalidation_0-mlogloss:0.20947\tvalidation_1-mlogloss:0.45388\n",
      "[236]\tvalidation_0-mlogloss:0.20811\tvalidation_1-mlogloss:0.45245\n",
      "[237]\tvalidation_0-mlogloss:0.20667\tvalidation_1-mlogloss:0.45122\n",
      "[238]\tvalidation_0-mlogloss:0.20522\tvalidation_1-mlogloss:0.45009\n",
      "[239]\tvalidation_0-mlogloss:0.20381\tvalidation_1-mlogloss:0.44935\n",
      "[240]\tvalidation_0-mlogloss:0.20241\tvalidation_1-mlogloss:0.44800\n",
      "[241]\tvalidation_0-mlogloss:0.20101\tvalidation_1-mlogloss:0.44701\n",
      "[242]\tvalidation_0-mlogloss:0.19958\tvalidation_1-mlogloss:0.44560\n",
      "[243]\tvalidation_0-mlogloss:0.19828\tvalidation_1-mlogloss:0.44491\n",
      "[244]\tvalidation_0-mlogloss:0.19694\tvalidation_1-mlogloss:0.44380\n",
      "[245]\tvalidation_0-mlogloss:0.19553\tvalidation_1-mlogloss:0.44263\n",
      "[246]\tvalidation_0-mlogloss:0.19419\tvalidation_1-mlogloss:0.44164\n",
      "[247]\tvalidation_0-mlogloss:0.19288\tvalidation_1-mlogloss:0.44026\n",
      "[248]\tvalidation_0-mlogloss:0.19153\tvalidation_1-mlogloss:0.43917\n",
      "[249]\tvalidation_0-mlogloss:0.19033\tvalidation_1-mlogloss:0.43849\n",
      "[250]\tvalidation_0-mlogloss:0.18910\tvalidation_1-mlogloss:0.43781\n",
      "[251]\tvalidation_0-mlogloss:0.18785\tvalidation_1-mlogloss:0.43732\n",
      "[252]\tvalidation_0-mlogloss:0.18673\tvalidation_1-mlogloss:0.43660\n",
      "[253]\tvalidation_0-mlogloss:0.18556\tvalidation_1-mlogloss:0.43604\n",
      "[254]\tvalidation_0-mlogloss:0.18426\tvalidation_1-mlogloss:0.43499\n",
      "[255]\tvalidation_0-mlogloss:0.18306\tvalidation_1-mlogloss:0.43401\n",
      "[256]\tvalidation_0-mlogloss:0.18180\tvalidation_1-mlogloss:0.43306\n",
      "[257]\tvalidation_0-mlogloss:0.18062\tvalidation_1-mlogloss:0.43226\n",
      "[258]\tvalidation_0-mlogloss:0.17942\tvalidation_1-mlogloss:0.43134\n",
      "[259]\tvalidation_0-mlogloss:0.17823\tvalidation_1-mlogloss:0.43047\n",
      "[260]\tvalidation_0-mlogloss:0.17708\tvalidation_1-mlogloss:0.42954\n",
      "[261]\tvalidation_0-mlogloss:0.17589\tvalidation_1-mlogloss:0.42887\n",
      "[262]\tvalidation_0-mlogloss:0.17481\tvalidation_1-mlogloss:0.42830\n",
      "[263]\tvalidation_0-mlogloss:0.17361\tvalidation_1-mlogloss:0.42702\n",
      "[264]\tvalidation_0-mlogloss:0.17243\tvalidation_1-mlogloss:0.42645\n",
      "[265]\tvalidation_0-mlogloss:0.17132\tvalidation_1-mlogloss:0.42602\n",
      "[266]\tvalidation_0-mlogloss:0.17023\tvalidation_1-mlogloss:0.42541\n",
      "[267]\tvalidation_0-mlogloss:0.16911\tvalidation_1-mlogloss:0.42450\n",
      "[268]\tvalidation_0-mlogloss:0.16809\tvalidation_1-mlogloss:0.42393\n",
      "[269]\tvalidation_0-mlogloss:0.16694\tvalidation_1-mlogloss:0.42292\n",
      "[270]\tvalidation_0-mlogloss:0.16584\tvalidation_1-mlogloss:0.42185\n",
      "[271]\tvalidation_0-mlogloss:0.16488\tvalidation_1-mlogloss:0.42083\n",
      "[272]\tvalidation_0-mlogloss:0.16396\tvalidation_1-mlogloss:0.42052\n",
      "[273]\tvalidation_0-mlogloss:0.16286\tvalidation_1-mlogloss:0.41994\n",
      "[274]\tvalidation_0-mlogloss:0.16181\tvalidation_1-mlogloss:0.41906\n",
      "[275]\tvalidation_0-mlogloss:0.16074\tvalidation_1-mlogloss:0.41829\n",
      "[276]\tvalidation_0-mlogloss:0.15965\tvalidation_1-mlogloss:0.41684\n",
      "[277]\tvalidation_0-mlogloss:0.15858\tvalidation_1-mlogloss:0.41586\n",
      "[278]\tvalidation_0-mlogloss:0.15756\tvalidation_1-mlogloss:0.41556\n",
      "[279]\tvalidation_0-mlogloss:0.15649\tvalidation_1-mlogloss:0.41469\n",
      "[280]\tvalidation_0-mlogloss:0.15554\tvalidation_1-mlogloss:0.41383\n",
      "[281]\tvalidation_0-mlogloss:0.15449\tvalidation_1-mlogloss:0.41317\n",
      "[282]\tvalidation_0-mlogloss:0.15347\tvalidation_1-mlogloss:0.41235\n",
      "[283]\tvalidation_0-mlogloss:0.15250\tvalidation_1-mlogloss:0.41160\n",
      "[284]\tvalidation_0-mlogloss:0.15154\tvalidation_1-mlogloss:0.41109\n",
      "[285]\tvalidation_0-mlogloss:0.15062\tvalidation_1-mlogloss:0.41029\n",
      "[286]\tvalidation_0-mlogloss:0.14964\tvalidation_1-mlogloss:0.40954\n",
      "[287]\tvalidation_0-mlogloss:0.14870\tvalidation_1-mlogloss:0.40890\n",
      "[288]\tvalidation_0-mlogloss:0.14777\tvalidation_1-mlogloss:0.40788\n",
      "[289]\tvalidation_0-mlogloss:0.14683\tvalidation_1-mlogloss:0.40702\n",
      "[290]\tvalidation_0-mlogloss:0.14599\tvalidation_1-mlogloss:0.40634\n",
      "[291]\tvalidation_0-mlogloss:0.14506\tvalidation_1-mlogloss:0.40533\n",
      "[292]\tvalidation_0-mlogloss:0.14419\tvalidation_1-mlogloss:0.40517\n",
      "[293]\tvalidation_0-mlogloss:0.14328\tvalidation_1-mlogloss:0.40440\n",
      "[294]\tvalidation_0-mlogloss:0.14244\tvalidation_1-mlogloss:0.40413\n",
      "[295]\tvalidation_0-mlogloss:0.14155\tvalidation_1-mlogloss:0.40325\n",
      "[296]\tvalidation_0-mlogloss:0.14065\tvalidation_1-mlogloss:0.40240\n",
      "[297]\tvalidation_0-mlogloss:0.13977\tvalidation_1-mlogloss:0.40175\n",
      "[298]\tvalidation_0-mlogloss:0.13887\tvalidation_1-mlogloss:0.40092\n",
      "[299]\tvalidation_0-mlogloss:0.13805\tvalidation_1-mlogloss:0.40056\n",
      "[300]\tvalidation_0-mlogloss:0.13716\tvalidation_1-mlogloss:0.39964\n",
      "[301]\tvalidation_0-mlogloss:0.13629\tvalidation_1-mlogloss:0.39911\n",
      "[302]\tvalidation_0-mlogloss:0.13545\tvalidation_1-mlogloss:0.39832\n",
      "[303]\tvalidation_0-mlogloss:0.13463\tvalidation_1-mlogloss:0.39794\n",
      "[304]\tvalidation_0-mlogloss:0.13384\tvalidation_1-mlogloss:0.39736\n",
      "[305]\tvalidation_0-mlogloss:0.13308\tvalidation_1-mlogloss:0.39726\n",
      "[306]\tvalidation_0-mlogloss:0.13230\tvalidation_1-mlogloss:0.39686\n",
      "[307]\tvalidation_0-mlogloss:0.13147\tvalidation_1-mlogloss:0.39610\n",
      "[308]\tvalidation_0-mlogloss:0.13065\tvalidation_1-mlogloss:0.39547\n",
      "[309]\tvalidation_0-mlogloss:0.12990\tvalidation_1-mlogloss:0.39514\n",
      "[310]\tvalidation_0-mlogloss:0.12907\tvalidation_1-mlogloss:0.39458\n",
      "[311]\tvalidation_0-mlogloss:0.12831\tvalidation_1-mlogloss:0.39409\n",
      "[312]\tvalidation_0-mlogloss:0.12756\tvalidation_1-mlogloss:0.39343\n",
      "[313]\tvalidation_0-mlogloss:0.12692\tvalidation_1-mlogloss:0.39290\n",
      "[314]\tvalidation_0-mlogloss:0.12621\tvalidation_1-mlogloss:0.39245\n",
      "[315]\tvalidation_0-mlogloss:0.12548\tvalidation_1-mlogloss:0.39164\n",
      "[316]\tvalidation_0-mlogloss:0.12474\tvalidation_1-mlogloss:0.39119\n",
      "[317]\tvalidation_0-mlogloss:0.12403\tvalidation_1-mlogloss:0.39039\n",
      "[318]\tvalidation_0-mlogloss:0.12334\tvalidation_1-mlogloss:0.38991\n",
      "[319]\tvalidation_0-mlogloss:0.12261\tvalidation_1-mlogloss:0.38918\n",
      "[320]\tvalidation_0-mlogloss:0.12185\tvalidation_1-mlogloss:0.38883\n",
      "[321]\tvalidation_0-mlogloss:0.12112\tvalidation_1-mlogloss:0.38830\n",
      "[322]\tvalidation_0-mlogloss:0.12043\tvalidation_1-mlogloss:0.38827\n",
      "[323]\tvalidation_0-mlogloss:0.11975\tvalidation_1-mlogloss:0.38788\n",
      "[324]\tvalidation_0-mlogloss:0.11908\tvalidation_1-mlogloss:0.38779\n",
      "[325]\tvalidation_0-mlogloss:0.11840\tvalidation_1-mlogloss:0.38739\n",
      "[326]\tvalidation_0-mlogloss:0.11770\tvalidation_1-mlogloss:0.38702\n",
      "[327]\tvalidation_0-mlogloss:0.11712\tvalidation_1-mlogloss:0.38690\n",
      "[328]\tvalidation_0-mlogloss:0.11642\tvalidation_1-mlogloss:0.38625\n",
      "[329]\tvalidation_0-mlogloss:0.11573\tvalidation_1-mlogloss:0.38605\n",
      "[330]\tvalidation_0-mlogloss:0.11514\tvalidation_1-mlogloss:0.38558\n",
      "[331]\tvalidation_0-mlogloss:0.11446\tvalidation_1-mlogloss:0.38495\n",
      "[332]\tvalidation_0-mlogloss:0.11381\tvalidation_1-mlogloss:0.38483\n",
      "[333]\tvalidation_0-mlogloss:0.11319\tvalidation_1-mlogloss:0.38437\n",
      "[334]\tvalidation_0-mlogloss:0.11256\tvalidation_1-mlogloss:0.38364\n",
      "[335]\tvalidation_0-mlogloss:0.11191\tvalidation_1-mlogloss:0.38308\n",
      "[336]\tvalidation_0-mlogloss:0.11131\tvalidation_1-mlogloss:0.38280\n",
      "[337]\tvalidation_0-mlogloss:0.11072\tvalidation_1-mlogloss:0.38227\n",
      "[338]\tvalidation_0-mlogloss:0.11009\tvalidation_1-mlogloss:0.38161\n",
      "[339]\tvalidation_0-mlogloss:0.10946\tvalidation_1-mlogloss:0.38088\n",
      "[340]\tvalidation_0-mlogloss:0.10884\tvalidation_1-mlogloss:0.38054\n",
      "[341]\tvalidation_0-mlogloss:0.10827\tvalidation_1-mlogloss:0.38030\n",
      "[342]\tvalidation_0-mlogloss:0.10768\tvalidation_1-mlogloss:0.37987\n",
      "[343]\tvalidation_0-mlogloss:0.10709\tvalidation_1-mlogloss:0.37978\n",
      "[344]\tvalidation_0-mlogloss:0.10651\tvalidation_1-mlogloss:0.37977\n",
      "[345]\tvalidation_0-mlogloss:0.10595\tvalidation_1-mlogloss:0.37927\n",
      "[346]\tvalidation_0-mlogloss:0.10534\tvalidation_1-mlogloss:0.37888\n",
      "[347]\tvalidation_0-mlogloss:0.10475\tvalidation_1-mlogloss:0.37844\n",
      "[348]\tvalidation_0-mlogloss:0.10418\tvalidation_1-mlogloss:0.37784\n",
      "[349]\tvalidation_0-mlogloss:0.10360\tvalidation_1-mlogloss:0.37734\n",
      "[350]\tvalidation_0-mlogloss:0.10307\tvalidation_1-mlogloss:0.37716\n",
      "[351]\tvalidation_0-mlogloss:0.10250\tvalidation_1-mlogloss:0.37659\n",
      "[352]\tvalidation_0-mlogloss:0.10193\tvalidation_1-mlogloss:0.37592\n",
      "[353]\tvalidation_0-mlogloss:0.10142\tvalidation_1-mlogloss:0.37570\n",
      "[354]\tvalidation_0-mlogloss:0.10085\tvalidation_1-mlogloss:0.37519\n",
      "[355]\tvalidation_0-mlogloss:0.10034\tvalidation_1-mlogloss:0.37513\n",
      "[356]\tvalidation_0-mlogloss:0.09977\tvalidation_1-mlogloss:0.37457\n",
      "[357]\tvalidation_0-mlogloss:0.09928\tvalidation_1-mlogloss:0.37460\n",
      "[358]\tvalidation_0-mlogloss:0.09875\tvalidation_1-mlogloss:0.37400\n",
      "[359]\tvalidation_0-mlogloss:0.09823\tvalidation_1-mlogloss:0.37368\n",
      "[360]\tvalidation_0-mlogloss:0.09771\tvalidation_1-mlogloss:0.37332\n",
      "[361]\tvalidation_0-mlogloss:0.09717\tvalidation_1-mlogloss:0.37320\n",
      "[362]\tvalidation_0-mlogloss:0.09667\tvalidation_1-mlogloss:0.37313\n",
      "[363]\tvalidation_0-mlogloss:0.09616\tvalidation_1-mlogloss:0.37275\n",
      "[364]\tvalidation_0-mlogloss:0.09568\tvalidation_1-mlogloss:0.37269\n",
      "[365]\tvalidation_0-mlogloss:0.09518\tvalidation_1-mlogloss:0.37215\n",
      "[366]\tvalidation_0-mlogloss:0.09468\tvalidation_1-mlogloss:0.37198\n",
      "[367]\tvalidation_0-mlogloss:0.09416\tvalidation_1-mlogloss:0.37166\n",
      "[368]\tvalidation_0-mlogloss:0.09369\tvalidation_1-mlogloss:0.37145\n",
      "[369]\tvalidation_0-mlogloss:0.09319\tvalidation_1-mlogloss:0.37103\n",
      "[370]\tvalidation_0-mlogloss:0.09272\tvalidation_1-mlogloss:0.37052\n",
      "[371]\tvalidation_0-mlogloss:0.09221\tvalidation_1-mlogloss:0.37006\n",
      "[372]\tvalidation_0-mlogloss:0.09176\tvalidation_1-mlogloss:0.37016\n",
      "[373]\tvalidation_0-mlogloss:0.09128\tvalidation_1-mlogloss:0.36994\n",
      "[374]\tvalidation_0-mlogloss:0.09079\tvalidation_1-mlogloss:0.36939\n",
      "[375]\tvalidation_0-mlogloss:0.09036\tvalidation_1-mlogloss:0.36900\n",
      "[376]\tvalidation_0-mlogloss:0.08989\tvalidation_1-mlogloss:0.36863\n",
      "[377]\tvalidation_0-mlogloss:0.08950\tvalidation_1-mlogloss:0.36831\n",
      "[378]\tvalidation_0-mlogloss:0.08905\tvalidation_1-mlogloss:0.36774\n",
      "[379]\tvalidation_0-mlogloss:0.08859\tvalidation_1-mlogloss:0.36761\n",
      "[380]\tvalidation_0-mlogloss:0.08815\tvalidation_1-mlogloss:0.36711\n",
      "[381]\tvalidation_0-mlogloss:0.08770\tvalidation_1-mlogloss:0.36684\n",
      "[382]\tvalidation_0-mlogloss:0.08725\tvalidation_1-mlogloss:0.36663\n",
      "[383]\tvalidation_0-mlogloss:0.08682\tvalidation_1-mlogloss:0.36638\n",
      "[384]\tvalidation_0-mlogloss:0.08639\tvalidation_1-mlogloss:0.36635\n",
      "[385]\tvalidation_0-mlogloss:0.08601\tvalidation_1-mlogloss:0.36605\n",
      "[386]\tvalidation_0-mlogloss:0.08562\tvalidation_1-mlogloss:0.36600\n",
      "[387]\tvalidation_0-mlogloss:0.08518\tvalidation_1-mlogloss:0.36538\n",
      "[388]\tvalidation_0-mlogloss:0.08481\tvalidation_1-mlogloss:0.36524\n",
      "[389]\tvalidation_0-mlogloss:0.08445\tvalidation_1-mlogloss:0.36467\n",
      "[390]\tvalidation_0-mlogloss:0.08403\tvalidation_1-mlogloss:0.36433\n",
      "[391]\tvalidation_0-mlogloss:0.08362\tvalidation_1-mlogloss:0.36428\n",
      "[392]\tvalidation_0-mlogloss:0.08320\tvalidation_1-mlogloss:0.36424\n",
      "[393]\tvalidation_0-mlogloss:0.08283\tvalidation_1-mlogloss:0.36404\n",
      "[394]\tvalidation_0-mlogloss:0.08242\tvalidation_1-mlogloss:0.36327\n",
      "[395]\tvalidation_0-mlogloss:0.08204\tvalidation_1-mlogloss:0.36320\n",
      "[396]\tvalidation_0-mlogloss:0.08170\tvalidation_1-mlogloss:0.36309\n",
      "[397]\tvalidation_0-mlogloss:0.08130\tvalidation_1-mlogloss:0.36319\n",
      "[398]\tvalidation_0-mlogloss:0.08091\tvalidation_1-mlogloss:0.36308\n",
      "[399]\tvalidation_0-mlogloss:0.08052\tvalidation_1-mlogloss:0.36252\n",
      "[400]\tvalidation_0-mlogloss:0.08015\tvalidation_1-mlogloss:0.36256\n",
      "[401]\tvalidation_0-mlogloss:0.07985\tvalidation_1-mlogloss:0.36235\n",
      "[402]\tvalidation_0-mlogloss:0.07948\tvalidation_1-mlogloss:0.36217\n",
      "[403]\tvalidation_0-mlogloss:0.07914\tvalidation_1-mlogloss:0.36186\n",
      "[404]\tvalidation_0-mlogloss:0.07878\tvalidation_1-mlogloss:0.36143\n",
      "[405]\tvalidation_0-mlogloss:0.07851\tvalidation_1-mlogloss:0.36140\n",
      "[406]\tvalidation_0-mlogloss:0.07819\tvalidation_1-mlogloss:0.36155\n",
      "[407]\tvalidation_0-mlogloss:0.07785\tvalidation_1-mlogloss:0.36146\n",
      "[408]\tvalidation_0-mlogloss:0.07751\tvalidation_1-mlogloss:0.36129\n",
      "[409]\tvalidation_0-mlogloss:0.07718\tvalidation_1-mlogloss:0.36086\n",
      "[410]\tvalidation_0-mlogloss:0.07685\tvalidation_1-mlogloss:0.36073\n",
      "[411]\tvalidation_0-mlogloss:0.07650\tvalidation_1-mlogloss:0.36046\n",
      "[412]\tvalidation_0-mlogloss:0.07618\tvalidation_1-mlogloss:0.36038\n",
      "[413]\tvalidation_0-mlogloss:0.07583\tvalidation_1-mlogloss:0.36047\n",
      "[414]\tvalidation_0-mlogloss:0.07547\tvalidation_1-mlogloss:0.35996\n",
      "[415]\tvalidation_0-mlogloss:0.07515\tvalidation_1-mlogloss:0.35971\n",
      "[416]\tvalidation_0-mlogloss:0.07483\tvalidation_1-mlogloss:0.35921\n",
      "[417]\tvalidation_0-mlogloss:0.07452\tvalidation_1-mlogloss:0.35925\n",
      "[418]\tvalidation_0-mlogloss:0.07427\tvalidation_1-mlogloss:0.35900\n",
      "[419]\tvalidation_0-mlogloss:0.07397\tvalidation_1-mlogloss:0.35851\n",
      "[420]\tvalidation_0-mlogloss:0.07368\tvalidation_1-mlogloss:0.35853\n",
      "[421]\tvalidation_0-mlogloss:0.07338\tvalidation_1-mlogloss:0.35865\n",
      "[422]\tvalidation_0-mlogloss:0.07306\tvalidation_1-mlogloss:0.35844\n",
      "[423]\tvalidation_0-mlogloss:0.07278\tvalidation_1-mlogloss:0.35843\n",
      "[424]\tvalidation_0-mlogloss:0.07246\tvalidation_1-mlogloss:0.35843\n",
      "[425]\tvalidation_0-mlogloss:0.07212\tvalidation_1-mlogloss:0.35764\n",
      "[426]\tvalidation_0-mlogloss:0.07181\tvalidation_1-mlogloss:0.35711\n",
      "[427]\tvalidation_0-mlogloss:0.07151\tvalidation_1-mlogloss:0.35717\n",
      "[428]\tvalidation_0-mlogloss:0.07118\tvalidation_1-mlogloss:0.35694\n",
      "[429]\tvalidation_0-mlogloss:0.07087\tvalidation_1-mlogloss:0.35694\n",
      "[430]\tvalidation_0-mlogloss:0.07061\tvalidation_1-mlogloss:0.35694\n",
      "[431]\tvalidation_0-mlogloss:0.07031\tvalidation_1-mlogloss:0.35681\n",
      "[432]\tvalidation_0-mlogloss:0.07008\tvalidation_1-mlogloss:0.35686\n",
      "[433]\tvalidation_0-mlogloss:0.06978\tvalidation_1-mlogloss:0.35647\n",
      "[434]\tvalidation_0-mlogloss:0.06948\tvalidation_1-mlogloss:0.35650\n",
      "[435]\tvalidation_0-mlogloss:0.06920\tvalidation_1-mlogloss:0.35660\n",
      "[436]\tvalidation_0-mlogloss:0.06893\tvalidation_1-mlogloss:0.35675\n",
      "[437]\tvalidation_0-mlogloss:0.06865\tvalidation_1-mlogloss:0.35650\n",
      "[438]\tvalidation_0-mlogloss:0.06838\tvalidation_1-mlogloss:0.35630\n",
      "[439]\tvalidation_0-mlogloss:0.06810\tvalidation_1-mlogloss:0.35602\n",
      "[440]\tvalidation_0-mlogloss:0.06791\tvalidation_1-mlogloss:0.35581\n",
      "[441]\tvalidation_0-mlogloss:0.06764\tvalidation_1-mlogloss:0.35580\n",
      "[442]\tvalidation_0-mlogloss:0.06737\tvalidation_1-mlogloss:0.35577\n",
      "[443]\tvalidation_0-mlogloss:0.06710\tvalidation_1-mlogloss:0.35563\n",
      "[444]\tvalidation_0-mlogloss:0.06681\tvalidation_1-mlogloss:0.35546\n",
      "[445]\tvalidation_0-mlogloss:0.06653\tvalidation_1-mlogloss:0.35522\n",
      "[446]\tvalidation_0-mlogloss:0.06632\tvalidation_1-mlogloss:0.35527\n",
      "[447]\tvalidation_0-mlogloss:0.06605\tvalidation_1-mlogloss:0.35527\n",
      "[448]\tvalidation_0-mlogloss:0.06583\tvalidation_1-mlogloss:0.35512\n",
      "[449]\tvalidation_0-mlogloss:0.06558\tvalidation_1-mlogloss:0.35461\n",
      "[450]\tvalidation_0-mlogloss:0.06531\tvalidation_1-mlogloss:0.35406\n",
      "[451]\tvalidation_0-mlogloss:0.06506\tvalidation_1-mlogloss:0.35389\n",
      "[452]\tvalidation_0-mlogloss:0.06481\tvalidation_1-mlogloss:0.35355\n",
      "[453]\tvalidation_0-mlogloss:0.06460\tvalidation_1-mlogloss:0.35327\n",
      "[454]\tvalidation_0-mlogloss:0.06436\tvalidation_1-mlogloss:0.35307\n",
      "[455]\tvalidation_0-mlogloss:0.06410\tvalidation_1-mlogloss:0.35299\n",
      "[456]\tvalidation_0-mlogloss:0.06386\tvalidation_1-mlogloss:0.35296\n",
      "[457]\tvalidation_0-mlogloss:0.06368\tvalidation_1-mlogloss:0.35282\n",
      "[458]\tvalidation_0-mlogloss:0.06344\tvalidation_1-mlogloss:0.35283\n",
      "[459]\tvalidation_0-mlogloss:0.06323\tvalidation_1-mlogloss:0.35268\n",
      "[460]\tvalidation_0-mlogloss:0.06303\tvalidation_1-mlogloss:0.35243\n",
      "[461]\tvalidation_0-mlogloss:0.06282\tvalidation_1-mlogloss:0.35206\n",
      "[462]\tvalidation_0-mlogloss:0.06257\tvalidation_1-mlogloss:0.35194\n",
      "[463]\tvalidation_0-mlogloss:0.06242\tvalidation_1-mlogloss:0.35202\n",
      "[464]\tvalidation_0-mlogloss:0.06217\tvalidation_1-mlogloss:0.35170\n",
      "[465]\tvalidation_0-mlogloss:0.06197\tvalidation_1-mlogloss:0.35181\n",
      "[466]\tvalidation_0-mlogloss:0.06173\tvalidation_1-mlogloss:0.35198\n",
      "[467]\tvalidation_0-mlogloss:0.06153\tvalidation_1-mlogloss:0.35171\n",
      "[468]\tvalidation_0-mlogloss:0.06138\tvalidation_1-mlogloss:0.35184\n",
      "[469]\tvalidation_0-mlogloss:0.06113\tvalidation_1-mlogloss:0.35196\n",
      "[470]\tvalidation_0-mlogloss:0.06092\tvalidation_1-mlogloss:0.35208\n",
      "[471]\tvalidation_0-mlogloss:0.06076\tvalidation_1-mlogloss:0.35179\n",
      "[472]\tvalidation_0-mlogloss:0.06058\tvalidation_1-mlogloss:0.35181\n",
      "[473]\tvalidation_0-mlogloss:0.06041\tvalidation_1-mlogloss:0.35155\n",
      "[474]\tvalidation_0-mlogloss:0.06028\tvalidation_1-mlogloss:0.35161\n",
      "[475]\tvalidation_0-mlogloss:0.06009\tvalidation_1-mlogloss:0.35157\n",
      "[476]\tvalidation_0-mlogloss:0.05988\tvalidation_1-mlogloss:0.35149\n",
      "[477]\tvalidation_0-mlogloss:0.05969\tvalidation_1-mlogloss:0.35135\n",
      "[478]\tvalidation_0-mlogloss:0.05951\tvalidation_1-mlogloss:0.35100\n",
      "[479]\tvalidation_0-mlogloss:0.05930\tvalidation_1-mlogloss:0.35096\n",
      "[480]\tvalidation_0-mlogloss:0.05910\tvalidation_1-mlogloss:0.35091\n",
      "[481]\tvalidation_0-mlogloss:0.05888\tvalidation_1-mlogloss:0.35104\n",
      "[482]\tvalidation_0-mlogloss:0.05866\tvalidation_1-mlogloss:0.35096\n",
      "[483]\tvalidation_0-mlogloss:0.05852\tvalidation_1-mlogloss:0.35087\n",
      "[484]\tvalidation_0-mlogloss:0.05838\tvalidation_1-mlogloss:0.35094\n",
      "[485]\tvalidation_0-mlogloss:0.05822\tvalidation_1-mlogloss:0.35063\n",
      "[486]\tvalidation_0-mlogloss:0.05807\tvalidation_1-mlogloss:0.35034\n",
      "[487]\tvalidation_0-mlogloss:0.05787\tvalidation_1-mlogloss:0.35006\n",
      "[488]\tvalidation_0-mlogloss:0.05776\tvalidation_1-mlogloss:0.34962\n",
      "[489]\tvalidation_0-mlogloss:0.05760\tvalidation_1-mlogloss:0.34932\n",
      "[490]\tvalidation_0-mlogloss:0.05744\tvalidation_1-mlogloss:0.34883\n",
      "[491]\tvalidation_0-mlogloss:0.05732\tvalidation_1-mlogloss:0.34876\n",
      "[492]\tvalidation_0-mlogloss:0.05716\tvalidation_1-mlogloss:0.34874\n",
      "[493]\tvalidation_0-mlogloss:0.05704\tvalidation_1-mlogloss:0.34855\n",
      "[494]\tvalidation_0-mlogloss:0.05695\tvalidation_1-mlogloss:0.34845\n",
      "[495]\tvalidation_0-mlogloss:0.05678\tvalidation_1-mlogloss:0.34848\n",
      "[496]\tvalidation_0-mlogloss:0.05662\tvalidation_1-mlogloss:0.34842\n",
      "[497]\tvalidation_0-mlogloss:0.05648\tvalidation_1-mlogloss:0.34826\n",
      "[498]\tvalidation_0-mlogloss:0.05640\tvalidation_1-mlogloss:0.34811\n",
      "[499]\tvalidation_0-mlogloss:0.05625\tvalidation_1-mlogloss:0.34800\n",
      "[500]\tvalidation_0-mlogloss:0.05613\tvalidation_1-mlogloss:0.34799\n",
      "[501]\tvalidation_0-mlogloss:0.05597\tvalidation_1-mlogloss:0.34766\n",
      "[502]\tvalidation_0-mlogloss:0.05586\tvalidation_1-mlogloss:0.34765\n",
      "[503]\tvalidation_0-mlogloss:0.05575\tvalidation_1-mlogloss:0.34741\n",
      "[504]\tvalidation_0-mlogloss:0.05560\tvalidation_1-mlogloss:0.34696\n",
      "[505]\tvalidation_0-mlogloss:0.05544\tvalidation_1-mlogloss:0.34703\n",
      "[506]\tvalidation_0-mlogloss:0.05531\tvalidation_1-mlogloss:0.34665\n",
      "[507]\tvalidation_0-mlogloss:0.05519\tvalidation_1-mlogloss:0.34653\n",
      "[508]\tvalidation_0-mlogloss:0.05508\tvalidation_1-mlogloss:0.34625\n",
      "[509]\tvalidation_0-mlogloss:0.05494\tvalidation_1-mlogloss:0.34588\n",
      "[510]\tvalidation_0-mlogloss:0.05477\tvalidation_1-mlogloss:0.34556\n",
      "[511]\tvalidation_0-mlogloss:0.05463\tvalidation_1-mlogloss:0.34511\n",
      "[512]\tvalidation_0-mlogloss:0.05453\tvalidation_1-mlogloss:0.34489\n",
      "[513]\tvalidation_0-mlogloss:0.05443\tvalidation_1-mlogloss:0.34476\n",
      "[514]\tvalidation_0-mlogloss:0.05425\tvalidation_1-mlogloss:0.34437\n",
      "[515]\tvalidation_0-mlogloss:0.05410\tvalidation_1-mlogloss:0.34410\n",
      "[516]\tvalidation_0-mlogloss:0.05394\tvalidation_1-mlogloss:0.34368\n",
      "[517]\tvalidation_0-mlogloss:0.05384\tvalidation_1-mlogloss:0.34360\n",
      "[518]\tvalidation_0-mlogloss:0.05382\tvalidation_1-mlogloss:0.34372\n",
      "[519]\tvalidation_0-mlogloss:0.05372\tvalidation_1-mlogloss:0.34370\n",
      "[520]\tvalidation_0-mlogloss:0.05362\tvalidation_1-mlogloss:0.34353\n",
      "[521]\tvalidation_0-mlogloss:0.05353\tvalidation_1-mlogloss:0.34341\n",
      "[522]\tvalidation_0-mlogloss:0.05342\tvalidation_1-mlogloss:0.34307\n",
      "[523]\tvalidation_0-mlogloss:0.05334\tvalidation_1-mlogloss:0.34308\n",
      "[524]\tvalidation_0-mlogloss:0.05325\tvalidation_1-mlogloss:0.34294\n",
      "[525]\tvalidation_0-mlogloss:0.05318\tvalidation_1-mlogloss:0.34286\n",
      "[526]\tvalidation_0-mlogloss:0.05313\tvalidation_1-mlogloss:0.34267\n",
      "[527]\tvalidation_0-mlogloss:0.05302\tvalidation_1-mlogloss:0.34230\n",
      "[528]\tvalidation_0-mlogloss:0.05293\tvalidation_1-mlogloss:0.34221\n",
      "[529]\tvalidation_0-mlogloss:0.05280\tvalidation_1-mlogloss:0.34212\n",
      "[530]\tvalidation_0-mlogloss:0.05266\tvalidation_1-mlogloss:0.34172\n",
      "[531]\tvalidation_0-mlogloss:0.05257\tvalidation_1-mlogloss:0.34154\n",
      "[532]\tvalidation_0-mlogloss:0.05248\tvalidation_1-mlogloss:0.34136\n",
      "[533]\tvalidation_0-mlogloss:0.05240\tvalidation_1-mlogloss:0.34123\n",
      "[534]\tvalidation_0-mlogloss:0.05234\tvalidation_1-mlogloss:0.34123\n",
      "[535]\tvalidation_0-mlogloss:0.05224\tvalidation_1-mlogloss:0.34123\n",
      "[536]\tvalidation_0-mlogloss:0.05219\tvalidation_1-mlogloss:0.34122\n",
      "[537]\tvalidation_0-mlogloss:0.05209\tvalidation_1-mlogloss:0.34099\n",
      "[538]\tvalidation_0-mlogloss:0.05199\tvalidation_1-mlogloss:0.34088\n",
      "[539]\tvalidation_0-mlogloss:0.05190\tvalidation_1-mlogloss:0.34094\n",
      "[540]\tvalidation_0-mlogloss:0.05177\tvalidation_1-mlogloss:0.34097\n",
      "[541]\tvalidation_0-mlogloss:0.05165\tvalidation_1-mlogloss:0.34101\n",
      "[542]\tvalidation_0-mlogloss:0.05156\tvalidation_1-mlogloss:0.34084\n",
      "[543]\tvalidation_0-mlogloss:0.05151\tvalidation_1-mlogloss:0.34063\n",
      "[544]\tvalidation_0-mlogloss:0.05144\tvalidation_1-mlogloss:0.34046\n",
      "[545]\tvalidation_0-mlogloss:0.05134\tvalidation_1-mlogloss:0.34004\n",
      "[546]\tvalidation_0-mlogloss:0.05126\tvalidation_1-mlogloss:0.33986\n",
      "[547]\tvalidation_0-mlogloss:0.05118\tvalidation_1-mlogloss:0.33978\n",
      "[548]\tvalidation_0-mlogloss:0.05112\tvalidation_1-mlogloss:0.33970\n",
      "[549]\tvalidation_0-mlogloss:0.05104\tvalidation_1-mlogloss:0.33968\n",
      "[550]\tvalidation_0-mlogloss:0.05095\tvalidation_1-mlogloss:0.33941\n",
      "[551]\tvalidation_0-mlogloss:0.05086\tvalidation_1-mlogloss:0.33922\n",
      "[552]\tvalidation_0-mlogloss:0.05072\tvalidation_1-mlogloss:0.33905\n",
      "[553]\tvalidation_0-mlogloss:0.05070\tvalidation_1-mlogloss:0.33911\n",
      "[554]\tvalidation_0-mlogloss:0.05068\tvalidation_1-mlogloss:0.33919\n",
      "[555]\tvalidation_0-mlogloss:0.05059\tvalidation_1-mlogloss:0.33927\n",
      "[556]\tvalidation_0-mlogloss:0.05052\tvalidation_1-mlogloss:0.33912\n",
      "[557]\tvalidation_0-mlogloss:0.05049\tvalidation_1-mlogloss:0.33922\n",
      "[558]\tvalidation_0-mlogloss:0.05042\tvalidation_1-mlogloss:0.33926\n",
      "[559]\tvalidation_0-mlogloss:0.05028\tvalidation_1-mlogloss:0.33902\n",
      "[560]\tvalidation_0-mlogloss:0.05019\tvalidation_1-mlogloss:0.33890\n",
      "[561]\tvalidation_0-mlogloss:0.05011\tvalidation_1-mlogloss:0.33888\n",
      "[562]\tvalidation_0-mlogloss:0.05005\tvalidation_1-mlogloss:0.33890\n",
      "[563]\tvalidation_0-mlogloss:0.05001\tvalidation_1-mlogloss:0.33887\n",
      "[564]\tvalidation_0-mlogloss:0.04993\tvalidation_1-mlogloss:0.33880\n",
      "[565]\tvalidation_0-mlogloss:0.04984\tvalidation_1-mlogloss:0.33876\n",
      "[566]\tvalidation_0-mlogloss:0.04975\tvalidation_1-mlogloss:0.33860\n",
      "[567]\tvalidation_0-mlogloss:0.04970\tvalidation_1-mlogloss:0.33836\n",
      "[568]\tvalidation_0-mlogloss:0.04968\tvalidation_1-mlogloss:0.33824\n",
      "[569]\tvalidation_0-mlogloss:0.04963\tvalidation_1-mlogloss:0.33845\n",
      "[570]\tvalidation_0-mlogloss:0.04960\tvalidation_1-mlogloss:0.33854\n",
      "[571]\tvalidation_0-mlogloss:0.04954\tvalidation_1-mlogloss:0.33852\n",
      "[572]\tvalidation_0-mlogloss:0.04946\tvalidation_1-mlogloss:0.33846\n",
      "[573]\tvalidation_0-mlogloss:0.04937\tvalidation_1-mlogloss:0.33837\n",
      "[574]\tvalidation_0-mlogloss:0.04932\tvalidation_1-mlogloss:0.33833\n",
      "[575]\tvalidation_0-mlogloss:0.04927\tvalidation_1-mlogloss:0.33828\n",
      "[576]\tvalidation_0-mlogloss:0.04922\tvalidation_1-mlogloss:0.33822\n",
      "[577]\tvalidation_0-mlogloss:0.04919\tvalidation_1-mlogloss:0.33832\n",
      "[578]\tvalidation_0-mlogloss:0.04913\tvalidation_1-mlogloss:0.33831\n",
      "[579]\tvalidation_0-mlogloss:0.04906\tvalidation_1-mlogloss:0.33797\n",
      "[580]\tvalidation_0-mlogloss:0.04903\tvalidation_1-mlogloss:0.33795\n",
      "[581]\tvalidation_0-mlogloss:0.04897\tvalidation_1-mlogloss:0.33798\n",
      "[582]\tvalidation_0-mlogloss:0.04893\tvalidation_1-mlogloss:0.33812\n",
      "[583]\tvalidation_0-mlogloss:0.04888\tvalidation_1-mlogloss:0.33790\n",
      "[584]\tvalidation_0-mlogloss:0.04884\tvalidation_1-mlogloss:0.33782\n",
      "[585]\tvalidation_0-mlogloss:0.04876\tvalidation_1-mlogloss:0.33786\n",
      "[586]\tvalidation_0-mlogloss:0.04872\tvalidation_1-mlogloss:0.33799\n",
      "[587]\tvalidation_0-mlogloss:0.04871\tvalidation_1-mlogloss:0.33813\n",
      "[588]\tvalidation_0-mlogloss:0.04866\tvalidation_1-mlogloss:0.33833\n",
      "[589]\tvalidation_0-mlogloss:0.04853\tvalidation_1-mlogloss:0.33826\n",
      "[590]\tvalidation_0-mlogloss:0.04848\tvalidation_1-mlogloss:0.33831\n",
      "[591]\tvalidation_0-mlogloss:0.04840\tvalidation_1-mlogloss:0.33837\n",
      "[592]\tvalidation_0-mlogloss:0.04833\tvalidation_1-mlogloss:0.33840\n",
      "[593]\tvalidation_0-mlogloss:0.04825\tvalidation_1-mlogloss:0.33823\n",
      "[594]\tvalidation_0-mlogloss:0.04820\tvalidation_1-mlogloss:0.33812\n",
      "[595]\tvalidation_0-mlogloss:0.04816\tvalidation_1-mlogloss:0.33831\n",
      "[596]\tvalidation_0-mlogloss:0.04808\tvalidation_1-mlogloss:0.33825\n",
      "[597]\tvalidation_0-mlogloss:0.04802\tvalidation_1-mlogloss:0.33822\n",
      "[598]\tvalidation_0-mlogloss:0.04798\tvalidation_1-mlogloss:0.33821\n",
      "[599]\tvalidation_0-mlogloss:0.04794\tvalidation_1-mlogloss:0.33815\n",
      "[600]\tvalidation_0-mlogloss:0.04792\tvalidation_1-mlogloss:0.33828\n",
      "[601]\tvalidation_0-mlogloss:0.04786\tvalidation_1-mlogloss:0.33827\n",
      "[602]\tvalidation_0-mlogloss:0.04782\tvalidation_1-mlogloss:0.33809\n",
      "[603]\tvalidation_0-mlogloss:0.04778\tvalidation_1-mlogloss:0.33811\n",
      "[TXGB:] Processing time: 42688.656 milliseconds. Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "result = TXGB(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>acc_top_K5</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.866667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.719328</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.741346</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc  acc_top_K5  balanced_accuracy  precision_macro  recall_macro  \\\n",
       "0  0.866667           0           0.766667         0.719328      0.766667   \n",
       "\n",
       "   f1_macro  loss  \n",
       "0  0.741346  None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.1.6. BITULER\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matanalysis.methods import BITULER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###########    DATA PREPARATION      ###########\n",
      "\n",
      "Creating a virtual grid without polygons\n",
      "...cell size by degree: 0.0002706929603721246\n",
      "...grid_size_lat_y:358586\n",
      "...grid_size_lon_x:1221516\n",
      "...A virtual grid was created\n",
      "\n",
      "Creating or updating index of the grid feature..\n",
      "\n",
      "...[1419,1419] indexes were created to lat and lon\n",
      "\n",
      "Creating or updating index of the grid feature..\n",
      "\n",
      "...[664,664] indexes were created to lat and lon\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6b5851e5bf4667a428fb817acd6c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute 'poi': 113 unique values\n",
      "Attribute 'tid': 71 unique values\n",
      "Total of attribute/value pairs: 184\n",
      "\n",
      "\n",
      "###########      DATA ENCODING        ###########\n",
      "\n",
      "Input total: 3\n",
      "... tid_0: 71\n",
      "... tid_1: 27\n",
      "... tid_2: 45\n",
      "col_name: ['poi', 'tid', 'label']...\n",
      "... num_classes: 5\n",
      "... max_lenght: 37\n",
      "Removing column tid of attr\n",
      "Removing column label of attr\n",
      "\n",
      "\n",
      "#####   Encoding string data to integer   ######\n",
      "   Encoding: poi\n",
      "\n",
      "\n",
      "###########      Generating y_train and y_test     ###########\n",
      "Label encoding on label y\n",
      "Input total: 3\n",
      "\n",
      "[BITULER:] Building BITULER Model\n",
      "[BITULER:] Starting model training, 16 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6524e5cdde9c464284d02c3f6bdf27ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[BITULER:] Model Training:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:54:54.693830: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-12-17 16:54:54.693958: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 16:54:55.118278: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-12-17 16:54:56.278984: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:54:56.453038: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:54:56.463349: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:54:56.673219: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:54:56.685972: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6119 - acc: 0.2254"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:54:57.468874: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:54:57.538624: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:54:57.545218: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 754ms/step - loss: 1.6119 - acc: 0.2254 - val_loss: 1.5774 - val_acc: 0.2593\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 1.5774 - acc: 0.3380 - val_loss: 1.5517 - val_acc: 0.4444\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.5438 - acc: 0.3944 - val_loss: 1.5254 - val_acc: 0.6296\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.5196 - acc: 0.4085 - val_loss: 1.4945 - val_acc: 0.6296\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.4831 - acc: 0.5915 - val_loss: 1.4594 - val_acc: 0.5926\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.4383 - acc: 0.6761 - val_loss: 1.4191 - val_acc: 0.5926\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.3890 - acc: 0.6479 - val_loss: 1.3740 - val_acc: 0.4815\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.3361 - acc: 0.6338 - val_loss: 1.3261 - val_acc: 0.5556\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.2632 - acc: 0.6761 - val_loss: 1.2669 - val_acc: 0.5926\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.1969 - acc: 0.6338 - val_loss: 1.1800 - val_acc: 0.6296\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.0366 - acc: 0.7324 - val_loss: 1.1112 - val_acc: 0.5926\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.9603 - acc: 0.7465 - val_loss: 1.0221 - val_acc: 0.6296\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.8410 - acc: 0.7324 - val_loss: 0.9125 - val_acc: 0.6667\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.7724 - acc: 0.7887 - val_loss: 0.8481 - val_acc: 0.7037\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.7081 - acc: 0.7887 - val_loss: 0.8048 - val_acc: 0.6667\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6075 - acc: 0.7746 - val_loss: 0.7357 - val_acc: 0.6296\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5406 - acc: 0.7887 - val_loss: 0.6688 - val_acc: 0.6296\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4691 - acc: 0.8028 - val_loss: 0.6181 - val_acc: 0.7037\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3786 - acc: 0.8732 - val_loss: 0.5127 - val_acc: 0.8519\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3224 - acc: 0.9155 - val_loss: 0.4743 - val_acc: 0.8519\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3394 - acc: 0.9014 - val_loss: 0.4306 - val_acc: 0.8889\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.2429 - acc: 0.9718 - val_loss: 0.4637 - val_acc: 0.8889\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.1881 - acc: 0.9718 - val_loss: 0.3860 - val_acc: 0.8889\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.1701 - acc: 0.9577 - val_loss: 0.6793 - val_acc: 0.8148\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.1447 - acc: 0.9718 - val_loss: 0.2281 - val_acc: 1.0000\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.1457 - acc: 0.9718 - val_loss: 0.2778 - val_acc: 1.0000\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.1611 - acc: 1.0000 - val_loss: 0.2842 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.1507 - acc: 1.0000 - val_loss: 0.2885 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.1305 - acc: 1.0000 - val_loss: 0.2691 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1031 - acc: 1.0000 - val_loss: 0.2357 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0750 - acc: 1.0000 - val_loss: 0.1842 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0542 - acc: 1.0000 - val_loss: 0.1498 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0423 - acc: 1.0000 - val_loss: 0.1610 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0372 - acc: 1.0000 - val_loss: 0.1971 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0286 - acc: 1.0000 - val_loss: 0.2490 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0240 - acc: 1.0000 - val_loss: 0.2855 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0200 - acc: 1.0000 - val_loss: 0.2615 - val_acc: 0.8889\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0252 - acc: 0.9859 - val_loss: 0.4290 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.5472 - val_acc: 0.8889\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.4637 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.2855 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.2847 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.2975 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.3076 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.3164 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.3186 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.3143 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.3079 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.3007 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.2956 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.2934 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.2963 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.3102 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.3190 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.3271 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.3338 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.3400 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.3452 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.3497 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.3516 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.3507 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.3489 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.3477 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.3487 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.3519 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.3570 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.3639 - val_acc: 0.9259\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.3719 - val_acc: 0.9259\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.3794 - val_acc: 0.9259\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.3858 - val_acc: 0.9259\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.3908 - val_acc: 0.9259\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.3947 - val_acc: 0.9259\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.3978 - val_acc: 0.9259\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.4009 - val_acc: 0.9259\n",
      "1/1 [==============================] - 0s 414ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:55:04.982645: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:05.041054: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:05.048067: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 16:55:06.651544: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:06.824130: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:06.834180: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:06.993783: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:07.007036: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6101 - acc: 0.1972"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:55:07.747620: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:07.817142: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:07.823713: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 735ms/step - loss: 1.6101 - acc: 0.1972 - val_loss: 1.5639 - val_acc: 0.4815\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 1.5629 - acc: 0.4225 - val_loss: 1.5202 - val_acc: 0.4815\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.5049 - acc: 0.6338 - val_loss: 1.4783 - val_acc: 0.4815\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.4534 - acc: 0.5775 - val_loss: 1.4275 - val_acc: 0.4815\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 1.4025 - acc: 0.5915 - val_loss: 1.3684 - val_acc: 0.4815\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.3308 - acc: 0.5634 - val_loss: 1.3049 - val_acc: 0.4444\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.2423 - acc: 0.5211 - val_loss: 1.2658 - val_acc: 0.3704\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.1759 - acc: 0.4789 - val_loss: 1.2684 - val_acc: 0.3704\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.1294 - acc: 0.4930 - val_loss: 1.1170 - val_acc: 0.4815\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.9870 - acc: 0.5634 - val_loss: 0.9725 - val_acc: 0.6667\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.8582 - acc: 0.7042 - val_loss: 0.8498 - val_acc: 0.6667\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7468 - acc: 0.8310 - val_loss: 0.7250 - val_acc: 0.8519\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5949 - acc: 0.9155 - val_loss: 0.6369 - val_acc: 0.8148\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4653 - acc: 0.8732 - val_loss: 0.5302 - val_acc: 0.8519\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3989 - acc: 0.9014 - val_loss: 1.0227 - val_acc: 0.5926\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5085 - acc: 0.7746 - val_loss: 0.6526 - val_acc: 0.7037\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4718 - acc: 0.8451 - val_loss: 0.5028 - val_acc: 0.8519\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4005 - acc: 0.8451 - val_loss: 0.3775 - val_acc: 0.9259\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.2696 - acc: 0.9577 - val_loss: 0.3803 - val_acc: 0.8519\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2606 - acc: 0.9577 - val_loss: 0.3689 - val_acc: 0.9259\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.2283 - acc: 0.9859 - val_loss: 0.3385 - val_acc: 0.9259\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.2063 - acc: 1.0000 - val_loss: 0.3139 - val_acc: 0.9259\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.1675 - acc: 1.0000 - val_loss: 0.2955 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.1555 - acc: 1.0000 - val_loss: 0.2842 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1351 - acc: 1.0000 - val_loss: 0.2773 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1248 - acc: 1.0000 - val_loss: 0.2723 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.1132 - acc: 0.9859 - val_loss: 0.2673 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.1082 - acc: 1.0000 - val_loss: 0.2534 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1005 - acc: 1.0000 - val_loss: 0.2344 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0742 - acc: 1.0000 - val_loss: 0.2187 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0657 - acc: 1.0000 - val_loss: 0.2084 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0554 - acc: 1.0000 - val_loss: 0.2032 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0474 - acc: 1.0000 - val_loss: 0.2039 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0526 - acc: 1.0000 - val_loss: 0.2048 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0386 - acc: 1.0000 - val_loss: 0.2020 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0340 - acc: 1.0000 - val_loss: 0.1967 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0238 - acc: 1.0000 - val_loss: 0.1876 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0286 - acc: 1.0000 - val_loss: 0.1733 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0212 - acc: 1.0000 - val_loss: 0.1610 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0283 - acc: 1.0000 - val_loss: 0.1540 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0231 - acc: 1.0000 - val_loss: 0.1519 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0177 - acc: 1.0000 - val_loss: 0.1534 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0198 - acc: 1.0000 - val_loss: 0.1544 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.1565 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0134 - acc: 1.0000 - val_loss: 0.1602 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.1632 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.1657 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.1670 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.1677 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.1700 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.1738 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.1739 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.1750 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.1781 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.1809 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.1859 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.1893 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.1934 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.1968 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.1966 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.1943 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.1902 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.1838 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.1737 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.1639 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.1554 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.1495 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.1521 - val_acc: 0.9259\n",
      "1/1 [==============================] - 0s 400ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:55:14.998570: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:15.056202: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:15.062770: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 16:55:16.654444: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:16.830499: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:16.841225: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:17.014591: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:17.027820: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6029 - acc: 0.2254"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:55:17.880226: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:17.949998: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:17.956566: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 789ms/step - loss: 1.6029 - acc: 0.2254 - val_loss: 1.5408 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.5209 - acc: 0.4225 - val_loss: 1.4817 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.4599 - acc: 0.4366 - val_loss: 1.4231 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.3909 - acc: 0.3944 - val_loss: 1.3706 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 1.3113 - acc: 0.4366 - val_loss: 1.3246 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.2623 - acc: 0.4366 - val_loss: 1.2486 - val_acc: 0.3704\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.1659 - acc: 0.5915 - val_loss: 1.1356 - val_acc: 0.5926\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 1.0264 - acc: 0.6901 - val_loss: 1.0090 - val_acc: 0.7037\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.8858 - acc: 0.7887 - val_loss: 0.8859 - val_acc: 0.7037\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.7970 - acc: 0.8028 - val_loss: 0.7727 - val_acc: 0.7037\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6342 - acc: 0.8310 - val_loss: 0.7038 - val_acc: 0.7037\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5464 - acc: 0.8451 - val_loss: 0.6793 - val_acc: 0.7037\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4922 - acc: 0.8592 - val_loss: 0.5537 - val_acc: 0.7407\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3550 - acc: 0.9155 - val_loss: 1.3516 - val_acc: 0.4815\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.8046 - acc: 0.6479 - val_loss: 0.4892 - val_acc: 0.8148\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.3757 - acc: 0.8451 - val_loss: 0.4744 - val_acc: 0.8148\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.2757 - acc: 0.9014 - val_loss: 0.5196 - val_acc: 0.8889\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.2736 - acc: 0.9718 - val_loss: 0.6034 - val_acc: 0.7778\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2721 - acc: 0.9296 - val_loss: 0.5779 - val_acc: 0.8889\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2733 - acc: 0.9859 - val_loss: 0.4878 - val_acc: 0.9259\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.2222 - acc: 0.9859 - val_loss: 0.4067 - val_acc: 0.9259\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.1835 - acc: 1.0000 - val_loss: 0.3609 - val_acc: 0.9259\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.1805 - acc: 1.0000 - val_loss: 0.3356 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.1580 - acc: 1.0000 - val_loss: 0.3173 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.1556 - acc: 0.9859 - val_loss: 0.3013 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.1450 - acc: 0.9859 - val_loss: 0.2875 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.1146 - acc: 1.0000 - val_loss: 0.2762 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.1060 - acc: 1.0000 - val_loss: 0.2674 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0830 - acc: 1.0000 - val_loss: 0.2620 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.1055 - acc: 1.0000 - val_loss: 0.2594 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0714 - acc: 1.0000 - val_loss: 0.2595 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0712 - acc: 1.0000 - val_loss: 0.2629 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0567 - acc: 1.0000 - val_loss: 0.2711 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0650 - acc: 1.0000 - val_loss: 0.2810 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0463 - acc: 1.0000 - val_loss: 0.2900 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0485 - acc: 1.0000 - val_loss: 0.2991 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0453 - acc: 1.0000 - val_loss: 0.3067 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0389 - acc: 1.0000 - val_loss: 0.3134 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0409 - acc: 1.0000 - val_loss: 0.3195 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0469 - acc: 1.0000 - val_loss: 0.3231 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0314 - acc: 1.0000 - val_loss: 0.3244 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0350 - acc: 1.0000 - val_loss: 0.3243 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0279 - acc: 1.0000 - val_loss: 0.3225 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0299 - acc: 1.0000 - val_loss: 0.3209 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0272 - acc: 1.0000 - val_loss: 0.3184 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0231 - acc: 1.0000 - val_loss: 0.3160 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0280 - acc: 1.0000 - val_loss: 0.3149 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0234 - acc: 1.0000 - val_loss: 0.3149 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0214 - acc: 1.0000 - val_loss: 0.3122 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0222 - acc: 1.0000 - val_loss: 0.3057 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0215 - acc: 1.0000 - val_loss: 0.2986 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0187 - acc: 1.0000 - val_loss: 0.2927 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0204 - acc: 1.0000 - val_loss: 0.2879 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0212 - acc: 1.0000 - val_loss: 0.2845 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0233 - acc: 1.0000 - val_loss: 0.2821 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0153 - acc: 1.0000 - val_loss: 0.2802 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0205 - acc: 1.0000 - val_loss: 0.2793 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0200 - acc: 1.0000 - val_loss: 0.2785 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.2789 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.2805 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0165 - acc: 1.0000 - val_loss: 0.2830 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.2863 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.2905 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.2949 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.2988 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.3035 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.3087 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.3135 - val_acc: 0.9259\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.3183 - val_acc: 0.9259\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.3235 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:55:25.695933: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:25.756631: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:25.763268: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 513ms/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 16:55:27.287227: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:27.465095: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:27.475110: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:27.678460: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:27.691415: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6076 - acc: 0.2113"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:55:28.658222: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:28.730803: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:28.737777: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 948ms/step - loss: 1.6076 - acc: 0.2113 - val_loss: 1.5259 - val_acc: 0.4815\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.5053 - acc: 0.6197 - val_loss: 1.4496 - val_acc: 0.4074\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.4162 - acc: 0.5070 - val_loss: 1.3725 - val_acc: 0.4074\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.3248 - acc: 0.4789 - val_loss: 1.2995 - val_acc: 0.4074\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.2376 - acc: 0.4648 - val_loss: 1.2417 - val_acc: 0.4074\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.1588 - acc: 0.5352 - val_loss: 1.1599 - val_acc: 0.4444\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.0790 - acc: 0.5634 - val_loss: 1.0186 - val_acc: 0.5926\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.8898 - acc: 0.7324 - val_loss: 0.8632 - val_acc: 0.7037\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.7472 - acc: 0.7887 - val_loss: 0.7196 - val_acc: 0.8148\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.5841 - acc: 0.8873 - val_loss: 0.6109 - val_acc: 0.8148\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4009 - acc: 0.9718 - val_loss: 0.4532 - val_acc: 0.8889\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.2765 - acc: 1.0000 - val_loss: 0.3902 - val_acc: 0.9630\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.2623 - acc: 1.0000 - val_loss: 0.3422 - val_acc: 0.9259\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.1817 - acc: 1.0000 - val_loss: 0.4017 - val_acc: 0.8889\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.1893 - acc: 0.9296 - val_loss: 0.6136 - val_acc: 0.8519\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.1559 - acc: 0.9859 - val_loss: 0.2623 - val_acc: 0.9259\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.1029 - acc: 1.0000 - val_loss: 0.2133 - val_acc: 0.9259\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0828 - acc: 1.0000 - val_loss: 0.1728 - val_acc: 1.0000\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0756 - acc: 1.0000 - val_loss: 0.1387 - val_acc: 1.0000\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0632 - acc: 1.0000 - val_loss: 0.1259 - val_acc: 1.0000\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0504 - acc: 1.0000 - val_loss: 0.1287 - val_acc: 0.9630\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0431 - acc: 1.0000 - val_loss: 0.1329 - val_acc: 0.9259\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0453 - acc: 1.0000 - val_loss: 0.1418 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0316 - acc: 1.0000 - val_loss: 0.1572 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0286 - acc: 1.0000 - val_loss: 0.1716 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0266 - acc: 1.0000 - val_loss: 0.1781 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0236 - acc: 1.0000 - val_loss: 0.1775 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0202 - acc: 1.0000 - val_loss: 0.1715 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.1610 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.1489 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0161 - acc: 1.0000 - val_loss: 0.1353 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.1208 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.1066 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.1055 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.1104 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.1195 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.1316 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.1421 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.1582 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.1774 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.1971 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.2136 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.2241 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.2293 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.2268 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.2211 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.2135 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.2053 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.1996 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.1944 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.1791 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.1562 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.1364 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.1258 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.1262 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.1274 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.1259 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.1282 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.1320 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.1372 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.1447 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.1501 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.1565 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.1641 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.1705 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.1759 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.1799 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.1844 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:55:36.660329: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:36.721720: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:36.728503: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 427ms/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 16:55:38.395846: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:38.592121: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:38.602532: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:38.820429: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:38.833808: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6072 - acc: 0.2113"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:55:39.679429: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:39.753048: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:39.759765: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 840ms/step - loss: 1.6072 - acc: 0.2113 - val_loss: 1.5689 - val_acc: 0.4074\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 1.5575 - acc: 0.4366 - val_loss: 1.5266 - val_acc: 0.4074\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.5032 - acc: 0.4648 - val_loss: 1.4773 - val_acc: 0.4074\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.4414 - acc: 0.4507 - val_loss: 1.4483 - val_acc: 0.4815\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.3986 - acc: 0.4366 - val_loss: 1.4766 - val_acc: 0.4074\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 1.3725 - acc: 0.4930 - val_loss: 1.3545 - val_acc: 0.4074\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 1.2202 - acc: 0.5493 - val_loss: 1.2867 - val_acc: 0.4815\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.1516 - acc: 0.5775 - val_loss: 1.2623 - val_acc: 0.5926\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 1.0955 - acc: 0.6901 - val_loss: 3.3957 - val_acc: 0.2593\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 2.6857 - acc: 0.3380 - val_loss: 1.1188 - val_acc: 0.6667\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.9580 - acc: 0.7465 - val_loss: 1.1488 - val_acc: 0.5926\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.9546 - acc: 0.6620 - val_loss: 1.1112 - val_acc: 0.5926\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.9185 - acc: 0.6620 - val_loss: 1.0502 - val_acc: 0.5926\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.8754 - acc: 0.6479 - val_loss: 0.9818 - val_acc: 0.5926\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.7837 - acc: 0.6620 - val_loss: 0.9298 - val_acc: 0.5926\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7257 - acc: 0.6901 - val_loss: 0.8278 - val_acc: 0.5926\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6376 - acc: 0.7042 - val_loss: 0.7553 - val_acc: 0.6667\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5912 - acc: 0.8028 - val_loss: 0.6799 - val_acc: 0.7037\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.5146 - acc: 0.8169 - val_loss: 0.9310 - val_acc: 0.5926\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.5951 - acc: 0.7465 - val_loss: 0.6396 - val_acc: 0.7037\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4730 - acc: 0.8873 - val_loss: 0.6220 - val_acc: 0.9259\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4735 - acc: 0.9718 - val_loss: 0.6239 - val_acc: 0.9630\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4780 - acc: 1.0000 - val_loss: 0.5808 - val_acc: 0.9630\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4392 - acc: 1.0000 - val_loss: 0.5382 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.3894 - acc: 1.0000 - val_loss: 0.4831 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.3216 - acc: 1.0000 - val_loss: 0.4192 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2527 - acc: 1.0000 - val_loss: 0.3578 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.1892 - acc: 1.0000 - val_loss: 0.3131 - val_acc: 0.8889\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1491 - acc: 1.0000 - val_loss: 0.3209 - val_acc: 0.8889\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.1317 - acc: 0.9718 - val_loss: 0.3558 - val_acc: 0.8889\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.1367 - acc: 0.9718 - val_loss: 0.3088 - val_acc: 0.8889\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0988 - acc: 0.9718 - val_loss: 0.2618 - val_acc: 0.8889\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0684 - acc: 1.0000 - val_loss: 0.2443 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0643 - acc: 1.0000 - val_loss: 0.2572 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0502 - acc: 1.0000 - val_loss: 0.3411 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0412 - acc: 1.0000 - val_loss: 0.4254 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0270 - acc: 1.0000 - val_loss: 0.2949 - val_acc: 0.8889\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0170 - acc: 1.0000 - val_loss: 0.2253 - val_acc: 0.8889\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0312 - acc: 0.9859 - val_loss: 0.2003 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0253 - acc: 1.0000 - val_loss: 0.1946 - val_acc: 0.8889\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.3673 - val_acc: 0.8889\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.4508 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.2959 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.1620 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.1081 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0962 - val_acc: 0.9630\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0973 - val_acc: 0.9630\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.1017 - val_acc: 0.9630\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.1075 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.1190 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.1600 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.2408 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.3356 - val_acc: 0.8889\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.4212 - val_acc: 0.8889\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.4906 - val_acc: 0.8889\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.5018 - val_acc: 0.8889\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.4969 - val_acc: 0.8889\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.4794 - val_acc: 0.8889\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.4533 - val_acc: 0.8889\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.4116 - val_acc: 0.8889\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.3766 - val_acc: 0.8889\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.3644 - val_acc: 0.8889\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.3725 - val_acc: 0.8889\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.3818 - val_acc: 0.8889\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 9.6225e-04 - acc: 1.0000 - val_loss: 0.3921 - val_acc: 0.8889\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.3999 - val_acc: 0.8889\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.4022 - val_acc: 0.8889\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 8.5035e-04 - acc: 1.0000 - val_loss: 0.4041 - val_acc: 0.8889\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.4089 - val_acc: 0.8889\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 8.5362e-04 - acc: 1.0000 - val_loss: 0.4175 - val_acc: 0.8889\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 7.3004e-04 - acc: 1.0000 - val_loss: 0.4269 - val_acc: 0.8889\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 7.4634e-04 - acc: 1.0000 - val_loss: 0.4349 - val_acc: 0.8889\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2fff52af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 419ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:55:47.688089: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:47.748081: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:47.754851: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 16:55:49.395531: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:49.576171: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:49.585988: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:49.782979: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:49.795950: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6117 - acc: 0.1972"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:55:50.653254: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:50.733685: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:50.740433: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 900ms/step - loss: 1.6117 - acc: 0.1972 - val_loss: 1.5444 - val_acc: 0.4074\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.5387 - acc: 0.4648 - val_loss: 1.4826 - val_acc: 0.5926\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 1.4618 - acc: 0.5775 - val_loss: 1.4053 - val_acc: 0.4815\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 1.3855 - acc: 0.5211 - val_loss: 1.3360 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 1.2819 - acc: 0.4085 - val_loss: 1.2851 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.1875 - acc: 0.4507 - val_loss: 1.1453 - val_acc: 0.5556\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 1.0478 - acc: 0.6620 - val_loss: 1.0207 - val_acc: 0.7037\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.8939 - acc: 0.7887 - val_loss: 0.9211 - val_acc: 0.7778\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.7696 - acc: 0.8310 - val_loss: 0.8047 - val_acc: 0.8148\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6822 - acc: 0.9155 - val_loss: 0.6445 - val_acc: 0.8148\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4856 - acc: 0.9155 - val_loss: 0.5980 - val_acc: 0.7778\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3953 - acc: 0.8873 - val_loss: 0.4583 - val_acc: 0.8148\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.2579 - acc: 0.9577 - val_loss: 0.3272 - val_acc: 0.9259\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.2011 - acc: 0.9296 - val_loss: 0.2543 - val_acc: 0.9259\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.1344 - acc: 0.9718 - val_loss: 0.2841 - val_acc: 0.8889\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0975 - acc: 1.0000 - val_loss: 0.9668 - val_acc: 0.7778\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3229 - acc: 0.9014 - val_loss: 0.4163 - val_acc: 0.8889\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.2110 - acc: 1.0000 - val_loss: 0.3650 - val_acc: 0.9259\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.1727 - acc: 1.0000 - val_loss: 0.3059 - val_acc: 0.9259\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.1277 - acc: 1.0000 - val_loss: 0.2431 - val_acc: 0.9630\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0938 - acc: 1.0000 - val_loss: 0.2219 - val_acc: 0.9630\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0827 - acc: 1.0000 - val_loss: 0.2044 - val_acc: 1.0000\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0776 - acc: 1.0000 - val_loss: 0.1713 - val_acc: 1.0000\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0538 - acc: 1.0000 - val_loss: 0.1575 - val_acc: 0.9630\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0414 - acc: 1.0000 - val_loss: 0.1237 - val_acc: 0.9630\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0323 - acc: 1.0000 - val_loss: 0.1272 - val_acc: 1.0000\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0266 - acc: 1.0000 - val_loss: 0.1304 - val_acc: 1.0000\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0252 - acc: 1.0000 - val_loss: 0.1248 - val_acc: 1.0000\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0193 - acc: 1.0000 - val_loss: 0.1130 - val_acc: 1.0000\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0158 - acc: 1.0000 - val_loss: 0.0966 - val_acc: 1.0000\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.0805 - val_acc: 1.0000\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.0683 - val_acc: 1.0000\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.0610 - val_acc: 1.0000\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.0571 - val_acc: 1.0000\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0565 - val_acc: 1.0000\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0585 - val_acc: 1.0000\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0618 - val_acc: 0.9630\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0622 - val_acc: 0.9630\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0595 - val_acc: 0.9630\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0582 - val_acc: 0.9630\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0590 - val_acc: 0.9630\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0606 - val_acc: 0.9630\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0621 - val_acc: 0.9630\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0632 - val_acc: 0.9630\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0641 - val_acc: 0.9630\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0645 - val_acc: 0.9630\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0648 - val_acc: 0.9630\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0648 - val_acc: 0.9630\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0645 - val_acc: 0.9630\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0642 - val_acc: 0.9630\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0639 - val_acc: 0.9630\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0636 - val_acc: 0.9630\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0633 - val_acc: 0.9630\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0635 - val_acc: 0.9630\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0639 - val_acc: 0.9630\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0645 - val_acc: 0.9630\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9630\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0664 - val_acc: 0.9630\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0675 - val_acc: 0.9630\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0685 - val_acc: 0.9630\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0690 - val_acc: 0.9630\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0696 - val_acc: 0.9630\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0699 - val_acc: 0.9630\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0700 - val_acc: 0.9630\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0703 - val_acc: 0.9630\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0705 - val_acc: 0.9630\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0707 - val_acc: 0.9630\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 9.0090e-04 - acc: 1.0000 - val_loss: 0.0713 - val_acc: 0.9630\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 9.1975e-04 - acc: 1.0000 - val_loss: 0.0720 - val_acc: 0.9630\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 9.7213e-04 - acc: 1.0000 - val_loss: 0.0730 - val_acc: 0.9630\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 8.1711e-04 - acc: 1.0000 - val_loss: 0.0744 - val_acc: 0.9630\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 7.1484e-04 - acc: 1.0000 - val_loss: 0.0762 - val_acc: 0.9630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:55:59.122546: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:59.185144: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:55:59.191901: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2c9b9a940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 452ms/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 16:56:00.833140: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:01.010765: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:01.021372: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:01.282860: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:01.295936: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6072 - acc: 0.2394"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:56:02.228037: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:02.308392: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:02.315253: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 915ms/step - loss: 1.6072 - acc: 0.2394 - val_loss: 1.5073 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 1.4986 - acc: 0.3662 - val_loss: 1.4153 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 1.3762 - acc: 0.3662 - val_loss: 1.3376 - val_acc: 0.4074\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 1.2879 - acc: 0.5634 - val_loss: 1.2601 - val_acc: 0.5556\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.1777 - acc: 0.6620 - val_loss: 1.1197 - val_acc: 0.7407\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.0329 - acc: 0.8028 - val_loss: 0.9035 - val_acc: 0.7037\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.7846 - acc: 0.8451 - val_loss: 0.7312 - val_acc: 0.7037\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.5655 - acc: 0.8451 - val_loss: 0.6462 - val_acc: 0.8148\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.4553 - acc: 0.9014 - val_loss: 0.4959 - val_acc: 0.8519\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3550 - acc: 0.8873 - val_loss: 0.4674 - val_acc: 0.8519\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.2951 - acc: 0.9437 - val_loss: 0.4447 - val_acc: 0.8519\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.2426 - acc: 0.9296 - val_loss: 0.3277 - val_acc: 0.8519\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.1801 - acc: 0.9718 - val_loss: 0.2745 - val_acc: 0.8519\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.1520 - acc: 0.9577 - val_loss: 0.2158 - val_acc: 0.9259\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.1435 - acc: 0.9577 - val_loss: 0.3105 - val_acc: 0.8889\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0906 - acc: 0.9859 - val_loss: 0.6448 - val_acc: 0.8519\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.1345 - acc: 0.9859 - val_loss: 0.2521 - val_acc: 0.9259\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0950 - acc: 1.0000 - val_loss: 0.2366 - val_acc: 0.9259\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0939 - acc: 1.0000 - val_loss: 0.2319 - val_acc: 0.9259\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0839 - acc: 1.0000 - val_loss: 0.2232 - val_acc: 0.9259\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0745 - acc: 1.0000 - val_loss: 0.2027 - val_acc: 0.9259\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0576 - acc: 1.0000 - val_loss: 0.1757 - val_acc: 0.9259\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0388 - acc: 1.0000 - val_loss: 0.1548 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0234 - acc: 1.0000 - val_loss: 0.1588 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.1901 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.1984 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.1748 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.1543 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.1420 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.1367 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.1365 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.1388 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1428 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.1472 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.1525 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.1579 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1614 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.1629 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1657 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.1712 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1798 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1918 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.2033 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.2127 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.2219 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.2314 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.2408 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.2511 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.2613 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.2689 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.2746 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.2790 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.2833 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.2865 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.2883 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.2893 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.2892 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.2893 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.2897 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2900 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.2910 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.2922 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.2917 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 9.0117e-04 - acc: 1.0000 - val_loss: 0.2906 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:56:10.679351: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:10.743759: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:10.750784: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 624ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 16:56:12.336000: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:12.534509: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:12.547186: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:12.824760: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:12.838430: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.5974 - acc: 0.2676"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:56:13.968728: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:14.051642: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:14.058966: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 1s/step - loss: 1.5974 - acc: 0.2676 - val_loss: 1.4725 - val_acc: 0.3704\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 1.4447 - acc: 0.4366 - val_loss: 1.3815 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 1.3412 - acc: 0.3803 - val_loss: 1.3283 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 1.2429 - acc: 0.4789 - val_loss: 1.1914 - val_acc: 0.4444\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 1.1012 - acc: 0.6197 - val_loss: 1.0347 - val_acc: 0.6667\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.9158 - acc: 0.7465 - val_loss: 0.8368 - val_acc: 0.8519\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.6944 - acc: 0.8592 - val_loss: 0.6843 - val_acc: 0.8519\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.5100 - acc: 0.9296 - val_loss: 0.6457 - val_acc: 0.9259\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.4928 - acc: 0.9155 - val_loss: 0.5773 - val_acc: 0.9259\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.4327 - acc: 0.9155 - val_loss: 0.5042 - val_acc: 0.7778\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.3874 - acc: 0.8169 - val_loss: 0.6752 - val_acc: 0.7037\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3889 - acc: 0.8451 - val_loss: 0.4232 - val_acc: 0.7778\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.2986 - acc: 0.8310 - val_loss: 0.2931 - val_acc: 1.0000\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.1600 - acc: 1.0000 - val_loss: 0.3113 - val_acc: 0.9259\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.1438 - acc: 1.0000 - val_loss: 0.3114 - val_acc: 0.9259\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.1375 - acc: 1.0000 - val_loss: 0.2995 - val_acc: 0.9259\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.1055 - acc: 1.0000 - val_loss: 0.2819 - val_acc: 0.9259\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.1019 - acc: 1.0000 - val_loss: 0.2595 - val_acc: 0.9259\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0817 - acc: 1.0000 - val_loss: 0.2356 - val_acc: 0.9259\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0509 - acc: 1.0000 - val_loss: 0.2136 - val_acc: 0.9259\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0340 - acc: 1.0000 - val_loss: 0.1957 - val_acc: 0.9259\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.1834 - val_acc: 0.9259\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0164 - acc: 1.0000 - val_loss: 0.1765 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.1724 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.1701 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.1681 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.1654 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.1619 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.1581 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.1541 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1505 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1473 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.1445 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.1421 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1400 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.1381 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.1366 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1354 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.1344 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1337 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.1332 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1327 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1324 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.1321 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1319 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1317 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1316 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1315 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1314 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1313 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1312 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1311 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1311 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1311 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1311 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1311 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1311 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1311 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1312 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1312 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1313 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1314 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1314 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:56:22.327541: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:22.391988: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:22.400165: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 470ms/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 16:56:24.142923: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:24.346028: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:24.357500: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:24.658450: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:24.671994: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6126 - acc: 0.1972"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:56:25.708686: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:25.798657: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:25.805776: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 1s/step - loss: 1.6126 - acc: 0.1972 - val_loss: 1.5593 - val_acc: 0.4074\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 1.5511 - acc: 0.4507 - val_loss: 1.5102 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 1.4971 - acc: 0.4366 - val_loss: 1.4462 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 1.4302 - acc: 0.4366 - val_loss: 1.3901 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 1.3442 - acc: 0.4225 - val_loss: 1.3254 - val_acc: 0.4444\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 1.2509 - acc: 0.5493 - val_loss: 1.2854 - val_acc: 0.5926\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 1.2023 - acc: 0.8028 - val_loss: 1.2263 - val_acc: 0.8148\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.1300 - acc: 0.9014 - val_loss: 1.1216 - val_acc: 0.8519\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.9786 - acc: 0.9296 - val_loss: 1.1195 - val_acc: 0.3704\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.9606 - acc: 0.5775 - val_loss: 0.8251 - val_acc: 0.8148\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6383 - acc: 0.8732 - val_loss: 0.7014 - val_acc: 0.8519\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.4817 - acc: 0.8873 - val_loss: 0.8095 - val_acc: 0.7407\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6548 - acc: 0.7887 - val_loss: 0.6978 - val_acc: 0.7037\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.4729 - acc: 0.8169 - val_loss: 0.6441 - val_acc: 0.9259\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4729 - acc: 0.9155 - val_loss: 0.5604 - val_acc: 0.8519\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3967 - acc: 0.9296 - val_loss: 0.5315 - val_acc: 0.8519\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3528 - acc: 0.9296 - val_loss: 0.5131 - val_acc: 0.8148\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.3040 - acc: 0.9718 - val_loss: 0.3458 - val_acc: 0.9259\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.1823 - acc: 1.0000 - val_loss: 0.2279 - val_acc: 1.0000\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.1288 - acc: 1.0000 - val_loss: 0.2069 - val_acc: 1.0000\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.1372 - acc: 0.9859 - val_loss: 0.2056 - val_acc: 1.0000\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0982 - acc: 0.9859 - val_loss: 0.1680 - val_acc: 1.0000\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0908 - acc: 1.0000 - val_loss: 0.1183 - val_acc: 1.0000\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0450 - acc: 1.0000 - val_loss: 0.1024 - val_acc: 1.0000\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0412 - acc: 1.0000 - val_loss: 0.1239 - val_acc: 0.9630\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0245 - acc: 1.0000 - val_loss: 0.1785 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0239 - acc: 1.0000 - val_loss: 0.2360 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0223 - acc: 1.0000 - val_loss: 0.2537 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0189 - acc: 1.0000 - val_loss: 0.2367 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0176 - acc: 1.0000 - val_loss: 0.1907 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.1324 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0957 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0723 - val_acc: 1.0000\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0562 - val_acc: 1.0000\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0450 - val_acc: 1.0000\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0373 - val_acc: 1.0000\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0324 - val_acc: 1.0000\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0289 - val_acc: 1.0000\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0280 - val_acc: 1.0000\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0282 - val_acc: 1.0000\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0308 - acc: 0.9859 - val_loss: 0.0222 - val_acc: 1.0000\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0185 - val_acc: 1.0000\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0172 - val_acc: 1.0000\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0191 - val_acc: 1.0000\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0239 - val_acc: 1.0000\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 7.8220e-04 - acc: 1.0000 - val_loss: 0.0295 - val_acc: 1.0000\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 8.8425e-04 - acc: 1.0000 - val_loss: 0.0357 - val_acc: 1.0000\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 6.5643e-04 - acc: 1.0000 - val_loss: 0.0423 - val_acc: 1.0000\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 6.1377e-04 - acc: 1.0000 - val_loss: 0.0489 - val_acc: 1.0000\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 8.2074e-04 - acc: 1.0000 - val_loss: 0.0558 - val_acc: 1.0000\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 5.6184e-04 - acc: 1.0000 - val_loss: 0.0625 - val_acc: 1.0000\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 6.6298e-04 - acc: 1.0000 - val_loss: 0.0679 - val_acc: 0.9630\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0713 - val_acc: 0.9630\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 5.5067e-04 - acc: 1.0000 - val_loss: 0.0741 - val_acc: 0.9630\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 5.4062e-04 - acc: 1.0000 - val_loss: 0.0765 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 5.7266e-04 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 5.9915e-04 - acc: 1.0000 - val_loss: 0.0780 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 5.1880e-04 - acc: 1.0000 - val_loss: 0.0770 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 4.5456e-04 - acc: 1.0000 - val_loss: 0.0759 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0727 - val_acc: 0.9630\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 5.6938e-04 - acc: 1.0000 - val_loss: 0.0690 - val_acc: 0.9630\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 4.7759e-04 - acc: 1.0000 - val_loss: 0.0658 - val_acc: 0.9630\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 4.3641e-04 - acc: 1.0000 - val_loss: 0.0630 - val_acc: 0.9630\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 6.0709e-04 - acc: 1.0000 - val_loss: 0.0607 - val_acc: 1.0000\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 5.6000e-04 - acc: 1.0000 - val_loss: 0.0589 - val_acc: 1.0000\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 4.6223e-04 - acc: 1.0000 - val_loss: 0.0574 - val_acc: 1.0000\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 5.2961e-04 - acc: 1.0000 - val_loss: 0.0564 - val_acc: 1.0000\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 5.7361e-04 - acc: 1.0000 - val_loss: 0.0556 - val_acc: 1.0000\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 4.2495e-04 - acc: 1.0000 - val_loss: 0.0553 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:56:34.407447: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:34.473357: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:34.480099: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 484ms/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 16:56:36.196880: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:36.381222: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:36.393048: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:36.654977: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:36.668028: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6129 - acc: 0.1549"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:56:37.608030: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:37.687505: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:37.694299: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 921ms/step - loss: 1.6129 - acc: 0.1549 - val_loss: 1.5266 - val_acc: 0.3704\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 1.5115 - acc: 0.4366 - val_loss: 1.4372 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 1.4002 - acc: 0.3662 - val_loss: 1.4434 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 1.3686 - acc: 0.3662 - val_loss: 1.3234 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.2356 - acc: 0.4085 - val_loss: 1.2160 - val_acc: 0.5926\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 1.1336 - acc: 0.6197 - val_loss: 1.0516 - val_acc: 0.6296\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.9302 - acc: 0.6901 - val_loss: 1.0619 - val_acc: 0.6296\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.8486 - acc: 0.7465 - val_loss: 0.7738 - val_acc: 0.5926\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.5737 - acc: 0.8028 - val_loss: 0.6553 - val_acc: 0.8148\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.4908 - acc: 0.9014 - val_loss: 0.6215 - val_acc: 0.7778\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.4728 - acc: 0.8028 - val_loss: 0.6034 - val_acc: 0.8519\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3508 - acc: 0.9437 - val_loss: 0.4498 - val_acc: 0.9259\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2735 - acc: 1.0000 - val_loss: 0.3805 - val_acc: 0.9630\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.2433 - acc: 0.9718 - val_loss: 0.3264 - val_acc: 1.0000\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.2060 - acc: 0.9577 - val_loss: 0.2738 - val_acc: 0.8889\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.1696 - acc: 0.9155 - val_loss: 0.2232 - val_acc: 0.9630\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.1122 - acc: 1.0000 - val_loss: 0.1987 - val_acc: 0.9630\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0792 - acc: 1.0000 - val_loss: 0.3088 - val_acc: 0.8889\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0784 - acc: 0.9859 - val_loss: 0.1897 - val_acc: 0.9259\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0448 - acc: 1.0000 - val_loss: 0.2729 - val_acc: 0.9259\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0965 - acc: 1.0000 - val_loss: 0.2313 - val_acc: 0.9259\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0374 - acc: 1.0000 - val_loss: 1.1077 - val_acc: 0.8148\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0974 - acc: 0.9718 - val_loss: 0.1900 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0310 - acc: 1.0000 - val_loss: 0.2180 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0431 - acc: 1.0000 - val_loss: 0.2111 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0385 - acc: 1.0000 - val_loss: 0.1948 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0358 - acc: 1.0000 - val_loss: 0.1783 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0275 - acc: 1.0000 - val_loss: 0.1641 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0214 - acc: 1.0000 - val_loss: 0.1522 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.1429 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.1341 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.1269 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.1211 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.1165 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.1131 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1104 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1081 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.1060 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1044 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1030 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1018 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1008 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1000 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 9.2375e-04 - acc: 1.0000 - val_loss: 0.0992 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 5.6890e-04 - acc: 1.0000 - val_loss: 0.0985 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 8.6389e-04 - acc: 1.0000 - val_loss: 0.0980 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 8.0260e-04 - acc: 1.0000 - val_loss: 0.0976 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 7.7131e-04 - acc: 1.0000 - val_loss: 0.0972 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 6.7051e-04 - acc: 1.0000 - val_loss: 0.0968 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 6.5102e-04 - acc: 1.0000 - val_loss: 0.0965 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 6.7285e-04 - acc: 1.0000 - val_loss: 0.0963 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 5.3989e-04 - acc: 1.0000 - val_loss: 0.0961 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 4.9008e-04 - acc: 1.0000 - val_loss: 0.0959 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 5.4088e-04 - acc: 1.0000 - val_loss: 0.0957 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 5.9820e-04 - acc: 1.0000 - val_loss: 0.0955 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 4.4254e-04 - acc: 1.0000 - val_loss: 0.0952 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 4.6257e-04 - acc: 1.0000 - val_loss: 0.0949 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 6.8778e-04 - acc: 1.0000 - val_loss: 0.0944 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 4.6935e-04 - acc: 1.0000 - val_loss: 0.0939 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 4.5553e-04 - acc: 1.0000 - val_loss: 0.0934 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.5717e-04 - acc: 1.0000 - val_loss: 0.0930 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 4.8525e-04 - acc: 1.0000 - val_loss: 0.0925 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 3.9950e-04 - acc: 1.0000 - val_loss: 0.0922 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 4.0783e-04 - acc: 1.0000 - val_loss: 0.0918 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:56:45.573489: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:45.639401: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:45.646314: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 464ms/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 16:56:47.328120: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:47.516837: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:47.527939: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:47.811220: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:47.824347: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6079 - acc: 0.1831"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:56:48.774263: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:48.858603: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:48.865885: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 933ms/step - loss: 1.6079 - acc: 0.1831 - val_loss: 1.5036 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 1.4833 - acc: 0.3944 - val_loss: 1.4139 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 1.3836 - acc: 0.4085 - val_loss: 1.4214 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 1.3500 - acc: 0.3662 - val_loss: 1.3075 - val_acc: 0.3704\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 1.1865 - acc: 0.4507 - val_loss: 1.0935 - val_acc: 0.5185\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.9351 - acc: 0.6901 - val_loss: 1.0713 - val_acc: 0.5185\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.9359 - acc: 0.6338 - val_loss: 0.8352 - val_acc: 0.7037\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6560 - acc: 0.7887 - val_loss: 0.8550 - val_acc: 0.6667\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.6144 - acc: 0.7887 - val_loss: 0.7687 - val_acc: 0.8148\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.5815 - acc: 0.9014 - val_loss: 0.7024 - val_acc: 0.8519\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.5235 - acc: 0.9577 - val_loss: 0.6237 - val_acc: 0.9259\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.4493 - acc: 1.0000 - val_loss: 0.5986 - val_acc: 0.9259\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3884 - acc: 1.0000 - val_loss: 0.6313 - val_acc: 0.8148\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3470 - acc: 0.9718 - val_loss: 0.4955 - val_acc: 0.9259\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.2832 - acc: 1.0000 - val_loss: 0.3826 - val_acc: 0.9259\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.2329 - acc: 1.0000 - val_loss: 0.3272 - val_acc: 0.9259\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.1887 - acc: 1.0000 - val_loss: 0.2854 - val_acc: 0.9259\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.1539 - acc: 1.0000 - val_loss: 0.2499 - val_acc: 0.9259\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.1168 - acc: 1.0000 - val_loss: 0.2203 - val_acc: 0.9259\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0829 - acc: 1.0000 - val_loss: 0.2055 - val_acc: 0.9259\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0594 - acc: 1.0000 - val_loss: 0.2770 - val_acc: 0.9259\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0395 - acc: 1.0000 - val_loss: 0.3630 - val_acc: 0.8889\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0298 - acc: 1.0000 - val_loss: 0.1834 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0203 - acc: 1.0000 - val_loss: 0.1833 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0178 - acc: 1.0000 - val_loss: 0.2302 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.4328 - val_acc: 0.8889\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0183 - acc: 1.0000 - val_loss: 1.3583 - val_acc: 0.5926\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.3701 - acc: 0.8732 - val_loss: 0.5405 - val_acc: 0.7778\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.1470 - acc: 0.9437 - val_loss: 0.1409 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0179 - acc: 1.0000 - val_loss: 0.1369 - val_acc: 0.9630\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0285 - acc: 1.0000 - val_loss: 0.1109 - val_acc: 0.9630\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0233 - acc: 1.0000 - val_loss: 0.0940 - val_acc: 1.0000\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0178 - acc: 1.0000 - val_loss: 0.0882 - val_acc: 1.0000\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.0873 - val_acc: 1.0000\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.0878 - val_acc: 1.0000\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.0878 - val_acc: 1.0000\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.0876 - val_acc: 1.0000\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.0875 - val_acc: 1.0000\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.0872 - val_acc: 1.0000\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0867 - val_acc: 1.0000\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0856 - val_acc: 1.0000\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0852 - val_acc: 1.0000\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0849 - val_acc: 0.9630\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0847 - val_acc: 0.9630\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0843 - val_acc: 0.9630\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0839 - val_acc: 0.9630\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0835 - val_acc: 0.9630\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0830 - val_acc: 0.9630\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0824 - val_acc: 0.9630\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0819 - val_acc: 0.9630\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0816 - val_acc: 0.9630\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0813 - val_acc: 0.9630\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0810 - val_acc: 0.9630\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0807 - val_acc: 0.9630\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0805 - val_acc: 0.9630\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0804 - val_acc: 0.9630\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0804 - val_acc: 0.9630\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0804 - val_acc: 0.9630\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0804 - val_acc: 0.9630\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0806 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0806 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0804 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0803 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0803 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0802 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0801 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0802 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0804 - val_acc: 0.9259\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0804 - val_acc: 0.9259\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0804 - val_acc: 0.9259\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0804 - val_acc: 0.9259\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0805 - val_acc: 0.9259\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 8.8422e-04 - acc: 1.0000 - val_loss: 0.0806 - val_acc: 0.9259\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0808 - val_acc: 0.9259\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0810 - val_acc: 0.9259\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 9.6797e-04 - acc: 1.0000 - val_loss: 0.0813 - val_acc: 0.9259\n",
      "Epoch 77/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 9.4008e-04 - acc: 1.0000 - val_loss: 0.0817 - val_acc: 0.9259\n",
      "Epoch 78/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 9.9359e-04 - acc: 1.0000 - val_loss: 0.0822 - val_acc: 0.9259\n",
      "Epoch 79/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 9.7151e-04 - acc: 1.0000 - val_loss: 0.0827 - val_acc: 0.9259\n",
      "Epoch 80/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 9.4387e-04 - acc: 1.0000 - val_loss: 0.0833 - val_acc: 0.9259\n",
      "Epoch 81/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0838 - val_acc: 0.9259\n",
      "Epoch 82/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 9.4228e-04 - acc: 1.0000 - val_loss: 0.0844 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:56:58.864778: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:58.931335: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:56:58.938258: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 560ms/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 16:57:00.508084: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:00.700794: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:00.711600: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:01.018558: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:01.031812: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.5925 - acc: 0.2535"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:57:02.178267: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:02.257772: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:02.264785: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 1s/step - loss: 1.5925 - acc: 0.2535 - val_loss: 1.4637 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 1.4397 - acc: 0.3662 - val_loss: 1.3627 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 1.3470 - acc: 0.3803 - val_loss: 1.2596 - val_acc: 0.3704\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 1.1900 - acc: 0.5211 - val_loss: 1.0805 - val_acc: 0.7037\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.9678 - acc: 0.7746 - val_loss: 0.8800 - val_acc: 0.7778\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.7800 - acc: 0.8169 - val_loss: 0.7379 - val_acc: 0.6667\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.6062 - acc: 0.7887 - val_loss: 1.2301 - val_acc: 0.4444\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.7748 - acc: 0.6197 - val_loss: 0.5880 - val_acc: 0.8889\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.4221 - acc: 0.9296 - val_loss: 0.4891 - val_acc: 1.0000\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.3545 - acc: 1.0000 - val_loss: 0.5074 - val_acc: 0.8889\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.2873 - acc: 0.9859 - val_loss: 0.4530 - val_acc: 0.9259\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.2216 - acc: 1.0000 - val_loss: 0.2542 - val_acc: 1.0000\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.1549 - acc: 1.0000 - val_loss: 0.2348 - val_acc: 0.9259\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0881 - acc: 1.0000 - val_loss: 0.2596 - val_acc: 0.9259\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0617 - acc: 1.0000 - val_loss: 0.2402 - val_acc: 0.9259\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0419 - acc: 1.0000 - val_loss: 0.1784 - val_acc: 0.9259\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0217 - acc: 1.0000 - val_loss: 0.1335 - val_acc: 0.9259\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.0963 - val_acc: 0.9259\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0673 - val_acc: 0.9630\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0703 - val_acc: 0.9630\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0995 - val_acc: 0.9259\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.1344 - val_acc: 0.9259\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.1614 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1800 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1924 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.2007 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.2046 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2051 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.2040 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.2020 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1984 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1946 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 8.0237e-04 - acc: 1.0000 - val_loss: 0.1914 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 6.1984e-04 - acc: 1.0000 - val_loss: 0.1889 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 7.3033e-04 - acc: 1.0000 - val_loss: 0.1865 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 6.8740e-04 - acc: 1.0000 - val_loss: 0.1842 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 7.1463e-04 - acc: 1.0000 - val_loss: 0.1822 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 7.2709e-04 - acc: 1.0000 - val_loss: 0.1804 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 6.7479e-04 - acc: 1.0000 - val_loss: 0.1784 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 7.2082e-04 - acc: 1.0000 - val_loss: 0.1754 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 5.9206e-04 - acc: 1.0000 - val_loss: 0.1714 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 4.9498e-04 - acc: 1.0000 - val_loss: 0.1681 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 5.9740e-04 - acc: 1.0000 - val_loss: 0.1656 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 6.3083e-04 - acc: 1.0000 - val_loss: 0.1635 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 5.1820e-04 - acc: 1.0000 - val_loss: 0.1618 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 5.0401e-04 - acc: 1.0000 - val_loss: 0.1601 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 4.6494e-04 - acc: 1.0000 - val_loss: 0.1582 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 4.9115e-04 - acc: 1.0000 - val_loss: 0.1565 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 4.8792e-04 - acc: 1.0000 - val_loss: 0.1553 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 4.8401e-04 - acc: 1.0000 - val_loss: 0.1544 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 5.5993e-04 - acc: 1.0000 - val_loss: 0.1539 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 4.9022e-04 - acc: 1.0000 - val_loss: 0.1538 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 4.3366e-04 - acc: 1.0000 - val_loss: 0.1540 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 4.7520e-04 - acc: 1.0000 - val_loss: 0.1544 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 5.5695e-04 - acc: 1.0000 - val_loss: 0.1548 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.9435e-04 - acc: 1.0000 - val_loss: 0.1554 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 4.5422e-04 - acc: 1.0000 - val_loss: 0.1563 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 4.6234e-04 - acc: 1.0000 - val_loss: 0.1573 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 3.9101e-04 - acc: 1.0000 - val_loss: 0.1583 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:57:10.256562: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:10.321435: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:10.328448: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 468ms/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 16:57:12.042315: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:12.247018: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:12.257188: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:12.647476: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:12.660859: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6073 - acc: 0.1690"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:57:13.711689: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:13.795280: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:13.802162: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 1s/step - loss: 1.6073 - acc: 0.1690 - val_loss: 1.5448 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 1.5405 - acc: 0.3803 - val_loss: 1.4806 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 1.4486 - acc: 0.3662 - val_loss: 1.4400 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 1.3918 - acc: 0.3662 - val_loss: 1.5783 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 1.4817 - acc: 0.3944 - val_loss: 1.3175 - val_acc: 0.4815\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 1.2294 - acc: 0.6901 - val_loss: 1.2470 - val_acc: 0.6667\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.1308 - acc: 0.7887 - val_loss: 1.1621 - val_acc: 0.7778\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 1.0080 - acc: 0.7887 - val_loss: 1.2819 - val_acc: 0.4074\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.0051 - acc: 0.5211 - val_loss: 1.0209 - val_acc: 0.5926\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.7689 - acc: 0.7324 - val_loss: 0.9358 - val_acc: 0.6667\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.7104 - acc: 0.7606 - val_loss: 0.8419 - val_acc: 0.6667\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6357 - acc: 0.7887 - val_loss: 0.7629 - val_acc: 0.7037\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.5985 - acc: 0.8451 - val_loss: 0.7465 - val_acc: 0.6667\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.5174 - acc: 0.8169 - val_loss: 0.7925 - val_acc: 0.5926\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4532 - acc: 0.7746 - val_loss: 0.5426 - val_acc: 0.7037\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.3530 - acc: 0.8028 - val_loss: 0.4744 - val_acc: 0.7778\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3108 - acc: 0.8451 - val_loss: 0.4517 - val_acc: 0.7037\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.2816 - acc: 0.8732 - val_loss: 0.4290 - val_acc: 0.7407\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.2538 - acc: 0.9155 - val_loss: 0.3843 - val_acc: 0.9630\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.2363 - acc: 0.9718 - val_loss: 0.3581 - val_acc: 0.9630\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.2094 - acc: 0.9859 - val_loss: 0.3467 - val_acc: 0.8889\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.1683 - acc: 0.9859 - val_loss: 0.4276 - val_acc: 0.8889\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.1414 - acc: 0.9859 - val_loss: 0.3843 - val_acc: 0.8889\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0883 - acc: 0.9859 - val_loss: 0.3601 - val_acc: 0.8889\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0584 - acc: 1.0000 - val_loss: 0.3917 - val_acc: 0.8519\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0392 - acc: 1.0000 - val_loss: 0.3509 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.1116 - acc: 0.9859 - val_loss: 0.7326 - val_acc: 0.5926\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.3140 - acc: 0.8169 - val_loss: 0.5581 - val_acc: 0.7037\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.1948 - acc: 0.9014 - val_loss: 0.2948 - val_acc: 0.8889\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.4961 - acc: 0.9437 - val_loss: 0.2972 - val_acc: 0.8889\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.1050 - acc: 0.9859 - val_loss: 0.3050 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0914 - acc: 0.9718 - val_loss: 9.0948 - val_acc: 0.2593\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 7.2457 - acc: 0.3803 - val_loss: 0.9290 - val_acc: 0.6667\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.7047 - acc: 0.7042 - val_loss: 1.2802 - val_acc: 0.5556\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.0586 - acc: 0.6620 - val_loss: 1.0769 - val_acc: 0.7037\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.9448 - acc: 0.7042 - val_loss: 0.8082 - val_acc: 0.7037\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6865 - acc: 0.7324 - val_loss: 0.5689 - val_acc: 0.7037\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5448 - acc: 0.7465 - val_loss: 0.4030 - val_acc: 0.8889\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.3715 - acc: 0.9155 - val_loss: 0.3223 - val_acc: 0.9630\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.3036 - acc: 0.9577 - val_loss: 0.3007 - val_acc: 0.9630\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.2522 - acc: 0.9014 - val_loss: 0.3154 - val_acc: 0.8148\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.2106 - acc: 0.8873 - val_loss: 0.3394 - val_acc: 0.8148\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.1844 - acc: 0.9296 - val_loss: 0.3535 - val_acc: 0.8148\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.1821 - acc: 0.9155 - val_loss: 0.3361 - val_acc: 0.8519\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.1883 - acc: 0.9155 - val_loss: 0.2867 - val_acc: 0.9630\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.1275 - acc: 0.9859 - val_loss: 0.2517 - val_acc: 0.9630\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.1057 - acc: 1.0000 - val_loss: 0.2327 - val_acc: 0.9630\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0975 - acc: 1.0000 - val_loss: 0.2201 - val_acc: 0.9630\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0966 - acc: 1.0000 - val_loss: 0.2078 - val_acc: 0.9630\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0890 - acc: 1.0000 - val_loss: 0.1915 - val_acc: 0.9630\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0771 - acc: 1.0000 - val_loss: 0.1737 - val_acc: 0.9630\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0736 - acc: 1.0000 - val_loss: 0.1603 - val_acc: 0.9630\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0626 - acc: 1.0000 - val_loss: 0.1540 - val_acc: 0.9630\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0553 - acc: 1.0000 - val_loss: 0.1502 - val_acc: 0.9630\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0524 - acc: 1.0000 - val_loss: 0.1451 - val_acc: 0.9630\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0401 - acc: 1.0000 - val_loss: 0.1398 - val_acc: 0.9630\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0338 - acc: 1.0000 - val_loss: 0.1356 - val_acc: 0.9630\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0293 - acc: 1.0000 - val_loss: 0.1337 - val_acc: 0.9630\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0280 - acc: 1.0000 - val_loss: 0.1311 - val_acc: 0.9630\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0243 - acc: 1.0000 - val_loss: 0.1253 - val_acc: 0.9630\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0233 - acc: 1.0000 - val_loss: 0.1203 - val_acc: 0.9630\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0216 - acc: 1.0000 - val_loss: 0.1173 - val_acc: 0.9630\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0183 - acc: 1.0000 - val_loss: 0.1155 - val_acc: 0.9630\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0172 - acc: 1.0000 - val_loss: 0.1147 - val_acc: 0.9630\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0165 - acc: 1.0000 - val_loss: 0.1150 - val_acc: 0.9630\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.1160 - val_acc: 0.9630\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.1176 - val_acc: 0.9630\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0134 - acc: 1.0000 - val_loss: 0.1196 - val_acc: 0.9630\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.1223 - val_acc: 0.9630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:57:22.969301: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:23.037126: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:23.043929: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 496ms/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 16:57:24.789544: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:24.985401: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:24.996010: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:25.386678: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:25.399857: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6112 - acc: 0.1690"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:57:26.605531: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:26.692021: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:26.699006: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 1s/step - loss: 1.6112 - acc: 0.1690 - val_loss: 1.5313 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 253ms/step - loss: 1.5173 - acc: 0.4366 - val_loss: 1.4537 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 179ms/step - loss: 1.4158 - acc: 0.4366 - val_loss: 1.3481 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 1.2940 - acc: 0.5211 - val_loss: 1.2330 - val_acc: 0.5185\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 1.1335 - acc: 0.6620 - val_loss: 1.1276 - val_acc: 0.6296\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.9748 - acc: 0.7465 - val_loss: 1.6855 - val_acc: 0.2593\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.4435 - acc: 0.2958 - val_loss: 0.9898 - val_acc: 0.5556\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.7081 - acc: 0.7183 - val_loss: 0.9413 - val_acc: 0.5556\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.6865 - acc: 0.7606 - val_loss: 0.8147 - val_acc: 0.7037\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.6214 - acc: 0.7746 - val_loss: 0.6918 - val_acc: 0.7037\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.4521 - acc: 0.8169 - val_loss: 0.7821 - val_acc: 0.6296\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.5622 - acc: 0.7465 - val_loss: 0.6932 - val_acc: 0.7037\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.4253 - acc: 0.8451 - val_loss: 0.6824 - val_acc: 0.8889\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.4284 - acc: 0.9296 - val_loss: 0.6098 - val_acc: 0.8889\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.3678 - acc: 1.0000 - val_loss: 0.5412 - val_acc: 0.8889\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3135 - acc: 1.0000 - val_loss: 0.5813 - val_acc: 0.7037\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.2797 - acc: 0.9014 - val_loss: 0.4148 - val_acc: 0.9259\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.2193 - acc: 1.0000 - val_loss: 0.3476 - val_acc: 0.9259\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.1608 - acc: 1.0000 - val_loss: 0.3198 - val_acc: 0.9259\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.1109 - acc: 0.9859 - val_loss: 0.2213 - val_acc: 0.9259\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0782 - acc: 1.0000 - val_loss: 0.3175 - val_acc: 0.9259\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.1073 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.9259\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0965 - acc: 1.0000 - val_loss: 0.2279 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0579 - acc: 1.0000 - val_loss: 0.2030 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0379 - acc: 1.0000 - val_loss: 0.2061 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0254 - acc: 1.0000 - val_loss: 0.2304 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0194 - acc: 1.0000 - val_loss: 0.2597 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.2977 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.3387 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.3768 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.4137 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.4484 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.4789 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 8.9924e-04 - acc: 1.0000 - val_loss: 0.5046 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 8.4291e-04 - acc: 1.0000 - val_loss: 0.5267 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 6.5252e-04 - acc: 1.0000 - val_loss: 0.5458 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 6.1041e-04 - acc: 1.0000 - val_loss: 0.5620 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 4.8494e-04 - acc: 1.0000 - val_loss: 0.5761 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 4.8068e-04 - acc: 1.0000 - val_loss: 0.5879 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 5.4053e-04 - acc: 1.0000 - val_loss: 0.5977 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 4.5177e-04 - acc: 1.0000 - val_loss: 0.6058 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 4.3664e-04 - acc: 1.0000 - val_loss: 0.6125 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 2.6988e-04 - acc: 1.0000 - val_loss: 0.6181 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 2.9072e-04 - acc: 1.0000 - val_loss: 0.6228 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.6450e-04 - acc: 1.0000 - val_loss: 0.6266 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 3.5377e-04 - acc: 1.0000 - val_loss: 0.6296 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.0647e-04 - acc: 1.0000 - val_loss: 0.6321 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 2.3132e-04 - acc: 1.0000 - val_loss: 0.6343 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 2.4413e-04 - acc: 1.0000 - val_loss: 0.6361 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.1135e-04 - acc: 1.0000 - val_loss: 0.6375 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 2.3454e-04 - acc: 1.0000 - val_loss: 0.6386 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3.0166e-04 - acc: 1.0000 - val_loss: 0.6395 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 2.4313e-04 - acc: 1.0000 - val_loss: 0.6402 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 2.6482e-04 - acc: 1.0000 - val_loss: 0.6409 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 2.0858e-04 - acc: 1.0000 - val_loss: 0.6416 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 2.6980e-04 - acc: 1.0000 - val_loss: 0.6424 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 2.6814e-04 - acc: 1.0000 - val_loss: 0.6433 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 2.2071e-04 - acc: 1.0000 - val_loss: 0.6442 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.8655e-04 - acc: 1.0000 - val_loss: 0.6448 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 2.4259e-04 - acc: 1.0000 - val_loss: 0.6452 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 2.7662e-04 - acc: 1.0000 - val_loss: 0.6454 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.5371e-04 - acc: 1.0000 - val_loss: 0.6457 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 2.0214e-04 - acc: 1.0000 - val_loss: 0.6458 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.8911e-04 - acc: 1.0000 - val_loss: 0.6460 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 2.2335e-04 - acc: 1.0000 - val_loss: 0.6461 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.9726e-04 - acc: 1.0000 - val_loss: 0.6461 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.6691e-04 - acc: 1.0000 - val_loss: 0.6461 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:57:36.385411: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:36.454192: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:36.461094: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 511ms/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 16:57:38.187405: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:38.390675: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:38.401136: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:38.776520: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:38.793761: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6087 - acc: 0.2254"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:57:39.999723: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:40.089480: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:40.096557: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 1s/step - loss: 1.6087 - acc: 0.2254 - val_loss: 1.4978 - val_acc: 0.4815\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 263ms/step - loss: 1.4825 - acc: 0.5775 - val_loss: 1.3988 - val_acc: 0.5185\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 1.3464 - acc: 0.6056 - val_loss: 1.2863 - val_acc: 0.4815\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 1.2054 - acc: 0.5775 - val_loss: 1.1854 - val_acc: 0.4815\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 1.0250 - acc: 0.7042 - val_loss: 1.2015 - val_acc: 0.2963\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.9888 - acc: 0.5775 - val_loss: 0.8452 - val_acc: 0.6667\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.6710 - acc: 0.7887 - val_loss: 0.8643 - val_acc: 0.6296\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.5884 - acc: 0.7183 - val_loss: 0.6392 - val_acc: 0.8148\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.4440 - acc: 0.9577 - val_loss: 0.5404 - val_acc: 0.9630\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3856 - acc: 0.9718 - val_loss: 0.4482 - val_acc: 0.9630\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.2887 - acc: 1.0000 - val_loss: 0.3914 - val_acc: 0.8889\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.1867 - acc: 1.0000 - val_loss: 0.6047 - val_acc: 0.6667\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.3355 - acc: 0.8451 - val_loss: 0.2685 - val_acc: 1.0000\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.1441 - acc: 0.9859 - val_loss: 0.3698 - val_acc: 1.0000\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.2419 - acc: 1.0000 - val_loss: 0.3638 - val_acc: 0.9630\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.2233 - acc: 1.0000 - val_loss: 0.3287 - val_acc: 0.9259\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.1883 - acc: 1.0000 - val_loss: 0.3009 - val_acc: 0.9259\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.1316 - acc: 1.0000 - val_loss: 0.2917 - val_acc: 0.9259\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0909 - acc: 1.0000 - val_loss: 0.2963 - val_acc: 0.8889\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0706 - acc: 1.0000 - val_loss: 0.2490 - val_acc: 0.9259\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0538 - acc: 1.0000 - val_loss: 0.1859 - val_acc: 0.9259\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0447 - acc: 1.0000 - val_loss: 0.1420 - val_acc: 0.9630\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0618 - acc: 1.0000 - val_loss: 0.1725 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0283 - acc: 1.0000 - val_loss: 0.1978 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0247 - acc: 1.0000 - val_loss: 0.2095 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0165 - acc: 1.0000 - val_loss: 0.2195 - val_acc: 0.8889\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0161 - acc: 1.0000 - val_loss: 0.2256 - val_acc: 0.8889\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.2263 - val_acc: 0.8889\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.2234 - val_acc: 0.8889\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.2188 - val_acc: 0.8889\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.2126 - val_acc: 0.8889\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.2038 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.1928 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.1853 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.1801 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.1780 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.1803 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1868 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1970 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.2066 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.2136 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.2168 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.2162 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.2133 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.2090 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.2025 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 9.7094e-04 - acc: 1.0000 - val_loss: 0.1965 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 8.0024e-04 - acc: 1.0000 - val_loss: 0.1902 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1851 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 6.7917e-04 - acc: 1.0000 - val_loss: 0.1812 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 7.2427e-04 - acc: 1.0000 - val_loss: 0.1775 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 6.6814e-04 - acc: 1.0000 - val_loss: 0.1736 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 6.8470e-04 - acc: 1.0000 - val_loss: 0.1700 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 5.9057e-04 - acc: 1.0000 - val_loss: 0.1677 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 6.2781e-04 - acc: 1.0000 - val_loss: 0.1660 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 5.1235e-04 - acc: 1.0000 - val_loss: 0.1640 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 5.1760e-04 - acc: 1.0000 - val_loss: 0.1620 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 4.4940e-04 - acc: 1.0000 - val_loss: 0.1602 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 4.8183e-04 - acc: 1.0000 - val_loss: 0.1589 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 4.9058e-04 - acc: 1.0000 - val_loss: 0.1580 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 4.3442e-04 - acc: 1.0000 - val_loss: 0.1575 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 5.4376e-04 - acc: 1.0000 - val_loss: 0.1572 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 4.0998e-04 - acc: 1.0000 - val_loss: 0.1570 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:57:49.669542: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:49.753515: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:49.760500: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 524ms/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 16:57:51.494879: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:51.696606: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:51.707035: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:52.096951: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:52.109958: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.5990 - acc: 0.2535"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:57:53.349218: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:53.439677: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:57:53.447140: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 1s/step - loss: 1.5990 - acc: 0.2535 - val_loss: 1.4614 - val_acc: 0.4074\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 193ms/step - loss: 1.4301 - acc: 0.4789 - val_loss: 1.3514 - val_acc: 0.3704\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 215ms/step - loss: 1.3655 - acc: 0.4366 - val_loss: 1.2295 - val_acc: 0.4815\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 1.1194 - acc: 0.6620 - val_loss: 1.0062 - val_acc: 0.6667\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 0.8325 - acc: 0.8028 - val_loss: 0.9642 - val_acc: 0.6296\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.7473 - acc: 0.6761 - val_loss: 0.7566 - val_acc: 0.6667\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 171ms/step - loss: 0.5119 - acc: 0.7746 - val_loss: 1.1648 - val_acc: 0.5556\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 168ms/step - loss: 0.6992 - acc: 0.7042 - val_loss: 0.7572 - val_acc: 0.7037\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.5660 - acc: 0.8451 - val_loss: 0.5714 - val_acc: 0.9259\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.4020 - acc: 1.0000 - val_loss: 0.5522 - val_acc: 0.9259\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3549 - acc: 1.0000 - val_loss: 0.5284 - val_acc: 0.9259\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.3260 - acc: 1.0000 - val_loss: 0.4891 - val_acc: 0.9259\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2801 - acc: 1.0000 - val_loss: 0.4363 - val_acc: 0.9259\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.2266 - acc: 1.0000 - val_loss: 0.3770 - val_acc: 0.9259\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.1710 - acc: 1.0000 - val_loss: 0.3197 - val_acc: 0.9259\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.1289 - acc: 1.0000 - val_loss: 0.2733 - val_acc: 0.9259\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0990 - acc: 1.0000 - val_loss: 0.2360 - val_acc: 0.9259\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0695 - acc: 1.0000 - val_loss: 0.2075 - val_acc: 0.9259\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0453 - acc: 1.0000 - val_loss: 0.1925 - val_acc: 0.9259\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0362 - acc: 1.0000 - val_loss: 0.1958 - val_acc: 0.9259\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0235 - acc: 1.0000 - val_loss: 0.2161 - val_acc: 0.9259\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0157 - acc: 1.0000 - val_loss: 0.2374 - val_acc: 0.9259\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.2517 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.2558 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.2513 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.2449 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.2401 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.2353 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.2316 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.2279 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.2259 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.2256 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.2252 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.2231 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.2209 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 9.8843e-04 - acc: 1.0000 - val_loss: 0.2203 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 9.6943e-04 - acc: 1.0000 - val_loss: 0.2198 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2197 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 9.5186e-04 - acc: 1.0000 - val_loss: 0.2203 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 8.6085e-04 - acc: 1.0000 - val_loss: 0.2209 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 9.1234e-04 - acc: 1.0000 - val_loss: 0.2221 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 9.5135e-04 - acc: 1.0000 - val_loss: 0.2239 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 8.2625e-04 - acc: 1.0000 - val_loss: 0.2253 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 8.4116e-04 - acc: 1.0000 - val_loss: 0.2255 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 7.5585e-04 - acc: 1.0000 - val_loss: 0.2255 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 6.5661e-04 - acc: 1.0000 - val_loss: 0.2252 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 5.6163e-04 - acc: 1.0000 - val_loss: 0.2251 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 6.5864e-04 - acc: 1.0000 - val_loss: 0.2242 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 4.8347e-04 - acc: 1.0000 - val_loss: 0.2225 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 5.8172e-04 - acc: 1.0000 - val_loss: 0.2210 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 8.7224e-04 - acc: 1.0000 - val_loss: 0.2195 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 6.3932e-04 - acc: 1.0000 - val_loss: 0.2191 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 6.0775e-04 - acc: 1.0000 - val_loss: 0.2193 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 5.4571e-04 - acc: 1.0000 - val_loss: 0.2199 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 4.0795e-04 - acc: 1.0000 - val_loss: 0.2205 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 5.3596e-04 - acc: 1.0000 - val_loss: 0.2213 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 4.5339e-04 - acc: 1.0000 - val_loss: 0.2224 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 5.2820e-04 - acc: 1.0000 - val_loss: 0.2236 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 5.9057e-04 - acc: 1.0000 - val_loss: 0.2248 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:58:02.679768: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:02.749480: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:02.756485: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 647ms/step\n",
      "[BITULER:] Filename: ./BITULER-/eval_bituler-bilstm-100-1-0.5-100-64-1000-20-val_acc-0.001-['poi', 'tid', 'label'].csv.\n",
      "[BITULER:] Creating a model to test set\n",
      "[BITULER:] Parameters: nn_bilstm_un_100_st_1_dp_0.5_es_100_bs_64_epoch_1000_pat_20_mon_val_acc_lr_0.001_features_['poi', 'tid', 'label']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed59e086f8fc4f55ae524dc1369c8e8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Model Testing:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 16:58:04.365913: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:04.576299: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:04.588476: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:04.972738: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:04.985881: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6070 - acc: 0.2394"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:58:06.343389: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:06.433876: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:06.440644: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 1s/step - loss: 1.6070 - acc: 0.2394 - val_loss: 1.5771 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 239ms/step - loss: 1.5720 - acc: 0.4085 - val_loss: 1.5500 - val_acc: 0.4074\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 1.5387 - acc: 0.4930 - val_loss: 1.5203 - val_acc: 0.4074\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 193ms/step - loss: 1.5038 - acc: 0.5634 - val_loss: 1.4854 - val_acc: 0.4074\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 1.4566 - acc: 0.5211 - val_loss: 1.4428 - val_acc: 0.4074\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 200ms/step - loss: 1.4176 - acc: 0.4366 - val_loss: 1.3942 - val_acc: 0.4074\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 1.3464 - acc: 0.4366 - val_loss: 1.3500 - val_acc: 0.4074\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 1.3031 - acc: 0.4648 - val_loss: 1.3213 - val_acc: 0.4074\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 1.2522 - acc: 0.4648 - val_loss: 1.2914 - val_acc: 0.4074\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 1.0995 - acc: 0.5775 - val_loss: 1.2849 - val_acc: 0.5185\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.0675 - acc: 0.6056 - val_loss: 1.0660 - val_acc: 0.6296\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.8860 - acc: 0.7465 - val_loss: 0.9660 - val_acc: 0.6667\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.8110 - acc: 0.7606 - val_loss: 0.9636 - val_acc: 0.6667\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.7755 - acc: 0.7887 - val_loss: 0.8904 - val_acc: 0.7407\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6981 - acc: 0.8028 - val_loss: 0.8356 - val_acc: 0.6296\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6269 - acc: 0.8028 - val_loss: 0.8185 - val_acc: 0.6667\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.5925 - acc: 0.7887 - val_loss: 0.7873 - val_acc: 0.7037\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5322 - acc: 0.7887 - val_loss: 0.6960 - val_acc: 0.7037\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.4804 - acc: 0.8169 - val_loss: 0.6322 - val_acc: 0.7037\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4196 - acc: 0.8310 - val_loss: 0.5850 - val_acc: 0.7037\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3891 - acc: 0.8310 - val_loss: 0.5592 - val_acc: 0.7037\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.3569 - acc: 0.8592 - val_loss: 0.5429 - val_acc: 0.7407\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.3031 - acc: 0.8592 - val_loss: 0.4951 - val_acc: 0.8148\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.2719 - acc: 0.9296 - val_loss: 0.5035 - val_acc: 0.8889\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.2512 - acc: 0.9296 - val_loss: 0.4880 - val_acc: 0.8889\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.2242 - acc: 0.9718 - val_loss: 0.4911 - val_acc: 0.8889\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.1967 - acc: 0.9718 - val_loss: 0.5214 - val_acc: 0.8889\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.1988 - acc: 0.9718 - val_loss: 0.3827 - val_acc: 0.8889\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.1617 - acc: 0.9718 - val_loss: 0.5050 - val_acc: 0.8889\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.1570 - acc: 0.9859 - val_loss: 0.3820 - val_acc: 0.8889\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.1135 - acc: 1.0000 - val_loss: 0.5150 - val_acc: 0.8889\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.1126 - acc: 1.0000 - val_loss: 0.4589 - val_acc: 0.8148\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.1839 - acc: 0.9577 - val_loss: 0.4315 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0905 - acc: 1.0000 - val_loss: 0.4336 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.1195 - acc: 1.0000 - val_loss: 0.4143 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.0915 - acc: 0.9859 - val_loss: 0.4319 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0808 - acc: 0.9859 - val_loss: 0.4694 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0721 - acc: 1.0000 - val_loss: 0.5159 - val_acc: 0.8889\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0598 - acc: 0.9859 - val_loss: 0.3577 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0503 - acc: 1.0000 - val_loss: 0.2996 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0388 - acc: 1.0000 - val_loss: 0.2775 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0454 - acc: 1.0000 - val_loss: 0.2744 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0285 - acc: 1.0000 - val_loss: 0.3040 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0288 - acc: 1.0000 - val_loss: 0.3645 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0222 - acc: 1.0000 - val_loss: 0.4305 - val_acc: 0.8889\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0195 - acc: 1.0000 - val_loss: 0.4537 - val_acc: 0.8889\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0196 - acc: 1.0000 - val_loss: 0.4565 - val_acc: 0.8889\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.4599 - val_acc: 0.8889\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.4435 - val_acc: 0.8889\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.4399 - val_acc: 0.8889\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0142 - acc: 1.0000 - val_loss: 0.4418 - val_acc: 0.8889\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.4486 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.4611 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.4607 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.4585 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.4628 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.4794 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.5019 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.5083 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.4937 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.4684 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.4449 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.4248 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.4133 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.4046 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.3988 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.3947 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.3876 - val_acc: 0.9259\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.3816 - val_acc: 0.9259\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.3772 - val_acc: 0.9259\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.3718 - val_acc: 0.9259\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.3611 - val_acc: 0.9259\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.3490 - val_acc: 0.9259\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.3367 - val_acc: 0.9259\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.3262 - val_acc: 0.9259\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.3177 - val_acc: 0.9259\n",
      "Epoch 77/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.3119 - val_acc: 0.9259\n",
      "Epoch 78/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.3081 - val_acc: 0.9259\n",
      "Epoch 79/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.3055 - val_acc: 0.9259\n",
      "Epoch 80/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.3075 - val_acc: 0.9259\n",
      "Epoch 81/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.3141 - val_acc: 0.9259\n",
      "Epoch 82/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.3209 - val_acc: 0.9259\n",
      "Epoch 83/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.3266 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:58:17.292086: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:17.366367: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:17.373085: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 140ms/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 16:58:19.215091: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:19.416783: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:19.429342: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:19.815949: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:19.829044: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6095 - acc: 0.1690"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:58:21.068169: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:21.158408: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:21.165297: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 1s/step - loss: 1.6095 - acc: 0.1690 - val_loss: 1.5732 - val_acc: 0.3704\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 232ms/step - loss: 1.5702 - acc: 0.4507 - val_loss: 1.5435 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 191ms/step - loss: 1.5390 - acc: 0.3803 - val_loss: 1.5125 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 1.5027 - acc: 0.3803 - val_loss: 1.4768 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.4685 - acc: 0.3662 - val_loss: 1.4381 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 1.4194 - acc: 0.3662 - val_loss: 1.4001 - val_acc: 0.3333\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.3637 - acc: 0.3662 - val_loss: 1.3836 - val_acc: 0.3333\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 1.3280 - acc: 0.3662 - val_loss: 1.4027 - val_acc: 0.3333\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.2945 - acc: 0.3662 - val_loss: 1.3058 - val_acc: 0.3333\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 1.2224 - acc: 0.4225 - val_loss: 1.1870 - val_acc: 0.5185\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.0786 - acc: 0.6056 - val_loss: 1.1732 - val_acc: 0.5185\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 1.0615 - acc: 0.5775 - val_loss: 1.0779 - val_acc: 0.7037\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.9709 - acc: 0.7746 - val_loss: 0.9811 - val_acc: 0.7407\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.8639 - acc: 0.8028 - val_loss: 0.8786 - val_acc: 0.7407\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.7318 - acc: 0.8028 - val_loss: 0.7200 - val_acc: 0.7407\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5637 - acc: 0.8169 - val_loss: 0.6589 - val_acc: 0.6296\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.4671 - acc: 0.8451 - val_loss: 0.6230 - val_acc: 0.6667\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4404 - acc: 0.7887 - val_loss: 0.4995 - val_acc: 0.7407\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3675 - acc: 0.8310 - val_loss: 0.5272 - val_acc: 0.8519\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3425 - acc: 0.9155 - val_loss: 0.4372 - val_acc: 0.8519\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.2732 - acc: 0.9577 - val_loss: 0.3882 - val_acc: 0.8519\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.2505 - acc: 0.8732 - val_loss: 0.3572 - val_acc: 0.8519\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.1984 - acc: 0.9859 - val_loss: 0.4501 - val_acc: 0.8519\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.1854 - acc: 0.9577 - val_loss: 0.3495 - val_acc: 0.8889\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.1520 - acc: 0.9859 - val_loss: 0.3327 - val_acc: 0.8889\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.1640 - acc: 0.9718 - val_loss: 0.2620 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.1537 - acc: 0.9718 - val_loss: 0.3223 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.1572 - acc: 1.0000 - val_loss: 0.2795 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.1214 - acc: 1.0000 - val_loss: 0.2100 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0844 - acc: 1.0000 - val_loss: 0.1643 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0613 - acc: 1.0000 - val_loss: 0.2078 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0648 - acc: 1.0000 - val_loss: 0.2021 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0484 - acc: 1.0000 - val_loss: 0.1468 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0411 - acc: 1.0000 - val_loss: 0.1470 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0285 - acc: 1.0000 - val_loss: 0.1622 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0235 - acc: 1.0000 - val_loss: 0.1758 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0253 - acc: 1.0000 - val_loss: 0.1805 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.1791 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.1728 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0208 - acc: 1.0000 - val_loss: 0.1646 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0127 - acc: 1.0000 - val_loss: 0.1571 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.1496 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.1454 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.1491 - val_acc: 0.9630\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.1609 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.1686 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.1723 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.1583 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.1150 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0919 - val_acc: 0.9630\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0824 - val_acc: 0.9630\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0808 - val_acc: 0.9630\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0819 - val_acc: 0.9630\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0830 - val_acc: 0.9630\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0846 - val_acc: 0.9630\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0860 - val_acc: 0.9630\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0876 - val_acc: 0.9630\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0884 - val_acc: 0.9630\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0900 - val_acc: 0.9630\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0935 - val_acc: 0.9630\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9630\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.1101 - val_acc: 0.9630\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1236 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.1365 - val_acc: 0.8889\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.1505 - val_acc: 0.8889\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1654 - val_acc: 0.8889\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1774 - val_acc: 0.8889\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.1630 - val_acc: 0.8889\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.1338 - val_acc: 0.9259\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.1121 - val_acc: 0.9259\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0968 - val_acc: 0.9259\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0865 - val_acc: 0.9630\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0800 - val_acc: 0.9630\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9630\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0802 - val_acc: 0.9630\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0850 - val_acc: 0.9259\n",
      "Epoch 77/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0918 - val_acc: 0.9259\n",
      "Epoch 78/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0941 - val_acc: 0.9259\n",
      "Epoch 79/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0955 - val_acc: 0.9259\n",
      "Epoch 80/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0989 - val_acc: 0.9259\n",
      "Epoch 81/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.1015 - val_acc: 0.9259\n",
      "Epoch 82/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1023 - val_acc: 0.9259\n",
      "Epoch 83/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0994 - val_acc: 0.9259\n",
      "Epoch 84/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0954 - val_acc: 0.9259\n",
      "Epoch 85/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0962 - val_acc: 0.9259\n",
      "Epoch 86/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0980 - val_acc: 0.9259\n",
      "Epoch 87/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.1060 - val_acc: 0.9259\n",
      "Epoch 88/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.1192 - val_acc: 0.9259\n",
      "Epoch 89/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.1281 - val_acc: 0.9259\n",
      "Epoch 90/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.1422 - val_acc: 0.9259\n",
      "Epoch 91/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1580 - val_acc: 0.8889\n",
      "Epoch 92/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1747 - val_acc: 0.8889\n",
      "Epoch 93/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1941 - val_acc: 0.8889\n",
      "Epoch 94/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.2071 - val_acc: 0.8889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:58:32.944773: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:33.015176: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:33.021959: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 179ms/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 16:58:34.917978: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:35.118834: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:35.131835: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:35.514646: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:35.527877: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6017 - acc: 0.2958"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:58:36.762037: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:36.851332: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:36.858022: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 1s/step - loss: 1.6017 - acc: 0.2958 - val_loss: 1.5684 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 269ms/step - loss: 1.5627 - acc: 0.3944 - val_loss: 1.5362 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 236ms/step - loss: 1.5321 - acc: 0.3662 - val_loss: 1.5046 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 1.4908 - acc: 0.4085 - val_loss: 1.4725 - val_acc: 0.4074\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 1.4480 - acc: 0.4507 - val_loss: 1.4340 - val_acc: 0.4815\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 1.4091 - acc: 0.5211 - val_loss: 1.3816 - val_acc: 0.4815\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 1.3307 - acc: 0.5634 - val_loss: 1.3178 - val_acc: 0.4815\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 1.2698 - acc: 0.5634 - val_loss: 1.2666 - val_acc: 0.5185\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.1999 - acc: 0.5915 - val_loss: 1.2114 - val_acc: 0.5185\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 1.0958 - acc: 0.6056 - val_loss: 1.1105 - val_acc: 0.4815\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.9693 - acc: 0.6620 - val_loss: 1.1608 - val_acc: 0.3704\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.9795 - acc: 0.5915 - val_loss: 1.0014 - val_acc: 0.5926\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.8564 - acc: 0.7465 - val_loss: 0.8968 - val_acc: 0.6667\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.7631 - acc: 0.7746 - val_loss: 0.8769 - val_acc: 0.6296\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7287 - acc: 0.7324 - val_loss: 0.9245 - val_acc: 0.6667\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7455 - acc: 0.7606 - val_loss: 0.8269 - val_acc: 0.6667\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.6652 - acc: 0.7606 - val_loss: 0.7452 - val_acc: 0.6296\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5898 - acc: 0.8028 - val_loss: 0.7002 - val_acc: 0.6667\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.5394 - acc: 0.7746 - val_loss: 0.6737 - val_acc: 0.7037\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4987 - acc: 0.7746 - val_loss: 0.6306 - val_acc: 0.6667\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.4718 - acc: 0.7887 - val_loss: 0.5630 - val_acc: 0.7037\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.3723 - acc: 0.8169 - val_loss: 0.5214 - val_acc: 0.7037\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3369 - acc: 0.8592 - val_loss: 0.4975 - val_acc: 0.8148\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.3322 - acc: 0.8732 - val_loss: 0.4730 - val_acc: 0.8519\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.3031 - acc: 0.9155 - val_loss: 0.4432 - val_acc: 0.8519\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.2910 - acc: 0.9296 - val_loss: 0.4136 - val_acc: 0.8519\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.2551 - acc: 0.9437 - val_loss: 0.4026 - val_acc: 0.8889\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.2254 - acc: 0.9437 - val_loss: 0.4158 - val_acc: 0.8519\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.2192 - acc: 0.9437 - val_loss: 0.4022 - val_acc: 0.8889\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.2131 - acc: 0.9296 - val_loss: 0.3593 - val_acc: 0.8889\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.1914 - acc: 0.9859 - val_loss: 0.3183 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.1591 - acc: 1.0000 - val_loss: 0.3000 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.1501 - acc: 1.0000 - val_loss: 0.2950 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.1388 - acc: 1.0000 - val_loss: 0.3078 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.1328 - acc: 1.0000 - val_loss: 0.3421 - val_acc: 0.8889\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.1098 - acc: 1.0000 - val_loss: 0.3779 - val_acc: 0.8889\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.1003 - acc: 1.0000 - val_loss: 0.3160 - val_acc: 0.8889\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0877 - acc: 1.0000 - val_loss: 0.2266 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0775 - acc: 1.0000 - val_loss: 0.2013 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0624 - acc: 1.0000 - val_loss: 0.2088 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0541 - acc: 1.0000 - val_loss: 0.2253 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0467 - acc: 1.0000 - val_loss: 0.2644 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0496 - acc: 1.0000 - val_loss: 0.3219 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0362 - acc: 1.0000 - val_loss: 0.3903 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0345 - acc: 1.0000 - val_loss: 0.4160 - val_acc: 0.8889\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0255 - acc: 1.0000 - val_loss: 0.3604 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0262 - acc: 1.0000 - val_loss: 0.2826 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.1905 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0148 - acc: 1.0000 - val_loss: 0.0809 - val_acc: 0.9630\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.0430 - val_acc: 1.0000\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.0356 - val_acc: 1.0000\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.0308 - val_acc: 1.0000\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.0286 - val_acc: 1.0000\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0258 - val_acc: 1.0000\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0221 - val_acc: 1.0000\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0212 - val_acc: 1.0000\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0279 - val_acc: 1.0000\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0523 - val_acc: 0.9630\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0913 - val_acc: 0.9630\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.1289 - val_acc: 0.9630\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.1504 - val_acc: 0.9630\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.1705 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.1933 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.2051 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.1778 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.1589 - val_acc: 0.9630\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.1441 - val_acc: 0.9630\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.1350 - val_acc: 0.9630\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1318 - val_acc: 0.9630\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.1331 - val_acc: 0.9630\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.1376 - val_acc: 0.9630\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.1456 - val_acc: 0.9630\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1554 - val_acc: 0.9630\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.1675 - val_acc: 0.9259\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.1789 - val_acc: 0.9259\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.1877 - val_acc: 0.9259\n",
      "Epoch 77/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.1936 - val_acc: 0.9259\n",
      "Epoch 78/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1928 - val_acc: 0.9259\n",
      "Epoch 79/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1915 - val_acc: 0.9259\n",
      "Epoch 80/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.1627 - val_acc: 0.9630\n",
      "Epoch 81/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.1421 - val_acc: 0.9630\n",
      "Epoch 82/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1272 - val_acc: 0.9630\n",
      "Epoch 83/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1167 - val_acc: 0.9630\n",
      "Epoch 84/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1115 - val_acc: 0.9630\n",
      "Epoch 85/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1099 - val_acc: 0.9630\n",
      "Epoch 86/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1110 - val_acc: 0.9630\n",
      "Epoch 87/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1154 - val_acc: 0.9630\n",
      "Epoch 88/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1210 - val_acc: 0.9630\n",
      "Epoch 89/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1275 - val_acc: 0.9630\n",
      "Epoch 90/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1309 - val_acc: 0.9630\n",
      "Epoch 91/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1312 - val_acc: 0.9630\n",
      "Epoch 92/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1310 - val_acc: 0.9630\n",
      "Epoch 93/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1247 - val_acc: 0.9630\n",
      "Epoch 94/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1192 - val_acc: 0.9630\n",
      "Epoch 95/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1057 - val_acc: 0.9630\n",
      "Epoch 96/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0893 - val_acc: 0.9630\n",
      "Epoch 97/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0800 - val_acc: 0.9630\n",
      "Epoch 98/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0745 - val_acc: 0.9630\n",
      "Epoch 99/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0721 - val_acc: 0.9630\n",
      "Epoch 100/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0715 - val_acc: 0.9630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:58:49.382594: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:49.452601: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:49.459359: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 158ms/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 16:58:51.290113: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:51.487088: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:51.499822: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:51.881514: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:51.896255: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6100 - acc: 0.1127"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:58:53.113571: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:53.202095: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:58:53.208953: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 1s/step - loss: 1.6100 - acc: 0.1127 - val_loss: 1.5769 - val_acc: 0.3704\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 264ms/step - loss: 1.5739 - acc: 0.4507 - val_loss: 1.5492 - val_acc: 0.4074\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 1.5451 - acc: 0.4789 - val_loss: 1.5194 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 1.5067 - acc: 0.4225 - val_loss: 1.4855 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 1.4682 - acc: 0.3944 - val_loss: 1.4490 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 1.4129 - acc: 0.3803 - val_loss: 1.4181 - val_acc: 0.3333\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 1.3924 - acc: 0.3662 - val_loss: 1.4023 - val_acc: 0.3333\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 1.3428 - acc: 0.3803 - val_loss: 1.3697 - val_acc: 0.3333\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.2966 - acc: 0.3662 - val_loss: 1.2894 - val_acc: 0.3333\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.2044 - acc: 0.4648 - val_loss: 1.1980 - val_acc: 0.4815\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 1.0965 - acc: 0.6479 - val_loss: 1.1258 - val_acc: 0.6296\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.0154 - acc: 0.7324 - val_loss: 1.0248 - val_acc: 0.5926\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.8318 - acc: 0.7887 - val_loss: 1.0603 - val_acc: 0.5185\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.8007 - acc: 0.6620 - val_loss: 0.8235 - val_acc: 0.6667\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.6669 - acc: 0.8028 - val_loss: 0.7220 - val_acc: 0.7778\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.6173 - acc: 0.8028 - val_loss: 0.6872 - val_acc: 0.7778\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.5399 - acc: 0.8028 - val_loss: 0.5422 - val_acc: 0.8519\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3870 - acc: 0.9296 - val_loss: 0.5633 - val_acc: 0.8519\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.3564 - acc: 0.9155 - val_loss: 0.6990 - val_acc: 0.7407\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3602 - acc: 0.9014 - val_loss: 0.4575 - val_acc: 0.8889\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2529 - acc: 0.9577 - val_loss: 0.3959 - val_acc: 0.8889\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.2437 - acc: 1.0000 - val_loss: 0.3893 - val_acc: 0.9259\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.2443 - acc: 1.0000 - val_loss: 0.3532 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.2127 - acc: 1.0000 - val_loss: 0.2972 - val_acc: 0.9630\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.1779 - acc: 1.0000 - val_loss: 0.2457 - val_acc: 0.9630\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.1290 - acc: 1.0000 - val_loss: 0.2120 - val_acc: 0.9630\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.1198 - acc: 0.9859 - val_loss: 0.2080 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.1089 - acc: 0.9859 - val_loss: 0.3409 - val_acc: 0.8889\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0819 - acc: 1.0000 - val_loss: 0.5179 - val_acc: 0.8889\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0937 - acc: 1.0000 - val_loss: 0.3637 - val_acc: 0.8889\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0751 - acc: 1.0000 - val_loss: 0.2523 - val_acc: 0.8889\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0683 - acc: 1.0000 - val_loss: 0.2307 - val_acc: 0.8889\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0621 - acc: 1.0000 - val_loss: 0.2277 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0619 - acc: 1.0000 - val_loss: 0.2278 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0555 - acc: 1.0000 - val_loss: 0.2279 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0558 - acc: 1.0000 - val_loss: 0.2248 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0480 - acc: 1.0000 - val_loss: 0.2121 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0469 - acc: 1.0000 - val_loss: 0.1951 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0398 - acc: 1.0000 - val_loss: 0.1810 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0351 - acc: 1.0000 - val_loss: 0.1671 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0250 - acc: 1.0000 - val_loss: 0.1519 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0245 - acc: 1.0000 - val_loss: 0.1387 - val_acc: 0.9630\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0219 - acc: 1.0000 - val_loss: 0.1300 - val_acc: 0.9630\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0196 - acc: 1.0000 - val_loss: 0.1208 - val_acc: 0.9630\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0153 - acc: 1.0000 - val_loss: 0.1108 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.1069 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0194 - acc: 1.0000 - val_loss: 0.0946 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.0893 - val_acc: 0.9630\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.0926 - val_acc: 0.9630\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.1045 - val_acc: 0.9630\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.1257 - val_acc: 0.9630\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.1422 - val_acc: 0.9630\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.1619 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.1947 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.2244 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.2383 - val_acc: 0.8889\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.1967 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.1349 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.1001 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0823 - val_acc: 0.9630\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0752 - val_acc: 0.9630\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0718 - val_acc: 0.9630\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0716 - val_acc: 0.9630\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0746 - val_acc: 0.9630\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0804 - val_acc: 0.9630\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0878 - val_acc: 0.9630\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0975 - val_acc: 0.9630\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.1107 - val_acc: 0.9630\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1244 - val_acc: 0.9630\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.1255 - val_acc: 0.9630\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.1220 - val_acc: 0.9630\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1146 - val_acc: 0.9630\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0982 - val_acc: 0.9630\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0927 - val_acc: 0.9630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:59:03.207021: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:03.279031: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:03.285784: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 145ms/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 16:59:05.085371: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:05.289338: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:05.301956: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:05.678014: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:05.692532: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6031 - acc: 0.2254"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:59:06.958486: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:07.048514: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:07.056538: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 1s/step - loss: 1.6031 - acc: 0.2254 - val_loss: 1.5735 - val_acc: 0.3704\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 1.5692 - acc: 0.4366 - val_loss: 1.5429 - val_acc: 0.3704\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 1.5319 - acc: 0.4225 - val_loss: 1.5123 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 1.4948 - acc: 0.4085 - val_loss: 1.4829 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 1.4680 - acc: 0.3803 - val_loss: 1.4514 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 1.4258 - acc: 0.3944 - val_loss: 1.4118 - val_acc: 0.3333\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.3830 - acc: 0.4366 - val_loss: 1.3615 - val_acc: 0.3704\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 1.3230 - acc: 0.4648 - val_loss: 1.3027 - val_acc: 0.3704\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 1.2275 - acc: 0.4507 - val_loss: 1.2436 - val_acc: 0.4074\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 1.1250 - acc: 0.5493 - val_loss: 1.2321 - val_acc: 0.5185\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.0681 - acc: 0.6338 - val_loss: 1.1346 - val_acc: 0.4815\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.9741 - acc: 0.6056 - val_loss: 1.0017 - val_acc: 0.5556\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.8110 - acc: 0.6620 - val_loss: 0.8807 - val_acc: 0.6667\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6837 - acc: 0.7606 - val_loss: 0.8233 - val_acc: 0.6667\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6310 - acc: 0.7606 - val_loss: 0.7052 - val_acc: 0.7037\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5221 - acc: 0.8169 - val_loss: 0.6778 - val_acc: 0.7407\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4601 - acc: 0.8873 - val_loss: 0.5981 - val_acc: 0.7407\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3761 - acc: 0.8873 - val_loss: 0.5553 - val_acc: 0.8889\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.3171 - acc: 0.9437 - val_loss: 0.5348 - val_acc: 0.8889\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.3212 - acc: 0.9577 - val_loss: 0.4687 - val_acc: 0.8889\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.2786 - acc: 0.9577 - val_loss: 0.3953 - val_acc: 0.8889\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.2138 - acc: 0.9859 - val_loss: 0.3568 - val_acc: 0.9259\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.1859 - acc: 0.9718 - val_loss: 0.4013 - val_acc: 0.8889\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.1651 - acc: 0.9577 - val_loss: 0.5545 - val_acc: 0.8519\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.1949 - acc: 0.9437 - val_loss: 0.3747 - val_acc: 0.8889\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.1487 - acc: 0.9577 - val_loss: 0.3054 - val_acc: 0.8889\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.1292 - acc: 0.9718 - val_loss: 0.3058 - val_acc: 0.8889\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.1084 - acc: 1.0000 - val_loss: 0.3104 - val_acc: 0.8889\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.1013 - acc: 1.0000 - val_loss: 0.2993 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0960 - acc: 1.0000 - val_loss: 0.3062 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0877 - acc: 1.0000 - val_loss: 0.3415 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0799 - acc: 1.0000 - val_loss: 0.4355 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0639 - acc: 1.0000 - val_loss: 0.4621 - val_acc: 0.8889\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0630 - acc: 1.0000 - val_loss: 0.3875 - val_acc: 0.8889\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.0621 - acc: 1.0000 - val_loss: 0.3111 - val_acc: 0.8889\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0511 - acc: 1.0000 - val_loss: 0.3192 - val_acc: 0.8889\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0437 - acc: 1.0000 - val_loss: 0.3918 - val_acc: 0.8889\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0440 - acc: 1.0000 - val_loss: 0.4691 - val_acc: 0.8889\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0399 - acc: 1.0000 - val_loss: 0.5072 - val_acc: 0.8889\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0316 - acc: 1.0000 - val_loss: 0.5052 - val_acc: 0.8889\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0304 - acc: 1.0000 - val_loss: 0.4623 - val_acc: 0.8889\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0261 - acc: 1.0000 - val_loss: 0.4034 - val_acc: 0.8889\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0217 - acc: 1.0000 - val_loss: 0.3505 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0245 - acc: 1.0000 - val_loss: 0.3184 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0165 - acc: 1.0000 - val_loss: 0.3282 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0146 - acc: 1.0000 - val_loss: 0.3675 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0191 - acc: 1.0000 - val_loss: 0.3660 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.3735 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.3933 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.4241 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.4454 - val_acc: 0.8889\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.4530 - val_acc: 0.8889\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.4354 - val_acc: 0.8889\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.4347 - val_acc: 0.8889\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.4587 - val_acc: 0.8889\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4928 - val_acc: 0.8889\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.5158 - val_acc: 0.8889\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.5305 - val_acc: 0.8889\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.5505 - val_acc: 0.8889\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.5481 - val_acc: 0.8889\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.5411 - val_acc: 0.8889\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.5399 - val_acc: 0.8889\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.5153 - val_acc: 0.8889\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.4819 - val_acc: 0.8889\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.4465 - val_acc: 0.8889\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.4123 - val_acc: 0.8889\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.3885 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.3919 - val_acc: 0.9259\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.3943 - val_acc: 0.9259\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.4018 - val_acc: 0.9259\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.4087 - val_acc: 0.9259\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.4000 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:59:16.826913: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:16.899124: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:16.905839: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 151ms/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 16:59:18.755271: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:18.967303: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:18.980182: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:19.386466: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:19.399302: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6055 - acc: 0.2113"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:59:20.658793: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:20.749495: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:20.756260: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 4s 1s/step - loss: 1.6055 - acc: 0.2113 - val_loss: 1.5734 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 254ms/step - loss: 1.5727 - acc: 0.3944 - val_loss: 1.5467 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 1.5410 - acc: 0.3944 - val_loss: 1.5182 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 178ms/step - loss: 1.5105 - acc: 0.4085 - val_loss: 1.4852 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 182ms/step - loss: 1.4775 - acc: 0.3803 - val_loss: 1.4471 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 1.4374 - acc: 0.3662 - val_loss: 1.4086 - val_acc: 0.3333\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.3925 - acc: 0.3662 - val_loss: 1.3794 - val_acc: 0.3333\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 1.3151 - acc: 0.3662 - val_loss: 1.3439 - val_acc: 0.3333\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 1.2847 - acc: 0.4225 - val_loss: 1.2922 - val_acc: 0.4444\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.2337 - acc: 0.4648 - val_loss: 1.2305 - val_acc: 0.4815\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.1533 - acc: 0.5211 - val_loss: 1.1485 - val_acc: 0.4815\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.0098 - acc: 0.5775 - val_loss: 1.0195 - val_acc: 0.5185\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.8603 - acc: 0.6901 - val_loss: 0.8937 - val_acc: 0.6667\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.7180 - acc: 0.8028 - val_loss: 0.7963 - val_acc: 0.7037\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.6366 - acc: 0.8169 - val_loss: 0.7554 - val_acc: 0.7037\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.5587 - acc: 0.8592 - val_loss: 0.6558 - val_acc: 0.7778\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4879 - acc: 0.8028 - val_loss: 1.1144 - val_acc: 0.6667\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.6879 - acc: 0.7324 - val_loss: 0.4896 - val_acc: 0.7778\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3615 - acc: 0.8310 - val_loss: 0.5192 - val_acc: 0.8148\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3630 - acc: 0.8592 - val_loss: 0.5169 - val_acc: 0.9259\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3637 - acc: 0.9437 - val_loss: 0.4887 - val_acc: 0.9630\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3183 - acc: 1.0000 - val_loss: 0.3977 - val_acc: 0.9630\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.2693 - acc: 1.0000 - val_loss: 0.3558 - val_acc: 0.9630\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.2495 - acc: 0.9296 - val_loss: 0.3033 - val_acc: 0.9630\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2037 - acc: 0.9577 - val_loss: 0.2704 - val_acc: 0.9630\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.1648 - acc: 1.0000 - val_loss: 0.2558 - val_acc: 1.0000\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.1438 - acc: 1.0000 - val_loss: 0.2407 - val_acc: 0.9630\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.1194 - acc: 1.0000 - val_loss: 0.2256 - val_acc: 0.9630\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.1111 - acc: 1.0000 - val_loss: 0.2125 - val_acc: 0.9630\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.1005 - acc: 1.0000 - val_loss: 0.2076 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0726 - acc: 1.0000 - val_loss: 0.1980 - val_acc: 0.9630\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0702 - acc: 1.0000 - val_loss: 0.1841 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0490 - acc: 1.0000 - val_loss: 0.1674 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0396 - acc: 1.0000 - val_loss: 0.1481 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0379 - acc: 1.0000 - val_loss: 0.1320 - val_acc: 0.9630\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0319 - acc: 1.0000 - val_loss: 0.1228 - val_acc: 0.9630\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0270 - acc: 1.0000 - val_loss: 0.1172 - val_acc: 0.9630\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0237 - acc: 1.0000 - val_loss: 0.1160 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0222 - acc: 1.0000 - val_loss: 0.1216 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0265 - acc: 1.0000 - val_loss: 0.0938 - val_acc: 0.9630\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0182 - acc: 1.0000 - val_loss: 0.0806 - val_acc: 0.9630\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.0806 - val_acc: 0.9630\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.0802 - val_acc: 0.9630\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.0790 - val_acc: 0.9630\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.0763 - val_acc: 0.9630\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.0725 - val_acc: 0.9630\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0685 - val_acc: 0.9630\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0662 - val_acc: 0.9630\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9630\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.0665 - val_acc: 0.9630\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0691 - val_acc: 0.9630\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0731 - val_acc: 0.9630\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0750 - val_acc: 0.9630\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0754 - val_acc: 0.9630\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0758 - val_acc: 0.9630\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0774 - val_acc: 0.9630\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0805 - val_acc: 0.9630\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0829 - val_acc: 0.9630\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0851 - val_acc: 0.9630\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0866 - val_acc: 0.9630\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0879 - val_acc: 0.9630\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0881 - val_acc: 0.9630\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0881 - val_acc: 0.9630\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0880 - val_acc: 0.9630\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0877 - val_acc: 0.9630\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0874 - val_acc: 0.9630\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0867 - val_acc: 0.9630\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0856 - val_acc: 0.9630\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0841 - val_acc: 0.9630\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0817 - val_acc: 0.9630\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0794 - val_acc: 0.9630\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0774 - val_acc: 0.9630\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0760 - val_acc: 0.9630\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0751 - val_acc: 0.9630\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0742 - val_acc: 0.9630\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0732 - val_acc: 0.9630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:59:30.763947: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:30.834512: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:30.841269: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 160ms/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 16:59:32.682664: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:32.900523: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:32.913109: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:33.302863: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:33.316026: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6115 - acc: 0.2113"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:59:34.590706: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:34.679349: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:34.686245: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 4s 1s/step - loss: 1.6115 - acc: 0.2113 - val_loss: 1.5777 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 241ms/step - loss: 1.5759 - acc: 0.3944 - val_loss: 1.5484 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 1.5436 - acc: 0.3662 - val_loss: 1.5204 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 1.5113 - acc: 0.3662 - val_loss: 1.4907 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 1.4716 - acc: 0.3662 - val_loss: 1.4563 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 1.4271 - acc: 0.3662 - val_loss: 1.4167 - val_acc: 0.3333\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 1.4024 - acc: 0.3662 - val_loss: 1.3800 - val_acc: 0.3333\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 1.3626 - acc: 0.4085 - val_loss: 1.3416 - val_acc: 0.3333\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.2863 - acc: 0.4225 - val_loss: 1.2814 - val_acc: 0.4815\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.2081 - acc: 0.5493 - val_loss: 1.2089 - val_acc: 0.4815\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.1057 - acc: 0.6197 - val_loss: 1.1127 - val_acc: 0.5185\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.0067 - acc: 0.6620 - val_loss: 0.9970 - val_acc: 0.7407\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.8559 - acc: 0.7183 - val_loss: 0.9901 - val_acc: 0.7037\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.8207 - acc: 0.7183 - val_loss: 1.2187 - val_acc: 0.5185\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.8861 - acc: 0.6479 - val_loss: 0.9271 - val_acc: 0.7037\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7783 - acc: 0.7324 - val_loss: 0.7757 - val_acc: 0.7778\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.6141 - acc: 0.8169 - val_loss: 0.7009 - val_acc: 0.7037\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5392 - acc: 0.8732 - val_loss: 0.7021 - val_acc: 0.8519\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5176 - acc: 0.9155 - val_loss: 0.6855 - val_acc: 0.8148\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4859 - acc: 0.8732 - val_loss: 0.6431 - val_acc: 0.8519\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.4397 - acc: 0.9296 - val_loss: 0.5847 - val_acc: 0.8889\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.3985 - acc: 0.9577 - val_loss: 0.5287 - val_acc: 0.8889\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.3437 - acc: 0.9577 - val_loss: 0.4827 - val_acc: 0.8889\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3027 - acc: 0.9577 - val_loss: 0.4485 - val_acc: 0.8889\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.2588 - acc: 0.9859 - val_loss: 0.4328 - val_acc: 0.8889\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.2464 - acc: 0.9577 - val_loss: 0.3816 - val_acc: 0.8889\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.2112 - acc: 0.9718 - val_loss: 0.3297 - val_acc: 0.8889\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.1767 - acc: 1.0000 - val_loss: 0.3010 - val_acc: 0.8889\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.1606 - acc: 1.0000 - val_loss: 0.2800 - val_acc: 0.8889\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.1531 - acc: 1.0000 - val_loss: 0.2639 - val_acc: 0.8889\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.1268 - acc: 1.0000 - val_loss: 0.2647 - val_acc: 0.8889\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.1174 - acc: 1.0000 - val_loss: 0.2869 - val_acc: 0.8889\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0989 - acc: 0.9859 - val_loss: 0.3116 - val_acc: 0.8889\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0980 - acc: 0.9859 - val_loss: 0.3162 - val_acc: 0.8889\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0856 - acc: 1.0000 - val_loss: 0.2765 - val_acc: 0.8889\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0653 - acc: 1.0000 - val_loss: 0.2410 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0619 - acc: 1.0000 - val_loss: 0.2189 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0598 - acc: 1.0000 - val_loss: 0.2055 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0553 - acc: 1.0000 - val_loss: 0.1935 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0476 - acc: 1.0000 - val_loss: 0.1821 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0412 - acc: 1.0000 - val_loss: 0.1788 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0257 - acc: 1.0000 - val_loss: 0.1854 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0206 - acc: 1.0000 - val_loss: 0.1940 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0275 - acc: 1.0000 - val_loss: 0.2048 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0193 - acc: 1.0000 - val_loss: 0.1921 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0172 - acc: 1.0000 - val_loss: 0.1790 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0197 - acc: 1.0000 - val_loss: 0.1704 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0200 - acc: 1.0000 - val_loss: 0.1731 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0168 - acc: 1.0000 - val_loss: 0.1859 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.2047 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.2204 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.2328 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.2483 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.2681 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.2938 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.3137 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.2585 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.2351 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.2236 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.2197 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.2217 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.2255 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.2299 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.2315 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.2306 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.2284 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.2276 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.2300 - val_acc: 0.9259\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.2347 - val_acc: 0.9259\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.2415 - val_acc: 0.9259\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.2492 - val_acc: 0.9259\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.2582 - val_acc: 0.9259\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.2662 - val_acc: 0.9259\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.2728 - val_acc: 0.9259\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.2792 - val_acc: 0.9259\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.2829 - val_acc: 0.9259\n",
      "Epoch 77/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.2837 - val_acc: 0.9259\n",
      "Epoch 78/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.2837 - val_acc: 0.9259\n",
      "Epoch 79/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.2827 - val_acc: 0.9259\n",
      "Epoch 80/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.2798 - val_acc: 0.9259\n",
      "Epoch 81/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.2773 - val_acc: 0.9259\n",
      "Epoch 82/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.2760 - val_acc: 0.9259\n",
      "Epoch 83/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.2749 - val_acc: 0.9259\n",
      "Epoch 84/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.2738 - val_acc: 0.9259\n",
      "Epoch 85/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.2729 - val_acc: 0.9259\n",
      "Epoch 86/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.2732 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:59:45.676242: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:45.749647: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:45.756540: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 157ms/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 16:59:47.581934: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:47.788815: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:47.800486: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:48.234471: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:48.247617: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6103 - acc: 0.1268"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:59:49.472157: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:49.558621: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 16:59:49.565358: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 1s/step - loss: 1.6103 - acc: 0.1268 - val_loss: 1.5788 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 225ms/step - loss: 1.5739 - acc: 0.3803 - val_loss: 1.5501 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 1.5452 - acc: 0.4366 - val_loss: 1.5205 - val_acc: 0.4074\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 1.5006 - acc: 0.4930 - val_loss: 1.4874 - val_acc: 0.4074\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 1.4715 - acc: 0.4507 - val_loss: 1.4503 - val_acc: 0.4444\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 1.4297 - acc: 0.4648 - val_loss: 1.4095 - val_acc: 0.4444\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 1.3699 - acc: 0.4648 - val_loss: 1.3627 - val_acc: 0.4815\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 1.3274 - acc: 0.4789 - val_loss: 1.3136 - val_acc: 0.4444\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.2784 - acc: 0.5070 - val_loss: 1.2626 - val_acc: 0.4444\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.1898 - acc: 0.5070 - val_loss: 1.1704 - val_acc: 0.4815\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 1.0438 - acc: 0.5915 - val_loss: 1.1500 - val_acc: 0.5556\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.9924 - acc: 0.6056 - val_loss: 1.0280 - val_acc: 0.4815\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.8832 - acc: 0.6479 - val_loss: 1.0404 - val_acc: 0.5185\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.8983 - acc: 0.6479 - val_loss: 0.9076 - val_acc: 0.6296\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.7036 - acc: 0.7042 - val_loss: 0.7830 - val_acc: 0.6667\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6084 - acc: 0.7606 - val_loss: 0.7322 - val_acc: 0.6296\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.5356 - acc: 0.7606 - val_loss: 0.7079 - val_acc: 0.7037\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.4703 - acc: 0.8732 - val_loss: 0.5990 - val_acc: 0.8519\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4280 - acc: 0.8592 - val_loss: 0.5221 - val_acc: 0.8889\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3670 - acc: 0.8592 - val_loss: 0.4225 - val_acc: 0.8889\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.2865 - acc: 0.9437 - val_loss: 0.4711 - val_acc: 0.8148\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.2522 - acc: 0.9296 - val_loss: 0.6630 - val_acc: 0.7778\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.2818 - acc: 0.9014 - val_loss: 0.3820 - val_acc: 0.8519\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.1915 - acc: 0.9577 - val_loss: 0.2977 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.1602 - acc: 0.9577 - val_loss: 0.2573 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.1409 - acc: 0.9859 - val_loss: 0.2584 - val_acc: 0.8889\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.1308 - acc: 1.0000 - val_loss: 0.2775 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.1193 - acc: 1.0000 - val_loss: 0.2828 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.1033 - acc: 1.0000 - val_loss: 0.2746 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0885 - acc: 1.0000 - val_loss: 0.2622 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0708 - acc: 1.0000 - val_loss: 0.2551 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0614 - acc: 1.0000 - val_loss: 0.2547 - val_acc: 0.8889\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0460 - acc: 1.0000 - val_loss: 0.2531 - val_acc: 0.8889\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0383 - acc: 1.0000 - val_loss: 0.2311 - val_acc: 0.8889\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0324 - acc: 1.0000 - val_loss: 0.1969 - val_acc: 0.8889\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0288 - acc: 1.0000 - val_loss: 0.1714 - val_acc: 0.8889\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0224 - acc: 1.0000 - val_loss: 0.1604 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0185 - acc: 1.0000 - val_loss: 0.1649 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0178 - acc: 1.0000 - val_loss: 0.1783 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0173 - acc: 1.0000 - val_loss: 0.1939 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.2115 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.2261 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.2318 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.2326 - val_acc: 0.8889\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.2366 - val_acc: 0.8889\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.2492 - val_acc: 0.8889\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.2683 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.2807 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.2845 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.2842 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.2681 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.2226 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.1493 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.1008 - val_acc: 0.9630\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0977 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.1016 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.1413 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.1923 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.2285 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.2513 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.2670 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.2765 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.2822 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.2739 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.2296 - val_acc: 0.8889\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.1874 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.1796 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.2110 - val_acc: 0.8889\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.2956 - val_acc: 0.9259\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.3086 - val_acc: 0.9259\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.3002 - val_acc: 0.9259\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.2918 - val_acc: 0.9259\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.2839 - val_acc: 0.9259\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.2729 - val_acc: 0.9259\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.2485 - val_acc: 0.9259\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.2026 - val_acc: 0.9259\n",
      "Epoch 77/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.1567 - val_acc: 0.9259\n",
      "Epoch 78/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1354 - val_acc: 0.9630\n",
      "Epoch 79/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.1445 - val_acc: 0.9259\n",
      "Epoch 80/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1701 - val_acc: 0.8889\n",
      "Epoch 81/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.2052 - val_acc: 0.8889\n",
      "Epoch 82/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.2402 - val_acc: 0.8889\n",
      "Epoch 83/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.2710 - val_acc: 0.8889\n",
      "Epoch 84/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.2882 - val_acc: 0.8889\n",
      "Epoch 85/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.2971 - val_acc: 0.9259\n",
      "Epoch 86/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.3056 - val_acc: 0.9259\n",
      "Epoch 87/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.3074 - val_acc: 0.9259\n",
      "Epoch 88/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.3055 - val_acc: 0.9259\n",
      "Epoch 89/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.3001 - val_acc: 0.9259\n",
      "Epoch 90/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.2943 - val_acc: 0.9259\n",
      "Epoch 91/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.2903 - val_acc: 0.9259\n",
      "Epoch 92/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.2876 - val_acc: 0.9259\n",
      "Epoch 93/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.2860 - val_acc: 0.9259\n",
      "Epoch 94/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.2848 - val_acc: 0.8889\n",
      "Epoch 95/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.2842 - val_acc: 0.8889\n",
      "Epoch 96/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.2765 - val_acc: 0.8889\n",
      "Epoch 97/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.2706 - val_acc: 0.8889\n",
      "Epoch 98/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.2684 - val_acc: 0.8889\n",
      "Epoch 99/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.2639 - val_acc: 0.8889\n",
      "Epoch 100/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.2571 - val_acc: 0.8889\n",
      "Epoch 101/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.2472 - val_acc: 0.8889\n",
      "Epoch 102/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.2399 - val_acc: 0.8889\n",
      "Epoch 103/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.2337 - val_acc: 0.9259\n",
      "Epoch 104/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.2294 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:00:02.351737: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:02.423458: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:02.430358: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 169ms/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:00:04.233388: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:04.460302: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:04.470450: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:04.906588: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:04.919616: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6024 - acc: 0.2535"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:00:06.301685: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:06.397230: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:06.404092: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 4s 1s/step - loss: 1.6024 - acc: 0.2535 - val_loss: 1.5752 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 291ms/step - loss: 1.5741 - acc: 0.3803 - val_loss: 1.5506 - val_acc: 0.4074\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 1.5445 - acc: 0.4507 - val_loss: 1.5255 - val_acc: 0.4074\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 200ms/step - loss: 1.5137 - acc: 0.5211 - val_loss: 1.4963 - val_acc: 0.4074\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 1.4753 - acc: 0.5634 - val_loss: 1.4625 - val_acc: 0.4815\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 1.4317 - acc: 0.6197 - val_loss: 1.4211 - val_acc: 0.4815\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 1.3871 - acc: 0.5775 - val_loss: 1.3705 - val_acc: 0.4815\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 1.3125 - acc: 0.5634 - val_loss: 1.3265 - val_acc: 0.4444\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 202ms/step - loss: 1.2627 - acc: 0.5634 - val_loss: 1.3154 - val_acc: 0.4074\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 1.2202 - acc: 0.4789 - val_loss: 1.2401 - val_acc: 0.4815\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 1.1338 - acc: 0.6197 - val_loss: 1.1538 - val_acc: 0.5185\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.0035 - acc: 0.6197 - val_loss: 1.0300 - val_acc: 0.5926\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 0.8686 - acc: 0.6620 - val_loss: 0.8886 - val_acc: 0.6667\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.7223 - acc: 0.7887 - val_loss: 0.9048 - val_acc: 0.5926\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6532 - acc: 0.7606 - val_loss: 0.7935 - val_acc: 0.7037\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.6136 - acc: 0.7746 - val_loss: 0.8558 - val_acc: 0.5926\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5681 - acc: 0.7746 - val_loss: 0.6732 - val_acc: 0.8148\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4108 - acc: 0.8592 - val_loss: 0.5169 - val_acc: 0.8889\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.3489 - acc: 0.9296 - val_loss: 0.4774 - val_acc: 0.8889\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3523 - acc: 0.8873 - val_loss: 0.4086 - val_acc: 0.9259\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.2670 - acc: 0.9296 - val_loss: 0.4388 - val_acc: 0.8519\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.2326 - acc: 0.9437 - val_loss: 0.4304 - val_acc: 0.8519\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2058 - acc: 0.9437 - val_loss: 0.3356 - val_acc: 0.8519\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.1757 - acc: 0.9296 - val_loss: 0.2736 - val_acc: 0.8889\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.1497 - acc: 0.9577 - val_loss: 0.2425 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.1304 - acc: 0.9718 - val_loss: 0.2453 - val_acc: 0.9630\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.1384 - acc: 0.9577 - val_loss: 0.2481 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.1170 - acc: 0.9859 - val_loss: 0.2451 - val_acc: 0.8889\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0983 - acc: 0.9859 - val_loss: 0.2493 - val_acc: 0.8889\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0834 - acc: 1.0000 - val_loss: 0.2527 - val_acc: 0.8889\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0838 - acc: 1.0000 - val_loss: 0.2563 - val_acc: 0.8889\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0635 - acc: 1.0000 - val_loss: 0.2700 - val_acc: 0.8889\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0779 - acc: 1.0000 - val_loss: 0.2986 - val_acc: 0.8889\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0642 - acc: 1.0000 - val_loss: 0.3063 - val_acc: 0.8889\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0599 - acc: 1.0000 - val_loss: 0.2590 - val_acc: 0.8889\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0419 - acc: 1.0000 - val_loss: 0.2001 - val_acc: 0.8889\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0480 - acc: 1.0000 - val_loss: 0.1398 - val_acc: 0.9630\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0352 - acc: 1.0000 - val_loss: 0.0981 - val_acc: 0.9630\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0420 - acc: 1.0000 - val_loss: 0.0833 - val_acc: 0.9630\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0421 - acc: 1.0000 - val_loss: 0.0649 - val_acc: 1.0000\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0246 - acc: 1.0000 - val_loss: 0.1033 - val_acc: 0.9630\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0320 - acc: 1.0000 - val_loss: 0.1153 - val_acc: 0.9630\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0313 - acc: 1.0000 - val_loss: 0.1100 - val_acc: 0.9630\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0252 - acc: 1.0000 - val_loss: 0.1913 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0183 - acc: 1.0000 - val_loss: 0.5062 - val_acc: 0.8519\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0222 - acc: 1.0000 - val_loss: 0.1592 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.1569 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.1614 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0170 - acc: 1.0000 - val_loss: 0.1292 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.1101 - val_acc: 0.9630\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.0999 - val_acc: 0.9630\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.1334 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.1693 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.1308 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.0973 - val_acc: 0.9630\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.0809 - val_acc: 0.9630\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0831 - val_acc: 0.9630\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0893 - val_acc: 0.9630\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0948 - val_acc: 0.9630\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0853 - val_acc: 0.9630\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0784 - val_acc: 0.9630\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0716 - val_acc: 0.9630\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0657 - val_acc: 0.9630\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0606 - val_acc: 0.9630\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0574 - val_acc: 0.9630\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0566 - val_acc: 0.9630\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0565 - val_acc: 0.9630\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0577 - val_acc: 0.9630\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0591 - val_acc: 0.9630\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0638 - val_acc: 0.9630\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0706 - val_acc: 0.9630\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0746 - val_acc: 0.9630\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0842 - val_acc: 0.9630\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0899 - val_acc: 0.9630\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0959 - val_acc: 0.9630\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0952 - val_acc: 0.9630\n",
      "Epoch 77/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0990 - val_acc: 0.9630\n",
      "Epoch 78/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.1105 - val_acc: 0.9630\n",
      "Epoch 79/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.1254 - val_acc: 0.9630\n",
      "Epoch 80/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1418 - val_acc: 0.9259\n",
      "Epoch 81/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.1557 - val_acc: 0.9259\n",
      "Epoch 82/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.1563 - val_acc: 0.9259\n",
      "Epoch 83/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1536 - val_acc: 0.9259\n",
      "Epoch 84/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.1503 - val_acc: 0.9259\n",
      "Epoch 85/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1470 - val_acc: 0.9259\n",
      "Epoch 86/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1408 - val_acc: 0.9259\n",
      "Epoch 87/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1340 - val_acc: 0.9630\n",
      "Epoch 88/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.1309 - val_acc: 0.9259\n",
      "Epoch 89/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1293 - val_acc: 0.9259\n",
      "Epoch 90/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.1268 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:00:18.758829: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:18.846159: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:18.852905: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 192ms/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:00:20.858507: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:21.072372: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:21.082723: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:21.672011: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:21.684999: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6079 - acc: 0.1972"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:00:23.260122: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:23.354264: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:23.361215: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 4s 1s/step - loss: 1.6079 - acc: 0.1972 - val_loss: 1.5706 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 1.5640 - acc: 0.4225 - val_loss: 1.5411 - val_acc: 0.4074\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 1s 318ms/step - loss: 1.5345 - acc: 0.4648 - val_loss: 1.5080 - val_acc: 0.4815\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 1.4919 - acc: 0.5070 - val_loss: 1.4689 - val_acc: 0.4444\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 1.4557 - acc: 0.4789 - val_loss: 1.4306 - val_acc: 0.3704\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 1.4087 - acc: 0.4507 - val_loss: 1.4007 - val_acc: 0.3333\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 1.3667 - acc: 0.3944 - val_loss: 1.3707 - val_acc: 0.3333\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 1.3384 - acc: 0.3662 - val_loss: 1.3343 - val_acc: 0.3333\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 1.2744 - acc: 0.4085 - val_loss: 1.2784 - val_acc: 0.3333\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 1.2057 - acc: 0.4648 - val_loss: 1.1837 - val_acc: 0.4444\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.0656 - acc: 0.5775 - val_loss: 1.0868 - val_acc: 0.5185\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.9506 - acc: 0.6620 - val_loss: 1.0095 - val_acc: 0.6296\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.8153 - acc: 0.7042 - val_loss: 0.9117 - val_acc: 0.6296\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.7287 - acc: 0.7606 - val_loss: 0.7490 - val_acc: 0.7037\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.5872 - acc: 0.8028 - val_loss: 0.6996 - val_acc: 0.7778\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.5233 - acc: 0.8028 - val_loss: 0.5945 - val_acc: 0.7037\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.4416 - acc: 0.8169 - val_loss: 0.7184 - val_acc: 0.7407\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4087 - acc: 0.8873 - val_loss: 0.4842 - val_acc: 0.7778\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3339 - acc: 0.8592 - val_loss: 0.4160 - val_acc: 0.7778\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.3032 - acc: 0.8732 - val_loss: 0.3858 - val_acc: 0.9259\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.2654 - acc: 0.9014 - val_loss: 0.5348 - val_acc: 0.8889\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.2229 - acc: 0.9577 - val_loss: 0.5987 - val_acc: 0.8889\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.2176 - acc: 0.9577 - val_loss: 0.3310 - val_acc: 0.8889\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.1800 - acc: 0.9718 - val_loss: 0.2868 - val_acc: 0.8889\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.1575 - acc: 1.0000 - val_loss: 0.2836 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.1509 - acc: 1.0000 - val_loss: 0.2420 - val_acc: 0.8889\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.1113 - acc: 1.0000 - val_loss: 0.2510 - val_acc: 0.8889\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0996 - acc: 1.0000 - val_loss: 0.2849 - val_acc: 0.8889\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0864 - acc: 1.0000 - val_loss: 0.2858 - val_acc: 0.8889\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0744 - acc: 1.0000 - val_loss: 0.2648 - val_acc: 0.8889\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0572 - acc: 1.0000 - val_loss: 0.2542 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0474 - acc: 1.0000 - val_loss: 0.2448 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0388 - acc: 1.0000 - val_loss: 0.2335 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0271 - acc: 1.0000 - val_loss: 0.2222 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0173 - acc: 1.0000 - val_loss: 0.2033 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0226 - acc: 1.0000 - val_loss: 0.1821 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0269 - acc: 1.0000 - val_loss: 0.2616 - val_acc: 0.8519\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0247 - acc: 1.0000 - val_loss: 0.4088 - val_acc: 0.8519\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0212 - acc: 1.0000 - val_loss: 0.2430 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0225 - acc: 1.0000 - val_loss: 0.2545 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0293 - acc: 1.0000 - val_loss: 0.2541 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0176 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.3220 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.4120 - val_acc: 0.8889\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.4725 - val_acc: 0.8889\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.2082 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0207 - acc: 1.0000 - val_loss: 0.3277 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0638 - acc: 0.9859 - val_loss: 0.2673 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0436 - acc: 1.0000 - val_loss: 0.2076 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0207 - acc: 1.0000 - val_loss: 0.1741 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.1605 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0127 - acc: 1.0000 - val_loss: 0.1550 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.1525 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.1510 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.1498 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.1493 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.1494 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.1496 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.1503 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.1519 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.1544 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.1582 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.1630 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.1687 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.1754 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.1822 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.1889 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.1961 - val_acc: 0.9259\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.2031 - val_acc: 0.9259\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.2091 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:00:34.457533: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:34.536244: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:34.543132: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 200ms/step\n",
      "[BITULER:] Processing time: 340418.56799999997 milliseconds. Done.\n"
     ]
    }
   ],
   "source": [
    "result = BITULER(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>acc_top_K5</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.866667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.84697</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc  acc_top_K5  balanced_accuracy  precision_macro  recall_macro  \\\n",
       "0  0.866667           0           0.816667         0.916667      0.816667   \n",
       "\n",
       "   f1_macro  loss  \n",
       "0   0.84697  None  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.1.7. TULVAE\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matanalysis.methods import TULVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###########    DATA PREPARATION      ###########\n",
      "\n",
      "Creating a virtual grid without polygons\n",
      "...cell size by degree: 0.0002706929603721246\n",
      "...grid_size_lat_y:358586\n",
      "...grid_size_lon_x:1221516\n",
      "...A virtual grid was created\n",
      "\n",
      "Creating or updating index of the grid feature..\n",
      "\n",
      "...[1419,1419] indexes were created to lat and lon\n",
      "\n",
      "Creating or updating index of the grid feature..\n",
      "\n",
      "...[664,664] indexes were created to lat and lon\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964ef4cc96204c60bda4b1ca7438a179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute 'poi': 113 unique values\n",
      "Attribute 'tid': 71 unique values\n",
      "Total of attribute/value pairs: 184\n",
      "\n",
      "\n",
      "###########      DATA ENCODING        ###########\n",
      "\n",
      "Input total: 3\n",
      "... tid_0: 71\n",
      "... tid_1: 27\n",
      "... tid_2: 45\n",
      "col_name: ['poi', 'tid', 'label']...\n",
      "... num_classes: 5\n",
      "... max_lenght: 37\n",
      "Removing column tid of attr\n",
      "Removing column label of attr\n",
      "\n",
      "\n",
      "#####   Encoding string data to integer   ######\n",
      "   Encoding: poi\n",
      "\n",
      "\n",
      "###########      Generating y_train and y_test     ###########\n",
      "Label encoding on label y\n",
      "Input total: 3\n",
      "\n",
      "[TULVAE:] Building TULVAE Model\n",
      "[TULVAE:] Starting model training, 27 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff904b69e524c29a6bf32ac6c60718e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[TULVAE:] Model Training:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:00:37.812667: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:38.205132: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:38.214969: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:38.695725: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:38.706633: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:39.206797: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:39.219846: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:39.895560: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:39.911632: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6096 - acc: 0.2676"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:00:42.262776: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:42.413013: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:42.419813: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:42.772236: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:00:42.779102: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 3s/step - loss: 1.6096 - acc: 0.2676 - val_loss: 1.5941 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 1s 566ms/step - loss: 1.5930 - acc: 0.3803 - val_loss: 1.5786 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 1s 376ms/step - loss: 1.5747 - acc: 0.4225 - val_loss: 1.5649 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 1s 307ms/step - loss: 1.5568 - acc: 0.4225 - val_loss: 1.5274 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 1s 448ms/step - loss: 1.5160 - acc: 0.4085 - val_loss: 1.5003 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 1s 397ms/step - loss: 1.4546 - acc: 0.3380 - val_loss: 1.4835 - val_acc: 0.3333\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 236ms/step - loss: 1.4435 - acc: 0.3521 - val_loss: 1.4381 - val_acc: 0.3333\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 1.4296 - acc: 0.3803 - val_loss: 1.4190 - val_acc: 0.3333\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 1.3818 - acc: 0.3662 - val_loss: 1.3725 - val_acc: 0.3333\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 214ms/step - loss: 1.3540 - acc: 0.3803 - val_loss: 1.2625 - val_acc: 0.4074\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 225ms/step - loss: 1.1786 - acc: 0.5070 - val_loss: 1.1393 - val_acc: 0.5185\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 1.0087 - acc: 0.6338 - val_loss: 1.0286 - val_acc: 0.4815\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 0.9251 - acc: 0.6761 - val_loss: 0.9234 - val_acc: 0.5926\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.8437 - acc: 0.6620 - val_loss: 1.8027 - val_acc: 0.4444\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 1.2872 - acc: 0.5634 - val_loss: 1.0576 - val_acc: 0.5926\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.9330 - acc: 0.6197 - val_loss: 1.0880 - val_acc: 0.5185\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.9633 - acc: 0.6338 - val_loss: 0.8683 - val_acc: 0.7778\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.7826 - acc: 0.7606 - val_loss: 0.7949 - val_acc: 0.7778\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.7224 - acc: 0.7324 - val_loss: 0.7593 - val_acc: 0.7407\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.6934 - acc: 0.7887 - val_loss: 0.7486 - val_acc: 0.7407\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.6447 - acc: 0.8028 - val_loss: 0.7189 - val_acc: 0.7407\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.5723 - acc: 0.8028 - val_loss: 0.6819 - val_acc: 0.7407\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.5074 - acc: 0.8028 - val_loss: 0.6510 - val_acc: 0.7407\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.4861 - acc: 0.8028 - val_loss: 0.5997 - val_acc: 0.7407\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.4732 - acc: 0.8028 - val_loss: 0.5666 - val_acc: 0.7407\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.4094 - acc: 0.8028 - val_loss: 0.5286 - val_acc: 0.7407\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3793 - acc: 0.8028 - val_loss: 0.4976 - val_acc: 0.7407\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.3755 - acc: 0.8028 - val_loss: 0.4743 - val_acc: 0.7407\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3354 - acc: 0.8028 - val_loss: 0.4624 - val_acc: 0.7407\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3126 - acc: 0.8028 - val_loss: 0.4385 - val_acc: 0.7407\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3005 - acc: 0.8169 - val_loss: 0.4143 - val_acc: 0.7407\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2791 - acc: 0.8169 - val_loss: 0.3913 - val_acc: 0.7407\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.2497 - acc: 0.8451 - val_loss: 0.3759 - val_acc: 0.8519\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.2465 - acc: 0.9437 - val_loss: 0.3874 - val_acc: 0.8889\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.2298 - acc: 0.9014 - val_loss: 0.3544 - val_acc: 0.8889\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.2091 - acc: 0.9296 - val_loss: 0.3353 - val_acc: 0.8889\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.2060 - acc: 0.9577 - val_loss: 0.2991 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.1750 - acc: 0.9718 - val_loss: 0.2884 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.1711 - acc: 0.9859 - val_loss: 0.2710 - val_acc: 0.8889\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.1571 - acc: 0.9577 - val_loss: 0.2435 - val_acc: 0.8889\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.1136 - acc: 0.9859 - val_loss: 0.2775 - val_acc: 0.8889\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.1106 - acc: 0.9859 - val_loss: 0.2995 - val_acc: 0.8889\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0836 - acc: 0.9859 - val_loss: 0.3041 - val_acc: 0.8889\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.1104 - acc: 0.9577 - val_loss: 0.2630 - val_acc: 0.8889\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0778 - acc: 0.9859 - val_loss: 0.2952 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0829 - acc: 0.9859 - val_loss: 0.2090 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0469 - acc: 1.0000 - val_loss: 0.1849 - val_acc: 0.8889\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0481 - acc: 1.0000 - val_loss: 0.1584 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0347 - acc: 1.0000 - val_loss: 0.1981 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0170 - acc: 1.0000 - val_loss: 0.2174 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0212 - acc: 1.0000 - val_loss: 0.2620 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.2481 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.2688 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.3408 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.2697 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.2186 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.1680 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.1865 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.1209 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.1182 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.1758 - val_acc: 0.8889\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.1379 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1487 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.2111 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.2091 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.1749 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.2345 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.2722 - val_acc: 0.9259\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.2160 - val_acc: 0.9259\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.2156 - val_acc: 0.9259\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.2438 - val_acc: 0.9259\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.2184 - val_acc: 0.9259\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.2536 - val_acc: 0.9259\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.2018 - val_acc: 0.9259\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1150 - val_acc: 0.9259\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0749 - val_acc: 0.9259\n",
      "Epoch 77/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.1047 - val_acc: 0.9259\n",
      "Epoch 78/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.1560 - val_acc: 0.8889\n",
      "Epoch 79/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0152 - acc: 1.0000 - val_loss: 0.2805 - val_acc: 0.9259\n",
      "Epoch 80/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.3233 - val_acc: 0.9259\n",
      "Epoch 81/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.3619 - val_acc: 0.9259\n",
      "Epoch 82/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.3952 - val_acc: 0.9259\n",
      "Epoch 83/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.4153 - val_acc: 0.9259\n",
      "Epoch 84/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.4293 - val_acc: 0.9259\n",
      "Epoch 85/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.3974 - val_acc: 0.9259\n",
      "Epoch 86/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.3917 - val_acc: 0.9259\n",
      "Epoch 87/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.3742 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:01:00.284115: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:00.416270: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:00.423124: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:00.812008: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:00.818723: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:01:04.042569: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:04.446891: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:04.457549: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:04.957102: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:04.967961: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:05.498082: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:05.511556: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:06.216639: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:06.229962: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6067 - acc: 0.1972"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:01:08.699343: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:08.853739: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:08.860599: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:09.251194: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:09.257950: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 3s/step - loss: 1.6067 - acc: 0.1972 - val_loss: 1.5911 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 1s 549ms/step - loss: 1.5896 - acc: 0.3803 - val_loss: 1.5726 - val_acc: 0.3704\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 1s 526ms/step - loss: 1.5669 - acc: 0.4225 - val_loss: 1.5482 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 1s 535ms/step - loss: 1.5253 - acc: 0.3662 - val_loss: 1.5106 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 1s 386ms/step - loss: 1.4839 - acc: 0.3803 - val_loss: 1.4678 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 318ms/step - loss: 1.4488 - acc: 0.3662 - val_loss: 1.4289 - val_acc: 0.3333\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 1s 455ms/step - loss: 1.3535 - acc: 0.3944 - val_loss: 1.3746 - val_acc: 0.4444\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 1.3448 - acc: 0.4507 - val_loss: 1.3108 - val_acc: 0.4444\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 1.2168 - acc: 0.5634 - val_loss: 1.2193 - val_acc: 0.4815\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 235ms/step - loss: 1.0810 - acc: 0.5634 - val_loss: 1.0779 - val_acc: 0.5185\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.9523 - acc: 0.6479 - val_loss: 0.9242 - val_acc: 0.5556\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 0.8205 - acc: 0.6761 - val_loss: 0.8309 - val_acc: 0.7037\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.8087 - acc: 0.7465 - val_loss: 0.7415 - val_acc: 0.7778\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.6620 - acc: 0.7746 - val_loss: 0.6547 - val_acc: 0.7778\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.5397 - acc: 0.7887 - val_loss: 0.5423 - val_acc: 0.7407\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.4838 - acc: 0.8310 - val_loss: 0.4675 - val_acc: 0.8519\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3784 - acc: 0.8310 - val_loss: 0.4416 - val_acc: 0.7037\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.3261 - acc: 0.8028 - val_loss: 0.5243 - val_acc: 0.7037\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.3212 - acc: 0.8169 - val_loss: 0.5458 - val_acc: 0.7037\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2907 - acc: 0.8310 - val_loss: 0.3419 - val_acc: 0.7778\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.2836 - acc: 0.8169 - val_loss: 0.3892 - val_acc: 0.8148\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.3078 - acc: 0.8028 - val_loss: 0.3132 - val_acc: 1.0000\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.2185 - acc: 1.0000 - val_loss: 0.3098 - val_acc: 1.0000\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.1951 - acc: 1.0000 - val_loss: 0.3120 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.1923 - acc: 0.9859 - val_loss: 0.2922 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.1360 - acc: 0.9859 - val_loss: 0.2262 - val_acc: 0.9630\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.1019 - acc: 1.0000 - val_loss: 0.2002 - val_acc: 1.0000\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.1021 - acc: 1.0000 - val_loss: 0.1867 - val_acc: 0.9630\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0665 - acc: 1.0000 - val_loss: 0.1549 - val_acc: 1.0000\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0642 - acc: 1.0000 - val_loss: 0.1468 - val_acc: 0.9630\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0481 - acc: 1.0000 - val_loss: 0.1332 - val_acc: 0.9630\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.0387 - acc: 1.0000 - val_loss: 0.1435 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.1261 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.1236 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0173 - acc: 1.0000 - val_loss: 0.1205 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.1255 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.1315 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.1261 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.1158 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1312 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.1207 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.1238 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.1185 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.1265 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.1198 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1058 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1009 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1114 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1135 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1075 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.1184 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1085 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1113 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1010 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0986 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0991 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0948 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0999 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0984 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0981 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1048 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0913 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 7.7166e-04 - acc: 1.0000 - val_loss: 0.0975 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0989 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0946 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0953 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0919 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 9.9683e-04 - acc: 1.0000 - val_loss: 0.0980 - val_acc: 0.9259\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0988 - val_acc: 0.9259\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 9.9091e-04 - acc: 1.0000 - val_loss: 0.0984 - val_acc: 0.9259\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 9.6878e-04 - acc: 1.0000 - val_loss: 0.0994 - val_acc: 0.9259\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0970 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:01:25.341068: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:25.473554: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:25.480336: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:25.851156: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:25.858678: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:01:28.989165: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:29.369354: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:29.379590: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:29.878680: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:29.889715: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:30.428786: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:30.441952: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:31.203388: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:31.216537: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6073 - acc: 0.1972"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:01:33.680297: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:33.836988: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:33.843928: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:34.245796: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:34.252727: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 3s/step - loss: 1.6073 - acc: 0.1972 - val_loss: 1.5828 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 1s 508ms/step - loss: 1.5813 - acc: 0.3662 - val_loss: 1.5558 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 1s 587ms/step - loss: 1.5465 - acc: 0.3521 - val_loss: 1.5185 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 1s 478ms/step - loss: 1.5191 - acc: 0.3521 - val_loss: 1.4856 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 1s 309ms/step - loss: 1.4586 - acc: 0.3521 - val_loss: 1.4375 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 255ms/step - loss: 1.4088 - acc: 0.3662 - val_loss: 1.4051 - val_acc: 0.3333\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 1.3557 - acc: 0.3662 - val_loss: 1.3433 - val_acc: 0.3333\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 329ms/step - loss: 1.2952 - acc: 0.4085 - val_loss: 1.2696 - val_acc: 0.4815\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 257ms/step - loss: 1.2519 - acc: 0.5493 - val_loss: 1.1419 - val_acc: 0.5926\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 245ms/step - loss: 1.0316 - acc: 0.7324 - val_loss: 0.9792 - val_acc: 0.6296\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 298ms/step - loss: 0.9088 - acc: 0.7183 - val_loss: 0.8335 - val_acc: 0.7037\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 257ms/step - loss: 0.7366 - acc: 0.7042 - val_loss: 0.6285 - val_acc: 0.7407\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.5507 - acc: 0.8028 - val_loss: 0.5573 - val_acc: 0.7407\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.4746 - acc: 0.8028 - val_loss: 0.5415 - val_acc: 0.7407\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.4076 - acc: 0.8169 - val_loss: 0.4341 - val_acc: 0.8889\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.4189 - acc: 0.8310 - val_loss: 0.3714 - val_acc: 0.7778\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.2715 - acc: 0.9014 - val_loss: 0.3796 - val_acc: 0.7778\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2565 - acc: 0.9014 - val_loss: 0.3820 - val_acc: 0.8148\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.2211 - acc: 0.9155 - val_loss: 0.3719 - val_acc: 0.9259\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.1865 - acc: 0.9718 - val_loss: 0.3394 - val_acc: 0.9630\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.1799 - acc: 0.9859 - val_loss: 0.2993 - val_acc: 0.9630\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.1465 - acc: 1.0000 - val_loss: 0.2840 - val_acc: 0.9630\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.1390 - acc: 1.0000 - val_loss: 0.3265 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.1026 - acc: 1.0000 - val_loss: 0.4576 - val_acc: 0.8519\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0798 - acc: 1.0000 - val_loss: 0.3255 - val_acc: 0.8889\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0642 - acc: 1.0000 - val_loss: 0.2063 - val_acc: 0.9630\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0734 - acc: 0.9859 - val_loss: 0.1798 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.0469 - acc: 1.0000 - val_loss: 0.1526 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.0451 - acc: 1.0000 - val_loss: 0.1606 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0247 - acc: 1.0000 - val_loss: 0.1487 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0181 - acc: 1.0000 - val_loss: 0.1231 - val_acc: 0.9630\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.1517 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.1736 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.2076 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.2350 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.2286 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.2258 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.2410 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.2289 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.2264 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.2168 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.2351 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.2393 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.2342 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2093 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2131 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.2412 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.2383 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2470 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.2465 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.2034 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 8.3892e-04 - acc: 1.0000 - val_loss: 0.1777 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 6.7859e-04 - acc: 1.0000 - val_loss: 0.1609 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1502 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1562 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 8.5104e-04 - acc: 1.0000 - val_loss: 0.1559 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 7.3611e-04 - acc: 1.0000 - val_loss: 0.1682 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 6.7568e-04 - acc: 1.0000 - val_loss: 0.1790 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 4.0148e-04 - acc: 1.0000 - val_loss: 0.1901 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.2569 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.3096 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 4.3005e-04 - acc: 1.0000 - val_loss: 0.3699 - val_acc: 0.8889\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.3314 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 7.5641e-04 - acc: 1.0000 - val_loss: 0.2861 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 5.1265e-04 - acc: 1.0000 - val_loss: 0.2466 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 3.2618e-04 - acc: 1.0000 - val_loss: 0.1997 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 4.4479e-04 - acc: 1.0000 - val_loss: 0.2036 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 5.5142e-04 - acc: 1.0000 - val_loss: 0.2080 - val_acc: 0.9259\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 5.0645e-04 - acc: 1.0000 - val_loss: 0.1736 - val_acc: 0.9259\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 5.1412e-04 - acc: 1.0000 - val_loss: 0.1856 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:01:50.177032: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:50.311730: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:50.318607: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:50.725627: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:50.732609: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:01:54.091203: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:54.496641: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:54.506893: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:55.009180: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:55.019850: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:55.563523: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:55.576540: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:56.288314: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:56.301853: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6069 - acc: 0.2958"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:01:58.746225: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:58.914345: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:58.921408: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:59.313570: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:01:59.320492: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 3s/step - loss: 1.6069 - acc: 0.2958 - val_loss: 1.5881 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 1.5838 - acc: 0.3521 - val_loss: 1.5664 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 1s 504ms/step - loss: 1.5582 - acc: 0.4507 - val_loss: 1.5472 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 1.5406 - acc: 0.3380 - val_loss: 1.4971 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 1s 318ms/step - loss: 1.4971 - acc: 0.4366 - val_loss: 1.4759 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 1s 262ms/step - loss: 1.4336 - acc: 0.3521 - val_loss: 1.4222 - val_acc: 0.3333\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 1s 419ms/step - loss: 1.4046 - acc: 0.3521 - val_loss: 1.3608 - val_acc: 0.3333\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 214ms/step - loss: 1.3478 - acc: 0.3521 - val_loss: 1.3144 - val_acc: 0.3333\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 230ms/step - loss: 1.2313 - acc: 0.4507 - val_loss: 1.1907 - val_acc: 0.5556\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 1.1564 - acc: 0.6197 - val_loss: 1.1038 - val_acc: 0.7037\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 1.0459 - acc: 0.6761 - val_loss: 0.9736 - val_acc: 0.7037\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.9048 - acc: 0.7324 - val_loss: 0.8678 - val_acc: 0.6296\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 179ms/step - loss: 0.7767 - acc: 0.7042 - val_loss: 0.6850 - val_acc: 0.7407\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.6541 - acc: 0.8169 - val_loss: 0.7086 - val_acc: 0.7778\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.6809 - acc: 0.8169 - val_loss: 0.5345 - val_acc: 0.8148\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 0.4411 - acc: 0.8592 - val_loss: 0.5554 - val_acc: 0.7407\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.4606 - acc: 0.7746 - val_loss: 0.3877 - val_acc: 0.8148\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.2923 - acc: 0.8732 - val_loss: 0.3303 - val_acc: 0.8148\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.2881 - acc: 0.8732 - val_loss: 0.3105 - val_acc: 0.9259\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.2391 - acc: 0.9014 - val_loss: 0.3370 - val_acc: 0.8519\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.2691 - acc: 0.8732 - val_loss: 0.3751 - val_acc: 0.8519\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.2139 - acc: 0.8873 - val_loss: 0.3187 - val_acc: 0.8148\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.2046 - acc: 0.8873 - val_loss: 0.2485 - val_acc: 1.0000\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.1605 - acc: 0.9859 - val_loss: 0.1474 - val_acc: 1.0000\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.1414 - acc: 0.9859 - val_loss: 0.1246 - val_acc: 1.0000\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.1000 - acc: 1.0000 - val_loss: 0.1851 - val_acc: 1.0000\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0922 - acc: 1.0000 - val_loss: 0.2244 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.1085 - acc: 0.9859 - val_loss: 0.2151 - val_acc: 0.8889\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.1070 - acc: 0.9859 - val_loss: 0.2198 - val_acc: 0.8889\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.1066 - acc: 0.9718 - val_loss: 0.1841 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0716 - acc: 0.9859 - val_loss: 0.1722 - val_acc: 0.9630\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0525 - acc: 1.0000 - val_loss: 0.1473 - val_acc: 0.9630\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0354 - acc: 1.0000 - val_loss: 0.1144 - val_acc: 1.0000\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0329 - acc: 1.0000 - val_loss: 0.1067 - val_acc: 1.0000\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.0226 - acc: 1.0000 - val_loss: 0.0990 - val_acc: 0.9630\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.0934 - val_acc: 1.0000\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.0936 - val_acc: 0.9630\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0205 - acc: 1.0000 - val_loss: 0.0848 - val_acc: 0.9630\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.1021 - val_acc: 0.9630\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.0840 - val_acc: 0.9630\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.0768 - val_acc: 0.9630\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.0723 - val_acc: 0.9630\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.0984 - val_acc: 0.9630\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0747 - val_acc: 0.9630\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0760 - val_acc: 0.9630\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0735 - val_acc: 0.9630\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0917 - val_acc: 0.9630\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0725 - val_acc: 0.9630\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.0743 - val_acc: 0.9630\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0919 - val_acc: 0.9630\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0746 - val_acc: 1.0000\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0596 - val_acc: 1.0000\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0875 - val_acc: 0.9630\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0752 - val_acc: 0.9630\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0646 - val_acc: 1.0000\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0627 - val_acc: 0.9630\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0716 - val_acc: 1.0000\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0546 - val_acc: 1.0000\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0624 - val_acc: 0.9630\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0765 - val_acc: 0.9630\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0705 - val_acc: 1.0000\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0709 - val_acc: 0.9630\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0722 - val_acc: 1.0000\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0477 - val_acc: 1.0000\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0795 - val_acc: 0.9630\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0563 - val_acc: 1.0000\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0681 - val_acc: 1.0000\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0729 - val_acc: 0.9630\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0354 - val_acc: 1.0000\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0660 - val_acc: 1.0000\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0409 - val_acc: 1.0000\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0522 - val_acc: 1.0000\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0535 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:02:15.783692: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:15.915856: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:15.922695: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:16.313535: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:16.320431: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:02:19.617686: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:20.013940: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:20.024968: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:20.505549: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:20.516353: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:21.097889: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:21.111205: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:21.843909: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:21.857288: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6013 - acc: 0.3521"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:02:24.345640: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:24.517292: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:24.524426: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:24.957588: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:24.964326: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 3s/step - loss: 1.6013 - acc: 0.3521 - val_loss: 1.5754 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 1s 651ms/step - loss: 1.5694 - acc: 0.4789 - val_loss: 1.5435 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 1s 416ms/step - loss: 1.5386 - acc: 0.3803 - val_loss: 1.5014 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 1s 411ms/step - loss: 1.4804 - acc: 0.3662 - val_loss: 1.4635 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 1s 406ms/step - loss: 1.4148 - acc: 0.3944 - val_loss: 1.4340 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 1.4204 - acc: 0.3662 - val_loss: 1.4097 - val_acc: 0.3333\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 264ms/step - loss: 1.3849 - acc: 0.3803 - val_loss: 1.4167 - val_acc: 0.3333\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 169ms/step - loss: 1.3308 - acc: 0.3662 - val_loss: 1.2901 - val_acc: 0.3333\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 224ms/step - loss: 1.1989 - acc: 0.3521 - val_loss: 1.1375 - val_acc: 0.4444\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 1s 395ms/step - loss: 1.0972 - acc: 0.5070 - val_loss: 1.0253 - val_acc: 0.6667\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.9481 - acc: 0.7324 - val_loss: 0.8348 - val_acc: 0.7037\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 259ms/step - loss: 0.6796 - acc: 0.8169 - val_loss: 0.7556 - val_acc: 0.6667\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 0.5383 - acc: 0.8310 - val_loss: 0.4985 - val_acc: 0.8519\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.4283 - acc: 0.8732 - val_loss: 0.4632 - val_acc: 0.8519\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 303ms/step - loss: 0.3644 - acc: 0.8732 - val_loss: 0.3742 - val_acc: 1.0000\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.2576 - acc: 0.9718 - val_loss: 0.3523 - val_acc: 0.9259\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 0.2210 - acc: 0.9014 - val_loss: 0.3519 - val_acc: 0.9259\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.2190 - acc: 0.9296 - val_loss: 0.3418 - val_acc: 0.9259\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.1812 - acc: 0.9859 - val_loss: 0.3077 - val_acc: 0.9259\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.1289 - acc: 1.0000 - val_loss: 0.2938 - val_acc: 0.9259\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.1195 - acc: 1.0000 - val_loss: 0.2567 - val_acc: 0.9259\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.1148 - acc: 0.9859 - val_loss: 0.2183 - val_acc: 0.9259\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0743 - acc: 1.0000 - val_loss: 0.1992 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.0770 - acc: 1.0000 - val_loss: 0.1590 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0580 - acc: 1.0000 - val_loss: 0.1571 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0480 - acc: 1.0000 - val_loss: 0.1827 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.0300 - acc: 1.0000 - val_loss: 0.2262 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.0233 - acc: 1.0000 - val_loss: 0.2200 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.2216 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.1957 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.1991 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.1837 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.1895 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1931 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.1314 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.1111 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1316 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 9.5398e-04 - acc: 1.0000 - val_loss: 0.1296 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1018 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1246 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1268 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1278 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1369 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1331 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1493 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 7.6699e-04 - acc: 1.0000 - val_loss: 0.1088 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1158 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 8.0261e-04 - acc: 1.0000 - val_loss: 0.1075 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 7.2507e-04 - acc: 1.0000 - val_loss: 0.1142 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 6.9226e-04 - acc: 1.0000 - val_loss: 0.0925 - val_acc: 0.9630\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 7.2485e-04 - acc: 1.0000 - val_loss: 0.0996 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 8.2389e-04 - acc: 1.0000 - val_loss: 0.1081 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 6.9563e-04 - acc: 1.0000 - val_loss: 0.1161 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 8.6406e-04 - acc: 1.0000 - val_loss: 0.0881 - val_acc: 0.9630\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 5.2239e-04 - acc: 1.0000 - val_loss: 0.1168 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 6.6739e-04 - acc: 1.0000 - val_loss: 0.1196 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 5.2121e-04 - acc: 1.0000 - val_loss: 0.0940 - val_acc: 0.9630\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 6.7659e-04 - acc: 1.0000 - val_loss: 0.0948 - val_acc: 0.9630\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 6.4225e-04 - acc: 1.0000 - val_loss: 0.1098 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 7.2053e-04 - acc: 1.0000 - val_loss: 0.1263 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1168 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 7.2318e-04 - acc: 1.0000 - val_loss: 0.0770 - val_acc: 0.9630\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 6.3620e-04 - acc: 1.0000 - val_loss: 0.0864 - val_acc: 0.9630\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 5.1612e-04 - acc: 1.0000 - val_loss: 0.0973 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 6.3296e-04 - acc: 1.0000 - val_loss: 0.1047 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:02:40.751344: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:40.893012: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:40.899804: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:41.310086: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:41.317040: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:02:44.649414: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:45.076258: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:45.087255: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:45.599238: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:45.610366: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:46.163987: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:46.177184: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:46.928040: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:46.941508: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6044 - acc: 0.2535"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:02:49.531627: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:49.699213: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:49.706063: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:50.158149: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:02:50.164948: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 3s/step - loss: 1.6044 - acc: 0.2535 - val_loss: 1.5749 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 1s 526ms/step - loss: 1.5789 - acc: 0.3944 - val_loss: 1.5441 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 1s 621ms/step - loss: 1.5260 - acc: 0.4648 - val_loss: 1.4972 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 1s 375ms/step - loss: 1.4959 - acc: 0.3662 - val_loss: 1.4650 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 1s 315ms/step - loss: 1.4095 - acc: 0.3944 - val_loss: 1.4198 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 346ms/step - loss: 1.4139 - acc: 0.4085 - val_loss: 1.3357 - val_acc: 0.3333\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 1s 245ms/step - loss: 1.3044 - acc: 0.4789 - val_loss: 1.2480 - val_acc: 0.4074\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 258ms/step - loss: 1.2016 - acc: 0.5211 - val_loss: 1.1405 - val_acc: 0.6296\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 1.0696 - acc: 0.7042 - val_loss: 0.9617 - val_acc: 0.6667\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 1s 454ms/step - loss: 0.8685 - acc: 0.7465 - val_loss: 0.8367 - val_acc: 0.7037\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 292ms/step - loss: 0.6887 - acc: 0.8028 - val_loss: 0.7048 - val_acc: 0.7037\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.5729 - acc: 0.8028 - val_loss: 0.6051 - val_acc: 0.7037\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.4907 - acc: 0.8028 - val_loss: 0.6285 - val_acc: 0.7037\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.3896 - acc: 0.8028 - val_loss: 0.4642 - val_acc: 0.7037\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.3498 - acc: 0.8310 - val_loss: 0.5725 - val_acc: 0.8148\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 1s 339ms/step - loss: 0.2682 - acc: 0.9014 - val_loss: 0.7137 - val_acc: 0.8148\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 328ms/step - loss: 0.2555 - acc: 0.9296 - val_loss: 0.3504 - val_acc: 0.8148\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 1s 483ms/step - loss: 0.2499 - acc: 0.8873 - val_loss: 0.2696 - val_acc: 0.9630\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 0.1893 - acc: 0.9437 - val_loss: 0.2535 - val_acc: 0.9630\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.1469 - acc: 0.9859 - val_loss: 0.2623 - val_acc: 0.9259\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.1071 - acc: 1.0000 - val_loss: 0.2368 - val_acc: 0.9259\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.1006 - acc: 0.9859 - val_loss: 0.2346 - val_acc: 0.9259\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0711 - acc: 0.9859 - val_loss: 0.2210 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0434 - acc: 0.9859 - val_loss: 0.2477 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 213ms/step - loss: 0.0275 - acc: 1.0000 - val_loss: 0.2480 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0265 - acc: 1.0000 - val_loss: 0.2266 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.1939 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.2053 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.2445 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.1900 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.1782 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.1806 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1939 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1847 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1679 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1608 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1986 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1583 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1622 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1912 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.2021 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1626 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 7.2834e-04 - acc: 1.0000 - val_loss: 0.2118 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 8.4292e-04 - acc: 1.0000 - val_loss: 0.2555 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 8.0142e-04 - acc: 1.0000 - val_loss: 0.1982 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 7.7168e-04 - acc: 1.0000 - val_loss: 0.1666 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 7.3845e-04 - acc: 1.0000 - val_loss: 0.1701 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 5.5559e-04 - acc: 1.0000 - val_loss: 0.2234 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 9.2170e-04 - acc: 1.0000 - val_loss: 0.2318 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 8.5399e-04 - acc: 1.0000 - val_loss: 0.2229 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 4.0480e-04 - acc: 1.0000 - val_loss: 0.2327 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 6.1788e-04 - acc: 1.0000 - val_loss: 0.2266 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2296 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 6.1013e-04 - acc: 1.0000 - val_loss: 0.1929 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 6.0500e-04 - acc: 1.0000 - val_loss: 0.2018 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 6.9488e-04 - acc: 1.0000 - val_loss: 0.2222 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 7.0683e-04 - acc: 1.0000 - val_loss: 0.2214 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 6.4952e-04 - acc: 1.0000 - val_loss: 0.2527 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 7.9717e-04 - acc: 1.0000 - val_loss: 0.2192 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 8.6690e-04 - acc: 1.0000 - val_loss: 0.2011 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 5.7520e-04 - acc: 1.0000 - val_loss: 0.1892 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 5.8481e-04 - acc: 1.0000 - val_loss: 0.2097 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 4.6683e-04 - acc: 1.0000 - val_loss: 0.2438 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 4.6334e-04 - acc: 1.0000 - val_loss: 0.2260 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 4.5579e-04 - acc: 1.0000 - val_loss: 0.2237 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 7.8087e-04 - acc: 1.0000 - val_loss: 0.2009 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 4.3176e-04 - acc: 1.0000 - val_loss: 0.2244 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 4.8357e-04 - acc: 1.0000 - val_loss: 0.2498 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:03:07.118870: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:07.260901: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:07.267801: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:07.680429: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:07.687344: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:03:11.211355: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:11.666362: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:11.680774: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:12.292171: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:12.307626: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:12.973796: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:12.987358: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:13.766625: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:13.779926: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6086 - acc: 0.1127"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:03:16.283730: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:16.443343: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:16.450584: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:16.870617: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:16.877854: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 9s 3s/step - loss: 1.6086 - acc: 0.1127 - val_loss: 1.5741 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 1s 710ms/step - loss: 1.5746 - acc: 0.4789 - val_loss: 1.5533 - val_acc: 0.4815\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 1s 624ms/step - loss: 1.5476 - acc: 0.3803 - val_loss: 1.5248 - val_acc: 0.6667\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 1s 488ms/step - loss: 1.5372 - acc: 0.4507 - val_loss: 1.4937 - val_acc: 0.4815\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 1s 408ms/step - loss: 1.4636 - acc: 0.5493 - val_loss: 1.4774 - val_acc: 0.6296\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 226ms/step - loss: 1.4017 - acc: 0.4789 - val_loss: 1.3511 - val_acc: 0.3333\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 293ms/step - loss: 1.3065 - acc: 0.5634 - val_loss: 1.3405 - val_acc: 0.4074\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 226ms/step - loss: 1.2417 - acc: 0.4930 - val_loss: 1.2231 - val_acc: 0.4444\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 271ms/step - loss: 1.1426 - acc: 0.5915 - val_loss: 1.1128 - val_acc: 0.5556\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 269ms/step - loss: 1.0161 - acc: 0.6338 - val_loss: 0.9834 - val_acc: 0.5926\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 288ms/step - loss: 0.8097 - acc: 0.7183 - val_loss: 0.7361 - val_acc: 0.7037\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.6979 - acc: 0.7746 - val_loss: 0.6483 - val_acc: 0.7778\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.5340 - acc: 0.8310 - val_loss: 0.4939 - val_acc: 0.7778\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.3899 - acc: 0.8451 - val_loss: 0.4748 - val_acc: 0.7037\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 0.3359 - acc: 0.8873 - val_loss: 0.4304 - val_acc: 0.8148\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 193ms/step - loss: 0.3168 - acc: 0.9437 - val_loss: 0.3464 - val_acc: 0.9630\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.2544 - acc: 0.9718 - val_loss: 0.2733 - val_acc: 0.9630\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.2154 - acc: 1.0000 - val_loss: 0.2534 - val_acc: 0.9630\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 171ms/step - loss: 0.1399 - acc: 1.0000 - val_loss: 0.2227 - val_acc: 1.0000\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.1421 - acc: 0.9577 - val_loss: 0.1822 - val_acc: 1.0000\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.0950 - acc: 1.0000 - val_loss: 0.1533 - val_acc: 0.9630\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.0818 - acc: 1.0000 - val_loss: 0.1307 - val_acc: 0.9630\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0415 - acc: 1.0000 - val_loss: 0.0881 - val_acc: 1.0000\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0351 - acc: 1.0000 - val_loss: 0.0395 - val_acc: 1.0000\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0371 - acc: 1.0000 - val_loss: 0.0277 - val_acc: 1.0000\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0217 - acc: 1.0000 - val_loss: 0.0264 - val_acc: 1.0000\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.0184 - val_acc: 1.0000\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0159 - acc: 1.0000 - val_loss: 0.0166 - val_acc: 1.0000\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.0143 - val_acc: 1.0000\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 1.0000\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 1.0000\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.0144 - val_acc: 1.0000\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0121 - val_acc: 1.0000\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0350 - val_acc: 0.9630\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0781 - val_acc: 0.9630\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0697 - val_acc: 0.9630\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0922 - val_acc: 0.9630\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.1048 - val_acc: 0.9630\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1062 - val_acc: 0.9630\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.1293 - val_acc: 0.9630\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0937 - val_acc: 0.9630\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0690 - val_acc: 0.9630\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0534 - val_acc: 0.9630\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0872 - val_acc: 0.9630\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0862 - val_acc: 0.9630\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1374 - val_acc: 0.9630\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1336 - val_acc: 0.9630\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1499 - val_acc: 0.9630\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.2449 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1973 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.2694 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.2270 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.2977 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.2359 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.2293 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.2498 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.2345 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1737 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 9.7507e-04 - acc: 1.0000 - val_loss: 0.1692 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.2024 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1893 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1149 - val_acc: 0.9630\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 8.2143e-04 - acc: 1.0000 - val_loss: 0.1641 - val_acc: 0.9630\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 7.3312e-04 - acc: 1.0000 - val_loss: 0.0745 - val_acc: 0.9630\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 9.7609e-04 - acc: 1.0000 - val_loss: 0.0808 - val_acc: 0.9630\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1167 - val_acc: 0.9630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:03:33.759031: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:33.901056: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:33.908022: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:34.364710: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:34.371626: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:03:37.886907: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:38.307732: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:38.318627: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:38.860388: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:38.872821: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:39.445965: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:39.459023: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:40.254282: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:40.267598: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6150 - acc: 0.1408"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:03:42.927514: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:43.093079: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:43.100319: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:43.540741: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:03:43.547758: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 3s/step - loss: 1.6150 - acc: 0.1408 - val_loss: 1.5787 - val_acc: 0.4815\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 1s 678ms/step - loss: 1.5835 - acc: 0.4930 - val_loss: 1.5549 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 1s 516ms/step - loss: 1.5290 - acc: 0.5070 - val_loss: 1.5186 - val_acc: 0.4815\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 1s 667ms/step - loss: 1.4835 - acc: 0.5915 - val_loss: 1.4486 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 1s 482ms/step - loss: 1.4411 - acc: 0.4789 - val_loss: 1.3611 - val_acc: 0.4074\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 1.3523 - acc: 0.5211 - val_loss: 1.3011 - val_acc: 0.4074\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 1.2662 - acc: 0.4085 - val_loss: 1.1757 - val_acc: 0.5185\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 234ms/step - loss: 1.1294 - acc: 0.6338 - val_loss: 1.0217 - val_acc: 0.6667\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 283ms/step - loss: 0.9067 - acc: 0.7183 - val_loss: 0.8724 - val_acc: 0.7037\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 0.7045 - acc: 0.7887 - val_loss: 0.7055 - val_acc: 0.7407\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 0.5850 - acc: 0.8028 - val_loss: 0.6134 - val_acc: 0.7037\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 199ms/step - loss: 0.4885 - acc: 0.8028 - val_loss: 0.6068 - val_acc: 0.7037\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.4135 - acc: 0.8028 - val_loss: 0.5852 - val_acc: 0.7778\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.4417 - acc: 0.8028 - val_loss: 0.5961 - val_acc: 0.7037\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.3345 - acc: 0.8028 - val_loss: 0.7047 - val_acc: 0.7037\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.3153 - acc: 0.8310 - val_loss: 0.8337 - val_acc: 0.7037\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.2998 - acc: 0.8732 - val_loss: 0.5679 - val_acc: 0.8148\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.2260 - acc: 0.9718 - val_loss: 0.4738 - val_acc: 0.8519\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.2195 - acc: 0.9859 - val_loss: 0.4238 - val_acc: 0.9259\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.2015 - acc: 0.9718 - val_loss: 0.3944 - val_acc: 0.9259\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.1616 - acc: 0.9859 - val_loss: 0.4000 - val_acc: 0.9259\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.1371 - acc: 1.0000 - val_loss: 0.3551 - val_acc: 0.9259\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.1213 - acc: 1.0000 - val_loss: 0.3712 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0767 - acc: 1.0000 - val_loss: 0.3519 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.0719 - acc: 1.0000 - val_loss: 0.3245 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0446 - acc: 1.0000 - val_loss: 0.3036 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0421 - acc: 1.0000 - val_loss: 0.2793 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.2786 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0148 - acc: 1.0000 - val_loss: 0.2852 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.2618 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.2682 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.2800 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.2855 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.2495 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.2748 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.2857 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.2929 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.3084 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.3065 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.2856 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.2997 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.3141 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.3274 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.3387 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2827 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.3375 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.3205 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 7.6173e-04 - acc: 1.0000 - val_loss: 0.3114 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.3052 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.2919 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.3540 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.3733 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.3449 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.3653 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.3498 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 8.2846e-04 - acc: 1.0000 - val_loss: 0.3549 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 8.7822e-04 - acc: 1.0000 - val_loss: 0.3176 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 7.2736e-04 - acc: 1.0000 - val_loss: 0.3482 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 6.0505e-04 - acc: 1.0000 - val_loss: 0.3149 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 7.0258e-04 - acc: 1.0000 - val_loss: 0.3354 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 7.0640e-04 - acc: 1.0000 - val_loss: 0.2979 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 8.8534e-04 - acc: 1.0000 - val_loss: 0.3471 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 8.0886e-04 - acc: 1.0000 - val_loss: 0.3680 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 7.0871e-04 - acc: 1.0000 - val_loss: 0.3257 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.8102e-04 - acc: 1.0000 - val_loss: 0.3176 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 6.9320e-04 - acc: 1.0000 - val_loss: 0.3429 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 5.0459e-04 - acc: 1.0000 - val_loss: 0.3450 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.3423 - val_acc: 0.9259\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 8.7860e-04 - acc: 1.0000 - val_loss: 0.3480 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:04:00.030420: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:00.172115: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:00.179019: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:00.589967: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:00.596841: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:04:03.811953: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:04.196728: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:04.208222: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:04.727469: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:04.739613: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:05.349352: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:05.362668: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:06.145052: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:06.158418: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6083 - acc: 0.2535"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:04:08.949770: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:09.107578: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:09.114672: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:09.545463: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:09.552343: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 3s/step - loss: 1.6083 - acc: 0.2535 - val_loss: 1.5749 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 1s 771ms/step - loss: 1.5748 - acc: 0.4085 - val_loss: 1.5473 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 1s 489ms/step - loss: 1.5117 - acc: 0.3803 - val_loss: 1.5028 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 1s 422ms/step - loss: 1.4918 - acc: 0.3803 - val_loss: 1.4565 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 1s 326ms/step - loss: 1.4058 - acc: 0.5070 - val_loss: 1.4057 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 1s 367ms/step - loss: 1.3881 - acc: 0.3521 - val_loss: 1.3447 - val_acc: 0.3333\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 1.2949 - acc: 0.4930 - val_loss: 1.2552 - val_acc: 0.4815\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 1s 372ms/step - loss: 1.2540 - acc: 0.4648 - val_loss: 1.1308 - val_acc: 0.6296\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 329ms/step - loss: 1.0430 - acc: 0.6197 - val_loss: 0.9354 - val_acc: 0.7407\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 293ms/step - loss: 0.8263 - acc: 0.7465 - val_loss: 0.7371 - val_acc: 0.8148\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 0.6298 - acc: 0.9155 - val_loss: 0.5892 - val_acc: 0.8519\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 249ms/step - loss: 0.4321 - acc: 0.9014 - val_loss: 0.5062 - val_acc: 0.7407\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 171ms/step - loss: 0.3006 - acc: 0.9296 - val_loss: 0.3448 - val_acc: 0.8889\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 242ms/step - loss: 0.2204 - acc: 0.9718 - val_loss: 0.2774 - val_acc: 0.9259\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 0.2336 - acc: 0.9859 - val_loss: 0.2842 - val_acc: 0.9630\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.1621 - acc: 0.9718 - val_loss: 0.2160 - val_acc: 0.9259\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.1090 - acc: 1.0000 - val_loss: 0.6504 - val_acc: 0.8519\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.1029 - acc: 0.9718 - val_loss: 0.1658 - val_acc: 0.9259\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0570 - acc: 1.0000 - val_loss: 0.1350 - val_acc: 0.9259\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0477 - acc: 1.0000 - val_loss: 0.1554 - val_acc: 0.9259\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0359 - acc: 1.0000 - val_loss: 0.1895 - val_acc: 0.9259\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.0280 - acc: 1.0000 - val_loss: 0.1812 - val_acc: 0.9259\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.0191 - acc: 1.0000 - val_loss: 0.1653 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.1186 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0866 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0841 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.1053 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.1496 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.2177 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.2718 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.3246 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.2982 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.3388 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.3422 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.3238 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.3178 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.2760 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.2786 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.2382 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.2391 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.2140 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1847 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 9.8794e-04 - acc: 1.0000 - val_loss: 0.1789 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1684 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 8.6736e-04 - acc: 1.0000 - val_loss: 0.1655 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1674 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1442 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1497 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 9.1424e-04 - acc: 1.0000 - val_loss: 0.1499 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 9.5624e-04 - acc: 1.0000 - val_loss: 0.1152 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 8.1858e-04 - acc: 1.0000 - val_loss: 0.1380 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 7.2449e-04 - acc: 1.0000 - val_loss: 0.1380 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 8.0700e-04 - acc: 1.0000 - val_loss: 0.1258 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 9.7731e-04 - acc: 1.0000 - val_loss: 0.1233 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 6.1348e-04 - acc: 1.0000 - val_loss: 0.0985 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 6.6254e-04 - acc: 1.0000 - val_loss: 0.1183 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 6.3859e-04 - acc: 1.0000 - val_loss: 0.1043 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 7.6826e-04 - acc: 1.0000 - val_loss: 0.1075 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 6.2121e-04 - acc: 1.0000 - val_loss: 0.1303 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 6.7020e-04 - acc: 1.0000 - val_loss: 0.1151 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 7.7983e-04 - acc: 1.0000 - val_loss: 0.1248 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 5.4635e-04 - acc: 1.0000 - val_loss: 0.1048 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 4.7886e-04 - acc: 1.0000 - val_loss: 0.1072 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 3.5764e-04 - acc: 1.0000 - val_loss: 0.1062 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 5.5356e-04 - acc: 1.0000 - val_loss: 0.1082 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:04:25.683866: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:25.818255: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:25.825260: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:26.275749: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:26.282770: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:04:29.641646: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:30.044446: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:30.056606: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:30.627998: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:30.641955: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:31.294166: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:31.307513: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:32.204120: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:32.217510: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6078 - acc: 0.2113"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:04:35.214297: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:35.387033: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:35.393984: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:35.849183: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:35.856144: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 9s 3s/step - loss: 1.6078 - acc: 0.2113 - val_loss: 1.5886 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 1s 662ms/step - loss: 1.5879 - acc: 0.3803 - val_loss: 1.5630 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 1s 517ms/step - loss: 1.5503 - acc: 0.3803 - val_loss: 1.5296 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 1s 508ms/step - loss: 1.5297 - acc: 0.3662 - val_loss: 1.4891 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 1s 375ms/step - loss: 1.4629 - acc: 0.3662 - val_loss: 1.4377 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 1s 485ms/step - loss: 1.4085 - acc: 0.3521 - val_loss: 1.4005 - val_acc: 0.3333\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 1.3779 - acc: 0.4648 - val_loss: 1.3555 - val_acc: 0.3333\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 245ms/step - loss: 1.2911 - acc: 0.6761 - val_loss: 1.2491 - val_acc: 0.7037\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 221ms/step - loss: 1.1612 - acc: 0.7324 - val_loss: 1.1341 - val_acc: 0.6296\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 0.9025 - acc: 0.7183 - val_loss: 1.1480 - val_acc: 0.5185\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 266ms/step - loss: 0.8585 - acc: 0.7042 - val_loss: 0.8043 - val_acc: 0.6667\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 0.7351 - acc: 0.7042 - val_loss: 0.7335 - val_acc: 0.7037\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.5436 - acc: 0.7887 - val_loss: 0.8327 - val_acc: 0.7037\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.5799 - acc: 0.7887 - val_loss: 0.7120 - val_acc: 0.7037\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.4898 - acc: 0.8028 - val_loss: 0.5696 - val_acc: 0.7037\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3888 - acc: 0.8169 - val_loss: 0.4849 - val_acc: 0.7407\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 0.3463 - acc: 0.8028 - val_loss: 0.4620 - val_acc: 0.7778\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3114 - acc: 0.8451 - val_loss: 0.4227 - val_acc: 0.7778\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.2847 - acc: 0.8310 - val_loss: 0.4513 - val_acc: 0.7407\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.2756 - acc: 0.9296 - val_loss: 0.4661 - val_acc: 0.9259\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2564 - acc: 0.9577 - val_loss: 0.4375 - val_acc: 0.9259\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2140 - acc: 0.9859 - val_loss: 0.3897 - val_acc: 0.9259\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 193ms/step - loss: 0.2140 - acc: 0.9718 - val_loss: 0.3140 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.1590 - acc: 0.9859 - val_loss: 0.2630 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.1519 - acc: 0.9859 - val_loss: 0.3044 - val_acc: 0.8889\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.1130 - acc: 0.9437 - val_loss: 0.3453 - val_acc: 0.8519\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.1264 - acc: 0.9437 - val_loss: 0.2582 - val_acc: 0.8889\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0676 - acc: 0.9577 - val_loss: 0.1782 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0830 - acc: 0.9718 - val_loss: 0.1746 - val_acc: 0.8889\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0339 - acc: 1.0000 - val_loss: 0.1386 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0256 - acc: 1.0000 - val_loss: 0.1269 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0216 - acc: 1.0000 - val_loss: 0.1079 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.1455 - val_acc: 0.8889\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.1897 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.2510 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.3226 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.3360 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.2182 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1308 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.2901 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.2774 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.3119 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.2592 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.2684 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.2143 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0935 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 4.2141e-04 - acc: 1.0000 - val_loss: 0.0704 - val_acc: 0.9630\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 5.3042e-04 - acc: 1.0000 - val_loss: 0.1037 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1700 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 8.5132e-04 - acc: 1.0000 - val_loss: 0.1859 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.1918 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 7.9827e-04 - acc: 1.0000 - val_loss: 0.1586 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 7.8836e-04 - acc: 1.0000 - val_loss: 0.0999 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 7.0510e-04 - acc: 1.0000 - val_loss: 0.0737 - val_acc: 0.9630\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1104 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 5.5790e-04 - acc: 1.0000 - val_loss: 0.0921 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.2487 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.2747 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.3099 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0267 - acc: 0.9859 - val_loss: 0.2960 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.2024 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 6.4424e-04 - acc: 1.0000 - val_loss: 0.3579 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 4.1568e-04 - acc: 1.0000 - val_loss: 0.3672 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 8.2900e-04 - acc: 1.0000 - val_loss: 0.3945 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 9.2066e-04 - acc: 1.0000 - val_loss: 0.4036 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 7.6644e-04 - acc: 1.0000 - val_loss: 0.4275 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 7.9201e-04 - acc: 1.0000 - val_loss: 0.3625 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 7.7138e-04 - acc: 1.0000 - val_loss: 0.4417 - val_acc: 0.9259\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 4.8846e-04 - acc: 1.0000 - val_loss: 0.5230 - val_acc: 0.9259\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.4606 - val_acc: 0.9259\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.4826 - val_acc: 0.9259\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 7.3607e-04 - acc: 1.0000 - val_loss: 0.3569 - val_acc: 0.9259\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 4.0741e-04 - acc: 1.0000 - val_loss: 0.4344 - val_acc: 0.9259\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 5.2156e-04 - acc: 1.0000 - val_loss: 0.4749 - val_acc: 0.9259\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.4900e-04 - acc: 1.0000 - val_loss: 0.4342 - val_acc: 0.9259\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 2.6199e-04 - acc: 1.0000 - val_loss: 0.3907 - val_acc: 0.9259\n",
      "Epoch 77/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 3.5583e-04 - acc: 1.0000 - val_loss: 0.3638 - val_acc: 0.9259\n",
      "Epoch 78/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 4.5855e-04 - acc: 1.0000 - val_loss: 0.3653 - val_acc: 0.9259\n",
      "Epoch 79/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 2.5340e-04 - acc: 1.0000 - val_loss: 0.3275 - val_acc: 0.9259\n",
      "Epoch 80/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 2.1286e-04 - acc: 1.0000 - val_loss: 0.3600 - val_acc: 0.9259\n",
      "Epoch 81/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 2.2242e-04 - acc: 1.0000 - val_loss: 0.3249 - val_acc: 0.9259\n",
      "Epoch 82/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.6005e-04 - acc: 1.0000 - val_loss: 0.3814 - val_acc: 0.9259\n",
      "Epoch 83/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 2.0722e-04 - acc: 1.0000 - val_loss: 0.3052 - val_acc: 0.9259\n",
      "Epoch 84/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 2.4275e-04 - acc: 1.0000 - val_loss: 0.3260 - val_acc: 0.9259\n",
      "Epoch 85/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 2.3227e-04 - acc: 1.0000 - val_loss: 0.3215 - val_acc: 0.9259\n",
      "Epoch 86/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.5836e-04 - acc: 1.0000 - val_loss: 0.3180 - val_acc: 0.9259\n",
      "Epoch 87/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.8487e-04 - acc: 1.0000 - val_loss: 0.3462 - val_acc: 0.9259\n",
      "Epoch 88/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 6.7342e-04 - acc: 1.0000 - val_loss: 0.2783 - val_acc: 0.9259\n",
      "Epoch 89/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 1.5468e-04 - acc: 1.0000 - val_loss: 0.3711 - val_acc: 0.9259\n",
      "Epoch 90/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.6214e-04 - acc: 1.0000 - val_loss: 0.2729 - val_acc: 0.9259\n",
      "Epoch 91/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 2.0069e-04 - acc: 1.0000 - val_loss: 0.3384 - val_acc: 0.9259\n",
      "Epoch 92/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 2.0250e-04 - acc: 1.0000 - val_loss: 0.2895 - val_acc: 0.9259\n",
      "Epoch 93/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 7.5532e-05 - acc: 1.0000 - val_loss: 0.4014 - val_acc: 0.9259\n",
      "Epoch 94/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 7.2212e-05 - acc: 1.0000 - val_loss: 0.2652 - val_acc: 0.9259\n",
      "Epoch 95/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.0806e-04 - acc: 1.0000 - val_loss: 0.2310 - val_acc: 0.9259\n",
      "Epoch 96/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.0229e-04 - acc: 1.0000 - val_loss: 0.2465 - val_acc: 0.9259\n",
      "Epoch 97/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 1.8881e-04 - acc: 1.0000 - val_loss: 0.2925 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:04:56.644501: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:56.781525: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:56.788345: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:57.248945: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:04:57.255878: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:05:00.610848: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:01.022200: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:01.035244: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:01.616736: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:01.629702: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:02.319578: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:02.332658: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:03.247069: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:03.260446: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6088 - acc: 0.2535"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:05:06.277602: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:06.443534: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:06.450762: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:06.946757: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:06.953859: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 9s 3s/step - loss: 1.6088 - acc: 0.2535 - val_loss: 1.5872 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 1s 762ms/step - loss: 1.5865 - acc: 0.4507 - val_loss: 1.5667 - val_acc: 0.4074\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 1s 515ms/step - loss: 1.5623 - acc: 0.3803 - val_loss: 1.5346 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 1.5179 - acc: 0.4648 - val_loss: 1.4842 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 1s 448ms/step - loss: 1.4461 - acc: 0.4366 - val_loss: 1.4249 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 1s 419ms/step - loss: 1.3948 - acc: 0.3521 - val_loss: 1.4828 - val_acc: 0.3333\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 1s 445ms/step - loss: 1.3333 - acc: 0.3662 - val_loss: 1.3014 - val_acc: 0.3333\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 275ms/step - loss: 1.2136 - acc: 0.4789 - val_loss: 1.1884 - val_acc: 0.5926\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 1s 361ms/step - loss: 1.1009 - acc: 0.7324 - val_loss: 1.0876 - val_acc: 0.4074\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 241ms/step - loss: 0.9534 - acc: 0.5915 - val_loss: 0.9157 - val_acc: 0.7778\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.7750 - acc: 0.7887 - val_loss: 0.7772 - val_acc: 0.7778\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 0.6965 - acc: 0.7887 - val_loss: 0.7156 - val_acc: 0.5926\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.4884 - acc: 0.8169 - val_loss: 0.7001 - val_acc: 0.6667\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 234ms/step - loss: 0.4735 - acc: 0.8169 - val_loss: 0.5681 - val_acc: 0.8519\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.3581 - acc: 0.9437 - val_loss: 0.4695 - val_acc: 0.9259\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.3232 - acc: 0.9718 - val_loss: 0.3749 - val_acc: 0.9259\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 0.2411 - acc: 0.9577 - val_loss: 0.3726 - val_acc: 0.8519\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 0.1998 - acc: 0.9859 - val_loss: 0.3503 - val_acc: 0.8889\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.1839 - acc: 0.9014 - val_loss: 0.2729 - val_acc: 0.8889\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.1595 - acc: 0.9155 - val_loss: 0.2206 - val_acc: 0.9259\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.1526 - acc: 0.9296 - val_loss: 0.2296 - val_acc: 0.8889\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.1354 - acc: 0.9296 - val_loss: 0.2906 - val_acc: 0.8519\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 0.1262 - acc: 0.9296 - val_loss: 0.3651 - val_acc: 0.8519\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.1107 - acc: 0.9577 - val_loss: 0.4735 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 0.1020 - acc: 0.9718 - val_loss: 0.4805 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.0937 - acc: 0.9859 - val_loss: 0.1498 - val_acc: 1.0000\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0811 - acc: 1.0000 - val_loss: 0.1395 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0807 - acc: 0.9437 - val_loss: 0.0803 - val_acc: 0.9630\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0517 - acc: 1.0000 - val_loss: 0.1132 - val_acc: 0.9630\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.0434 - acc: 1.0000 - val_loss: 0.1492 - val_acc: 0.9630\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0211 - acc: 1.0000 - val_loss: 0.1527 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0198 - acc: 1.0000 - val_loss: 0.1915 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.0272 - acc: 0.9859 - val_loss: 0.2244 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.3730 - val_acc: 0.8148\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.0674 - acc: 0.9718 - val_loss: 0.2961 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.0265 - acc: 0.9859 - val_loss: 0.2475 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.3160 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0252 - acc: 1.0000 - val_loss: 0.1803 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0180 - acc: 0.9859 - val_loss: 0.0995 - val_acc: 0.9630\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0841 - val_acc: 0.9630\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0878 - val_acc: 0.9630\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.1044 - val_acc: 0.9630\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0897 - val_acc: 0.9630\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.1008 - val_acc: 0.9630\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0945 - val_acc: 0.9630\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0963 - val_acc: 0.9630\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0920 - val_acc: 0.9630\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0999 - val_acc: 0.9630\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.1114 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.1036 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0808 - val_acc: 0.9630\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 7.0622e-04 - acc: 1.0000 - val_loss: 0.1187 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1068 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1073 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1054 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 8.8703e-04 - acc: 1.0000 - val_loss: 0.1062 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1137 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1321 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 9.1125e-04 - acc: 1.0000 - val_loss: 0.1198 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 7.8744e-04 - acc: 1.0000 - val_loss: 0.1184 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 8.0012e-04 - acc: 1.0000 - val_loss: 0.1076 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0961 - val_acc: 0.9630\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 6.6674e-04 - acc: 1.0000 - val_loss: 0.1231 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 6.0375e-04 - acc: 1.0000 - val_loss: 0.1003 - val_acc: 0.9630\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 5.5739e-04 - acc: 1.0000 - val_loss: 0.1116 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1208 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 6.2714e-04 - acc: 1.0000 - val_loss: 0.1069 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 4.0162e-04 - acc: 1.0000 - val_loss: 0.1037 - val_acc: 0.9259\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 4.6887e-04 - acc: 1.0000 - val_loss: 0.1042 - val_acc: 0.9259\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 6.1639e-04 - acc: 1.0000 - val_loss: 0.1092 - val_acc: 0.9259\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 4.4562e-04 - acc: 1.0000 - val_loss: 0.1165 - val_acc: 0.9259\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 7.3367e-04 - acc: 1.0000 - val_loss: 0.1141 - val_acc: 0.9259\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 5.1106e-04 - acc: 1.0000 - val_loss: 0.0987 - val_acc: 0.9630\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 4.6915e-04 - acc: 1.0000 - val_loss: 0.1192 - val_acc: 0.9259\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 5.2045e-04 - acc: 1.0000 - val_loss: 0.1376 - val_acc: 0.9259\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 2.7818e-04 - acc: 1.0000 - val_loss: 0.1114 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:05:25.703698: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:25.844227: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:25.850992: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:26.312617: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:26.319467: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:05:29.630857: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:30.047242: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:30.060288: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:30.646866: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:30.661138: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:31.344182: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:31.357578: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:32.270323: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:32.284554: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6108 - acc: 0.1690"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:05:35.267220: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:35.437446: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:35.444573: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:35.928482: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:35.935665: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 9s 3s/step - loss: 1.6108 - acc: 0.1690 - val_loss: 1.5861 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 1s 656ms/step - loss: 1.5827 - acc: 0.3521 - val_loss: 1.5531 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 1s 535ms/step - loss: 1.5352 - acc: 0.3944 - val_loss: 1.5109 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 1s 587ms/step - loss: 1.4865 - acc: 0.4366 - val_loss: 1.4415 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 1s 578ms/step - loss: 1.4356 - acc: 0.3944 - val_loss: 1.3878 - val_acc: 0.3704\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 1s 427ms/step - loss: 1.3398 - acc: 0.3944 - val_loss: 1.3006 - val_acc: 0.3704\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 1s 351ms/step - loss: 1.1836 - acc: 0.5070 - val_loss: 1.1310 - val_acc: 0.6296\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 301ms/step - loss: 0.9669 - acc: 0.6901 - val_loss: 1.2763 - val_acc: 0.4815\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 328ms/step - loss: 0.9380 - acc: 0.6338 - val_loss: 0.8520 - val_acc: 0.6296\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 301ms/step - loss: 0.7126 - acc: 0.7465 - val_loss: 0.7028 - val_acc: 0.6667\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 0.5153 - acc: 0.8028 - val_loss: 0.6676 - val_acc: 0.7037\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.4815 - acc: 0.8169 - val_loss: 0.7402 - val_acc: 0.6296\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.3846 - acc: 0.8592 - val_loss: 0.4938 - val_acc: 0.7778\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 0.2859 - acc: 0.8592 - val_loss: 0.4370 - val_acc: 0.7778\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 291ms/step - loss: 0.2896 - acc: 0.8169 - val_loss: 0.4569 - val_acc: 0.8519\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.1895 - acc: 0.9859 - val_loss: 0.3566 - val_acc: 0.9259\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.1676 - acc: 0.9859 - val_loss: 0.2820 - val_acc: 1.0000\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 168ms/step - loss: 0.1774 - acc: 0.9437 - val_loss: 0.2537 - val_acc: 0.9259\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 0.0989 - acc: 0.9859 - val_loss: 0.3394 - val_acc: 0.8519\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0659 - acc: 0.9859 - val_loss: 0.4067 - val_acc: 0.8148\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.0662 - acc: 0.9859 - val_loss: 0.4063 - val_acc: 0.8519\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0645 - acc: 0.9859 - val_loss: 0.3323 - val_acc: 0.8889\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.0284 - acc: 1.0000 - val_loss: 0.2700 - val_acc: 0.8889\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0193 - acc: 1.0000 - val_loss: 0.2113 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.1726 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.1573 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1336 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.1424 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.1356 - val_acc: 0.8889\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1462 - val_acc: 0.8889\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1364 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1614 - val_acc: 0.8889\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1297 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 9.7750e-04 - acc: 1.0000 - val_loss: 0.1145 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1286 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1312 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1345 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 7.2100e-04 - acc: 1.0000 - val_loss: 0.1426 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 5.0388e-04 - acc: 1.0000 - val_loss: 0.0967 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 3.8988e-04 - acc: 1.0000 - val_loss: 0.1380 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 4.0425e-04 - acc: 1.0000 - val_loss: 0.1367 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 4.4841e-04 - acc: 1.0000 - val_loss: 0.1213 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 3.4800e-04 - acc: 1.0000 - val_loss: 0.1436 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1279 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 2.9633e-04 - acc: 1.0000 - val_loss: 0.1274 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 2.5055e-04 - acc: 1.0000 - val_loss: 0.1186 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 3.4378e-04 - acc: 1.0000 - val_loss: 0.1250 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 3.1631e-04 - acc: 1.0000 - val_loss: 0.1743 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 1.8703e-04 - acc: 1.0000 - val_loss: 0.1308 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 2.9718e-04 - acc: 1.0000 - val_loss: 0.1494 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 3.7189e-04 - acc: 1.0000 - val_loss: 0.1721 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 3.2866e-04 - acc: 1.0000 - val_loss: 0.1390 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 3.3269e-04 - acc: 1.0000 - val_loss: 0.1282 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.9220e-04 - acc: 1.0000 - val_loss: 0.1303 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 2.0139e-04 - acc: 1.0000 - val_loss: 0.1486 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 2.4642e-04 - acc: 1.0000 - val_loss: 0.1377 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 2.0156e-04 - acc: 1.0000 - val_loss: 0.1445 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 1.8544e-04 - acc: 1.0000 - val_loss: 0.1327 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.8071e-04 - acc: 1.0000 - val_loss: 0.1389 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 1.8796e-04 - acc: 1.0000 - val_loss: 0.1571 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 1.7174e-04 - acc: 1.0000 - val_loss: 0.1641 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 2.7958e-04 - acc: 1.0000 - val_loss: 0.1451 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 1.0986e-04 - acc: 1.0000 - val_loss: 0.1575 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.5323e-04 - acc: 1.0000 - val_loss: 0.1510 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 2.0516e-04 - acc: 1.0000 - val_loss: 0.1596 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 1.4987e-04 - acc: 1.0000 - val_loss: 0.1473 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 2.0549e-04 - acc: 1.0000 - val_loss: 0.1350 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:05:54.340049: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:54.491122: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:54.498350: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:54.977715: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:54.984529: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:05:58.281131: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:58.701976: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:58.715620: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:59.331765: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:05:59.347111: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:06:00.062601: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:06:00.075681: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:06:01.066468: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:06:01.079627: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6144 - acc: 0.1690"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:06:04.137311: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:06:04.306254: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:06:04.313424: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:06:04.789131: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:06:04.796236: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 9s 3s/step - loss: 1.6144 - acc: 0.1690 - val_loss: 1.5946 - val_acc: 0.4074\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 1s 748ms/step - loss: 1.5870 - acc: 0.3521 - val_loss: 1.5633 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 1s 630ms/step - loss: 1.5673 - acc: 0.4085 - val_loss: 1.5429 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 1s 581ms/step - loss: 1.5204 - acc: 0.3662 - val_loss: 1.4894 - val_acc: 0.3704\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 1s 604ms/step - loss: 1.4650 - acc: 0.4225 - val_loss: 1.4249 - val_acc: 0.4074\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 1s 538ms/step - loss: 1.3975 - acc: 0.4085 - val_loss: 1.3589 - val_acc: 0.3704\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 1s 394ms/step - loss: 1.3286 - acc: 0.4225 - val_loss: 1.2466 - val_acc: 0.4074\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 1s 340ms/step - loss: 1.1918 - acc: 0.5493 - val_loss: 1.2106 - val_acc: 0.7407\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 231ms/step - loss: 1.1073 - acc: 0.8028 - val_loss: 1.0339 - val_acc: 0.7778\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 1.0573 - acc: 0.7042 - val_loss: 0.9386 - val_acc: 0.7407\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 230ms/step - loss: 0.7959 - acc: 0.8028 - val_loss: 0.6794 - val_acc: 0.7037\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 215ms/step - loss: 0.5084 - acc: 0.8028 - val_loss: 0.9904 - val_acc: 0.7037\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.7427 - acc: 0.7465 - val_loss: 0.7280 - val_acc: 0.6667\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 252ms/step - loss: 0.4440 - acc: 0.7887 - val_loss: 0.6418 - val_acc: 0.6667\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 171ms/step - loss: 0.3972 - acc: 0.8028 - val_loss: 0.5343 - val_acc: 0.8519\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 0.3174 - acc: 0.9155 - val_loss: 0.4841 - val_acc: 0.7037\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 241ms/step - loss: 0.3051 - acc: 0.8451 - val_loss: 0.4418 - val_acc: 0.7407\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.2771 - acc: 0.8592 - val_loss: 0.4212 - val_acc: 0.7407\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 0.2383 - acc: 0.9718 - val_loss: 0.4113 - val_acc: 0.8889\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.2081 - acc: 1.0000 - val_loss: 0.3930 - val_acc: 0.9259\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.1788 - acc: 1.0000 - val_loss: 0.3924 - val_acc: 0.9259\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.1736 - acc: 0.9859 - val_loss: 0.3774 - val_acc: 0.9259\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.1295 - acc: 0.9859 - val_loss: 0.3320 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.1202 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.0754 - acc: 1.0000 - val_loss: 0.2846 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0553 - acc: 1.0000 - val_loss: 0.2682 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 0.0453 - acc: 1.0000 - val_loss: 0.2424 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.2519 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.2193 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.2558 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.2339 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.2626 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.2411 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.2088 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.2069 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.2084 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 7.6264e-04 - acc: 1.0000 - val_loss: 0.2177 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1928 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 9.2372e-04 - acc: 1.0000 - val_loss: 0.1520 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.2170 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 7.6374e-04 - acc: 1.0000 - val_loss: 0.1828 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 9.6804e-04 - acc: 1.0000 - val_loss: 0.2352 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 4.2564e-04 - acc: 1.0000 - val_loss: 0.1641 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 4.4879e-04 - acc: 1.0000 - val_loss: 0.1796 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 4.7602e-04 - acc: 1.0000 - val_loss: 0.1676 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 3.6805e-04 - acc: 1.0000 - val_loss: 0.2222 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 3.3122e-04 - acc: 1.0000 - val_loss: 0.2146 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.9631e-04 - acc: 1.0000 - val_loss: 0.2144 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 2.7879e-04 - acc: 1.0000 - val_loss: 0.2439 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 3.4579e-04 - acc: 1.0000 - val_loss: 0.2197 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.2089e-04 - acc: 1.0000 - val_loss: 0.2083 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 2.4707e-04 - acc: 1.0000 - val_loss: 0.2149 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.5358e-04 - acc: 1.0000 - val_loss: 0.1940 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 4.1741e-04 - acc: 1.0000 - val_loss: 0.1915 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 3.0983e-04 - acc: 1.0000 - val_loss: 0.1861 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 2.4563e-04 - acc: 1.0000 - val_loss: 0.2055 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 2.2711e-04 - acc: 1.0000 - val_loss: 0.1763 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 4.8248e-04 - acc: 1.0000 - val_loss: 0.2175 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 2.2299e-04 - acc: 1.0000 - val_loss: 0.2243 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 1.8781e-04 - acc: 1.0000 - val_loss: 0.2213 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 2.1752e-04 - acc: 1.0000 - val_loss: 0.1879 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 1.9556e-04 - acc: 1.0000 - val_loss: 0.2625 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.9642e-04 - acc: 1.0000 - val_loss: 0.2512 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 3.1603e-04 - acc: 1.0000 - val_loss: 0.2238 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 3.6904e-04 - acc: 1.0000 - val_loss: 0.2619 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 2.3707e-04 - acc: 1.0000 - val_loss: 0.2367 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 4.9117e-04 - acc: 1.0000 - val_loss: 0.2142 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 2.9977e-04 - acc: 1.0000 - val_loss: 0.2624 - val_acc: 0.9259\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 1.3021e-04 - acc: 1.0000 - val_loss: 0.2420 - val_acc: 0.9259\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 1.3152e-04 - acc: 1.0000 - val_loss: 0.2290 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:06:23.934877: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:06:24.088336: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:06:24.095296: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:06:24.592027: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:06:24.599380: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:06:27.956887: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:06:28.413564: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:06:28.430999: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:06:29.060795: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:06:29.075338: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:06:29.784462: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:06:29.797606: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:06:30.736498: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:06:30.749787: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6082 - acc: 0.1690"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:06:33.893323: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:06:34.068557: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:06:34.075728: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:06:34.552804: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:06:34.559689: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 9s 3s/step - loss: 1.6082 - acc: 0.1690 - val_loss: 1.5775 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 1s 581ms/step - loss: 1.5721 - acc: 0.3944 - val_loss: 1.5439 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 1s 723ms/step - loss: 1.5259 - acc: 0.3521 - val_loss: 1.4906 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 1s 646ms/step - loss: 1.4546 - acc: 0.3521 - val_loss: 1.4157 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 1s 622ms/step - loss: 1.3730 - acc: 0.3662 - val_loss: 1.3969 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 1s 741ms/step - loss: 1.3248 - acc: 0.4085 - val_loss: 1.2539 - val_acc: 0.4074\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 340ms/step - loss: 1.1333 - acc: 0.5493 - val_loss: 1.1098 - val_acc: 0.7407\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 1s 406ms/step - loss: 0.9570 - acc: 0.8028 - val_loss: 0.9493 - val_acc: 0.7037\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 1s 449ms/step - loss: 0.8345 - acc: 0.7887 - val_loss: 0.8422 - val_acc: 0.6667\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 283ms/step - loss: 0.6090 - acc: 0.7746 - val_loss: 0.6095 - val_acc: 0.7037\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 1s 360ms/step - loss: 0.4046 - acc: 0.8310 - val_loss: 0.5471 - val_acc: 0.7778\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 1s 388ms/step - loss: 0.4249 - acc: 0.8169 - val_loss: 0.4309 - val_acc: 0.7778\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 0.3126 - acc: 0.8451 - val_loss: 0.4334 - val_acc: 0.7407\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.2600 - acc: 0.8592 - val_loss: 0.4175 - val_acc: 0.8148\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.2376 - acc: 0.9296 - val_loss: 1.5212 - val_acc: 0.6296\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 289ms/step - loss: 0.7100 - acc: 0.7606 - val_loss: 0.4459 - val_acc: 0.7778\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.2516 - acc: 0.8732 - val_loss: 0.4075 - val_acc: 0.7778\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.2154 - acc: 0.8732 - val_loss: 0.3157 - val_acc: 0.8889\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.1696 - acc: 0.9577 - val_loss: 0.2998 - val_acc: 0.8889\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.1519 - acc: 0.9718 - val_loss: 0.2713 - val_acc: 0.8889\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.1348 - acc: 0.9718 - val_loss: 0.2460 - val_acc: 0.8519\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.1269 - acc: 0.9718 - val_loss: 0.2688 - val_acc: 0.8519\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.1074 - acc: 0.9577 - val_loss: 0.2672 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.0734 - acc: 0.9859 - val_loss: 0.2412 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 0.0556 - acc: 1.0000 - val_loss: 0.1974 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.0415 - acc: 1.0000 - val_loss: 0.1540 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0353 - acc: 1.0000 - val_loss: 0.1458 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 0.0371 - acc: 1.0000 - val_loss: 0.1329 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.0175 - acc: 1.0000 - val_loss: 0.1200 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0175 - acc: 1.0000 - val_loss: 0.1318 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.1363 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.1695 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.1858 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1972 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.2082 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.2058 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.2289 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.2450 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2308 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 6.9879e-04 - acc: 1.0000 - val_loss: 0.2664 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.2508 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 8.9776e-04 - acc: 1.0000 - val_loss: 0.2887 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 4.9630e-04 - acc: 1.0000 - val_loss: 0.3007 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 4.8008e-04 - acc: 1.0000 - val_loss: 0.2774 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 7.7207e-04 - acc: 1.0000 - val_loss: 0.2948 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 5.1492e-04 - acc: 1.0000 - val_loss: 0.2650 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 7.9926e-04 - acc: 1.0000 - val_loss: 0.2592 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 3.9054e-04 - acc: 1.0000 - val_loss: 0.2791 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 8.1956e-04 - acc: 1.0000 - val_loss: 0.2418 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 6.7785e-04 - acc: 1.0000 - val_loss: 0.2708 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 4.1185e-04 - acc: 1.0000 - val_loss: 0.2899 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 6.6624e-04 - acc: 1.0000 - val_loss: 0.3005 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 4.2120e-04 - acc: 1.0000 - val_loss: 0.2892 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 4.3484e-04 - acc: 1.0000 - val_loss: 0.2951 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 5.0560e-04 - acc: 1.0000 - val_loss: 0.2890 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 7.9748e-04 - acc: 1.0000 - val_loss: 0.2735 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 2.1595e-04 - acc: 1.0000 - val_loss: 0.2958 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 3.6267e-04 - acc: 1.0000 - val_loss: 0.3194 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 2.9428e-04 - acc: 1.0000 - val_loss: 0.2892 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 3.2729e-04 - acc: 1.0000 - val_loss: 0.2830 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 3.3789e-04 - acc: 1.0000 - val_loss: 0.3400 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 2.6620e-04 - acc: 1.0000 - val_loss: 0.2432 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 4.2719e-04 - acc: 1.0000 - val_loss: 0.2706 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 4.0069e-04 - acc: 1.0000 - val_loss: 0.2587 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 3.7856e-04 - acc: 1.0000 - val_loss: 0.2728 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 2.0236e-04 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 3.2612e-04 - acc: 1.0000 - val_loss: 0.3053 - val_acc: 0.9259\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 5.0953e-04 - acc: 1.0000 - val_loss: 0.2635 - val_acc: 0.9259\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 2.3962e-04 - acc: 1.0000 - val_loss: 0.3069 - val_acc: 0.9259\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 3.3144e-04 - acc: 1.0000 - val_loss: 0.2836 - val_acc: 0.9259\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.7190e-04 - acc: 1.0000 - val_loss: 0.2295 - val_acc: 0.9259\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 2.5473e-04 - acc: 1.0000 - val_loss: 0.2961 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:06:56.050672: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:06:56.219152: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:06:56.226053: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:06:56.833174: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:06:56.839981: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:07:00.395324: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:07:00.836458: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:07:00.858549: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:07:01.699228: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:07:01.713413: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:07:02.604297: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:07:02.617555: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:07:03.872801: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:07:03.886012: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6099 - acc: 0.0986"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:07:07.621672: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:07:07.800209: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:07:07.807186: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:07:08.379708: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:07:08.389544: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 11s 4s/step - loss: 1.6099 - acc: 0.0986 - val_loss: 1.5749 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5676 - acc: 0.4366 - val_loss: 1.5218 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 1s 394ms/step - loss: 1.5096 - acc: 0.3803 - val_loss: 1.4599 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 1s 833ms/step - loss: 1.4182 - acc: 0.3803 - val_loss: 1.3801 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 1s 812ms/step - loss: 1.3447 - acc: 0.4507 - val_loss: 1.2906 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 1s 852ms/step - loss: 1.2120 - acc: 0.4648 - val_loss: 1.1121 - val_acc: 0.5556\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 1s 499ms/step - loss: 1.0352 - acc: 0.5775 - val_loss: 0.8969 - val_acc: 0.5926\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 193ms/step - loss: 0.8198 - acc: 0.6338 - val_loss: 0.9677 - val_acc: 0.5556\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 1s 425ms/step - loss: 0.6758 - acc: 0.7042 - val_loss: 0.5825 - val_acc: 0.8148\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 1s 645ms/step - loss: 0.4318 - acc: 0.8873 - val_loss: 0.5777 - val_acc: 0.8519\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 1s 308ms/step - loss: 0.3352 - acc: 0.9437 - val_loss: 0.7984 - val_acc: 0.7037\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 1s 488ms/step - loss: 0.3305 - acc: 0.8592 - val_loss: 0.3607 - val_acc: 0.9259\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 249ms/step - loss: 0.2171 - acc: 1.0000 - val_loss: 0.4613 - val_acc: 0.8889\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.1380 - acc: 0.9718 - val_loss: 0.7495 - val_acc: 0.8148\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.1468 - acc: 0.9437 - val_loss: 0.5122 - val_acc: 0.8889\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 259ms/step - loss: 0.0782 - acc: 0.9859 - val_loss: 0.3520 - val_acc: 0.9259\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 0.0705 - acc: 1.0000 - val_loss: 0.2920 - val_acc: 0.9259\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 226ms/step - loss: 0.0393 - acc: 1.0000 - val_loss: 0.2928 - val_acc: 0.9259\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0250 - acc: 1.0000 - val_loss: 0.6687 - val_acc: 0.8889\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.0154 - acc: 1.0000 - val_loss: 1.1699 - val_acc: 0.8148\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 233ms/step - loss: 0.0161 - acc: 1.0000 - val_loss: 0.5342 - val_acc: 0.9259\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.2477 - val_acc: 0.9259\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.1307 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0789 - val_acc: 1.0000\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0783 - val_acc: 1.0000\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0746 - val_acc: 1.0000\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 6.8031e-04 - acc: 1.0000 - val_loss: 0.0787 - val_acc: 1.0000\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 9.1717e-04 - acc: 1.0000 - val_loss: 0.0927 - val_acc: 0.9630\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 6.3185e-04 - acc: 1.0000 - val_loss: 0.1031 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 5.3421e-04 - acc: 1.0000 - val_loss: 0.1019 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 4.7472e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 3.3370e-04 - acc: 1.0000 - val_loss: 0.1303 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 2.2986e-04 - acc: 1.0000 - val_loss: 0.1575 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 2.8589e-04 - acc: 1.0000 - val_loss: 0.1503 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 3.3014e-04 - acc: 1.0000 - val_loss: 0.1694 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 4.3461e-04 - acc: 1.0000 - val_loss: 0.1829 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 2.3729e-04 - acc: 1.0000 - val_loss: 0.1970 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 3.8759e-04 - acc: 1.0000 - val_loss: 0.2152 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 2.4252e-04 - acc: 1.0000 - val_loss: 0.1919 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 2.1584e-04 - acc: 1.0000 - val_loss: 0.1950 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 2.3649e-04 - acc: 1.0000 - val_loss: 0.2146 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.5956e-04 - acc: 1.0000 - val_loss: 0.2030 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 2.5648e-04 - acc: 1.0000 - val_loss: 0.2313 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.9063e-04 - acc: 1.0000 - val_loss: 0.1940 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 4.4354e-04 - acc: 1.0000 - val_loss: 0.2073 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 2.8895e-04 - acc: 1.0000 - val_loss: 0.2020 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 1.7118e-04 - acc: 1.0000 - val_loss: 0.2009 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 2.0718e-04 - acc: 1.0000 - val_loss: 0.1998 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.8672e-04 - acc: 1.0000 - val_loss: 0.1843 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 2.2917e-04 - acc: 1.0000 - val_loss: 0.1973 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.9582e-04 - acc: 1.0000 - val_loss: 0.2007 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 2.8271e-04 - acc: 1.0000 - val_loss: 0.1999 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 1.7554e-04 - acc: 1.0000 - val_loss: 0.1806 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.1627e-04 - acc: 1.0000 - val_loss: 0.1722 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 1.7856e-04 - acc: 1.0000 - val_loss: 0.1646 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 2.4655e-04 - acc: 1.0000 - val_loss: 0.1836 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.6950e-04 - acc: 1.0000 - val_loss: 0.1572 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 1.2739e-04 - acc: 1.0000 - val_loss: 0.1879 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.8859e-04 - acc: 1.0000 - val_loss: 0.1650 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 1.7476e-04 - acc: 1.0000 - val_loss: 0.1812 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.2134e-04 - acc: 1.0000 - val_loss: 0.1692 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 1.7914e-04 - acc: 1.0000 - val_loss: 0.1722 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.2316e-04 - acc: 1.0000 - val_loss: 0.1836 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.5002e-04 - acc: 1.0000 - val_loss: 0.1595 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 9.8514e-05 - acc: 1.0000 - val_loss: 0.1674 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.6085e-04 - acc: 1.0000 - val_loss: 0.1821 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 1.5210e-04 - acc: 1.0000 - val_loss: 0.1683 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.2729e-04 - acc: 1.0000 - val_loss: 0.1694 - val_acc: 0.9259\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.2434e-04 - acc: 1.0000 - val_loss: 0.1675 - val_acc: 0.9259\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.1017e-04 - acc: 1.0000 - val_loss: 0.1764 - val_acc: 0.9259\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.3269e-04 - acc: 1.0000 - val_loss: 0.1786 - val_acc: 0.9259\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.2859e-04 - acc: 1.0000 - val_loss: 0.1836 - val_acc: 0.9259\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.0288e-04 - acc: 1.0000 - val_loss: 0.1875 - val_acc: 0.9259\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.1951e-04 - acc: 1.0000 - val_loss: 0.1740 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:07:31.918795: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:07:32.091359: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:07:32.098384: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:07:32.820124: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:07:32.827249: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:07:36.487850: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:07:36.942901: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:07:36.961366: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:07:37.701214: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:07:37.726126: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:07:38.537667: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:07:38.551171: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:07:39.584139: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:07:39.597671: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6118 - acc: 0.2254"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:07:43.565590: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:07:43.766010: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:07:43.773319: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:07:44.462046: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:07:44.469394: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 11s 5s/step - loss: 1.6118 - acc: 0.2254 - val_loss: 1.5851 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.5837 - acc: 0.3944 - val_loss: 1.5483 - val_acc: 0.3704\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5513 - acc: 0.4085 - val_loss: 1.5128 - val_acc: 0.3704\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 2s 956ms/step - loss: 1.5113 - acc: 0.4507 - val_loss: 1.4435 - val_acc: 0.4444\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 1s 477ms/step - loss: 1.4387 - acc: 0.6056 - val_loss: 1.3699 - val_acc: 0.3704\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 1s 636ms/step - loss: 1.3629 - acc: 0.4366 - val_loss: 1.2985 - val_acc: 0.4074\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 1s 526ms/step - loss: 1.2573 - acc: 0.4085 - val_loss: 1.1722 - val_acc: 0.6296\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 1s 578ms/step - loss: 1.0516 - acc: 0.7746 - val_loss: 1.0058 - val_acc: 0.7037\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 1s 882ms/step - loss: 0.8995 - acc: 0.8028 - val_loss: 2.1519 - val_acc: 0.2593\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 1s 348ms/step - loss: 1.6694 - acc: 0.3380 - val_loss: 0.9818 - val_acc: 0.5185\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 1s 414ms/step - loss: 0.8065 - acc: 0.6761 - val_loss: 0.6815 - val_acc: 0.7037\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 233ms/step - loss: 0.5313 - acc: 0.8028 - val_loss: 0.6942 - val_acc: 0.7037\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 1s 442ms/step - loss: 0.5115 - acc: 0.7887 - val_loss: 0.6454 - val_acc: 0.7037\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.4356 - acc: 0.8169 - val_loss: 0.5742 - val_acc: 0.8519\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 1s 229ms/step - loss: 0.3944 - acc: 0.9296 - val_loss: 0.5303 - val_acc: 0.7037\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3708 - acc: 0.8169 - val_loss: 0.4655 - val_acc: 0.7778\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 201ms/step - loss: 0.3243 - acc: 0.8028 - val_loss: 0.4296 - val_acc: 0.7778\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.2950 - acc: 0.8451 - val_loss: 0.4084 - val_acc: 0.8519\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 0.2295 - acc: 0.9437 - val_loss: 0.4000 - val_acc: 0.8889\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.1643 - acc: 0.9437 - val_loss: 0.3990 - val_acc: 0.8889\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.1512 - acc: 0.9296 - val_loss: 0.3861 - val_acc: 0.8889\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.1339 - acc: 0.9859 - val_loss: 0.3494 - val_acc: 0.8889\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0852 - acc: 0.9859 - val_loss: 0.3079 - val_acc: 0.8889\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0844 - acc: 0.9859 - val_loss: 0.3219 - val_acc: 0.8889\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 288ms/step - loss: 0.0749 - acc: 1.0000 - val_loss: 0.2693 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0399 - acc: 1.0000 - val_loss: 0.2961 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 0.0258 - acc: 1.0000 - val_loss: 0.2382 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.0150 - acc: 1.0000 - val_loss: 0.2278 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.2006 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.2081 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.2451 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.2452 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.2339 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.2626 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.2559 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.2848 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.2698 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.2587 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.3209 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.2773 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.3522 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.3226 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.3436 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.3213 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 7.3424e-04 - acc: 1.0000 - val_loss: 0.3246 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 8.5993e-04 - acc: 1.0000 - val_loss: 0.3247 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 8.6515e-04 - acc: 1.0000 - val_loss: 0.3225 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 7.3766e-04 - acc: 1.0000 - val_loss: 0.3061 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 7.5565e-04 - acc: 1.0000 - val_loss: 0.3294 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 8.6854e-04 - acc: 1.0000 - val_loss: 0.3384 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 9.0267e-04 - acc: 1.0000 - val_loss: 0.3386 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.3336 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 7.9270e-04 - acc: 1.0000 - val_loss: 0.3078 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 6.6697e-04 - acc: 1.0000 - val_loss: 0.3117 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 5.6384e-04 - acc: 1.0000 - val_loss: 0.2829 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 3.9061e-04 - acc: 1.0000 - val_loss: 0.2928 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 5.9738e-04 - acc: 1.0000 - val_loss: 0.3389 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 4.4097e-04 - acc: 1.0000 - val_loss: 0.3194 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 6.5946e-04 - acc: 1.0000 - val_loss: 0.3571 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 3.7586e-04 - acc: 1.0000 - val_loss: 0.3213 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 4.4363e-04 - acc: 1.0000 - val_loss: 0.3169 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.6318e-04 - acc: 1.0000 - val_loss: 0.3130 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.7368e-04 - acc: 1.0000 - val_loss: 0.2910 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 5.1936e-04 - acc: 1.0000 - val_loss: 0.3210 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 4.7515e-04 - acc: 1.0000 - val_loss: 0.3345 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 2.8238e-04 - acc: 1.0000 - val_loss: 0.3087 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 6.0876e-04 - acc: 1.0000 - val_loss: 0.3123 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 3.9497e-04 - acc: 1.0000 - val_loss: 0.3217 - val_acc: 0.9259\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 4.5002e-04 - acc: 1.0000 - val_loss: 0.2966 - val_acc: 0.9259\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 4.5674e-04 - acc: 1.0000 - val_loss: 0.3530 - val_acc: 0.9259\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 3.8527e-04 - acc: 1.0000 - val_loss: 0.2932 - val_acc: 0.9259\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 4.7490e-04 - acc: 1.0000 - val_loss: 0.3502 - val_acc: 0.9259\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 3.2978e-04 - acc: 1.0000 - val_loss: 0.3113 - val_acc: 0.9259\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 2.9789e-04 - acc: 1.0000 - val_loss: 0.2991 - val_acc: 0.9259\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 4.1447e-04 - acc: 1.0000 - val_loss: 0.3538 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:08:10.544231: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:08:10.709465: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:08:10.716509: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:08:11.346983: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:08:11.353841: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:08:15.070345: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:08:15.519776: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:08:15.541938: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:08:16.474917: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:08:16.490758: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:08:17.517442: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:08:17.530588: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:08:18.955585: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:08:18.969134: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6162 - acc: 0.1408"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:08:23.256555: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:08:23.457356: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:08:23.464493: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:08:24.185159: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:08:24.192363: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 12s 5s/step - loss: 1.6162 - acc: 0.1408 - val_loss: 1.5783 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5740 - acc: 0.4225 - val_loss: 1.5501 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5306 - acc: 0.4789 - val_loss: 1.4662 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 2s 805ms/step - loss: 1.4570 - acc: 0.3803 - val_loss: 1.3916 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 2s 894ms/step - loss: 1.3262 - acc: 0.3662 - val_loss: 1.6179 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 1s 326ms/step - loss: 1.3821 - acc: 0.3803 - val_loss: 1.2909 - val_acc: 0.3333\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 2s 800ms/step - loss: 1.0743 - acc: 0.6197 - val_loss: 1.0162 - val_acc: 0.6667\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 1s 454ms/step - loss: 0.8946 - acc: 0.7887 - val_loss: 0.8597 - val_acc: 0.7778\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 1s 315ms/step - loss: 0.7032 - acc: 0.8169 - val_loss: 0.7059 - val_acc: 0.7778\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 0.5316 - acc: 0.7887 - val_loss: 0.4804 - val_acc: 0.7037\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 1s 387ms/step - loss: 0.3549 - acc: 0.8310 - val_loss: 0.6159 - val_acc: 0.7778\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 1s 384ms/step - loss: 0.3541 - acc: 0.9014 - val_loss: 0.3802 - val_acc: 0.9259\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 200ms/step - loss: 0.2072 - acc: 1.0000 - val_loss: 0.2649 - val_acc: 0.8148\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 328ms/step - loss: 0.1794 - acc: 0.9296 - val_loss: 0.1992 - val_acc: 0.9630\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0712 - acc: 1.0000 - val_loss: 0.2129 - val_acc: 0.9259\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 314ms/step - loss: 0.0328 - acc: 1.0000 - val_loss: 0.2636 - val_acc: 0.9259\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.0211 - acc: 1.0000 - val_loss: 0.2847 - val_acc: 0.9259\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 179ms/step - loss: 0.0176 - acc: 1.0000 - val_loss: 0.2131 - val_acc: 0.9259\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 222ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.2159 - val_acc: 0.9259\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 182ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1856 - val_acc: 0.9259\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1635 - val_acc: 0.9259\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1865 - val_acc: 0.9259\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1857 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1728 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 9.1992e-04 - acc: 1.0000 - val_loss: 0.1747 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1726 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 8.1348e-04 - acc: 1.0000 - val_loss: 0.1634 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1592 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 5.5415e-04 - acc: 1.0000 - val_loss: 0.1618 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.3822e-04 - acc: 1.0000 - val_loss: 0.1874 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 3.2165e-04 - acc: 1.0000 - val_loss: 0.1568 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 2.5866e-04 - acc: 1.0000 - val_loss: 0.1379 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 3.1852e-04 - acc: 1.0000 - val_loss: 0.1633 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 3.7763e-04 - acc: 1.0000 - val_loss: 0.1409 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 2.9646e-04 - acc: 1.0000 - val_loss: 0.1465 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 1.8677e-04 - acc: 1.0000 - val_loss: 0.1679 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.9423e-04 - acc: 1.0000 - val_loss: 0.1686 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 2.0356e-04 - acc: 1.0000 - val_loss: 0.1545 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.4441e-04 - acc: 1.0000 - val_loss: 0.1466 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.3021e-04 - acc: 1.0000 - val_loss: 0.1724 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.6442e-04 - acc: 1.0000 - val_loss: 0.1835 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 2.4755e-04 - acc: 1.0000 - val_loss: 0.1626 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 2.1368e-04 - acc: 1.0000 - val_loss: 0.1461 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.5924e-04 - acc: 1.0000 - val_loss: 0.1569 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 2.1875e-04 - acc: 1.0000 - val_loss: 0.1773 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.5921e-04 - acc: 1.0000 - val_loss: 0.1841 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.2359e-04 - acc: 1.0000 - val_loss: 0.2005 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.0230e-04 - acc: 1.0000 - val_loss: 0.2008 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.9024e-04 - acc: 1.0000 - val_loss: 0.1595 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.6562e-04 - acc: 1.0000 - val_loss: 0.1794 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 1.0569e-04 - acc: 1.0000 - val_loss: 0.1338 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 1.1156e-04 - acc: 1.0000 - val_loss: 0.1284 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.2260e-04 - acc: 1.0000 - val_loss: 0.1768 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.0108e-04 - acc: 1.0000 - val_loss: 0.1573 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 2.1358e-04 - acc: 1.0000 - val_loss: 0.1839 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.4900e-04 - acc: 1.0000 - val_loss: 0.2004 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 1.3452e-04 - acc: 1.0000 - val_loss: 0.2502 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.2763e-04 - acc: 1.0000 - val_loss: 0.1976 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.8891e-04 - acc: 1.0000 - val_loss: 0.2182 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.0277e-04 - acc: 1.0000 - val_loss: 0.2342 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.5023e-04 - acc: 1.0000 - val_loss: 0.1509 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 9.3016e-05 - acc: 1.0000 - val_loss: 0.1565 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 8.9240e-05 - acc: 1.0000 - val_loss: 0.1712 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.6668e-04 - acc: 1.0000 - val_loss: 0.1689 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:08:50.117540: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:08:50.295852: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:08:50.303001: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:08:51.026084: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:08:51.033011: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:08:54.714922: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:08:55.207498: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:08:55.229536: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:08:56.221809: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:08:56.232330: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:08:57.375419: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:08:57.388652: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:08:58.940450: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:08:58.953881: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6066 - acc: 0.2254"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:09:03.222064: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:09:03.440270: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:09:03.447660: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:09:04.150338: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:09:04.157319: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 13s 5s/step - loss: 1.6066 - acc: 0.2254 - val_loss: 1.5591 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5541 - acc: 0.4507 - val_loss: 1.5011 - val_acc: 0.4815\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 2s 925ms/step - loss: 1.4893 - acc: 0.4507 - val_loss: 1.4115 - val_acc: 0.5185\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.3817 - acc: 0.5211 - val_loss: 1.3356 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.2799 - acc: 0.4225 - val_loss: 1.1832 - val_acc: 0.5185\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 1s 490ms/step - loss: 1.0916 - acc: 0.5915 - val_loss: 0.9642 - val_acc: 0.5926\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 1s 816ms/step - loss: 0.8596 - acc: 0.6620 - val_loss: 0.8133 - val_acc: 0.6667\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 1s 744ms/step - loss: 0.6762 - acc: 0.7887 - val_loss: 0.6236 - val_acc: 0.8889\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 1s 455ms/step - loss: 0.5063 - acc: 0.8169 - val_loss: 0.5766 - val_acc: 0.8519\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 1s 383ms/step - loss: 0.3800 - acc: 0.9014 - val_loss: 0.4603 - val_acc: 0.8519\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 1s 342ms/step - loss: 0.2727 - acc: 0.8873 - val_loss: 3.8364 - val_acc: 0.3704\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 168ms/step - loss: 2.9094 - acc: 0.5070 - val_loss: 0.8767 - val_acc: 0.7037\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 1s 252ms/step - loss: 0.2759 - acc: 0.9155 - val_loss: 0.9817 - val_acc: 0.7037\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.3307 - acc: 0.8592 - val_loss: 0.4840 - val_acc: 0.8519\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 1s 334ms/step - loss: 0.2572 - acc: 0.9296 - val_loss: 0.3830 - val_acc: 0.8889\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 201ms/step - loss: 0.1961 - acc: 0.9577 - val_loss: 0.3088 - val_acc: 0.9259\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.1852 - acc: 0.9859 - val_loss: 0.2799 - val_acc: 0.8519\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.1675 - acc: 0.9718 - val_loss: 0.2521 - val_acc: 0.8519\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.1544 - acc: 0.9437 - val_loss: 0.2074 - val_acc: 0.9259\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.1111 - acc: 0.9577 - val_loss: 0.1567 - val_acc: 1.0000\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 1s 473ms/step - loss: 0.0704 - acc: 1.0000 - val_loss: 0.1664 - val_acc: 1.0000\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 0.0998 - acc: 1.0000 - val_loss: 0.1486 - val_acc: 1.0000\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0593 - acc: 1.0000 - val_loss: 0.1128 - val_acc: 1.0000\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0321 - acc: 1.0000 - val_loss: 0.1333 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.0220 - acc: 1.0000 - val_loss: 0.1553 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.1643 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.0160 - acc: 1.0000 - val_loss: 0.1761 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.1775 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.1645 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.1742 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.1666 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.1518 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.1504 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1607 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1532 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1564 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1571 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.1465 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1577 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1598 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1337 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1461 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1405 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1485 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 8.7343e-04 - acc: 1.0000 - val_loss: 0.1399 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1338 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1475 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 9.1356e-04 - acc: 1.0000 - val_loss: 0.1514 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 6.6940e-04 - acc: 1.0000 - val_loss: 0.1441 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1479 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 5.0441e-04 - acc: 1.0000 - val_loss: 0.1383 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 5.7931e-04 - acc: 1.0000 - val_loss: 0.1390 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 8.0186e-04 - acc: 1.0000 - val_loss: 0.1367 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 5.4379e-04 - acc: 1.0000 - val_loss: 0.1348 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 5.9596e-04 - acc: 1.0000 - val_loss: 0.1373 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 5.8221e-04 - acc: 1.0000 - val_loss: 0.1354 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 4.4729e-04 - acc: 1.0000 - val_loss: 0.1355 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 5.2889e-04 - acc: 1.0000 - val_loss: 0.1504 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 6.2765e-04 - acc: 1.0000 - val_loss: 0.1412 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 6.5705e-04 - acc: 1.0000 - val_loss: 0.1464 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 5.5485e-04 - acc: 1.0000 - val_loss: 0.1480 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 3.8823e-04 - acc: 1.0000 - val_loss: 0.1443 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 8.1167e-04 - acc: 1.0000 - val_loss: 0.1300 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 3.9523e-04 - acc: 1.0000 - val_loss: 0.1450 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 6.5283e-04 - acc: 1.0000 - val_loss: 0.1454 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 6.7332e-04 - acc: 1.0000 - val_loss: 0.1451 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 6.5569e-04 - acc: 1.0000 - val_loss: 0.1487 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 5.2488e-04 - acc: 1.0000 - val_loss: 0.1543 - val_acc: 0.9259\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 3.5206e-04 - acc: 1.0000 - val_loss: 0.1398 - val_acc: 0.9259\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 4.6120e-04 - acc: 1.0000 - val_loss: 0.1411 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:09:31.334287: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:09:31.498709: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:09:31.505752: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:09:32.202351: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:09:32.209176: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:09:35.992252: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:09:36.501622: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:09:36.513498: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:09:37.578521: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:09:37.589801: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:09:38.773173: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:09:38.787600: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:09:40.328628: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:09:40.341926: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6112 - acc: 0.0986"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:09:45.334042: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:09:45.548462: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:09:45.555510: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:09:46.309740: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:09:46.316811: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 14s 5s/step - loss: 1.6112 - acc: 0.0986 - val_loss: 1.5869 - val_acc: 0.4074\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5824 - acc: 0.3944 - val_loss: 1.5609 - val_acc: 0.4444\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5548 - acc: 0.4085 - val_loss: 1.4930 - val_acc: 0.4444\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.4693 - acc: 0.4507 - val_loss: 1.4853 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.4491 - acc: 0.3944 - val_loss: 1.4557 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 1s 546ms/step - loss: 1.4080 - acc: 0.3662 - val_loss: 1.3998 - val_acc: 0.3704\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 1.3755 - acc: 0.3944 - val_loss: 1.3647 - val_acc: 0.5926\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 1s 800ms/step - loss: 1.2625 - acc: 0.5915 - val_loss: 1.2018 - val_acc: 0.5185\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 1s 717ms/step - loss: 1.0435 - acc: 0.5915 - val_loss: 1.0078 - val_acc: 0.7778\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 1s 514ms/step - loss: 0.8834 - acc: 0.8169 - val_loss: 1.2781 - val_acc: 0.3704\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 1s 375ms/step - loss: 1.0357 - acc: 0.5915 - val_loss: 0.9214 - val_acc: 0.6667\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 1s 231ms/step - loss: 0.8411 - acc: 0.7324 - val_loss: 0.7897 - val_acc: 0.8519\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 1s 327ms/step - loss: 0.6817 - acc: 0.8873 - val_loss: 0.8325 - val_acc: 0.8148\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.6720 - acc: 0.8732 - val_loss: 0.6956 - val_acc: 0.7407\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 193ms/step - loss: 0.6028 - acc: 0.7606 - val_loss: 0.6237 - val_acc: 0.7037\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.4450 - acc: 0.8310 - val_loss: 0.5770 - val_acc: 0.6667\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.3515 - acc: 0.8592 - val_loss: 0.3529 - val_acc: 0.7778\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.2243 - acc: 0.8873 - val_loss: 0.3144 - val_acc: 0.8519\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 169ms/step - loss: 0.1955 - acc: 0.8732 - val_loss: 0.2752 - val_acc: 0.8519\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 202ms/step - loss: 0.1695 - acc: 0.9296 - val_loss: 0.2360 - val_acc: 0.8889\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.1472 - acc: 0.9437 - val_loss: 0.1956 - val_acc: 0.9630\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 246ms/step - loss: 0.1271 - acc: 1.0000 - val_loss: 0.1717 - val_acc: 0.9630\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.1021 - acc: 0.9718 - val_loss: 0.1498 - val_acc: 0.9630\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 240ms/step - loss: 0.0835 - acc: 0.9859 - val_loss: 0.1464 - val_acc: 0.9630\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.0462 - acc: 1.0000 - val_loss: 0.1901 - val_acc: 0.9630\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 199ms/step - loss: 0.0867 - acc: 0.9577 - val_loss: 0.1504 - val_acc: 0.9630\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0277 - acc: 0.9859 - val_loss: 0.1194 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.3489 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0663 - acc: 0.9859 - val_loss: 0.2838 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.1111 - acc: 0.9577 - val_loss: 0.0765 - val_acc: 0.9630\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.0158 - acc: 1.0000 - val_loss: 0.1513 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 9.2144e-04 - acc: 1.0000 - val_loss: 0.2986 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0266 - acc: 0.9859 - val_loss: 0.3297 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0267 - acc: 0.9859 - val_loss: 0.2732 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1285 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 8.0024e-04 - acc: 1.0000 - val_loss: 0.1169 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.2433 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.2834 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 8.7940e-04 - acc: 1.0000 - val_loss: 0.2563 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 8.8678e-04 - acc: 1.0000 - val_loss: 0.1457 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2107 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1641 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 8.0489e-04 - acc: 1.0000 - val_loss: 0.1530 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2456 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 4.5262e-04 - acc: 1.0000 - val_loss: 0.1301 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 3.1988e-04 - acc: 1.0000 - val_loss: 0.2147 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 3.9510e-04 - acc: 1.0000 - val_loss: 0.2979 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 5.1947e-04 - acc: 1.0000 - val_loss: 0.2076 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 4.0072e-04 - acc: 1.0000 - val_loss: 0.2152 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 3.3425e-04 - acc: 1.0000 - val_loss: 0.2279 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.7194e-04 - acc: 1.0000 - val_loss: 0.1822 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 7.1494e-04 - acc: 1.0000 - val_loss: 0.2295 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 5.7597e-04 - acc: 1.0000 - val_loss: 0.2830 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 2.1080e-04 - acc: 1.0000 - val_loss: 0.2677 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 5.7177e-04 - acc: 1.0000 - val_loss: 0.3146 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 2.5975e-04 - acc: 1.0000 - val_loss: 0.2640 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 2.4827e-04 - acc: 1.0000 - val_loss: 0.1835 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 7.6097e-04 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.5278e-04 - acc: 1.0000 - val_loss: 0.2064 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 2.2558e-04 - acc: 1.0000 - val_loss: 0.2340 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 2.3131e-04 - acc: 1.0000 - val_loss: 0.2008 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 4.6949e-04 - acc: 1.0000 - val_loss: 0.2091 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 4.1156e-04 - acc: 1.0000 - val_loss: 0.2263 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.0205e-04 - acc: 1.0000 - val_loss: 0.3399 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 2.7609e-04 - acc: 1.0000 - val_loss: 0.2676 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.7543e-04 - acc: 1.0000 - val_loss: 0.2092 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.1327e-04 - acc: 1.0000 - val_loss: 0.2935 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 2.9264e-04 - acc: 1.0000 - val_loss: 0.2228 - val_acc: 0.9259\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 3.5028e-04 - acc: 1.0000 - val_loss: 0.1975 - val_acc: 0.9259\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.2726e-04 - acc: 1.0000 - val_loss: 0.1325 - val_acc: 0.9259\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 9.3900e-05 - acc: 1.0000 - val_loss: 0.2023 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:10:14.526609: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:10:14.686336: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:10:14.693197: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:10:15.396601: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:10:15.403679: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:10:19.302154: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:10:19.818596: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:10:19.829768: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:10:20.851491: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:10:20.862202: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:10:21.970043: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:10:21.983322: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:10:23.515868: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:10:23.529268: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6067 - acc: 0.2113"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:10:28.317561: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:10:28.532950: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:10:28.539890: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:10:29.269583: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:10:29.277385: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 13s 5s/step - loss: 1.6067 - acc: 0.2113 - val_loss: 1.5754 - val_acc: 0.4074\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5781 - acc: 0.4507 - val_loss: 1.5325 - val_acc: 0.4074\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5379 - acc: 0.3944 - val_loss: 1.4950 - val_acc: 0.5185\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.4718 - acc: 0.4366 - val_loss: 1.4438 - val_acc: 0.2593\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.3804 - acc: 0.4225 - val_loss: 1.4025 - val_acc: 0.5185\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 1s 1s/step - loss: 1.3426 - acc: 0.5775 - val_loss: 1.2622 - val_acc: 0.5926\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 1s 754ms/step - loss: 1.1694 - acc: 0.6901 - val_loss: 2.6412 - val_acc: 0.2593\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 1s 726ms/step - loss: 2.0380 - acc: 0.3380 - val_loss: 1.1413 - val_acc: 0.5185\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 1s 577ms/step - loss: 1.0951 - acc: 0.5493 - val_loss: 1.1857 - val_acc: 0.5185\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 1s 392ms/step - loss: 0.9901 - acc: 0.5915 - val_loss: 1.0896 - val_acc: 0.5185\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.9606 - acc: 0.5634 - val_loss: 1.1180 - val_acc: 0.4444\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 335ms/step - loss: 0.9023 - acc: 0.5775 - val_loss: 0.8846 - val_acc: 0.7037\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 1s 376ms/step - loss: 0.7397 - acc: 0.7606 - val_loss: 0.7763 - val_acc: 0.8519\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 1s 370ms/step - loss: 0.6252 - acc: 0.8873 - val_loss: 0.6718 - val_acc: 0.8519\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 169ms/step - loss: 0.4873 - acc: 0.8732 - val_loss: 0.4319 - val_acc: 0.7778\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.2802 - acc: 0.9155 - val_loss: 0.5098 - val_acc: 0.7778\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 241ms/step - loss: 0.3121 - acc: 0.8592 - val_loss: 0.4054 - val_acc: 0.8148\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.3491 - acc: 0.8592 - val_loss: 0.3613 - val_acc: 0.8148\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.2162 - acc: 0.8873 - val_loss: 0.3082 - val_acc: 0.9259\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.1447 - acc: 0.9155 - val_loss: 0.8306 - val_acc: 0.8148\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 171ms/step - loss: 0.2666 - acc: 0.8732 - val_loss: 0.2779 - val_acc: 0.8519\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1275 - acc: 0.9296 - val_loss: 0.1228 - val_acc: 0.9630\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 169ms/step - loss: 0.0766 - acc: 0.9718 - val_loss: 0.0942 - val_acc: 1.0000\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0825 - acc: 1.0000 - val_loss: 0.0801 - val_acc: 1.0000\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 250ms/step - loss: 0.0621 - acc: 1.0000 - val_loss: 0.0889 - val_acc: 1.0000\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 248ms/step - loss: 0.0567 - acc: 0.9859 - val_loss: 0.1104 - val_acc: 0.9630\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.0333 - acc: 1.0000 - val_loss: 0.2534 - val_acc: 0.8889\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0242 - acc: 1.0000 - val_loss: 0.2128 - val_acc: 0.8889\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.0192 - acc: 1.0000 - val_loss: 0.1012 - val_acc: 0.9630\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.0598 - val_acc: 1.0000\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0712 - val_acc: 0.9630\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0661 - val_acc: 1.0000\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0523 - val_acc: 1.0000\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 298ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.1115 - val_acc: 0.8889\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0604 - val_acc: 0.9630\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.0614 - val_acc: 0.9630\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0777 - val_acc: 0.9630\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0823 - val_acc: 0.9630\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1553 - val_acc: 0.8889\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0960 - val_acc: 0.9630\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0943 - val_acc: 0.9630\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0565 - val_acc: 1.0000\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 7.8502e-04 - acc: 1.0000 - val_loss: 0.0812 - val_acc: 0.9630\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0498 - val_acc: 0.9630\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 9.5654e-04 - acc: 1.0000 - val_loss: 0.0746 - val_acc: 0.9630\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 8.0708e-04 - acc: 1.0000 - val_loss: 0.1170 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 4.8509e-04 - acc: 1.0000 - val_loss: 0.0683 - val_acc: 0.9630\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0400 - val_acc: 1.0000\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 7.3687e-04 - acc: 1.0000 - val_loss: 0.0592 - val_acc: 1.0000\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 5.4225e-04 - acc: 1.0000 - val_loss: 0.0510 - val_acc: 1.0000\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0345 - val_acc: 1.0000\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 4.2847e-04 - acc: 1.0000 - val_loss: 0.0558 - val_acc: 0.9630\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 7.1023e-04 - acc: 1.0000 - val_loss: 0.0920 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 6.2101e-04 - acc: 1.0000 - val_loss: 0.0495 - val_acc: 1.0000\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.4401e-04 - acc: 1.0000 - val_loss: 0.0809 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 4.0099e-04 - acc: 1.0000 - val_loss: 0.0537 - val_acc: 0.9630\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 4.7998e-04 - acc: 1.0000 - val_loss: 0.1931 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 6.2672e-04 - acc: 1.0000 - val_loss: 0.0970 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 2.4058e-04 - acc: 1.0000 - val_loss: 0.1374 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 4.6754e-04 - acc: 1.0000 - val_loss: 0.1375 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 2.9834e-04 - acc: 1.0000 - val_loss: 0.1479 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 6.2859e-04 - acc: 1.0000 - val_loss: 0.0185 - val_acc: 1.0000\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1769 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 2.2075e-04 - acc: 1.0000 - val_loss: 0.1258 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 1.9786e-04 - acc: 1.0000 - val_loss: 0.2477 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 4.2861e-04 - acc: 1.0000 - val_loss: 0.1613 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 6.5514e-04 - acc: 1.0000 - val_loss: 0.0988 - val_acc: 0.9630\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 9.0255e-04 - acc: 1.0000 - val_loss: 0.0565 - val_acc: 0.9630\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 3.6350e-04 - acc: 1.0000 - val_loss: 0.0712 - val_acc: 0.9630\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.5468e-04 - acc: 1.0000 - val_loss: 0.1642 - val_acc: 0.9259\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 2.4205e-04 - acc: 1.0000 - val_loss: 0.0556 - val_acc: 0.9630\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 4.6546e-04 - acc: 1.0000 - val_loss: 0.1133 - val_acc: 0.9259\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.8965e-04 - acc: 1.0000 - val_loss: 0.0223 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:10:58.584471: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:10:58.750065: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:10:58.757169: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:10:59.474234: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:10:59.481316: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:11:03.249776: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:11:03.740289: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:11:03.751888: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:11:04.790948: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:11:04.802641: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:11:05.976685: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:11:05.992326: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:11:07.535875: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:11:07.549278: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6096 - acc: 0.1549"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:11:12.376704: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:11:12.592100: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:11:12.599217: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:11:13.323588: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:11:13.331001: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 13s 5s/step - loss: 1.6096 - acc: 0.1549 - val_loss: 1.5840 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5777 - acc: 0.4366 - val_loss: 1.5579 - val_acc: 0.7037\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5444 - acc: 0.4789 - val_loss: 1.5078 - val_acc: 0.6296\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.4970 - acc: 0.5070 - val_loss: 1.4354 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 1s 764ms/step - loss: 1.4711 - acc: 0.3380 - val_loss: 1.3846 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 1s 609ms/step - loss: 1.3757 - acc: 0.4789 - val_loss: 1.3132 - val_acc: 0.5185\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 1s 593ms/step - loss: 1.2224 - acc: 0.6901 - val_loss: 1.2312 - val_acc: 0.5926\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 1s 501ms/step - loss: 1.0255 - acc: 0.6761 - val_loss: 2.0084 - val_acc: 0.1852\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 1.5734 - acc: 0.3239 - val_loss: 0.9391 - val_acc: 0.6296\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 1s 513ms/step - loss: 0.7085 - acc: 0.7887 - val_loss: 0.7653 - val_acc: 0.7407\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 1s 418ms/step - loss: 0.5654 - acc: 0.9296 - val_loss: 0.6276 - val_acc: 0.8889\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 327ms/step - loss: 0.4552 - acc: 0.9718 - val_loss: 0.4974 - val_acc: 0.9259\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 1s 527ms/step - loss: 0.3499 - acc: 0.9859 - val_loss: 0.4250 - val_acc: 1.0000\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.2886 - acc: 1.0000 - val_loss: 0.5280 - val_acc: 0.7778\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 1s 559ms/step - loss: 0.2979 - acc: 0.8873 - val_loss: 0.4494 - val_acc: 0.7778\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 1s 398ms/step - loss: 0.2457 - acc: 0.9155 - val_loss: 0.2930 - val_acc: 0.9259\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.1046 - acc: 1.0000 - val_loss: 0.2972 - val_acc: 0.9259\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 1s 366ms/step - loss: 0.0683 - acc: 1.0000 - val_loss: 0.3632 - val_acc: 0.8889\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 0.0661 - acc: 0.9718 - val_loss: 0.3404 - val_acc: 0.9259\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.0376 - acc: 1.0000 - val_loss: 0.2921 - val_acc: 0.9259\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 0.0327 - acc: 1.0000 - val_loss: 0.2305 - val_acc: 0.9259\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 0.0194 - acc: 1.0000 - val_loss: 0.1997 - val_acc: 0.9259\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 212ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.1465 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 172ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.1342 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.1050 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0935 - val_acc: 0.9630\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0925 - val_acc: 0.9630\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0812 - val_acc: 0.9630\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 190ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0913 - val_acc: 0.9630\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0734 - val_acc: 1.0000\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0756 - val_acc: 1.0000\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 7.4976e-04 - acc: 1.0000 - val_loss: 0.0731 - val_acc: 1.0000\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 7.8437e-04 - acc: 1.0000 - val_loss: 0.0610 - val_acc: 1.0000\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 7.6851e-04 - acc: 1.0000 - val_loss: 0.0695 - val_acc: 1.0000\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 5.7796e-04 - acc: 1.0000 - val_loss: 0.0647 - val_acc: 1.0000\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 5.2025e-04 - acc: 1.0000 - val_loss: 0.0795 - val_acc: 1.0000\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 5.5408e-04 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 1.0000\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 4.8217e-04 - acc: 1.0000 - val_loss: 0.0707 - val_acc: 1.0000\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 3.9607e-04 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 1.0000\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 5.4685e-04 - acc: 1.0000 - val_loss: 0.0707 - val_acc: 1.0000\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 3.3369e-04 - acc: 1.0000 - val_loss: 0.0705 - val_acc: 1.0000\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 3.2516e-04 - acc: 1.0000 - val_loss: 0.0638 - val_acc: 1.0000\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 2.8819e-04 - acc: 1.0000 - val_loss: 0.0698 - val_acc: 1.0000\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 2.3622e-04 - acc: 1.0000 - val_loss: 0.0660 - val_acc: 1.0000\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.7039e-04 - acc: 1.0000 - val_loss: 0.0637 - val_acc: 1.0000\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 2.6704e-04 - acc: 1.0000 - val_loss: 0.0745 - val_acc: 1.0000\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 2.9654e-04 - acc: 1.0000 - val_loss: 0.0717 - val_acc: 1.0000\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.3310e-04 - acc: 1.0000 - val_loss: 0.0707 - val_acc: 1.0000\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.3207e-04 - acc: 1.0000 - val_loss: 0.0702 - val_acc: 1.0000\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 3.0606e-04 - acc: 1.0000 - val_loss: 0.0658 - val_acc: 1.0000\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 2.7739e-04 - acc: 1.0000 - val_loss: 0.0710 - val_acc: 1.0000\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1.9596e-04 - acc: 1.0000 - val_loss: 0.0634 - val_acc: 1.0000\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.7231e-04 - acc: 1.0000 - val_loss: 0.0734 - val_acc: 1.0000\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.8722e-04 - acc: 1.0000 - val_loss: 0.0759 - val_acc: 0.9630\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 2.1402e-04 - acc: 1.0000 - val_loss: 0.0657 - val_acc: 1.0000\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 3.5499e-04 - acc: 1.0000 - val_loss: 0.0773 - val_acc: 0.9630\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.0712e-04 - acc: 1.0000 - val_loss: 0.0692 - val_acc: 1.0000\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.3180e-04 - acc: 1.0000 - val_loss: 0.0715 - val_acc: 1.0000\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 2.7903e-04 - acc: 1.0000 - val_loss: 0.0733 - val_acc: 0.9630\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 2.5524e-04 - acc: 1.0000 - val_loss: 0.0720 - val_acc: 0.9630\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.6313e-04 - acc: 1.0000 - val_loss: 0.0676 - val_acc: 1.0000\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 2.4536e-04 - acc: 1.0000 - val_loss: 0.0807 - val_acc: 0.9630\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 1.7956e-04 - acc: 1.0000 - val_loss: 0.0756 - val_acc: 0.9630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:11:40.902407: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:11:41.069393: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:11:41.076541: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:11:41.798804: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:11:41.805866: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:11:45.639608: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:11:46.115922: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:11:46.126770: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:11:47.111372: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:11:47.122218: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:11:48.335092: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:11:48.348432: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:11:49.923009: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:11:49.936378: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6060 - acc: 0.1972"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:11:54.700510: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:11:54.921550: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:11:54.928758: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:11:55.667862: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:11:55.674906: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 13s 5s/step - loss: 1.6060 - acc: 0.1972 - val_loss: 1.5848 - val_acc: 0.4074\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5855 - acc: 0.4930 - val_loss: 1.5360 - val_acc: 0.3704\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 2s 988ms/step - loss: 1.5319 - acc: 0.4085 - val_loss: 1.4701 - val_acc: 0.4074\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 1s 613ms/step - loss: 1.4609 - acc: 0.4648 - val_loss: 1.4396 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 2s 2s/step - loss: 1.3318 - acc: 0.3944 - val_loss: 1.4524 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 1s 517ms/step - loss: 1.3407 - acc: 0.3944 - val_loss: 1.2412 - val_acc: 0.5185\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 1s 767ms/step - loss: 1.1831 - acc: 0.6338 - val_loss: 1.0951 - val_acc: 0.7037\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 1s 569ms/step - loss: 0.9168 - acc: 0.7324 - val_loss: 1.3689 - val_acc: 0.4815\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 1s 664ms/step - loss: 1.0170 - acc: 0.6056 - val_loss: 0.8067 - val_acc: 0.7037\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 1s 397ms/step - loss: 0.6468 - acc: 0.8028 - val_loss: 0.6030 - val_acc: 0.7407\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 1s 557ms/step - loss: 0.4779 - acc: 0.8028 - val_loss: 0.5585 - val_acc: 0.7037\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 1s 332ms/step - loss: 0.3856 - acc: 0.8169 - val_loss: 0.4541 - val_acc: 0.7778\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 367ms/step - loss: 0.3402 - acc: 0.8732 - val_loss: 0.7722 - val_acc: 0.7037\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 0.3242 - acc: 0.8592 - val_loss: 0.4793 - val_acc: 0.8519\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 1s 858ms/step - loss: 0.3166 - acc: 0.8732 - val_loss: 0.5192 - val_acc: 0.7407\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 1s 212ms/step - loss: 0.2052 - acc: 0.9014 - val_loss: 0.5256 - val_acc: 0.8889\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.1536 - acc: 0.9718 - val_loss: 0.3807 - val_acc: 0.9259\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.1141 - acc: 0.9718 - val_loss: 0.3200 - val_acc: 0.9259\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 1s 412ms/step - loss: 0.1117 - acc: 1.0000 - val_loss: 0.2748 - val_acc: 0.9259\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 253ms/step - loss: 0.0823 - acc: 0.9577 - val_loss: 0.2419 - val_acc: 0.8519\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.0664 - acc: 0.9718 - val_loss: 0.1775 - val_acc: 0.9259\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.0469 - acc: 1.0000 - val_loss: 0.1206 - val_acc: 1.0000\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.0299 - acc: 1.0000 - val_loss: 0.0816 - val_acc: 1.0000\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0386 - acc: 0.9859 - val_loss: 0.0997 - val_acc: 0.9630\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 171ms/step - loss: 0.0275 - acc: 1.0000 - val_loss: 0.0939 - val_acc: 0.9630\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.0839 - val_acc: 0.9630\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 168ms/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.1468 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1789 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.3062 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 169ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.3649 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 169ms/step - loss: 4.3634e-04 - acc: 1.0000 - val_loss: 0.3840 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 4.1219e-04 - acc: 1.0000 - val_loss: 0.4575 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 4.8051e-04 - acc: 1.0000 - val_loss: 0.4775 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 4.6111e-04 - acc: 1.0000 - val_loss: 0.5344 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 3.9670e-04 - acc: 1.0000 - val_loss: 0.6621 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 4.8947e-04 - acc: 1.0000 - val_loss: 0.7323 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 7.6508e-04 - acc: 1.0000 - val_loss: 0.7442 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.8975 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 4.3441e-04 - acc: 1.0000 - val_loss: 0.7788 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 2.2851e-04 - acc: 1.0000 - val_loss: 0.6773 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.8563 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 2.0101e-04 - acc: 1.0000 - val_loss: 0.8731 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.1922e-04 - acc: 1.0000 - val_loss: 0.7867 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.9222e-04 - acc: 1.0000 - val_loss: 0.9272 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 2.4151e-04 - acc: 1.0000 - val_loss: 0.7414 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 4.6789e-04 - acc: 1.0000 - val_loss: 0.8312 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0275 - acc: 0.9859 - val_loss: 0.8568 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 2.3317e-04 - acc: 1.0000 - val_loss: 0.9115 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.6711 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 0.0633 - acc: 0.9859 - val_loss: 0.7819 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0298 - acc: 0.9859 - val_loss: 0.9874 - val_acc: 0.8889\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0304 - acc: 1.0000 - val_loss: 0.7809 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0510 - acc: 0.9859 - val_loss: 0.8212 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0250 - acc: 0.9859 - val_loss: 0.7542 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0847 - acc: 0.9718 - val_loss: 0.8121 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.7983 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.8310 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.1063 - acc: 0.9859 - val_loss: 0.8729 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.1957 - acc: 0.9437 - val_loss: 0.8523 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1.8013e-04 - acc: 1.0000 - val_loss: 1.0959 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.3093 - val_acc: 0.8148\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0495 - acc: 0.9859 - val_loss: 1.2629 - val_acc: 0.8889\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0228 - acc: 0.9859 - val_loss: 0.5721 - val_acc: 0.9630\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0141 - acc: 0.9859 - val_loss: 0.4920 - val_acc: 0.9630\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.5279 - val_acc: 0.9630\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0959 - acc: 0.9859 - val_loss: 0.5646 - val_acc: 0.9630\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 2.7695e-04 - acc: 1.0000 - val_loss: 1.0070 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 1.3792 - val_acc: 0.8889\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.0066 - val_acc: 0.8148\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.9059 - val_acc: 0.9259\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.5446 - val_acc: 0.9259\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 9.8344e-04 - acc: 1.0000 - val_loss: 0.5075 - val_acc: 0.9630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:12:25.204523: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:12:25.387806: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:12:25.394941: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:12:26.157016: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:12:26.166527: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:12:29.942469: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:12:30.431284: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:12:30.442333: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:12:31.477378: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:12:31.488248: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:12:32.735106: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:12:32.748503: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:12:34.421598: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:12:34.435041: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6092 - acc: 0.2113"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:12:39.403939: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:12:39.616644: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:12:39.623780: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:12:40.360079: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:12:40.367198: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 14s 5s/step - loss: 1.6092 - acc: 0.2113 - val_loss: 1.5763 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5700 - acc: 0.4225 - val_loss: 1.5256 - val_acc: 0.5185\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5156 - acc: 0.5775 - val_loss: 1.4554 - val_acc: 0.5556\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 2s 881ms/step - loss: 1.4370 - acc: 0.3944 - val_loss: 1.3818 - val_acc: 0.4444\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 1s 798ms/step - loss: 1.3472 - acc: 0.5211 - val_loss: 1.2981 - val_acc: 0.4444\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 1s 775ms/step - loss: 1.2025 - acc: 0.4789 - val_loss: 1.3506 - val_acc: 0.4074\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 2s 833ms/step - loss: 1.1435 - acc: 0.4789 - val_loss: 0.9779 - val_acc: 0.7778\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 1s 605ms/step - loss: 0.8497 - acc: 0.7746 - val_loss: 0.9392 - val_acc: 0.7778\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 1s 486ms/step - loss: 0.7288 - acc: 0.8028 - val_loss: 0.7107 - val_acc: 0.7037\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 1s 399ms/step - loss: 0.5316 - acc: 0.8169 - val_loss: 0.6950 - val_acc: 0.6667\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 1s 204ms/step - loss: 0.4330 - acc: 0.8028 - val_loss: 0.5328 - val_acc: 0.7778\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 349ms/step - loss: 0.3392 - acc: 0.8592 - val_loss: 0.4775 - val_acc: 0.8889\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 1s 479ms/step - loss: 0.2254 - acc: 0.9718 - val_loss: 0.5848 - val_acc: 0.7037\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.2441 - acc: 0.9014 - val_loss: 0.3634 - val_acc: 0.7778\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.1768 - acc: 0.9155 - val_loss: 0.2937 - val_acc: 0.9259\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 190ms/step - loss: 0.1333 - acc: 0.9859 - val_loss: 0.3453 - val_acc: 0.9259\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.1161 - acc: 1.0000 - val_loss: 0.3794 - val_acc: 0.8519\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 272ms/step - loss: 0.1334 - acc: 0.9859 - val_loss: 0.2866 - val_acc: 0.9259\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 300ms/step - loss: 0.0464 - acc: 1.0000 - val_loss: 0.2435 - val_acc: 0.9259\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.0629 - acc: 1.0000 - val_loss: 0.2418 - val_acc: 0.9259\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 0.0987 - acc: 0.9296 - val_loss: 0.1654 - val_acc: 0.9259\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.0177 - acc: 1.0000 - val_loss: 0.2010 - val_acc: 0.9259\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.0206 - acc: 1.0000 - val_loss: 0.2403 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.3415 - val_acc: 0.8889\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0245 - acc: 0.9859 - val_loss: 0.5659 - val_acc: 0.8889\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.5989 - val_acc: 0.8889\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.4031 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.4160 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 6.3030e-04 - acc: 1.0000 - val_loss: 0.3055 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 4.1208e-04 - acc: 1.0000 - val_loss: 0.2752 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 1.7564e-04 - acc: 1.0000 - val_loss: 0.2898 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 2.0519e-04 - acc: 1.0000 - val_loss: 0.1865 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 3.6281e-04 - acc: 1.0000 - val_loss: 0.2716 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 2.2057e-04 - acc: 1.0000 - val_loss: 0.2723 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 2.5766e-04 - acc: 1.0000 - val_loss: 0.2378 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 3.3737e-04 - acc: 1.0000 - val_loss: 0.2483 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 2.5492e-04 - acc: 1.0000 - val_loss: 0.1730 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.8655e-04 - acc: 1.0000 - val_loss: 0.2413 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 3.1213e-04 - acc: 1.0000 - val_loss: 0.1979 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 2.2897e-04 - acc: 1.0000 - val_loss: 0.1687 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 2.9192e-04 - acc: 1.0000 - val_loss: 0.1836 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.2201e-04 - acc: 1.0000 - val_loss: 0.1950 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 2.2907e-04 - acc: 1.0000 - val_loss: 0.1762 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.7569e-04 - acc: 1.0000 - val_loss: 0.2126 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 2.0251e-04 - acc: 1.0000 - val_loss: 0.2265 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 2.3472e-04 - acc: 1.0000 - val_loss: 0.2193 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 182ms/step - loss: 1.1360e-04 - acc: 1.0000 - val_loss: 0.2123 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 3.8406e-04 - acc: 1.0000 - val_loss: 0.1914 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.2977e-04 - acc: 1.0000 - val_loss: 0.1990 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 2.2306e-04 - acc: 1.0000 - val_loss: 0.2300 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 2.5488e-04 - acc: 1.0000 - val_loss: 0.1941 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.7234e-04 - acc: 1.0000 - val_loss: 0.2164 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 2.9195e-04 - acc: 1.0000 - val_loss: 0.2007 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 6.2508e-05 - acc: 1.0000 - val_loss: 0.1878 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.1466e-04 - acc: 1.0000 - val_loss: 0.2140 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 7.3772e-05 - acc: 1.0000 - val_loss: 0.2427 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.1609e-04 - acc: 1.0000 - val_loss: 0.2184 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1788e-04 - acc: 1.0000 - val_loss: 0.1982 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 9.0214e-05 - acc: 1.0000 - val_loss: 0.2617 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.6520e-04 - acc: 1.0000 - val_loss: 0.1962 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.0903e-04 - acc: 1.0000 - val_loss: 0.2053 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 9.9451e-05 - acc: 1.0000 - val_loss: 0.1561 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 8.9191e-05 - acc: 1.0000 - val_loss: 0.2242 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 6.9348e-05 - acc: 1.0000 - val_loss: 0.1732 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.2466e-04 - acc: 1.0000 - val_loss: 0.2726 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:13:08.791090: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:13:08.962512: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:13:08.969562: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:13:09.709433: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:13:09.716429: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:13:13.390671: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:13:13.845465: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:13:13.856947: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:13:14.879810: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:13:14.903660: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:13:16.126145: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:13:16.139450: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:13:17.753486: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:13:17.767153: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6081 - acc: 0.1972"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:13:22.699784: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:13:22.920041: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:13:22.927322: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:13:23.672590: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:13:23.679710: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 14s 5s/step - loss: 1.6081 - acc: 0.1972 - val_loss: 1.5630 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5478 - acc: 0.3944 - val_loss: 1.4804 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.4472 - acc: 0.3662 - val_loss: 1.5882 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.4678 - acc: 0.3380 - val_loss: 1.3711 - val_acc: 0.4074\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 2s 651ms/step - loss: 1.3084 - acc: 0.4507 - val_loss: 1.2462 - val_acc: 0.6667\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 1s 719ms/step - loss: 1.1470 - acc: 0.8028 - val_loss: 1.0596 - val_acc: 0.7037\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.8841 - acc: 0.7465 - val_loss: 1.0325 - val_acc: 0.5185\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 1s 551ms/step - loss: 0.8414 - acc: 0.5915 - val_loss: 0.7087 - val_acc: 0.7037\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 1s 427ms/step - loss: 0.4912 - acc: 0.7746 - val_loss: 0.5264 - val_acc: 0.7407\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 1s 975ms/step - loss: 0.3521 - acc: 0.8873 - val_loss: 0.4781 - val_acc: 0.8519\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 1s 455ms/step - loss: 0.3283 - acc: 0.9155 - val_loss: 0.4047 - val_acc: 0.9630\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 1s 441ms/step - loss: 0.2737 - acc: 0.9296 - val_loss: 0.3287 - val_acc: 1.0000\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 265ms/step - loss: 0.1872 - acc: 1.0000 - val_loss: 0.2913 - val_acc: 0.9259\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 1s 445ms/step - loss: 0.1495 - acc: 1.0000 - val_loss: 0.3132 - val_acc: 0.8889\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 271ms/step - loss: 0.1124 - acc: 0.9859 - val_loss: 0.3398 - val_acc: 0.8889\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 1s 261ms/step - loss: 0.0924 - acc: 0.9718 - val_loss: 0.3218 - val_acc: 0.8889\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.0752 - acc: 0.9718 - val_loss: 0.1929 - val_acc: 0.9259\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 0.0400 - acc: 1.0000 - val_loss: 0.1909 - val_acc: 0.9259\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 249ms/step - loss: 0.0687 - acc: 0.9718 - val_loss: 0.0953 - val_acc: 0.9630\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 0.0175 - acc: 1.0000 - val_loss: 0.1735 - val_acc: 0.9259\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 256ms/step - loss: 0.0624 - acc: 0.9718 - val_loss: 0.0450 - val_acc: 1.0000\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 269ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0838 - val_acc: 0.9630\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.1504 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.2239 - val_acc: 0.8889\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.1857 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0178 - acc: 1.0000 - val_loss: 0.1115 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 178ms/step - loss: 5.5285e-04 - acc: 1.0000 - val_loss: 0.1014 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 6.2339e-04 - acc: 1.0000 - val_loss: 0.0870 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 2.7717e-04 - acc: 1.0000 - val_loss: 0.1182 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 3.6742e-04 - acc: 1.0000 - val_loss: 0.0869 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 4.6132e-04 - acc: 1.0000 - val_loss: 0.1348 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 295ms/step - loss: 5.2274e-04 - acc: 1.0000 - val_loss: 0.1416 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 300ms/step - loss: 5.2652e-04 - acc: 1.0000 - val_loss: 0.1190 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 9.8121e-04 - acc: 1.0000 - val_loss: 0.1845 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 3.9520e-04 - acc: 1.0000 - val_loss: 0.1572 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 3.9348e-04 - acc: 1.0000 - val_loss: 0.1471 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 3.2295e-04 - acc: 1.0000 - val_loss: 0.1354 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 2.1154e-04 - acc: 1.0000 - val_loss: 0.1315 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 5.8377e-04 - acc: 1.0000 - val_loss: 0.1442 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.7521e-04 - acc: 1.0000 - val_loss: 0.1904 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.4289e-04 - acc: 1.0000 - val_loss: 0.1947 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 2.7384e-04 - acc: 1.0000 - val_loss: 0.1953 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 4.2105e-04 - acc: 1.0000 - val_loss: 0.1544 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 2.2052e-04 - acc: 1.0000 - val_loss: 0.1579 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 1.2085e-04 - acc: 1.0000 - val_loss: 0.1038 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.8045e-04 - acc: 1.0000 - val_loss: 0.1257 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.4256e-04 - acc: 1.0000 - val_loss: 0.1799 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 3.2583e-04 - acc: 1.0000 - val_loss: 0.1721 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 2.8274e-04 - acc: 1.0000 - val_loss: 0.1243 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.2313e-04 - acc: 1.0000 - val_loss: 0.1143 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.2572e-04 - acc: 1.0000 - val_loss: 0.0996 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 2.4946e-04 - acc: 1.0000 - val_loss: 0.1390 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.9345e-04 - acc: 1.0000 - val_loss: 0.1128 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.4511e-04 - acc: 1.0000 - val_loss: 0.1197 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.7057e-04 - acc: 1.0000 - val_loss: 0.1023 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.7631e-04 - acc: 1.0000 - val_loss: 0.1247 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 2.4284e-04 - acc: 1.0000 - val_loss: 0.1215 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.0398e-04 - acc: 1.0000 - val_loss: 0.0942 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.8892e-04 - acc: 1.0000 - val_loss: 0.1611 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.2583e-04 - acc: 1.0000 - val_loss: 0.1604 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.3101e-04 - acc: 1.0000 - val_loss: 0.1460 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.3227e-04 - acc: 1.0000 - val_loss: 0.1204 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:13:52.398596: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:13:52.572424: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:13:52.579540: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:13:53.335551: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:13:53.343374: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:13:57.176110: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:13:57.685925: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:13:57.708426: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:13:58.696143: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:13:58.706973: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:13:59.913911: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:13:59.927078: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:14:01.512959: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:14:01.526139: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6087 - acc: 0.1831"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:14:05.964900: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:14:06.187988: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:14:06.195318: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:14:07.029183: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:14:07.036255: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 13s 5s/step - loss: 1.6087 - acc: 0.1831 - val_loss: 1.5833 - val_acc: 0.6296\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.5786 - acc: 0.3662 - val_loss: 1.5365 - val_acc: 0.3704\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5069 - acc: 0.4366 - val_loss: 1.4785 - val_acc: 0.3704\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.4104 - acc: 0.4225 - val_loss: 1.4155 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 2s 840ms/step - loss: 1.3614 - acc: 0.4789 - val_loss: 1.2776 - val_acc: 0.3704\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 1s 606ms/step - loss: 1.1725 - acc: 0.5070 - val_loss: 1.1680 - val_acc: 0.3333\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 1s 625ms/step - loss: 1.0695 - acc: 0.6056 - val_loss: 0.9439 - val_acc: 0.8148\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 1s 934ms/step - loss: 0.9932 - acc: 0.7606 - val_loss: 1.3845 - val_acc: 0.5185\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 1s 543ms/step - loss: 1.3130 - acc: 0.5070 - val_loss: 1.2062 - val_acc: 0.4444\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 1s 435ms/step - loss: 1.1633 - acc: 0.5352 - val_loss: 1.0056 - val_acc: 0.8889\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 1s 716ms/step - loss: 0.8710 - acc: 0.7887 - val_loss: 0.8485 - val_acc: 0.8889\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 0.7144 - acc: 0.9155 - val_loss: 0.7349 - val_acc: 0.8519\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 1s 564ms/step - loss: 0.5442 - acc: 0.9437 - val_loss: 0.7118 - val_acc: 0.8148\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 1s 526ms/step - loss: 0.5069 - acc: 0.8873 - val_loss: 0.6448 - val_acc: 0.7037\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 241ms/step - loss: 0.4345 - acc: 0.7887 - val_loss: 0.5067 - val_acc: 0.7037\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 1s 309ms/step - loss: 0.3672 - acc: 0.8310 - val_loss: 0.3928 - val_acc: 0.7778\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.2390 - acc: 0.9014 - val_loss: 0.4265 - val_acc: 0.8889\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 0.1741 - acc: 0.9859 - val_loss: 0.3739 - val_acc: 0.9259\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.1605 - acc: 0.9859 - val_loss: 0.2872 - val_acc: 0.9259\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 253ms/step - loss: 0.1007 - acc: 0.9859 - val_loss: 0.2183 - val_acc: 0.9259\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.0745 - acc: 1.0000 - val_loss: 0.1842 - val_acc: 0.9259\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.0515 - acc: 1.0000 - val_loss: 0.1643 - val_acc: 0.9259\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0394 - acc: 1.0000 - val_loss: 0.1432 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 250ms/step - loss: 0.0269 - acc: 1.0000 - val_loss: 0.1686 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 292ms/step - loss: 0.0238 - acc: 1.0000 - val_loss: 0.1969 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.2473 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.2047 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.2888 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.2971 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.3297 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.3647 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 171ms/step - loss: 6.7218e-04 - acc: 1.0000 - val_loss: 0.3565 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 5.8891e-04 - acc: 1.0000 - val_loss: 0.3711 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 9.3345e-04 - acc: 1.0000 - val_loss: 0.3352 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 7.1458e-04 - acc: 1.0000 - val_loss: 0.3361 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 5.8870e-04 - acc: 1.0000 - val_loss: 0.3400 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 4.1890e-04 - acc: 1.0000 - val_loss: 0.3674 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 4.3760e-04 - acc: 1.0000 - val_loss: 0.3933 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 4.7418e-04 - acc: 1.0000 - val_loss: 0.3539 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 4.8673e-04 - acc: 1.0000 - val_loss: 0.3319 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 2.2064e-04 - acc: 1.0000 - val_loss: 0.3510 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 3.6840e-04 - acc: 1.0000 - val_loss: 0.3247 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 3.5650e-04 - acc: 1.0000 - val_loss: 0.3925 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 3.1672e-04 - acc: 1.0000 - val_loss: 0.3375 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 2.3410e-04 - acc: 1.0000 - val_loss: 0.3460 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 2.2411e-04 - acc: 1.0000 - val_loss: 0.3543 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 5.4402e-04 - acc: 1.0000 - val_loss: 0.3128 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 2.9868e-04 - acc: 1.0000 - val_loss: 0.3368 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.8682e-04 - acc: 1.0000 - val_loss: 0.3372 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.0308e-04 - acc: 1.0000 - val_loss: 0.3370 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 2.3688e-04 - acc: 1.0000 - val_loss: 0.2902 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 2.2332e-04 - acc: 1.0000 - val_loss: 0.3263 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 172ms/step - loss: 1.6949e-04 - acc: 1.0000 - val_loss: 0.3551 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 2.8462e-04 - acc: 1.0000 - val_loss: 0.3487 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 1.9660e-04 - acc: 1.0000 - val_loss: 0.3620 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 2.0705e-04 - acc: 1.0000 - val_loss: 0.3561 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.5629e-04 - acc: 1.0000 - val_loss: 0.3004 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.3165e-04 - acc: 1.0000 - val_loss: 0.3149 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.6482e-04 - acc: 1.0000 - val_loss: 0.3364 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 2.6090e-04 - acc: 1.0000 - val_loss: 0.3730 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 2.3720e-04 - acc: 1.0000 - val_loss: 0.3217 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 2.0934e-04 - acc: 1.0000 - val_loss: 0.3136 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.4542e-04 - acc: 1.0000 - val_loss: 0.3093 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 2.2202e-04 - acc: 1.0000 - val_loss: 0.2436 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.7184e-04 - acc: 1.0000 - val_loss: 0.3282 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 1.0603e-04 - acc: 1.0000 - val_loss: 0.2514 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 1.3769e-04 - acc: 1.0000 - val_loss: 0.2876 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:14:37.276694: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:14:37.456005: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:14:37.463033: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:14:38.244965: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:14:38.252139: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:14:42.198395: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:14:42.686607: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:14:42.697650: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:14:43.720624: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:14:43.731437: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:14:44.957505: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:14:44.971560: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:14:46.611695: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:14:46.625548: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6046 - acc: 0.2535"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:14:51.508275: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:14:51.732820: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:14:51.740237: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:14:52.521681: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:14:52.528917: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 14s 5s/step - loss: 1.6046 - acc: 0.2535 - val_loss: 1.5605 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 4s 2s/step - loss: 1.5544 - acc: 0.4366 - val_loss: 1.4879 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.4462 - acc: 0.3944 - val_loss: 1.4583 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.4010 - acc: 0.3803 - val_loss: 1.3371 - val_acc: 0.5556\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 2s 723ms/step - loss: 1.2771 - acc: 0.5915 - val_loss: 1.1838 - val_acc: 0.7407\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 1s 866ms/step - loss: 1.1153 - acc: 0.8028 - val_loss: 0.8930 - val_acc: 0.7407\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 1s 755ms/step - loss: 0.8360 - acc: 0.7887 - val_loss: 1.1984 - val_acc: 0.4074\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 1s 260ms/step - loss: 0.9422 - acc: 0.5493 - val_loss: 0.7378 - val_acc: 0.7037\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 1s 723ms/step - loss: 0.5904 - acc: 0.8451 - val_loss: 0.6997 - val_acc: 0.7407\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 1s 595ms/step - loss: 0.5252 - acc: 0.8732 - val_loss: 0.5584 - val_acc: 0.8889\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 1s 242ms/step - loss: 0.3976 - acc: 0.9718 - val_loss: 0.5105 - val_acc: 0.9259\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 1s 802ms/step - loss: 0.3180 - acc: 1.0000 - val_loss: 0.4323 - val_acc: 0.9259\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 0.2535 - acc: 0.9859 - val_loss: 0.3565 - val_acc: 0.9259\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 0.1971 - acc: 1.0000 - val_loss: 0.2937 - val_acc: 0.9630\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 1s 206ms/step - loss: 0.1817 - acc: 0.9859 - val_loss: 0.2427 - val_acc: 0.9630\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 1s 236ms/step - loss: 0.1127 - acc: 1.0000 - val_loss: 0.2060 - val_acc: 0.9259\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 0.0537 - acc: 1.0000 - val_loss: 0.1534 - val_acc: 0.9259\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.0372 - acc: 1.0000 - val_loss: 0.1925 - val_acc: 0.9259\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.3239 - val_acc: 0.8889\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 348ms/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.2264 - val_acc: 0.9259\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.2189 - val_acc: 0.9259\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 282ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.1687 - val_acc: 0.9259\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.1764 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.1890 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.1580 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 172ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1600 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 191ms/step - loss: 6.2051e-04 - acc: 1.0000 - val_loss: 0.1407 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 5.7030e-04 - acc: 1.0000 - val_loss: 0.1490 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 6.8353e-04 - acc: 1.0000 - val_loss: 0.1557 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 5.4990e-04 - acc: 1.0000 - val_loss: 0.1641 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 2.8900e-04 - acc: 1.0000 - val_loss: 0.1448 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 3.7246e-04 - acc: 1.0000 - val_loss: 0.1577 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.9100e-04 - acc: 1.0000 - val_loss: 0.1410 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 227ms/step - loss: 1.3960e-04 - acc: 1.0000 - val_loss: 0.1591 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 224ms/step - loss: 3.0136e-04 - acc: 1.0000 - val_loss: 0.1331 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 2.4598e-04 - acc: 1.0000 - val_loss: 0.1433 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 2.6700e-04 - acc: 1.0000 - val_loss: 0.1753 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.0917e-04 - acc: 1.0000 - val_loss: 0.1468 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 213ms/step - loss: 1.8941e-04 - acc: 1.0000 - val_loss: 0.1552 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 1.1972e-04 - acc: 1.0000 - val_loss: 0.1128 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.1628e-04 - acc: 1.0000 - val_loss: 0.1588 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.6959e-04 - acc: 1.0000 - val_loss: 0.1253 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 2.1280e-04 - acc: 1.0000 - val_loss: 0.1472 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.9587e-04 - acc: 1.0000 - val_loss: 0.1370 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.2541e-04 - acc: 1.0000 - val_loss: 0.1647 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.0825e-04 - acc: 1.0000 - val_loss: 0.1401 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.5593e-04 - acc: 1.0000 - val_loss: 0.1710 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.4268e-04 - acc: 1.0000 - val_loss: 0.1574 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.3250e-04 - acc: 1.0000 - val_loss: 0.1397 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 6.3986e-05 - acc: 1.0000 - val_loss: 0.1574 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.4270e-04 - acc: 1.0000 - val_loss: 0.1387 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 2.2148e-04 - acc: 1.0000 - val_loss: 0.1513 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.6640e-04 - acc: 1.0000 - val_loss: 0.1278 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 5.2248e-05 - acc: 1.0000 - val_loss: 0.1608 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 9.2935e-05 - acc: 1.0000 - val_loss: 0.1636 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.7148e-04 - acc: 1.0000 - val_loss: 0.1542 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 7.0598e-05 - acc: 1.0000 - val_loss: 0.1749 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 9.2712e-05 - acc: 1.0000 - val_loss: 0.1426 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 5.4164e-05 - acc: 1.0000 - val_loss: 0.1657 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.1627e-04 - acc: 1.0000 - val_loss: 0.1663 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.1655e-04 - acc: 1.0000 - val_loss: 0.1675 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 2.7653e-04 - acc: 1.0000 - val_loss: 0.1728 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 7.0250e-05 - acc: 1.0000 - val_loss: 0.1907 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 1.5924e-04 - acc: 1.0000 - val_loss: 0.1741 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:15:22.391007: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:15:22.570682: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:15:22.577961: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:15:23.342090: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:15:23.349107: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:15:27.057782: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:15:27.594210: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:15:27.619398: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:15:28.708815: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:15:28.719970: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:15:29.988625: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:15:30.001818: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:15:31.579239: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:15:31.592433: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6098 - acc: 0.1127"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:15:36.362083: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:15:36.589094: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:15:36.596444: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:15:37.369719: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:15:37.376854: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 14s 5s/step - loss: 1.6098 - acc: 0.1127 - val_loss: 1.5661 - val_acc: 0.4444\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5613 - acc: 0.4366 - val_loss: 1.4881 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.4584 - acc: 0.4930 - val_loss: 1.3996 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.3537 - acc: 0.3662 - val_loss: 1.5824 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 2s 814ms/step - loss: 1.3055 - acc: 0.4225 - val_loss: 1.0858 - val_acc: 0.6667\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 2s 527ms/step - loss: 0.9110 - acc: 0.8028 - val_loss: 0.8301 - val_acc: 0.7778\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.6798 - acc: 0.6901 - val_loss: 0.9504 - val_acc: 0.5926\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 1s 632ms/step - loss: 0.5960 - acc: 0.7183 - val_loss: 0.5298 - val_acc: 0.7407\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 1s 618ms/step - loss: 0.3277 - acc: 0.9155 - val_loss: 0.4396 - val_acc: 0.8519\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 1s 492ms/step - loss: 0.2856 - acc: 0.8732 - val_loss: 0.3429 - val_acc: 0.8519\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 1s 761ms/step - loss: 0.2282 - acc: 0.8732 - val_loss: 0.3299 - val_acc: 0.8519\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 1s 475ms/step - loss: 0.1758 - acc: 0.8873 - val_loss: 0.2649 - val_acc: 0.8519\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 262ms/step - loss: 0.1484 - acc: 0.9155 - val_loss: 0.2553 - val_acc: 0.8889\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 261ms/step - loss: 0.1096 - acc: 0.9859 - val_loss: 0.2421 - val_acc: 0.9259\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 328ms/step - loss: 0.0831 - acc: 1.0000 - val_loss: 0.3098 - val_acc: 0.8519\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 1s 536ms/step - loss: 0.0469 - acc: 0.9859 - val_loss: 0.3639 - val_acc: 0.8519\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 264ms/step - loss: 0.0638 - acc: 0.9718 - val_loss: 0.1702 - val_acc: 0.9259\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.1156 - val_acc: 0.9259\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.1168 - val_acc: 0.9259\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.1065 - val_acc: 0.9259\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.1063 - val_acc: 0.9259\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0867 - val_acc: 0.9630\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0927 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 291ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0967 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0900 - val_acc: 0.9630\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0995 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0784 - val_acc: 0.9630\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 5.4336e-04 - acc: 1.0000 - val_loss: 0.1491 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.9803e-04 - acc: 1.0000 - val_loss: 0.1450 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 4.6965e-04 - acc: 1.0000 - val_loss: 0.1788 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.8563e-04 - acc: 1.0000 - val_loss: 0.1330 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 2.6180e-04 - acc: 1.0000 - val_loss: 0.1791 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 1.9745e-04 - acc: 1.0000 - val_loss: 0.2005 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.9934e-04 - acc: 1.0000 - val_loss: 0.1510 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 4.3513e-04 - acc: 1.0000 - val_loss: 0.2053 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 2.4463e-04 - acc: 1.0000 - val_loss: 0.2191 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 2.6392e-04 - acc: 1.0000 - val_loss: 0.1295 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 3.4042e-04 - acc: 1.0000 - val_loss: 0.2009 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.0204e-04 - acc: 1.0000 - val_loss: 0.1766 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.5760e-04 - acc: 1.0000 - val_loss: 0.1788 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 2.0695e-04 - acc: 1.0000 - val_loss: 0.2075 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 9.2231e-05 - acc: 1.0000 - val_loss: 0.1764 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.5451e-04 - acc: 1.0000 - val_loss: 0.2121 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.6273e-04 - acc: 1.0000 - val_loss: 0.2589 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.3184e-04 - acc: 1.0000 - val_loss: 0.1286 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 4.4819e-05 - acc: 1.0000 - val_loss: 0.1853 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 9.1023e-05 - acc: 1.0000 - val_loss: 0.1736 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.1761e-04 - acc: 1.0000 - val_loss: 0.1913 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.4156e-04 - acc: 1.0000 - val_loss: 0.2141 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 8.5901e-05 - acc: 1.0000 - val_loss: 0.2173 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 6.4455e-05 - acc: 1.0000 - val_loss: 0.2183 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 8.3438e-05 - acc: 1.0000 - val_loss: 0.1649 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 8.6824e-05 - acc: 1.0000 - val_loss: 0.1875 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 7.0326e-05 - acc: 1.0000 - val_loss: 0.2057 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 7.7328e-05 - acc: 1.0000 - val_loss: 0.1451 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 7.3163e-05 - acc: 1.0000 - val_loss: 0.1927 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 6.4620e-05 - acc: 1.0000 - val_loss: 0.1775 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 6.3262e-05 - acc: 1.0000 - val_loss: 0.1753 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 8.6456e-05 - acc: 1.0000 - val_loss: 0.1751 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 5.1552e-05 - acc: 1.0000 - val_loss: 0.2197 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 7.1094e-05 - acc: 1.0000 - val_loss: 0.1992 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 5.9682e-05 - acc: 1.0000 - val_loss: 0.2220 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 8.3471e-05 - acc: 1.0000 - val_loss: 0.2036 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 5.4529e-05 - acc: 1.0000 - val_loss: 0.1692 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 7.1054e-05 - acc: 1.0000 - val_loss: 0.2155 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 8.0614e-05 - acc: 1.0000 - val_loss: 0.1810 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 6.1892e-05 - acc: 1.0000 - val_loss: 0.1930 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 5.8583e-05 - acc: 1.0000 - val_loss: 0.2281 - val_acc: 0.9259\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 4.9017e-05 - acc: 1.0000 - val_loss: 0.2065 - val_acc: 0.9259\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 3.2695e-05 - acc: 1.0000 - val_loss: 0.2137 - val_acc: 0.9259\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.3472e-04 - acc: 1.0000 - val_loss: 0.1970 - val_acc: 0.9259\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.5559e-04 - acc: 1.0000 - val_loss: 0.1847 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:16:09.753544: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:16:09.941530: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:16:09.948986: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:16:10.761107: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:16:10.768148: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "[TULVAE:] Filename: ./TULVAE-/eval_tuvae-bilstm-200-1-0.5-100-100-64-1000-20-val_acc-0.001-['poi', 'tid', 'label'].csv.\n",
      "[TULVAE:] Creating a model to test set\n",
      "[TULVAE:] Parameters: nn_bilstm_un_200_st_1_dp_0.5_es_100_zv_100_bs_64_epoch_1000_pat_20_mon_val_acc_lr_0.001_features_['poi', 'tid', 'label']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1252c3efcef4898a622944c9d3eb93b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Model Testing:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:16:14.610133: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:16:15.141958: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:16:15.164664: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:16:16.193593: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:16:16.204766: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:16:17.481875: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:16:17.495408: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:16:19.119665: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:16:19.132829: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6085 - acc: 0.2535"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:16:24.174660: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:16:24.417403: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:16:24.425273: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:16:25.205560: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:16:25.212721: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 14s 5s/step - loss: 1.6085 - acc: 0.2535 - val_loss: 1.5930 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 2s 2s/step - loss: 1.5860 - acc: 0.4507 - val_loss: 1.5737 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5615 - acc: 0.3803 - val_loss: 1.5261 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5302 - acc: 0.3380 - val_loss: 1.4878 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 2s 943ms/step - loss: 1.4518 - acc: 0.3521 - val_loss: 1.4510 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 2s 676ms/step - loss: 1.3784 - acc: 0.3521 - val_loss: 1.4190 - val_acc: 0.3333\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.3847 - acc: 0.4085 - val_loss: 1.3583 - val_acc: 0.5185\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 1s 606ms/step - loss: 1.2722 - acc: 0.5352 - val_loss: 1.2426 - val_acc: 0.5185\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 1s 627ms/step - loss: 1.0915 - acc: 0.5352 - val_loss: 1.2479 - val_acc: 0.4444\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 1s 412ms/step - loss: 1.1084 - acc: 0.5211 - val_loss: 0.9873 - val_acc: 0.5185\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 1s 768ms/step - loss: 0.9287 - acc: 0.5775 - val_loss: 0.9788 - val_acc: 0.5185\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 1s 828ms/step - loss: 0.8714 - acc: 0.6197 - val_loss: 0.8918 - val_acc: 0.5185\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 1s 261ms/step - loss: 0.8031 - acc: 0.5493 - val_loss: 0.7545 - val_acc: 0.5185\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 213ms/step - loss: 0.6845 - acc: 0.6197 - val_loss: 0.7028 - val_acc: 0.5926\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 1s 444ms/step - loss: 0.5787 - acc: 0.7042 - val_loss: 0.5908 - val_acc: 0.8148\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 351ms/step - loss: 0.4883 - acc: 0.8592 - val_loss: 0.4704 - val_acc: 0.8519\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 223ms/step - loss: 0.4062 - acc: 0.8310 - val_loss: 0.5757 - val_acc: 0.8148\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 247ms/step - loss: 0.4799 - acc: 0.8451 - val_loss: 0.6301 - val_acc: 0.7407\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.5775 - acc: 0.7606 - val_loss: 0.6931 - val_acc: 0.7037\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.4197 - acc: 0.8028 - val_loss: 0.5922 - val_acc: 0.7407\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 0.3940 - acc: 0.7465 - val_loss: 0.4852 - val_acc: 0.7407\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.3257 - acc: 0.8732 - val_loss: 0.3948 - val_acc: 0.8519\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.3028 - acc: 0.8873 - val_loss: 0.3954 - val_acc: 0.7778\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 255ms/step - loss: 0.3181 - acc: 0.9296 - val_loss: 0.3572 - val_acc: 0.8519\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 335ms/step - loss: 0.2677 - acc: 0.9155 - val_loss: 0.4156 - val_acc: 0.7778\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.2648 - acc: 0.8732 - val_loss: 0.3274 - val_acc: 0.8519\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 168ms/step - loss: 0.2256 - acc: 0.9296 - val_loss: 0.3097 - val_acc: 0.8519\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.2239 - acc: 0.9296 - val_loss: 0.3084 - val_acc: 0.8519\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.2043 - acc: 0.9296 - val_loss: 0.3040 - val_acc: 0.8519\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.1955 - acc: 0.9296 - val_loss: 0.3238 - val_acc: 0.8519\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.2029 - acc: 1.0000 - val_loss: 0.3429 - val_acc: 1.0000\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.2003 - acc: 1.0000 - val_loss: 0.3221 - val_acc: 1.0000\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 169ms/step - loss: 0.1985 - acc: 0.9718 - val_loss: 0.2785 - val_acc: 1.0000\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.1623 - acc: 0.9859 - val_loss: 0.2438 - val_acc: 1.0000\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 0.1470 - acc: 0.9859 - val_loss: 0.2064 - val_acc: 0.9630\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.1165 - acc: 1.0000 - val_loss: 0.2206 - val_acc: 0.8889\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0795 - acc: 0.9859 - val_loss: 0.1848 - val_acc: 0.8519\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0729 - acc: 1.0000 - val_loss: 0.2146 - val_acc: 0.8519\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0629 - acc: 0.9859 - val_loss: 0.2367 - val_acc: 0.8889\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0637 - acc: 0.9859 - val_loss: 0.2308 - val_acc: 0.8889\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 178ms/step - loss: 0.0487 - acc: 1.0000 - val_loss: 0.1501 - val_acc: 0.8889\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0431 - acc: 0.9859 - val_loss: 0.1611 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.0284 - acc: 1.0000 - val_loss: 0.1071 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 172ms/step - loss: 0.0232 - acc: 1.0000 - val_loss: 0.1310 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0159 - acc: 1.0000 - val_loss: 0.1111 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.1167 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.1618 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.1134 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.1552 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.1345 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.1187 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0917 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.1135 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1781 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.2209 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1987 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.1553 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.2081 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1785 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 169ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.2118 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1554 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 9.9447e-04 - acc: 1.0000 - val_loss: 0.2271 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.2326 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1932 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1741 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 9.6015e-04 - acc: 1.0000 - val_loss: 0.2140 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.2042 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2248 - val_acc: 0.9259\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2330 - val_acc: 0.9259\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 9.8224e-04 - acc: 1.0000 - val_loss: 0.2577 - val_acc: 0.9259\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.2328 - val_acc: 0.9259\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 5.9604e-04 - acc: 1.0000 - val_loss: 0.1641 - val_acc: 0.9259\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 8.3354e-04 - acc: 1.0000 - val_loss: 0.1452 - val_acc: 0.9259\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0834 - val_acc: 0.9259\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 6.0423e-04 - acc: 1.0000 - val_loss: 0.1172 - val_acc: 0.9259\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 6.9768e-04 - acc: 1.0000 - val_loss: 0.1343 - val_acc: 0.9259\n",
      "Epoch 77/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1609 - val_acc: 0.9259\n",
      "Epoch 78/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 6.0088e-04 - acc: 1.0000 - val_loss: 0.1267 - val_acc: 0.9259\n",
      "Epoch 79/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 8.6921e-04 - acc: 1.0000 - val_loss: 0.1876 - val_acc: 0.9259\n",
      "Epoch 80/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.6715e-04 - acc: 1.0000 - val_loss: 0.1692 - val_acc: 0.9259\n",
      "Epoch 81/1000\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 7.5032e-04 - acc: 1.0000 - val_loss: 0.1986 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:16:57.631322: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:16:57.822974: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:16:57.832079: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:16:58.661427: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:16:58.668357: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 918ms/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:17:03.214089: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:17:03.716732: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:17:03.727896: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:17:04.794549: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:17:04.805409: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:17:06.077676: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:17:06.091155: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:17:07.719521: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:17:07.733032: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6083 - acc: 0.2394"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:17:12.871772: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:17:13.111434: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:17:13.118427: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:17:13.924521: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:17:13.931509: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 14s 5s/step - loss: 1.6083 - acc: 0.2394 - val_loss: 1.5865 - val_acc: 0.3704\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5932 - acc: 0.2958 - val_loss: 1.5720 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.5603 - acc: 0.3803 - val_loss: 1.5358 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5007 - acc: 0.4225 - val_loss: 1.4811 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 1.4961 - acc: 0.3662 - val_loss: 1.4372 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 2s 921ms/step - loss: 1.4035 - acc: 0.3803 - val_loss: 1.4109 - val_acc: 0.3333\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 1s 645ms/step - loss: 1.3790 - acc: 0.4085 - val_loss: 1.3627 - val_acc: 0.3704\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 1s 520ms/step - loss: 1.3129 - acc: 0.4930 - val_loss: 1.2432 - val_acc: 0.5556\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 1s 649ms/step - loss: 1.1559 - acc: 0.6479 - val_loss: 1.0954 - val_acc: 0.6667\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 1s 245ms/step - loss: 1.0084 - acc: 0.7606 - val_loss: 0.9694 - val_acc: 0.6296\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 1s 412ms/step - loss: 0.7857 - acc: 0.7324 - val_loss: 0.7946 - val_acc: 0.6667\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 1s 502ms/step - loss: 0.6210 - acc: 0.7887 - val_loss: 0.7292 - val_acc: 0.7037\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 1s 402ms/step - loss: 0.5584 - acc: 0.8028 - val_loss: 0.6452 - val_acc: 0.7407\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 1s 236ms/step - loss: 0.4863 - acc: 0.8028 - val_loss: 0.5245 - val_acc: 0.7407\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 1s 639ms/step - loss: 0.4003 - acc: 0.8028 - val_loss: 0.5678 - val_acc: 0.7037\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 296ms/step - loss: 0.3727 - acc: 0.8028 - val_loss: 0.4824 - val_acc: 0.7037\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 259ms/step - loss: 0.3099 - acc: 0.8451 - val_loss: 0.4450 - val_acc: 0.7778\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 305ms/step - loss: 0.2649 - acc: 0.9014 - val_loss: 0.3796 - val_acc: 0.8889\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.2641 - acc: 0.8873 - val_loss: 0.3282 - val_acc: 1.0000\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 258ms/step - loss: 0.2088 - acc: 0.9718 - val_loss: 0.3189 - val_acc: 0.8148\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 0.1865 - acc: 0.8873 - val_loss: 0.2811 - val_acc: 0.9259\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 0.1601 - acc: 0.9718 - val_loss: 0.1885 - val_acc: 0.9259\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0978 - acc: 1.0000 - val_loss: 0.3204 - val_acc: 0.8148\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 0.2826 - acc: 0.8169 - val_loss: 0.2037 - val_acc: 0.9630\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.1167 - acc: 0.9859 - val_loss: 0.2222 - val_acc: 0.9630\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.1260 - acc: 0.9577 - val_loss: 0.2032 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 314ms/step - loss: 0.0866 - acc: 1.0000 - val_loss: 0.1578 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0598 - acc: 0.9859 - val_loss: 0.1714 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0381 - acc: 1.0000 - val_loss: 0.2078 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0229 - acc: 1.0000 - val_loss: 0.1329 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0161 - acc: 1.0000 - val_loss: 0.1005 - val_acc: 0.9630\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.0854 - val_acc: 0.9630\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0220 - acc: 0.9859 - val_loss: 0.0798 - val_acc: 0.9630\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.1029 - val_acc: 0.9630\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0868 - val_acc: 0.9630\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0427 - val_acc: 0.9630\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0949 - val_acc: 0.9630\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1334 - val_acc: 0.9630\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0735 - val_acc: 0.9630\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0613 - val_acc: 0.9630\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0520 - val_acc: 0.9630\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0712 - val_acc: 0.9630\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 9.7429e-04 - acc: 1.0000 - val_loss: 0.0840 - val_acc: 0.9630\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1205 - val_acc: 0.9630\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.1406e-04 - acc: 1.0000 - val_loss: 0.1167 - val_acc: 0.9630\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 4.3601e-04 - acc: 1.0000 - val_loss: 0.1074 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 4.6475e-04 - acc: 1.0000 - val_loss: 0.1395 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0901 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 3.5178e-04 - acc: 1.0000 - val_loss: 0.1022 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 4.2265e-04 - acc: 1.0000 - val_loss: 0.0896 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 2.4048e-04 - acc: 1.0000 - val_loss: 0.1330 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 5.9286e-04 - acc: 1.0000 - val_loss: 0.0792 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 5.2831e-04 - acc: 1.0000 - val_loss: 0.1190 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0852 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.7386e-04 - acc: 1.0000 - val_loss: 0.1072 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.8089e-04 - acc: 1.0000 - val_loss: 0.1192 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 3.8113e-04 - acc: 1.0000 - val_loss: 0.1041 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 2.8145e-04 - acc: 1.0000 - val_loss: 0.1094 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 4.0514e-04 - acc: 1.0000 - val_loss: 0.1336 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 5.0053e-04 - acc: 1.0000 - val_loss: 0.0966 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 6.1018e-04 - acc: 1.0000 - val_loss: 0.1060 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 4.4759e-04 - acc: 1.0000 - val_loss: 0.1100 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 5.4423e-04 - acc: 1.0000 - val_loss: 0.1300 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 2.7237e-04 - acc: 1.0000 - val_loss: 0.0936 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 2.2603e-04 - acc: 1.0000 - val_loss: 0.1143 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 3.2548e-04 - acc: 1.0000 - val_loss: 0.0982 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 6.1198e-04 - acc: 1.0000 - val_loss: 0.1245 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 2.6985e-04 - acc: 1.0000 - val_loss: 0.1075 - val_acc: 0.9259\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 2.0638e-04 - acc: 1.0000 - val_loss: 0.1086 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:17:45.409709: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:17:45.591116: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:17:45.598171: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:17:46.403796: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:17:46.410655: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 578ms/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:17:50.627641: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:17:51.170443: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:17:51.181378: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:17:52.321733: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:17:52.332534: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:17:53.670700: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:17:53.684651: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:17:55.401858: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:17:55.415257: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6065 - acc: 0.2535"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:18:00.269620: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:18:00.507976: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:18:00.514838: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:18:01.352291: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:18:01.359135: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 14s 5s/step - loss: 1.6065 - acc: 0.2535 - val_loss: 1.5871 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5882 - acc: 0.3521 - val_loss: 1.5661 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5601 - acc: 0.3662 - val_loss: 1.5256 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.5223 - acc: 0.3521 - val_loss: 1.4932 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.4760 - acc: 0.3944 - val_loss: 1.5312 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 1s 738ms/step - loss: 1.4154 - acc: 0.3521 - val_loss: 1.6302 - val_acc: 0.3333\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 1s 492ms/step - loss: 1.4573 - acc: 0.3521 - val_loss: 1.3811 - val_acc: 0.4074\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 1.3108 - acc: 0.4366 - val_loss: 1.2866 - val_acc: 0.4815\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 1s 510ms/step - loss: 1.2543 - acc: 0.5775 - val_loss: 1.2063 - val_acc: 0.6296\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 367ms/step - loss: 1.1678 - acc: 0.7887 - val_loss: 1.0382 - val_acc: 0.7037\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 1s 555ms/step - loss: 0.9434 - acc: 0.7887 - val_loss: 2.2293 - val_acc: 0.4074\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 1s 410ms/step - loss: 1.4371 - acc: 0.5352 - val_loss: 0.8352 - val_acc: 0.7407\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 316ms/step - loss: 0.6758 - acc: 0.7887 - val_loss: 0.7349 - val_acc: 0.7778\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 1s 404ms/step - loss: 0.6268 - acc: 0.8028 - val_loss: 0.7266 - val_acc: 0.7407\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 283ms/step - loss: 0.5950 - acc: 0.8028 - val_loss: 0.5930 - val_acc: 0.7778\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 1s 501ms/step - loss: 0.4618 - acc: 0.8028 - val_loss: 0.6181 - val_acc: 0.7778\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 1s 403ms/step - loss: 0.5159 - acc: 0.8028 - val_loss: 0.4930 - val_acc: 0.7778\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 256ms/step - loss: 0.3709 - acc: 0.8028 - val_loss: 0.4571 - val_acc: 0.7407\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 1s 263ms/step - loss: 0.3180 - acc: 0.8028 - val_loss: 0.4030 - val_acc: 0.8148\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 0.2618 - acc: 0.8310 - val_loss: 0.3779 - val_acc: 0.8519\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 228ms/step - loss: 0.2101 - acc: 0.8732 - val_loss: 0.2726 - val_acc: 1.0000\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 232ms/step - loss: 0.1858 - acc: 0.9296 - val_loss: 0.3086 - val_acc: 1.0000\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.1938 - acc: 0.9155 - val_loss: 0.2856 - val_acc: 0.8519\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.1520 - acc: 0.9296 - val_loss: 0.3391 - val_acc: 0.8519\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 0.1128 - acc: 0.9437 - val_loss: 0.3960 - val_acc: 0.8519\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.1387 - acc: 0.9296 - val_loss: 0.4296 - val_acc: 0.8519\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0776 - acc: 0.9859 - val_loss: 0.3775 - val_acc: 0.8519\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.0981 - acc: 0.9437 - val_loss: 0.4389 - val_acc: 0.8519\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0738 - acc: 0.9718 - val_loss: 0.3726 - val_acc: 0.8889\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.0515 - acc: 0.9718 - val_loss: 0.2931 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 0.0534 - acc: 0.9859 - val_loss: 0.3911 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 0.0397 - acc: 1.0000 - val_loss: 0.3566 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0271 - acc: 1.0000 - val_loss: 0.4049 - val_acc: 0.8889\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0349 - acc: 1.0000 - val_loss: 0.4105 - val_acc: 0.8519\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.3704 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.0219 - acc: 1.0000 - val_loss: 0.5092 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.4958 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.7149 - val_acc: 0.8519\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0424 - acc: 0.9859 - val_loss: 2.3416 - val_acc: 0.5926\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.5070 - acc: 0.8592 - val_loss: 0.5209 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0173 - acc: 1.0000 - val_loss: 0.5003 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0492 - acc: 0.9718 - val_loss: 0.5952 - val_acc: 0.8519\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3553 - acc: 0.8873 - val_loss: 0.3266 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0555 - acc: 0.9859 - val_loss: 0.1739 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0226 - acc: 1.0000 - val_loss: 0.1205 - val_acc: 0.9630\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0299 - acc: 1.0000 - val_loss: 0.1006 - val_acc: 1.0000\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0283 - acc: 1.0000 - val_loss: 0.0467 - val_acc: 1.0000\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.0640 - val_acc: 1.0000\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0200 - acc: 1.0000 - val_loss: 0.0205 - val_acc: 1.0000\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0148 - acc: 1.0000 - val_loss: 0.0351 - val_acc: 1.0000\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0189 - val_acc: 1.0000\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 227ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0408 - val_acc: 1.0000\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.0315 - val_acc: 1.0000\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 1.0000\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0229 - acc: 0.9859 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0309 - acc: 0.9859 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:18:33.305997: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:18:33.522240: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:18:33.529328: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:18:34.367058: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:18:34.374020: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 824ms/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:18:38.753874: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:18:39.285373: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:18:39.296824: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:18:40.417006: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:18:40.428333: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:18:41.733309: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:18:41.746579: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:18:43.461933: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:18:43.475409: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6064 - acc: 0.2535"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:18:48.804939: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:18:49.044834: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:18:49.051824: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:18:49.865313: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:18:49.872207: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 14s 6s/step - loss: 1.6064 - acc: 0.2535 - val_loss: 1.5933 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 4s 2s/step - loss: 1.5890 - acc: 0.3662 - val_loss: 1.5781 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5789 - acc: 0.3521 - val_loss: 1.5661 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 1s 602ms/step - loss: 1.5449 - acc: 0.3662 - val_loss: 1.5327 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5193 - acc: 0.3521 - val_loss: 1.4924 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 1s 997ms/step - loss: 1.4689 - acc: 0.3521 - val_loss: 1.4267 - val_acc: 0.3333\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 1s 1s/step - loss: 1.4187 - acc: 0.3662 - val_loss: 1.3636 - val_acc: 0.3333\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 1s 721ms/step - loss: 1.3011 - acc: 0.3803 - val_loss: 1.2836 - val_acc: 0.4074\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 1s 508ms/step - loss: 1.1112 - acc: 0.5352 - val_loss: 1.0894 - val_acc: 0.6296\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.8906 - acc: 0.7465 - val_loss: 1.5880 - val_acc: 0.5556\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 1s 435ms/step - loss: 1.2019 - acc: 0.5915 - val_loss: 2.1710 - val_acc: 0.2593\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 1s 513ms/step - loss: 2.0977 - acc: 0.3380 - val_loss: 0.7969 - val_acc: 0.7778\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 241ms/step - loss: 0.6226 - acc: 0.8028 - val_loss: 0.7763 - val_acc: 0.8519\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 1s 452ms/step - loss: 0.6764 - acc: 0.8310 - val_loss: 0.7316 - val_acc: 0.8519\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 0.6515 - acc: 0.8732 - val_loss: 0.7363 - val_acc: 0.8519\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 1s 267ms/step - loss: 0.6729 - acc: 0.9155 - val_loss: 0.6505 - val_acc: 0.8519\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.5680 - acc: 0.9296 - val_loss: 0.6037 - val_acc: 0.8148\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 271ms/step - loss: 0.5180 - acc: 0.8873 - val_loss: 0.6104 - val_acc: 0.8148\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 303ms/step - loss: 0.5455 - acc: 0.8451 - val_loss: 0.5644 - val_acc: 0.8148\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 241ms/step - loss: 0.4177 - acc: 0.8873 - val_loss: 0.4882 - val_acc: 0.8519\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 0.3607 - acc: 0.9155 - val_loss: 0.3899 - val_acc: 0.8889\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 305ms/step - loss: 0.2600 - acc: 0.9718 - val_loss: 0.3627 - val_acc: 0.9630\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2135 - acc: 0.9859 - val_loss: 0.3026 - val_acc: 1.0000\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 0.2182 - acc: 0.9718 - val_loss: 0.2609 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.1698 - acc: 0.9296 - val_loss: 0.2109 - val_acc: 0.9630\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.1396 - acc: 0.9577 - val_loss: 0.1867 - val_acc: 0.9630\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0973 - acc: 0.9859 - val_loss: 0.0985 - val_acc: 1.0000\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0598 - acc: 1.0000 - val_loss: 0.0783 - val_acc: 1.0000\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.0612 - acc: 1.0000 - val_loss: 0.0629 - val_acc: 1.0000\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0457 - acc: 1.0000 - val_loss: 0.0459 - val_acc: 1.0000\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 0.0248 - acc: 1.0000 - val_loss: 0.0526 - val_acc: 1.0000\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.0521 - val_acc: 1.0000\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0152 - acc: 1.0000 - val_loss: 0.0446 - val_acc: 1.0000\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.0369 - val_acc: 1.0000\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0505 - val_acc: 0.9630\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 179ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0628 - val_acc: 0.9630\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0665 - val_acc: 0.9630\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0786 - val_acc: 0.9630\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1007 - val_acc: 0.9630\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 178ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0955 - val_acc: 0.9630\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.1045 - val_acc: 0.9630\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0914 - val_acc: 0.9630\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0539 - val_acc: 0.9630\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0775 - val_acc: 0.9630\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0749 - val_acc: 0.9630\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 6.3265e-04 - acc: 1.0000 - val_loss: 0.0580 - val_acc: 0.9630\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 9.2926e-04 - acc: 1.0000 - val_loss: 0.0705 - val_acc: 0.9630\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 6.1410e-04 - acc: 1.0000 - val_loss: 0.0622 - val_acc: 0.9630\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0365 - val_acc: 0.9630\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 5.7458e-04 - acc: 1.0000 - val_loss: 0.0394 - val_acc: 0.9630\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 7.5983e-04 - acc: 1.0000 - val_loss: 0.0426 - val_acc: 0.9630\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 7.5879e-04 - acc: 1.0000 - val_loss: 0.0388 - val_acc: 0.9630\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 6.5095e-04 - acc: 1.0000 - val_loss: 0.0434 - val_acc: 0.9630\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 5.5501e-04 - acc: 1.0000 - val_loss: 0.0322 - val_acc: 1.0000\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 7.5192e-04 - acc: 1.0000 - val_loss: 0.0239 - val_acc: 1.0000\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 5.6399e-04 - acc: 1.0000 - val_loss: 0.0373 - val_acc: 0.9630\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 5.3029e-04 - acc: 1.0000 - val_loss: 0.0312 - val_acc: 1.0000\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 4.8129e-04 - acc: 1.0000 - val_loss: 0.0277 - val_acc: 1.0000\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.7535e-04 - acc: 1.0000 - val_loss: 0.0431 - val_acc: 0.9630\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 5.4571e-04 - acc: 1.0000 - val_loss: 0.0252 - val_acc: 1.0000\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 3.2096e-04 - acc: 1.0000 - val_loss: 0.0219 - val_acc: 1.0000\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 8.0138e-04 - acc: 1.0000 - val_loss: 0.0183 - val_acc: 1.0000\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 2.9162e-04 - acc: 1.0000 - val_loss: 0.0271 - val_acc: 1.0000\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 3.3062e-04 - acc: 1.0000 - val_loss: 0.0231 - val_acc: 1.0000\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 6.3038e-04 - acc: 1.0000 - val_loss: 0.0209 - val_acc: 1.0000\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 3.4729e-04 - acc: 1.0000 - val_loss: 0.0199 - val_acc: 1.0000\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 6.1598e-04 - acc: 1.0000 - val_loss: 0.0157 - val_acc: 1.0000\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 2.8316e-04 - acc: 1.0000 - val_loss: 0.0224 - val_acc: 1.0000\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 6.4072e-04 - acc: 1.0000 - val_loss: 0.0190 - val_acc: 1.0000\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 7.2035e-04 - acc: 1.0000 - val_loss: 0.0214 - val_acc: 1.0000\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.4908e-04 - acc: 1.0000 - val_loss: 0.0169 - val_acc: 1.0000\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 3.7088e-04 - acc: 1.0000 - val_loss: 0.0316 - val_acc: 1.0000\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 3.9273e-04 - acc: 1.0000 - val_loss: 0.0201 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:19:22.098384: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:19:22.287777: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:19:22.294772: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:19:23.160590: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:19:23.167585: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 842ms/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:19:27.888865: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:19:28.453056: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:19:28.477253: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:19:29.563292: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:19:29.573773: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:19:30.897628: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:19:30.910979: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:19:32.611758: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:19:32.625068: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6095 - acc: 0.2394"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:19:38.156640: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:19:38.405005: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:19:38.411906: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:19:39.247118: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:19:39.253936: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 15s 6s/step - loss: 1.6095 - acc: 0.2394 - val_loss: 1.5946 - val_acc: 0.4815\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 4s 2s/step - loss: 1.5911 - acc: 0.3944 - val_loss: 1.5782 - val_acc: 0.4074\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5667 - acc: 0.4789 - val_loss: 1.5444 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 2s 946ms/step - loss: 1.5344 - acc: 0.3944 - val_loss: 1.5023 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 1s 1s/step - loss: 1.4560 - acc: 0.3803 - val_loss: 1.4803 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.4540 - acc: 0.3662 - val_loss: 1.4888 - val_acc: 0.3333\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 2s 937ms/step - loss: 1.4374 - acc: 0.3662 - val_loss: 1.3866 - val_acc: 0.4815\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 1s 885ms/step - loss: 1.3184 - acc: 0.5634 - val_loss: 1.3426 - val_acc: 0.4815\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 1s 651ms/step - loss: 1.2510 - acc: 0.6197 - val_loss: 1.2011 - val_acc: 0.4815\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 1s 444ms/step - loss: 1.0426 - acc: 0.6056 - val_loss: 0.9970 - val_acc: 0.5556\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 1s 559ms/step - loss: 0.8517 - acc: 0.6338 - val_loss: 1.6849 - val_acc: 0.2963\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 1s 705ms/step - loss: 1.3639 - acc: 0.4225 - val_loss: 1.3594 - val_acc: 0.4815\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.8923 - acc: 0.5775 - val_loss: 0.7834 - val_acc: 0.7037\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 1s 484ms/step - loss: 0.5915 - acc: 0.8028 - val_loss: 0.7736 - val_acc: 0.7407\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 0.6206 - acc: 0.8028 - val_loss: 0.7268 - val_acc: 0.7778\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 334ms/step - loss: 0.6022 - acc: 0.8028 - val_loss: 0.6470 - val_acc: 0.7778\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 1s 234ms/step - loss: 0.4609 - acc: 0.8028 - val_loss: 0.5109 - val_acc: 0.7778\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 273ms/step - loss: 0.4031 - acc: 0.8028 - val_loss: 0.4823 - val_acc: 0.7778\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3264 - acc: 0.8028 - val_loss: 0.3963 - val_acc: 0.7778\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 182ms/step - loss: 0.2813 - acc: 0.8028 - val_loss: 0.3595 - val_acc: 0.9630\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.2356 - acc: 0.9296 - val_loss: 0.2925 - val_acc: 0.8519\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.2552 - acc: 0.8592 - val_loss: 0.3044 - val_acc: 0.8889\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.2167 - acc: 0.8732 - val_loss: 0.3390 - val_acc: 0.8148\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.2226 - acc: 0.8873 - val_loss: 0.1861 - val_acc: 1.0000\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 239ms/step - loss: 0.1220 - acc: 0.9859 - val_loss: 0.2197 - val_acc: 1.0000\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.1271 - acc: 1.0000 - val_loss: 0.2376 - val_acc: 0.9630\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.1079 - acc: 1.0000 - val_loss: 0.2283 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0889 - acc: 0.9859 - val_loss: 0.2281 - val_acc: 0.8519\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0893 - acc: 0.9437 - val_loss: 0.2339 - val_acc: 0.8519\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0853 - acc: 0.9437 - val_loss: 0.2074 - val_acc: 0.8889\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 0.0592 - acc: 0.9859 - val_loss: 0.1959 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0444 - acc: 1.0000 - val_loss: 0.1986 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 212ms/step - loss: 0.1143 - acc: 0.9437 - val_loss: 0.1924 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0592 - acc: 0.9859 - val_loss: 0.2180 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0279 - acc: 1.0000 - val_loss: 0.2279 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.2601 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.3104 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.3314 - val_acc: 0.8889\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 179ms/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.3851 - val_acc: 0.8889\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 178ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.3091 - val_acc: 0.8889\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.2927 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.1848 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.1373 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.1161 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0954 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0889 - val_acc: 0.9630\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0955 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1001 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1009 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1121 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1166 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1489 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 9.4508e-04 - acc: 1.0000 - val_loss: 0.1813 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 5.1650e-04 - acc: 1.0000 - val_loss: 0.1879 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 7.0517e-04 - acc: 1.0000 - val_loss: 0.2109 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 6.9368e-04 - acc: 1.0000 - val_loss: 0.2085 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 178ms/step - loss: 7.0659e-04 - acc: 1.0000 - val_loss: 0.2415 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.2282 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.2061 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 4.8753e-04 - acc: 1.0000 - val_loss: 0.1833 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.8282e-04 - acc: 1.0000 - val_loss: 0.1757 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 4.3792e-04 - acc: 1.0000 - val_loss: 0.1478 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 4.7038e-04 - acc: 1.0000 - val_loss: 0.1386 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 3.2527e-04 - acc: 1.0000 - val_loss: 0.1512 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 2.9260e-04 - acc: 1.0000 - val_loss: 0.1397 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 5.0958e-04 - acc: 1.0000 - val_loss: 0.1641 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 4.6291e-04 - acc: 1.0000 - val_loss: 0.1271 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 182ms/step - loss: 3.8137e-04 - acc: 1.0000 - val_loss: 0.1280 - val_acc: 0.9259\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 2.7612e-04 - acc: 1.0000 - val_loss: 0.1455 - val_acc: 0.9259\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 3.8217e-04 - acc: 1.0000 - val_loss: 0.1426 - val_acc: 0.9259\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 4.5115e-04 - acc: 1.0000 - val_loss: 0.1446 - val_acc: 0.9259\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 2.5627e-04 - acc: 1.0000 - val_loss: 0.1350 - val_acc: 0.9259\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.9313e-04 - acc: 1.0000 - val_loss: 0.1342 - val_acc: 0.9259\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 4.5781e-04 - acc: 1.0000 - val_loss: 0.1281 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:20:11.616757: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:20:11.803164: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:20:11.810141: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:20:12.650544: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:20:12.657568: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 567ms/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:20:17.086564: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:20:17.659101: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:20:17.670032: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:20:18.825331: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:20:18.835247: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:20:20.176330: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:20:20.189717: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:20:21.901150: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:20:21.914799: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6089 - acc: 0.1690"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:20:27.202702: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:20:27.437440: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:20:27.444421: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:20:28.273613: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:20:28.281029: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 15s 6s/step - loss: 1.6089 - acc: 0.1690 - val_loss: 1.5908 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 4s 2s/step - loss: 1.5923 - acc: 0.3944 - val_loss: 1.5754 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5713 - acc: 0.3521 - val_loss: 1.5486 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5328 - acc: 0.3521 - val_loss: 1.5091 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 2s 782ms/step - loss: 1.5061 - acc: 0.3803 - val_loss: 1.4536 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 2s 568ms/step - loss: 1.4373 - acc: 0.3521 - val_loss: 1.4144 - val_acc: 0.3333\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 2s 654ms/step - loss: 1.3908 - acc: 0.3944 - val_loss: 1.3451 - val_acc: 0.4815\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 1s 949ms/step - loss: 1.2947 - acc: 0.4789 - val_loss: 1.2757 - val_acc: 0.5556\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 1s 406ms/step - loss: 1.1839 - acc: 0.6338 - val_loss: 1.2256 - val_acc: 0.4074\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 1s 537ms/step - loss: 1.0439 - acc: 0.5634 - val_loss: 1.1123 - val_acc: 0.6667\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.9230 - acc: 0.8028 - val_loss: 0.9216 - val_acc: 0.6667\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 259ms/step - loss: 0.7390 - acc: 0.7606 - val_loss: 0.8099 - val_acc: 0.6667\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.6260 - acc: 0.7887 - val_loss: 0.6413 - val_acc: 0.7407\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 280ms/step - loss: 0.5276 - acc: 0.8028 - val_loss: 0.6443 - val_acc: 0.7407\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 1s 404ms/step - loss: 0.4975 - acc: 0.8028 - val_loss: 0.5639 - val_acc: 0.7037\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 272ms/step - loss: 0.4077 - acc: 0.8028 - val_loss: 0.5164 - val_acc: 0.7037\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.3437 - acc: 0.8028 - val_loss: 0.4931 - val_acc: 0.7037\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 231ms/step - loss: 0.3475 - acc: 0.8028 - val_loss: 0.4997 - val_acc: 0.7037\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.3531 - acc: 0.8451 - val_loss: 0.4873 - val_acc: 0.7778\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 336ms/step - loss: 0.2848 - acc: 0.9155 - val_loss: 0.4509 - val_acc: 0.8519\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 201ms/step - loss: 0.2492 - acc: 0.9437 - val_loss: 0.3765 - val_acc: 0.9259\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 0.2211 - acc: 0.9577 - val_loss: 0.3415 - val_acc: 0.9630\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 286ms/step - loss: 0.2083 - acc: 0.9577 - val_loss: 0.3171 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.1669 - acc: 0.9859 - val_loss: 0.2957 - val_acc: 0.8889\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.1629 - acc: 0.9859 - val_loss: 0.2638 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 0.1513 - acc: 0.9859 - val_loss: 0.2453 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.1050 - acc: 1.0000 - val_loss: 0.2715 - val_acc: 0.9259\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0856 - acc: 1.0000 - val_loss: 0.1773 - val_acc: 0.8889\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.0547 - acc: 1.0000 - val_loss: 0.1689 - val_acc: 0.8889\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0501 - acc: 0.9859 - val_loss: 0.1449 - val_acc: 0.8889\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0382 - acc: 1.0000 - val_loss: 0.2068 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0459 - acc: 0.9859 - val_loss: 0.2293 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.2888 - val_acc: 0.8889\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.1872 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.1813 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.1243 - val_acc: 0.9259\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0898 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0942 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1144 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1073 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 258ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.1140 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 9.5022e-04 - acc: 1.0000 - val_loss: 0.1014 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0940 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 5.3410e-04 - acc: 1.0000 - val_loss: 0.1072 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 7.0127e-04 - acc: 1.0000 - val_loss: 0.1155 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 6.8333e-04 - acc: 1.0000 - val_loss: 0.1405 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 3.6330e-04 - acc: 1.0000 - val_loss: 0.1602 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 6.3231e-04 - acc: 1.0000 - val_loss: 0.1499 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 7.1188e-04 - acc: 1.0000 - val_loss: 0.1254 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 3.5663e-04 - acc: 1.0000 - val_loss: 0.1685 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 7.1711e-04 - acc: 1.0000 - val_loss: 0.1604 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 2.7426e-04 - acc: 1.0000 - val_loss: 0.1592 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 4.4413e-04 - acc: 1.0000 - val_loss: 0.2100 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 5.2244e-04 - acc: 1.0000 - val_loss: 0.1932 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 9.1626e-04 - acc: 1.0000 - val_loss: 0.1784 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 4.5561e-04 - acc: 1.0000 - val_loss: 0.1598 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 3.3875e-04 - acc: 1.0000 - val_loss: 0.1927 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 3.2871e-04 - acc: 1.0000 - val_loss: 0.1404 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 3.8572e-04 - acc: 1.0000 - val_loss: 0.1326 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 2.6490e-04 - acc: 1.0000 - val_loss: 0.1577 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.4889e-04 - acc: 1.0000 - val_loss: 0.1042 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 5.6001e-04 - acc: 1.0000 - val_loss: 0.1399 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 3.2457e-04 - acc: 1.0000 - val_loss: 0.1447 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 2.1412e-04 - acc: 1.0000 - val_loss: 0.1171 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 3.2038e-04 - acc: 1.0000 - val_loss: 0.1368 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1.9571e-04 - acc: 1.0000 - val_loss: 0.1073 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.4477e-04 - acc: 1.0000 - val_loss: 0.1281 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 5.6902e-04 - acc: 1.0000 - val_loss: 0.1355 - val_acc: 0.9259\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 2.8667e-04 - acc: 1.0000 - val_loss: 0.1301 - val_acc: 0.9259\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 2.9657e-04 - acc: 1.0000 - val_loss: 0.1028 - val_acc: 0.9259\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.8575e-04 - acc: 1.0000 - val_loss: 0.0879 - val_acc: 0.9630\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.8030e-04 - acc: 1.0000 - val_loss: 0.1173 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:21:00.967530: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:21:01.157313: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:21:01.164165: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:21:02.038822: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:21:02.045655: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 885ms/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:21:06.769642: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:21:07.424341: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:21:07.449286: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:21:08.559517: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:21:08.570538: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:21:09.985424: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:21:09.998812: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:21:11.775636: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:21:11.789219: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6094 - acc: 0.1831"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:21:17.312321: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:21:17.550971: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:21:17.558043: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:21:18.493967: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:21:18.501067: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 15s 6s/step - loss: 1.6094 - acc: 0.1831 - val_loss: 1.5956 - val_acc: 0.3704\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 4s 2s/step - loss: 1.5916 - acc: 0.4366 - val_loss: 1.5839 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.5794 - acc: 0.3944 - val_loss: 1.5601 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.5479 - acc: 0.3944 - val_loss: 1.5130 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5143 - acc: 0.3662 - val_loss: 1.4635 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.4557 - acc: 0.3803 - val_loss: 1.4202 - val_acc: 0.3333\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 1s 1s/step - loss: 1.4451 - acc: 0.3662 - val_loss: 1.3833 - val_acc: 0.3333\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 1s 628ms/step - loss: 1.3200 - acc: 0.3803 - val_loss: 1.2407 - val_acc: 0.4815\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 1s 910ms/step - loss: 1.1578 - acc: 0.6056 - val_loss: 1.2605 - val_acc: 0.5556\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 1s 473ms/step - loss: 1.1554 - acc: 0.5211 - val_loss: 1.0755 - val_acc: 0.5926\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 1s 523ms/step - loss: 0.9070 - acc: 0.7606 - val_loss: 0.9528 - val_acc: 0.7037\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 295ms/step - loss: 0.8081 - acc: 0.8028 - val_loss: 0.8011 - val_acc: 0.7407\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 1s 501ms/step - loss: 0.6394 - acc: 0.8028 - val_loss: 0.6681 - val_acc: 0.7037\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 1s 375ms/step - loss: 0.5573 - acc: 0.8028 - val_loss: 0.5774 - val_acc: 0.7407\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 322ms/step - loss: 0.4212 - acc: 0.8028 - val_loss: 0.5454 - val_acc: 0.7407\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 1s 376ms/step - loss: 0.4130 - acc: 0.8028 - val_loss: 2.5931 - val_acc: 0.5185\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 1.4101 - acc: 0.6761 - val_loss: 0.5018 - val_acc: 0.7778\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 0.3925 - acc: 0.8028 - val_loss: 0.4952 - val_acc: 0.7778\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 1s 407ms/step - loss: 0.4125 - acc: 0.8028 - val_loss: 0.4870 - val_acc: 0.7778\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.3645 - acc: 0.8169 - val_loss: 0.5427 - val_acc: 0.7407\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.4266 - acc: 0.8028 - val_loss: 0.5201 - val_acc: 0.8889\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.3908 - acc: 0.8592 - val_loss: 0.4475 - val_acc: 0.9259\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 237ms/step - loss: 0.3702 - acc: 0.8592 - val_loss: 0.4119 - val_acc: 0.7778\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 1s 535ms/step - loss: 0.3140 - acc: 0.8451 - val_loss: 0.4125 - val_acc: 0.7778\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.2805 - acc: 0.8028 - val_loss: 0.4053 - val_acc: 0.7778\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.2715 - acc: 0.8028 - val_loss: 0.3960 - val_acc: 0.7407\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 0.2405 - acc: 0.8592 - val_loss: 0.3601 - val_acc: 0.8519\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 0.1978 - acc: 1.0000 - val_loss: 0.3933 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 272ms/step - loss: 0.1980 - acc: 1.0000 - val_loss: 0.3870 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.1964 - acc: 1.0000 - val_loss: 0.3608 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 0.1551 - acc: 1.0000 - val_loss: 0.2881 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 0.1261 - acc: 1.0000 - val_loss: 0.2726 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 0.0885 - acc: 1.0000 - val_loss: 0.2415 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 225ms/step - loss: 0.0625 - acc: 1.0000 - val_loss: 0.2447 - val_acc: 0.9259\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0695 - acc: 1.0000 - val_loss: 0.2697 - val_acc: 0.8889\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0473 - acc: 1.0000 - val_loss: 0.3176 - val_acc: 0.8889\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0483 - acc: 1.0000 - val_loss: 0.2583 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 0.0454 - acc: 1.0000 - val_loss: 0.2581 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0206 - acc: 1.0000 - val_loss: 0.2080 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0168 - acc: 1.0000 - val_loss: 0.2432 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.2354 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.2582 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.2524 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.2310 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.3436 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.3696 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.3754 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.3596 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.3895 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.3919 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.3227 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.3864 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.3364 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.3083 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 6.3715e-04 - acc: 1.0000 - val_loss: 0.3661 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 7.9719e-04 - acc: 1.0000 - val_loss: 0.3612 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 8.8040e-04 - acc: 1.0000 - val_loss: 0.3810 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 6.6470e-04 - acc: 1.0000 - val_loss: 0.3572 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 6.6728e-04 - acc: 1.0000 - val_loss: 0.3100 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 8.7126e-04 - acc: 1.0000 - val_loss: 0.3435 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 6.9981e-04 - acc: 1.0000 - val_loss: 0.3299 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.3317 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 4.6339e-04 - acc: 1.0000 - val_loss: 0.3380 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 5.4594e-04 - acc: 1.0000 - val_loss: 0.3222 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 5.5062e-04 - acc: 1.0000 - val_loss: 0.3700 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 6.0488e-04 - acc: 1.0000 - val_loss: 0.4073 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 3.6977e-04 - acc: 1.0000 - val_loss: 0.3703 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 7.0228e-04 - acc: 1.0000 - val_loss: 0.3606 - val_acc: 0.9259\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 6.3220e-04 - acc: 1.0000 - val_loss: 0.3600 - val_acc: 0.9259\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 6.9506e-04 - acc: 1.0000 - val_loss: 0.4116 - val_acc: 0.9259\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 4.8981e-04 - acc: 1.0000 - val_loss: 0.3753 - val_acc: 0.9259\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 4.0507e-04 - acc: 1.0000 - val_loss: 0.3909 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:21:53.193198: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:21:53.394924: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:21:53.401898: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:21:54.286979: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:21:54.294420: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 770ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:21:58.823010: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:21:59.422683: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:21:59.449645: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:22:00.597623: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:22:00.608633: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:22:02.049741: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:22:02.063179: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:22:03.891100: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:22:03.904572: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6073 - acc: 0.2958"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:22:09.538913: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:22:09.779640: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:22:09.786557: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:22:10.636653: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:22:10.644246: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 15s 6s/step - loss: 1.6073 - acc: 0.2958 - val_loss: 1.5933 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5860 - acc: 0.4225 - val_loss: 1.5728 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.5561 - acc: 0.3662 - val_loss: 1.5322 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5248 - acc: 0.4085 - val_loss: 1.4815 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.4914 - acc: 0.3380 - val_loss: 1.4589 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 2s 798ms/step - loss: 1.4256 - acc: 0.3803 - val_loss: 1.4193 - val_acc: 0.3333\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.3638 - acc: 0.4225 - val_loss: 1.3567 - val_acc: 0.4444\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 1s 627ms/step - loss: 1.3056 - acc: 0.6479 - val_loss: 1.2891 - val_acc: 0.4815\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 1s 741ms/step - loss: 1.1240 - acc: 0.6197 - val_loss: 1.2163 - val_acc: 0.4815\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 1s 875ms/step - loss: 1.1307 - acc: 0.5211 - val_loss: 1.2168 - val_acc: 0.4815\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 1s 334ms/step - loss: 1.0074 - acc: 0.5915 - val_loss: 1.1799 - val_acc: 0.4815\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 308ms/step - loss: 0.9096 - acc: 0.7042 - val_loss: 0.9201 - val_acc: 0.6667\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 1s 505ms/step - loss: 0.8318 - acc: 0.7887 - val_loss: 0.8824 - val_acc: 0.7037\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 1s 189ms/step - loss: 0.7416 - acc: 0.7887 - val_loss: 0.7750 - val_acc: 0.7037\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.5665 - acc: 0.8028 - val_loss: 0.7267 - val_acc: 0.6296\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 1s 824ms/step - loss: 0.5049 - acc: 0.7887 - val_loss: 0.6629 - val_acc: 0.7037\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 1s 308ms/step - loss: 0.4496 - acc: 0.8028 - val_loss: 0.5473 - val_acc: 0.7037\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.3913 - acc: 0.8028 - val_loss: 0.5126 - val_acc: 0.7407\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.3780 - acc: 0.8028 - val_loss: 0.4766 - val_acc: 0.7037\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3337 - acc: 0.8169 - val_loss: 0.4383 - val_acc: 0.7407\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 1s 203ms/step - loss: 0.2691 - acc: 0.8732 - val_loss: 0.4658 - val_acc: 0.8889\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 0.2597 - acc: 0.9155 - val_loss: 0.4734 - val_acc: 0.8889\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.1852 - acc: 1.0000 - val_loss: 0.3586 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 182ms/step - loss: 0.1796 - acc: 0.9437 - val_loss: 0.2552 - val_acc: 0.9259\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 0.1550 - acc: 0.9577 - val_loss: 0.2223 - val_acc: 0.9259\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.1196 - acc: 0.9577 - val_loss: 0.1475 - val_acc: 0.9259\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0799 - acc: 1.0000 - val_loss: 0.1857 - val_acc: 0.9630\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0587 - acc: 1.0000 - val_loss: 0.3870 - val_acc: 0.9259\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0949 - acc: 0.9718 - val_loss: 0.4682 - val_acc: 0.9259\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 0.0556 - acc: 0.9859 - val_loss: 0.4517 - val_acc: 0.9259\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 264ms/step - loss: 0.0675 - acc: 0.9718 - val_loss: 0.4130 - val_acc: 0.9259\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 178ms/step - loss: 0.0371 - acc: 0.9859 - val_loss: 0.6321 - val_acc: 0.8148\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0390 - acc: 0.9859 - val_loss: 0.6319 - val_acc: 0.8148\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 202ms/step - loss: 0.0580 - acc: 0.9859 - val_loss: 0.4546 - val_acc: 0.8889\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0340 - acc: 0.9859 - val_loss: 0.4616 - val_acc: 0.9259\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.4513 - val_acc: 0.8889\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.3748 - val_acc: 0.9259\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.2950 - val_acc: 0.9259\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 255ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.2673 - val_acc: 0.9259\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.2108 - val_acc: 0.9259\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.2179 - val_acc: 0.9259\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.1829 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.2195 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.2269 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.2551 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.3119 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.3283 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.3339 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.3746 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 9.8944e-04 - acc: 1.0000 - val_loss: 0.3757 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.3261 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 6.7011e-04 - acc: 1.0000 - val_loss: 0.3994 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.4178 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 8.2453e-04 - acc: 1.0000 - val_loss: 0.4000 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.3690 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 7.8529e-04 - acc: 1.0000 - val_loss: 0.4215 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.3539 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.4402 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 5.7051e-04 - acc: 1.0000 - val_loss: 0.4186 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 4.5944e-04 - acc: 1.0000 - val_loss: 0.4586 - val_acc: 0.9259\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 3.4435e-04 - acc: 1.0000 - val_loss: 0.4449 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 4.5132e-04 - acc: 1.0000 - val_loss: 0.4286 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.4215 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 3.2341e-04 - acc: 1.0000 - val_loss: 0.4631 - val_acc: 0.9259\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 8.0440e-04 - acc: 1.0000 - val_loss: 0.4268 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.4398 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 2.0862e-04 - acc: 1.0000 - val_loss: 0.4904 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.9501e-04 - acc: 1.0000 - val_loss: 0.4279 - val_acc: 0.9259\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 4.4285e-04 - acc: 1.0000 - val_loss: 0.4164 - val_acc: 0.9259\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 7.6470e-04 - acc: 1.0000 - val_loss: 0.3878 - val_acc: 0.9259\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 6.0838e-04 - acc: 1.0000 - val_loss: 0.4358 - val_acc: 0.9259\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 2.3889e-04 - acc: 1.0000 - val_loss: 0.4314 - val_acc: 0.9259\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 5.7537e-04 - acc: 1.0000 - val_loss: 0.3776 - val_acc: 0.9259\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 2.8440e-04 - acc: 1.0000 - val_loss: 0.3653 - val_acc: 0.9259\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 4.5411e-04 - acc: 1.0000 - val_loss: 0.3982 - val_acc: 0.9259\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 3.6029e-04 - acc: 1.0000 - val_loss: 0.4187 - val_acc: 0.9259\n",
      "Epoch 77/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 2.2577e-04 - acc: 1.0000 - val_loss: 0.3118 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:22:44.641746: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:22:44.835719: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:22:44.842694: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:22:45.719483: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:22:45.726350: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 959ms/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:22:50.453283: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:22:51.035586: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:22:51.046506: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:22:52.245702: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:22:52.256523: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:22:53.685766: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:22:53.699528: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:22:55.495661: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:22:55.508870: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6110 - acc: 0.1549"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:23:00.734378: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:23:00.974725: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:23:00.981742: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:23:01.861164: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:23:01.868092: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 15s 6s/step - loss: 1.6110 - acc: 0.1549 - val_loss: 1.5946 - val_acc: 0.4444\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 4s 2s/step - loss: 1.5968 - acc: 0.3944 - val_loss: 1.5787 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5736 - acc: 0.4789 - val_loss: 1.5525 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.5556 - acc: 0.4085 - val_loss: 1.5084 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5053 - acc: 0.3803 - val_loss: 1.4867 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 1s 752ms/step - loss: 1.4362 - acc: 0.3662 - val_loss: 1.4265 - val_acc: 0.3333\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 1s 656ms/step - loss: 1.3963 - acc: 0.3803 - val_loss: 1.4064 - val_acc: 0.3333\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 1s 783ms/step - loss: 1.2659 - acc: 0.4366 - val_loss: 1.3358 - val_acc: 0.4444\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 1s 584ms/step - loss: 1.2163 - acc: 0.5070 - val_loss: 1.1111 - val_acc: 0.4815\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 1s 523ms/step - loss: 0.9573 - acc: 0.5775 - val_loss: 0.8904 - val_acc: 0.7037\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 1s 397ms/step - loss: 0.8170 - acc: 0.8028 - val_loss: 0.8738 - val_acc: 0.7778\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 1s 519ms/step - loss: 0.7740 - acc: 0.7606 - val_loss: 0.7344 - val_acc: 0.7778\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 272ms/step - loss: 0.6023 - acc: 0.7887 - val_loss: 0.7647 - val_acc: 0.7407\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 1s 494ms/step - loss: 0.5884 - acc: 0.8028 - val_loss: 0.7845 - val_acc: 0.5926\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 254ms/step - loss: 0.4784 - acc: 0.8028 - val_loss: 0.7015 - val_acc: 0.6667\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 422ms/step - loss: 0.4726 - acc: 0.8310 - val_loss: 0.5783 - val_acc: 0.7037\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 0.4584 - acc: 0.8451 - val_loss: 0.5637 - val_acc: 0.8889\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 1s 570ms/step - loss: 0.4120 - acc: 0.8169 - val_loss: 0.5054 - val_acc: 0.7778\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3751 - acc: 0.8451 - val_loss: 0.4619 - val_acc: 0.7778\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.3380 - acc: 0.8169 - val_loss: 0.4548 - val_acc: 0.7778\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 252ms/step - loss: 0.3421 - acc: 0.8169 - val_loss: 0.4087 - val_acc: 0.8889\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3053 - acc: 0.9155 - val_loss: 0.3652 - val_acc: 0.7778\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 222ms/step - loss: 0.2580 - acc: 0.8732 - val_loss: 0.3510 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 0.2265 - acc: 0.9296 - val_loss: 0.3344 - val_acc: 0.8889\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 182ms/step - loss: 0.2230 - acc: 0.9296 - val_loss: 0.3085 - val_acc: 0.8889\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.1876 - acc: 0.9859 - val_loss: 0.3006 - val_acc: 0.9630\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 0.1509 - acc: 1.0000 - val_loss: 0.2419 - val_acc: 0.9630\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 229ms/step - loss: 0.1396 - acc: 1.0000 - val_loss: 0.2178 - val_acc: 0.9630\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.1164 - acc: 1.0000 - val_loss: 0.1798 - val_acc: 1.0000\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0801 - acc: 1.0000 - val_loss: 0.1573 - val_acc: 1.0000\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.0645 - acc: 1.0000 - val_loss: 0.1499 - val_acc: 1.0000\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0492 - acc: 1.0000 - val_loss: 0.1609 - val_acc: 0.9259\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0381 - acc: 1.0000 - val_loss: 0.1453 - val_acc: 0.9259\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0316 - acc: 1.0000 - val_loss: 0.1137 - val_acc: 0.9630\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 0.0203 - acc: 1.0000 - val_loss: 0.0768 - val_acc: 1.0000\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.0771 - val_acc: 1.0000\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0134 - acc: 1.0000 - val_loss: 0.0460 - val_acc: 1.0000\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 190ms/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.0665 - val_acc: 0.9630\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0584 - val_acc: 1.0000\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0594 - val_acc: 0.9630\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0937 - val_acc: 0.9630\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1307 - val_acc: 0.9259\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0975 - val_acc: 0.9259\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1509 - val_acc: 0.9259\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 9.9706e-04 - acc: 1.0000 - val_loss: 0.1472 - val_acc: 0.9259\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1023 - val_acc: 0.9259\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.1133 - val_acc: 0.9259\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1060 - val_acc: 0.9259\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 6.3643e-04 - acc: 1.0000 - val_loss: 0.1322 - val_acc: 0.9259\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 3.4568e-04 - acc: 1.0000 - val_loss: 0.1155 - val_acc: 0.9259\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 5.8563e-04 - acc: 1.0000 - val_loss: 0.0923 - val_acc: 0.9259\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 5.1409e-04 - acc: 1.0000 - val_loss: 0.1208 - val_acc: 0.9259\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 3.6195e-04 - acc: 1.0000 - val_loss: 0.1034 - val_acc: 0.9259\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 3.5426e-04 - acc: 1.0000 - val_loss: 0.1316 - val_acc: 0.9259\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 4.4024e-04 - acc: 1.0000 - val_loss: 0.1501 - val_acc: 0.9259\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 3.6167e-04 - acc: 1.0000 - val_loss: 0.1127 - val_acc: 0.9259\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.8574e-04 - acc: 1.0000 - val_loss: 0.1209 - val_acc: 0.9259\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 4.0237e-04 - acc: 1.0000 - val_loss: 0.1044 - val_acc: 0.9259\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 3.4341e-04 - acc: 1.0000 - val_loss: 0.0904 - val_acc: 0.9259\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.1723e-04 - acc: 1.0000 - val_loss: 0.0760 - val_acc: 0.9630\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.3597e-04 - acc: 1.0000 - val_loss: 0.0935 - val_acc: 0.9259\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 193ms/step - loss: 2.7598e-04 - acc: 1.0000 - val_loss: 0.1090 - val_acc: 0.9259\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.6939e-04 - acc: 1.0000 - val_loss: 0.1025 - val_acc: 0.9259\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 2.1450e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 1.0000\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 2.0544e-04 - acc: 1.0000 - val_loss: 0.0917 - val_acc: 0.9259\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 2.5921e-04 - acc: 1.0000 - val_loss: 0.1064 - val_acc: 0.9259\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 4.1525e-04 - acc: 1.0000 - val_loss: 0.0780 - val_acc: 0.9259\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 3.7272e-04 - acc: 1.0000 - val_loss: 0.0920 - val_acc: 0.9259\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.0007e-04 - acc: 1.0000 - val_loss: 0.0833 - val_acc: 0.9259\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.8243e-04 - acc: 1.0000 - val_loss: 0.0756 - val_acc: 0.9630\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.5807e-04 - acc: 1.0000 - val_loss: 0.0837 - val_acc: 0.9259\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.8749e-04 - acc: 1.0000 - val_loss: 0.0889 - val_acc: 0.9259\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.3244e-04 - acc: 1.0000 - val_loss: 0.0797 - val_acc: 0.9630\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 2.0338e-04 - acc: 1.0000 - val_loss: 0.0889 - val_acc: 0.9259\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 1.8492e-04 - acc: 1.0000 - val_loss: 0.0671 - val_acc: 0.9630\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 2.5358e-04 - acc: 1.0000 - val_loss: 0.0976 - val_acc: 0.9259\n",
      "Epoch 77/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.3477e-04 - acc: 1.0000 - val_loss: 0.0759 - val_acc: 0.9630\n",
      "Epoch 78/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.0553e-04 - acc: 1.0000 - val_loss: 0.0687 - val_acc: 1.0000\n",
      "Epoch 79/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.2462e-04 - acc: 1.0000 - val_loss: 0.0749 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:23:37.503715: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:23:37.721926: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:23:37.730088: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:23:38.624755: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:23:38.631962: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 900ms/step\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2023-12-17 17:23:43.409883: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:23:43.949916: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:23:43.979500: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:23:45.219790: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:23:45.230888: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:23:46.746647: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:23:46.760684: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:23:48.690626: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:23:48.704118: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6065 - acc: 0.2113"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:23:53.794584: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:23:54.044986: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:23:54.052286: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:23:54.929205: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:23:54.936050: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 15s 5s/step - loss: 1.6065 - acc: 0.2113 - val_loss: 1.5946 - val_acc: 0.3333\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5860 - acc: 0.3662 - val_loss: 1.5605 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.5611 - acc: 0.3521 - val_loss: 1.5315 - val_acc: 0.3333\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5109 - acc: 0.3521 - val_loss: 1.4932 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.4807 - acc: 0.3521 - val_loss: 1.5353 - val_acc: 0.3333\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 1s 254ms/step - loss: 1.4561 - acc: 0.3521 - val_loss: 1.4288 - val_acc: 0.3333\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 2s 821ms/step - loss: 1.4125 - acc: 0.3662 - val_loss: 1.3820 - val_acc: 0.3333\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.3638 - acc: 0.3944 - val_loss: 1.3361 - val_acc: 0.3704\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 1s 821ms/step - loss: 1.2854 - acc: 0.4225 - val_loss: 1.2574 - val_acc: 0.4444\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 1s 829ms/step - loss: 1.1883 - acc: 0.4366 - val_loss: 1.0955 - val_acc: 0.5185\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 1s 348ms/step - loss: 1.0107 - acc: 0.6620 - val_loss: 0.9794 - val_acc: 0.6667\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.8666 - acc: 0.8310 - val_loss: 0.8352 - val_acc: 0.7407\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 1s 309ms/step - loss: 0.7071 - acc: 0.8169 - val_loss: 0.7184 - val_acc: 0.7407\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 1s 530ms/step - loss: 0.5770 - acc: 0.8169 - val_loss: 0.5705 - val_acc: 0.8519\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 169ms/step - loss: 0.4672 - acc: 0.8592 - val_loss: 0.5558 - val_acc: 0.8889\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 1s 259ms/step - loss: 0.4778 - acc: 0.8732 - val_loss: 0.8276 - val_acc: 0.7037\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.5624 - acc: 0.7746 - val_loss: 0.4893 - val_acc: 0.7778\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 319ms/step - loss: 0.3586 - acc: 0.8169 - val_loss: 0.3473 - val_acc: 0.9259\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 298ms/step - loss: 0.2608 - acc: 0.9296 - val_loss: 0.3055 - val_acc: 0.9259\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.2396 - acc: 0.9859 - val_loss: 0.2709 - val_acc: 0.8889\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 1s 356ms/step - loss: 0.1926 - acc: 0.9577 - val_loss: 0.2636 - val_acc: 0.8889\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 212ms/step - loss: 0.2239 - acc: 0.9014 - val_loss: 0.2087 - val_acc: 0.9259\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.1665 - acc: 0.9296 - val_loss: 0.1732 - val_acc: 0.9259\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.1313 - acc: 0.9437 - val_loss: 0.1582 - val_acc: 0.9630\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0935 - acc: 0.9718 - val_loss: 0.1494 - val_acc: 1.0000\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.0866 - acc: 0.9718 - val_loss: 0.1190 - val_acc: 0.9630\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 307ms/step - loss: 0.0771 - acc: 0.9859 - val_loss: 0.0916 - val_acc: 1.0000\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 0.0620 - acc: 0.9859 - val_loss: 0.0534 - val_acc: 1.0000\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 200ms/step - loss: 0.0455 - acc: 1.0000 - val_loss: 0.0633 - val_acc: 1.0000\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 0.0304 - acc: 1.0000 - val_loss: 0.0483 - val_acc: 1.0000\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 1s 343ms/step - loss: 0.0212 - acc: 1.0000 - val_loss: 0.0267 - val_acc: 1.0000\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.0230 - val_acc: 1.0000\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0283 - val_acc: 1.0000\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0179 - val_acc: 1.0000\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0250 - val_acc: 1.0000\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0208 - val_acc: 1.0000\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0188 - val_acc: 1.0000\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0152 - val_acc: 1.0000\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0177 - val_acc: 1.0000\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 1.0000\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 5.5609e-04 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 1.0000\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 3.3565e-04 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 1.0000\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 3.1503e-04 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 1.0000\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.7977e-04 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 1.0000\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.8388e-04 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 2.7070e-04 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.9392e-04 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 1.0000\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 2.1077e-04 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 2.6782e-04 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.5138e-04 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.9379e-04 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 1.0000\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 3.5637e-04 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.7565e-04 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 1.0000\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.6038e-04 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.8905e-04 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.8537e-04 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.3280e-04 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 1.0000\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.6163e-04 - acc: 1.0000 - val_loss: 0.0163 - val_acc: 1.0000\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.5562e-04 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.0026e-04 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 1.0000\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.1829e-04 - acc: 1.0000 - val_loss: 0.0137 - val_acc: 1.0000\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 1.5905e-04 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.8973e-04 - acc: 1.0000 - val_loss: 0.0184 - val_acc: 1.0000\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.2933e-04 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 1.0000\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 9.8929e-05 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 1.0000\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 9.9983e-05 - acc: 1.0000 - val_loss: 0.0191 - val_acc: 1.0000\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 9.8938e-05 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 1.0000\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 1.3818e-04 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 1.0000\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 1.3165e-04 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 1.0000\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 9.3009e-05 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 1.0000\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.6463e-04 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 1.0000\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.4382e-04 - acc: 1.0000 - val_loss: 0.0179 - val_acc: 1.0000\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 1.6430e-04 - acc: 1.0000 - val_loss: 0.0150 - val_acc: 1.0000\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 8.3527e-05 - acc: 1.0000 - val_loss: 0.0153 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 17:24:30.836305: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:24:31.023257: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:24:31.030098: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:24:31.904270: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-12-17 17:24:31.911924: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 717ms/step\n",
      "[TULVAE:] Processing time: 1438264.656 milliseconds. Done.\n"
     ]
    }
   ],
   "source": [
    "result = TULVAE(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>acc_top_K5</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.903333</td>\n",
       "      <td>0.949206</td>\n",
       "      <td>0.903333</td>\n",
       "      <td>0.919201</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc  acc_top_K5  balanced_accuracy  precision_macro  recall_macro  \\\n",
       "0  0.933333           0           0.903333         0.949206      0.903333   \n",
       "\n",
       "   f1_macro  loss  \n",
       "0  0.919201  None  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Movelet Based Methods\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matanalysis.methods import TRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###########    DATA PREPARATION      ###########\n",
      "\n",
      "Creating a virtual grid without polygons\n",
      "...cell size by degree: 0.0002706929603721246\n",
      "...grid_size_lat_y:358586\n",
      "...grid_size_lon_x:1221516\n",
      "...A virtual grid was created\n",
      "\n",
      "Creating or updating index of the grid feature..\n",
      "\n",
      "...[1419,1419] indexes were created to lat and lon\n",
      "\n",
      "Creating or updating index of the grid feature..\n",
      "\n",
      "...[664,664] indexes were created to lat and lon\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4c25af65d04d9c8bccf257298289b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute 'time': 704 unique values\n",
      "Attribute 'day': 7 unique values\n",
      "Attribute 'poi': 113 unique values\n",
      "Attribute 'tid': 71 unique values\n",
      "Attribute 'index_grid': 105 unique values\n",
      "Total of attribute/value pairs: 1000\n",
      "\n",
      "\n",
      "###########      DATA ENCODING        ###########\n",
      "Checking sets split count (train, <validation>, test):\n",
      "   TIDs_0: 71\n",
      "   TIDs_1: 27\n",
      "   TIDs_2: 45\n",
      "Encoding string data to integer\n",
      "   Encoding: time\n",
      "   Encoding: day\n",
      "   Encoding: poi\n",
      "   Encoding: index_grid\n",
      "Label encoding on label y\n",
      "\n",
      "[TRF:] Building Random Forrest Model\n",
      "[TRF:] Starting model training, 1080 iterations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b664eada794f4c27b6d5452f439e47f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[TRF:] Model Training:   0%|          | 0/1080 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tarlisportela/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mTRF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workdir/programs/mat-analysis-pkg/matanalysis/methods/trf/randomforrest.py:194\u001b[0m, in \u001b[0;36mTRF\u001b[0;34m(df_train, df_test, res_path, prefix, save_results, n_jobs, random_state, rounds, geohash, geo_precision)\u001b[0m\n\u001b[1;32m    182\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_postfix_str(print_params(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mne, md, mss, msl, mf, bs\u001b[39m\u001b[38;5;124m'\u001b[39m, ne, md, mss, msl, mf, bs))\n\u001b[1;32m    184\u001b[0m RF \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mRFClassifier(n_estimators\u001b[38;5;241m=\u001b[39mne,\n\u001b[1;32m    185\u001b[0m                      max_depth\u001b[38;5;241m=\u001b[39mmd,\n\u001b[1;32m    186\u001b[0m                      max_features\u001b[38;5;241m=\u001b[39mmf,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    191\u001b[0m                      verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    192\u001b[0m                      n_jobs\u001b[38;5;241m=\u001b[39mn_jobs)\n\u001b[0;32m--> 194\u001b[0m \u001b[43mRF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m validation_report, y_pred \u001b[38;5;241m=\u001b[39m RF\u001b[38;5;241m.\u001b[39mpredict(X_val, y_val)\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_results:\n",
      "File \u001b[0;32m~/workdir/programs/mat-analysis-pkg/matanalysis/methods/_lib/pymove/models/classification/RandomForest.py:45\u001b[0m, in \u001b[0;36mRFClassifier.fit\u001b[0;34m(self, X_train, y_train)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m     41\u001b[0m             X_train, \n\u001b[1;32m     42\u001b[0m             y_train):\n\u001b[1;32m     43\u001b[0m         \n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m#        print('Training Random Forest model...\\n')\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:476\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    465\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    468\u001b[0m ]\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 476\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    579\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 581\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TRF(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Ensemble Based Methods\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matanalysis.methods import TEC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEC(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# By Tarlis Portela (2023)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
